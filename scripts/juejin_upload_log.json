{
  "architecture/dual_core_arm_rtthread_smp.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853586442",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "双核 ARM SoC 上跑 RT-Thread SMP: MMU、Cache 与调度实战",
      "brief_content": "将 RT-Thread SMP 移植到 Zynq-7000 双核 Cortex-A9 平台，解决 MMU 页表配置、L1/L2 Cache 一致性、双核调度器初始化三个核心问题。实测表明带宽不是瓶颈，",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/151228053)\n>\n> 参考: [UG585 - Zynq-7000 SoC TRM](https://docs.amd.com/r/en-US/ug585-zynq-7000-SoC-TRM),\n> [ARM Cortex-A9 MPCore TRM](https://documentation-service.arm.com/static/5e7e1f4fb2608e4d7f0a369f)\n\n---\n\n## 1. 设计目标\n\n本文给出 Zynq-7000 (双核 Cortex-A9, 667 MHz) + RT-Thread SMP 的概要设计方案，面向 PL 持续产出数据、PS 实时处理的工业场景（激光雷达点云采集、工业视觉预处理、边缘传感器融合）。\n\n### 1.1 量化目标\n\n| 编号 | 目标 | 量化指标 | 验证方法 |\n|------|------|----------|----------|\n| G-1 | 端到端低延迟 | P50 <= 300 us, P99 <= 500 us | GTC 硬件定时器 + GPIO 示波器 |\n| G-2 | 低抖动 | P99-P50 jitter <= 200 us | 连续 24h 压测统计 |\n| G-3 | 双核负载隔离 | CPU1 实时 <= 60%, CPU0 控制 <= 40% | RT-Thread `top` 周期采样 |\n| G-4 | DMA/Cache 正确性 | 零 CRC 错误，连续 72h 无 coherency 异常 | 端到端 CRC 校验 |\n| G-5 | 故障可恢复 | DMA 错误后 <= 50 ms 恢复至 Ready | 故障注入测试 |\n| G-6 | 热路径零堆分配 | malloc/free 调用 0 次 | 静态分析 + 运行时 hook |\n\n### 1.2 约束条件\n\n| 项目 | 配置 |\n|------|------|\n| 硬件 | Zynq-7020, 双核 Cortex-A9 @ 667 MHz, 512 MB DDR3, 256 KB OCM |\n| RTOS | RT-Thread v5.x, SMP 模式 |\n| PL 时钟 | 150 MHz (AXI DMA 数据通路) |\n| 编译器 | arm-none-eabi-gcc 12.x, `-O2 -fno-exceptions -fno-rtti` |\n\n---\n\n## 2. 总体架构\n\n### 2.1 软硬协同架构\n\n```mermaid\nflowchart LR\n    subgraph PL[\"PL: FPGA (150 MHz)\"]\n        SENSOR[\"传感器接口\\nLVDS/SPI\"] --> PACK[\"数据打包\\n流水线\"]\n        PACK --> DMA[\"AXI DMA\\nSG 模式\"]\n    end\n\n    subgraph DDR[\"DDR3 共享内存\"]\n        RING_A[\"DMA Ring A\\n采集环 64 slots\"]\n        RING_B[\"DMA Ring B\\n结果环 32 slots\"]\n        MBOX[\"Control Mailbox\"]\n        SG_BD[\"SG 描述符池\"]\n    end\n\n    subgraph PS0[\"CPU0: 控制核\"]\n        CTRL[\"ControlTask\\nPrio 60\"]\n        NET[\"NetTask\\nPrio 50\"]\n        LOG[\"LogTask\\nPrio 30\"]\n    end\n\n    subgraph PS1[\"CPU1: 实时核\"]\n        INGEST[\"IngestTask\\nPrio 90\"]\n        PROC[\"ProcessTask\\nPrio 85\"]\n        PUB[\"PublishTask\\nPrio 80\"]\n    end\n\n    DMA -->|\"AXI HP0\"| RING_A\n    DMA -.->|\"BD Fetch\"| SG_BD\n    RING_A --> INGEST\n    INGEST -->|\"SPSC Ring\"| PROC\n    PROC -->|\"SPSC Ring\"| PUB\n    PUB --> RING_B --> NET\n    CTRL <-->|\"Atomic\"| MBOX\n```\n\n### 2.2 核心分工\n\n| 域 | 职责 | 约束 |\n|----|------|------|\n| **PL** | 传感器接口适配、数据打包、AXI DMA 搬运 | 仅做确定性流水线，不含条件逻辑 |\n| **CPU1 (实时核)** | 数据采集 / 处理 / 发布 | 固定亲和，禁止非实时任务迁入 |\n| **CPU0 (控制核)** | 内核调度、中断分发、协议栈、日志 | 承载全部非实时负载 |\n\n### 2.3 数据带宽分析\n\n以激光雷达 30K 点/s、16 B/点为例:\n\n| 环节 | 带宽 | 占 DDR 峰值 (4.26 GB/s) | 裕度 |\n|------|------|:------------------------:|:----:|\n| PL DMA 写入 | 480 KB/s | 0.01% | > 8000x |\n| CPU 读取处理 | 480 KB/s | 0.01% | > 8000x |\n| AXI HP 端口峰值 | 1.2 GB/s | -- | 参考上限 |\n\n> 带宽不是瓶颈。CPU 处理延迟和调度抖动是端到端延迟的主导因素。\n\n---\n\n## 3. 内存分区设计\n\n### 3.1 DDR3 地址映射\n\n| 区域 | 起始地址 | 大小 | MMU 属性 | 用途 |\n|------|----------|------|----------|------|\n| Kernel + App | 0x0010_0000 | 255 MB | Cacheable, WB-WA | RT-Thread 内核、任务栈 |\n| DMA Ring (A+B) | 0x1000_0000 | 1 MB | **Non-cacheable** | DMA 数据环形缓冲 |\n| SG 描述符 | 0x1010_0000 | 1 MB | **Non-cacheable** | AXI DMA SG BD 链 |\n| Mailbox | 0x1020_0000 | 1 MB | Cacheable, Shareable | 核间控制命令 |\n| 遥测缓冲 | 0x1030_0000 | 1 MB | Cacheable | 日志和统计 |\n| 通用 | 0x1040_0000 | ~252 MB | Cacheable, WB-WA | 应用数据 |\n\n### 3.2 DMA 区域选择 Non-cacheable 的设计决策\n\n| 考量 | 分析 |\n|------|------|\n| **复杂度** | Non-cacheable 消除全部 cache 一致性代码，审查零认知负担 |\n| **性能代价** | ~80 ns/access vs ~5 ns (cached)，但单次读 512 B 约 50 us |\n| **可接受性** | 带宽裕度 > 8000x，50 us 的额外延迟在 500 us 预算内可接受 |\n| **演进路径** | 若性能不足，可切换为 Cacheable + 严格 CMO 维护 |\n\n### 3.3 Cache 一致性策略\n\n| 区域 | 属性 | 策略 |\n|------|------|------|\n| DMA Ring / SG BD | Non-cacheable | 无需维护，硬件直接访问 DDR |\n| Mailbox | Cacheable, Shareable | SCU 硬件 snoop 保证双核一致性 |\n| 通用数据 | Cacheable | 各核 L1 独立，SCU 自动维护 |\n| PL 外设寄存器 | Device | 自带序列化 |\n\n**Cache 维护操作** (仅 Cacheable 区域需要):\n\n| 场景 | 操作 | 说明 |\n|------|------|------|\n| CPU 写 -> DMA 读 | Clean + DSB | 将脏数据写回 DDR |\n| DMA 写 -> CPU 读 | Invalidate + DSB | 丢弃 cache 中旧数据 |\n| 双核共享 | SCU 自动 | S 位 = 1 时 SCU snoop |\n\n---\n\n## 4. SMP 调度设计\n\n### 4.1 任务部署矩阵\n\n| 核心 | 任务 | 优先级 | 栈 | 触发方式 | WCET |\n|------|------|:------:|:--:|----------|:----:|\n| CPU1 | IngestTask | 90 | 2 KB | DMA 完成信号量 | 80 us |\n| CPU1 | ProcessTask | 85 | 4 KB | SPSC Ring 非空 | 300 us |\n| CPU1 | PublishTask | 80 | 2 KB | SPSC Ring 非空 | 100 us |\n| CPU1 | WatchdogTask | 95 | 512 B | 周期定时器 | 10 us |\n| CPU0 | ControlTask | 60 | 2 KB | 命令事件 | 500 us |\n| CPU0 | NetTask | 50 | 4 KB | 周期 100 Hz | 2 ms |\n| CPU0 | LogTask | 30 | 2 KB | 周期 10 Hz | 5 ms |\n\n### 4.2 CPU 亲和绑定\n\nRT-Thread SMP 维护两级就绪队列:\n\n| 队列 | 调度范围 | 用途 |\n|------|----------|------|\n| 全局就绪队列 | 可被任意核调度 | 未绑定的任务 |\n| 本地就绪队列 | 仅该核调度 | 绑定到特定 CPU 的任务 |\n\nCPU1 的实时任务通过 `RT_THREAD_CTRL_BIND_CPU` 绑定，保证 L1 Cache 热度和调度隔离。\n\n### 4.3 中断处理: 上半部 / 下半部分离\n\n```mermaid\nsequenceDiagram\n    participant PL as PL AXI DMA\n    participant GIC as GIC\n    participant ISR as DMA ISR\n    participant I as IngestTask\n    participant P as ProcessTask\n    participant U as PublishTask\n\n    PL->>GIC: DMA 完成中断\n    GIC->>ISR: 路由到 CPU1\n    Note over ISR: 上半部 <= 5 us\n    ISR->>I: sem_release\n    I->>I: 读 Ring A + CRC\n    I->>P: SPSC push\n    P->>P: 数据处理\n    P->>U: SPSC push\n    U->>U: 写 Ring B\n```\n\n上半部约束: 仅读状态、清中断、记时间戳、释放信号量。禁止内存分配和阻塞操作。\n\n### 4.4 优先级反转防范\n\n| 措施 | 适用场景 |\n|------|----------|\n| **无锁 SPSC Ring** | 核心数据路径 (Ingest -> Process -> Publish) |\n| 优先级继承互斥量 | Mailbox 读写 |\n| 避免共享 | 各任务独立缓冲区，通过 Ring 传递所有权 |\n\n---\n\n## 5. 数据通道设计\n\n### 5.1 环形缓冲结构\n\n```mermaid\nflowchart LR\n    subgraph RING[\"Ring Buffer (Non-cacheable)\"]\n        HEAD[\"head (生产者写)\"]\n        SLOTS[\"slot 0 ... slot 63\"]\n        TAIL[\"tail (消费者写)\"]\n    end\n\n    DMA[\"AXI DMA\"] -->|\"写 slot\"| RING\n    RING -->|\"读 slot\"| CPU[\"IngestTask\"]\n```\n\n**单 slot 结构** (544 B, cache line 对齐):\n\n| 字段 | 大小 | 说明 |\n|------|------|------|\n| seq | 4 B | 单调递增序列号 |\n| timestamp_ns | 8 B | GTC 硬件时间戳 |\n| len + crc16 | 4 B | 长度 + CRC-CCITT |\n| payload | 512 B | 数据载荷 (32 点 x 16 B) |\n| padding | 16 B | 对齐到 cache line |\n\n**内存占用**: Ring A (64 slots) ~34 KB + Ring B (32 slots) ~17 KB = ~51 KB\n\n### 5.2 SPSC Ring 正确性保证\n\n| 属性 | 机制 |\n|------|------|\n| 无 ABA | 单生产者单消费者，无 CAS |\n| 无撕裂 | uint32_t 对齐，ARM 原子 LDR/STR |\n| 内存序 | DMB 保证数据/索引写入顺序 |\n| 无 false sharing | head/tail 间 32B padding |\n\n### 5.3 背压状态机\n\n```mermaid\nstateDiagram-v2\n    [*] --> Normal\n    Normal --> Warning: ring >= 75%\n    Warning --> Normal: ring < 50%\n    Warning --> Backpressure: ring >= 90%\n    Backpressure --> Overflow: 连续丢帧 > 100\n    Overflow --> Degraded: 持续异常\n    Degraded --> Normal: 手动恢复\n```\n\n| 状态 | 动作 |\n|------|------|\n| Normal | 正常运行 |\n| Warning | 记录日志 |\n| Backpressure | 通知 PL 降频 |\n| Overflow | 暂停 DMA，清空 Ring |\n\n---\n\n## 6. 运行状态机\n\n```mermaid\nstateDiagram-v2\n    [*] --> Init\n    Init --> Ready: 初始化完成\n\n    Ready --> Active: CMD_START\n    Active --> Degraded: 过载\n    Active --> Fault: DMA错误 / 看门狗超时\n\n    Degraded --> Active: 负载恢复\n    Degraded --> Fault: 二次超时\n\n    Fault --> Ready: 恢复成功\n    Fault --> Shutdown: 重试耗尽\n    Shutdown --> [*]\n```\n\n| 转换 | 守卫条件 | 进入动作 |\n|------|----------|----------|\n| Ready -> Active | 自检通过 + DMA 正常 | 启动 DMA, 使能中断 |\n| Active -> Fault | DMA Error 或 CRC 连续失败 | 停止 DMA, 保存诊断 |\n| Fault -> Ready | retry < 3 | 复位 DMA, 重建 BD 链, retry++ |\n\n---\n\n## 7. DMA 子系统设计\n\n### 7.1 选型\n\n| 选项 | 方案 | 理由 |\n|------|------|------|\n| DMA IP | PL AXI DMA (SG) | BD 链自动遍历，不消耗 CPU |\n| 传输端口 | AXI HP0 (64-bit, 150 MHz, 1.2 GB/s) | 高带宽，Non-cacheable |\n| 不使用 ACP | -- | snoop 流量干扰 CPU cache |\n\n### 7.2 描述符链\n\nSG BD 为 64B 结构体，环形链接。BD 池位于 DDR_SG_DESC 区域 (Non-cacheable, 64B 对齐)。\n\n| BD 字段 | 说明 |\n|---------|------|\n| next_desc | 下一个 BD 地址 (环形) |\n| buf_addr | 指向 Ring slot payload |\n| control | 传输长度 |\n| status | 完成状态 + 错误标志 (硬件填写) |\n\n---\n\n## 8. 核间通信设计\n\n| 通信类型 | 机制 | 内存属性 | 延迟 |\n|----------|------|----------|:----:|\n| PL -> CPU1 数据 | DMA Ring + 中断 | Non-cacheable | 15-80 us |\n| 任务间数据 | SPSC Ring (无锁) | Non-cacheable | 50-100 ns |\n| CPU0 <-> CPU1 控制 | Mailbox + flag | Cacheable, Shareable | 100-500 ns |\n\n**Mailbox 协议**: 发送方写数据 -> DMB -> 写 flag=1 -> DSB; 接收方检查 flag -> DMB -> 读数据 -> 写 flag=0。\n\n**内存屏障规则**:\n- 写数据后、写标志前: DMB\n- 读标志后、读数据前: DMB\n- DMA 操作前后: DSB\n- 中断清除后: DSB\n\n---\n\n## 9. 时延预算\n\n### 9.1 单帧端到端\n\n| 阶段 | WCET | 典型值 |\n|------|:----:|:------:|\n| DMA 传输 | 10 us | 2-5 us |\n| 中断响应 | 15 us | 5-10 us |\n| IngestTask | 80 us | 40-60 us |\n| ProcessTask | 300 us | 100-250 us |\n| PublishTask | 100 us | 30-80 us |\n| **合计** | **505 us** | **177-405 us** |\n\n### 9.2 抖动来源\n\n| 来源 | 范围 | 缓解 |\n|------|:----:|------|\n| GIC 仲裁 | 2-5 us | CPU1 仅实时任务 |\n| 调度延迟 | 3-10 us | CPU1 仅 3 个任务 |\n| DDR 刷新 | 10-30 us | 实时端口优先 |\n| 算法分支 | 50-150 us | 固定路径 |\n\n### 9.3 热降额\n\n| 温度 | P99 预计 | 达标 |\n|:----:|:--------:|:----:|\n| 25 C | 500 us | 是 |\n| 55 C | 520 us | 是 |\n| 85 C | 560 us | 是 |\n| 85 C + 高负载 | 700 us | 需验证 |\n\n---\n\n## 10. 实施里程碑\n\n| 里程碑 | 关键交付 | 验收标准 |\n|--------|----------|----------|\n| M1: 最小链路 | MMU + DMA + Ring A | 10K 帧 CRC 零错误 |\n| M2: 实时闭环 | 绑核 + SPSC 流水线 | P50 <= 300 us, P99 <= 500 us |\n| M3: 鲁棒性 | HSM + 看门狗 + 故障恢复 | 72h 零崩溃 |\n| M4: 交付验证 | 延迟报告 + 热降额 | 100 万帧统计 |\n\n---\n\n## 11. 总结\n\n核心设计决策:\n\n1. **Non-cacheable DMA Ring**: 用 8000x 带宽裕度换取零 cache 一致性代码\n2. **双核职责固定 + 无锁 SPSC Ring**: 所有权传递消除优先级反转\n3. **HSM 全生命周期**: Init/Ready/Active/Degraded/Fault 覆盖故障恢复\n4. **量化驱动**: 每项决策追溯到 G-1 ~ G-6 指标\n\n---\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/151228053)\n",
      "ctime": "1771552441",
      "mtime": "1771552441",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/embedded_ab_firmware_upgrade_engine.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267144742",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 A/B 分区固件升级引擎: HSM 状态机 + 三层掉电保护",
      "brief_content": "面向 4 核 ARM-Linux (32-256MB RAM) 的工业级固件升级引擎设计与实现。以 osp::StateMachine 驱动 8 状态升级流程，通过 raw 分区状态持久化 + U-B",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 配套代码: [liudegui/osp-upgrade-engine](https://gitee.com/liudegui/osp-upgrade-engine) -- C++17 header-only 固件升级引擎\n>\n> 依赖库: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) -- header-only 嵌入式基础设施 (HSM, Bus, Watchdog, Process)\n>\n> 相关文章:\n> - [C 语言层次状态机框架: 从过程驱动到数据驱动的重构实践](../c_hsm_data_driven_framework/) -- HSM 转换表设计与 LCA 算法\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- AsyncBus/HSM/SPSC 核心实现\n\n## 1. 问题与方案选择\n\n工业嵌入式设备 (激光雷达、机器人、边缘计算) 的固件升级有三个硬约束: **掉电安全** (现场无人值守，任意时刻断电不能变砖)、**资源受限** (32-256MB RAM，不能跑 D-Bus + systemd)、**可验证** (升级后必须自检确认，失败自动回滚)。\n\n传统 Linux OTA 方案 (SWUpdate、RAUC) 面向通用 Linux 发行版，依赖链较重:\n\n| 维度 | SWUpdate / RAUC | osp-upgrade-engine |\n|------|-----------------|-------------------|\n| 运行时依赖 | D-Bus + systemd + GLib + libcurl | newosp header-only (零外部依赖) |\n| 内存占用 | ~10-50 MB | < 73 KB (含 4KB 写缓冲) |\n| 进程模型 | 独立 daemon | 嵌入应用进程 (SpinOnce 轮询) |\n| 状态机实现 | Lua 脚本 / 配置文件 | C++ 编译期 HSM (类型安全) |\n| 掉电保护 | SWUpdate: update_state 文件 | raw 分区 + U-Boot 冗余 env + bootcount |\n| 适用场景 | Yocto / Buildroot 完整发行版 | 资源受限嵌入式 (32-256MB RAM) |\n\nosp-upgrade-engine 不替代 SWUpdate 的全部功能 (Lua 脚本灵活性、HTTP 多源下载、加密分区)。它面向的是 SWUpdate 依赖链不可用或过重的场景。\n\n### 核心设计选择\n\n- **HSM 驱动**: 复用 `osp::StateMachine` 管理 8 阶段升级流程，每次状态转换前持久化到 raw 分区\n- **函数指针表 HAL**: 不用 virtual，函数指针 + void* ctx 实现硬件抽象，零间接调用开销\n- **三层掉电保护**: raw 分区状态持久化 + U-Boot 冗余 env 原子切换 + bootcount 超限自动回滚\n- **零堆分配**: PackageHeader 128B 栈解析，SHA-256 流式计算，PartitionWriter 4KB 栈缓冲\n\n## 2. 架构设计\n\n### 2.1 存储布局 (典型 8GB eMMC)\n\n```\n+------------------+----------+----------+-------------------------------+\n| 分区             | 设备节点  | 大小     | 用途                          |\n+------------------+----------+----------+-------------------------------+\n| bootloader       | mmcblk0p1| 2 MB     | U-Boot SPL + U-Boot           |\n| env              | mmcblk0p2| 128 KB   | U-Boot 环境变量 (冗余双副本)  |\n| recovery         | mmcblk0p3| 32 MB    | 最小 recovery 系统            |\n| rootfs_a         | mmcblk0p4| 1 GB     | 主系统 A (kernel + rootfs)    |\n| rootfs_b         | mmcblk0p5| 1 GB     | 主系统 B (kernel + rootfs)    |\n| config           | mmcblk0p6| 64 MB    | 持久化配置 (不随升级擦除)     |\n| data             | mmcblk0p7| 剩余     | 用户数据 + 升级包暂存         |\n| upgrade_state    | mmcblk0p8| 64 KB    | 升级状态持久化 (raw, 无 FS)   |\n+------------------+----------+----------+-------------------------------+\n```\n\nA/B 分区交替使用: 当前活跃分区运行系统，非活跃分区接收新固件。升级完成后通过 U-Boot env **原子切换**启动槽位。upgrade_state 是独立 raw 分区，不挂载文件系统，升级引擎直接 `pwrite/pread/fsync`，避免文件系统日志开销。\n\n### 2.2 组件关系\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│                     应用层 (激光雷达主程序)                       │\n│  调用 StartUpgrade() / ConfirmBoot() / SpinOnce()               │\n└────────────────────────────┬────────────────────────────────────┘\n                             │\n┌────────────────────────────▼────────────────────────────────────┐\n│                     UpgradeEngine (门面)                          │\n│  ┌──────────────┐  ┌──────────────┐  ┌───────────────────────┐  │\n│  │ UpgradeHSM   │  │ PackageHeader│  │  PartitionWriter      │  │\n│  │ (8 states,   │  │ (128B 解析,  │  │  (write+fsync+readback│  │\n│  │  LCA 转换)   │  │  CRC-32)     │  │   SHA-256 校验)       │  │\n│  └──────────────┘  └──────────────┘  └───────────────────────┘  │\n│  ┌──────────────┐  ┌──────────────┐  ┌───────────────────────┐  │\n│  │ BootEnvMgr   │  │ StatePersist │  │  PackageSigner        │  │\n│  │ (U-Boot env  │  │ (raw 分区    │  │  (Ed25519 + SHA-256,  │  │\n│  │  读写)       │  │  64B 记录)   │  │   mbedtls PSA API)    │  │\n│  └──────────────┘  └──────────────┘  └───────────────────────┘  │\n└──────────────────────────┬──────────────────────────────────────┘\n                           │ UpgradeHAL (函数指针表)\n         ┌─────────────────┼─────────────────┐\n         │                 │                  │\n  ┌──────▼──────┐  ┌───────▼──────┐  ┌───────▼───────┐\n  │ PosixHAL    │  │ SimPartition │  │  SimBootEnv   │\n  │ (生产环境)  │  │ (x86 仿真)   │  │  (x86 仿真)   │\n  └─────────────┘  └──────────────┘  └───────────────┘\n```\n\nUpgradeEngine 不创建额外线程。`SpinOnce()` 在调用者线程中执行 (主循环或 Executor)，每次处理一个 4KB chunk，不阻塞。\n\n## 3. HSM 状态机设计\n\n### 3.1 状态转换图\n\n```mermaid\nstateDiagram-v2\n    [*] --> Idle\n    Idle --> Verifying : EvStartUpgrade [头校验 + 版本兼容]\n    Verifying --> Writing : SHA-256 + Ed25519 通过\n    Verifying --> Idle : 校验失败 / 取消\n    Writing --> Switching : 写入完成 + 读回校验通过\n    Writing --> Idle : 写入失败 / 取消\n    Switching --> Rebooting : env 切换完成\n    Rebooting --> BootVerify : 重启后恢复\n    BootVerify --> Idle : 自检通过 (ConfirmBoot)\n    BootVerify --> Rollback : 自检失败 / Watchdog 超时\n    Rollback --> Idle : 回滚完成\n```\n\n8 个状态均为扁平结构 (parent_index = -1)，不使用层级嵌套。升级引擎的状态转换是严格线性的 (不存在从 Writing 跳到 BootVerify 的场景)，层级在此场景下增加复杂度但不带来收益。\n\n### 3.2 HSM Context\n\n所有状态 handler 共享一个 `UpgradeContext` 结构体，替代全局变量:\n\n```cpp\nstruct UpgradeContext {\n  UpgradeHAL* hal;                    // 硬件抽象层\n  PackageHeader header;               // 128B 包头 (栈)\n  uint8_t active_slot;                // 当前活跃分区 (0=A, 1=B)\n  uint8_t target_slot;                // 升级目标分区\n  uint32_t current_version;           // 当前固件版本\n  uint32_t local_hw_id;               // 本机 board_id (0-31)\n  const uint8_t* pub_key;             // Ed25519 公钥 (32B)\n\n  char pkg_path[256];                 // 升级包路径\n  int32_t pkg_fd;                     // 包文件描述符\n  uint64_t bytes_written;             // 写入进度\n  uint64_t total_size;                // payload 总大小\n\n  Sha256Calculator sha_calc;          // SHA-256 流式计算 (mbedtls)\n  uint8_t computed_digest[32];        // 计算结果\n\n  PartitionWriter* pw_ptr;            // 分区写入器 (引擎持有)\n  int32_t state_fd;                   // 状态分区 fd\n  UpgradeError last_error;            // 最近错误码\n  void* sm_ptr;                       // StateMachine 指针 (handler 内转换)\n\n  int32_t idx_idle, idx_verifying, idx_writing, idx_switching;\n  int32_t idx_rebooting, idx_boot_verify, idx_rollback;\n};\n\nusing UpgradeHSM = osp::StateMachine<UpgradeContext, 8>;\n```\n\n### 3.3 状态注册\n\n`osp::StateMachine` 使用声明式 API 注册状态，handler/entry/exit 均为静态函数指针:\n\n```cpp\nvoid SetupUpgradeHSM(UpgradeHSM& sm, UpgradeContext& ctx) noexcept {\n  ctx.idx_idle = sm.AddState({\n      \"Idle\", UpgradeHSM::kNoState,       // name, parent\n      detail::IdleHandler,                 // handler\n      detail::IdleEntry, nullptr, nullptr  // entry, exit, guard\n  });\n\n  ctx.idx_verifying = sm.AddState({\n      \"Verifying\", UpgradeHSM::kNoState,\n      detail::VerifyingHandler,\n      detail::VerifyingEntry, nullptr, nullptr\n  });\n\n  ctx.idx_writing = sm.AddState({\n      \"Writing\", UpgradeHSM::kNoState,\n      detail::WritingHandler,\n      detail::WritingEntry, detail::WritingExit, nullptr\n  });\n\n  // ... Switching, Rebooting, BootVerify, Rollback 省略\n\n  sm.SetInitialState(ctx.idx_idle);\n}\n```\n\n### 3.4 SpinOnce 驱动模式\n\n传统状态机用事件触发转换。固件升级的 Verifying 和 Writing 状态需要处理大量数据 (数百 MB)，不能在一个 handler 调用中完成。升级引擎引入 `kEvStepProcess` 事件，每次 SpinOnce 驱动处理一个 4KB chunk:\n\n```cpp\nvoid SpinOnce() noexcept {\n    osp::Event ev{kEvStepProcess, nullptr};\n    sm_.Dispatch(ev);\n    SetupPartitionWriterIfNeeded();\n}\n```\n\nWriting handler 示例 -- 每次调用读取 4KB、写入分区、更新进度:\n\n```cpp\nTransitionResult WritingHandler(UpgradeContext& ctx,\n                                const Event& event) noexcept {\n    if (event.id == kEvStepProcess) {\n        if (ctx.bytes_written >= ctx.total_size) {\n            // 写入完成: fsync + 读回 SHA-256 校验\n            ctx.pw_ptr->Fsync();\n            auto rb = ctx.pw_ptr->VerifyReadback(\n                ctx.header.payload_sha256, ctx.total_size);\n            if (!rb) return FailToIdle(ctx, UpgradeError::kReadbackFail);\n            return GetSM(ctx)->RequestTransition(ctx.idx_switching);\n        }\n\n        // 读取下一个 4KB chunk\n        uint8_t chunk[4096];\n        ssize_t n = ::read(ctx.pkg_fd, chunk, sizeof(chunk));\n        if (n <= 0) return FailToIdle(ctx, UpgradeError::kWriteFail);\n\n        // 写入目标分区\n        ctx.pw_ptr->WriteChunk(chunk, static_cast<uint32_t>(n));\n        ctx.bytes_written += static_cast<uint64_t>(n);\n\n        // 每 1MB 持久化一次进度\n        if (ctx.bytes_since_last_persist >= 1048576U) {\n            PersistCurrentState(ctx, StateIdx::kStateWriting);\n            ctx.bytes_since_last_persist = 0;\n        }\n        return TransitionResult::kHandled;\n    }\n    return TransitionResult::kUnhandled;\n}\n```\n\n每次 SpinOnce 只处理 4KB，主循环可以在 SpinOnce 间隙处理其他任务 (传感器数据采集、网络通信)，不会因为大文件写入阻塞整个系统。\n\n## 4. 掉电安全: 三层保护\n\n### 4.1 第一层: raw 分区状态持久化\n\n每次 HSM 状态转换前，先将 `UpgradeStateRecord` (64B) 写入 raw 分区:\n\n```cpp\nstruct UpgradeStateRecord {  // 64 bytes, packed\n    uint32_t magic;              // 0x55AA55AA\n    uint8_t  state;              // StateIdx 枚举值\n    uint8_t  active_slot;        // 当前活跃分区 (0=A, 1=B)\n    uint8_t  target_slot;        // 目标分区\n    uint8_t  retry_count;        // 剩余重试次数\n    uint32_t fw_version;         // 目标版本\n    uint64_t bytes_written;      // 写入进度 (断点)\n    uint64_t total_size;         // payload 总大小\n    uint8_t  payload_sha256[32]; // 期望的 SHA-256\n    uint32_t crc32;              // 前 60 字节的 CRC-32\n};\n```\n\n持久化协议: 构造记录 -> 计算 CRC-32 -> `pwrite(fd, &rec, 64, 0)` -> `fsync(fd)` -> 执行状态转换。\n\n系统启动时，`RecoverFromPersistentState()` 读取 raw 分区，根据持久化的状态决定恢复策略:\n\n```cpp\nvoid RecoverFromPersistentState() noexcept {\n    StatePersister persist(ctx_.state_fd);\n    auto res = persist.LoadState();\n    if (!res) return;  // magic/CRC 无效 -> 无升级进行\n\n    StateIdx persisted = static_cast<StateIdx>(res.value().state);\n    switch (persisted) {\n        case StateIdx::kStateWriting:\n            // 写入中断: 活跃分区未动，清除状态，留在 Idle\n            persist.ClearState();\n            break;\n        case StateIdx::kStateSwitching:\n        case StateIdx::kStateBooting:\n            // env 可能已切换: ForceTransition 到 BootVerify\n            sm_.ForceTransition(ctx_.idx_boot_verify);\n            break;\n        case StateIdx::kStateRollback:\n            // 回滚中断: 继续回滚\n            sm_.ForceTransition(ctx_.idx_rollback);\n            break;\n        default:\n            persist.ClearState();\n            break;\n    }\n}\n```\n\n`ForceTransition()` 是 newosp HSM 新增的 API，允许从外部 (非 handler 内部) 直接转换状态，执行标准 LCA 退出/进入路径。这避免了用\"恢复事件\"模拟状态跳转的 workaround。\n\n### 4.2 第二层: U-Boot 冗余 env 原子切换\n\nU-Boot 原生支持冗余 env (两个副本交替写入)，单条 `fw_setenv` 的原子性由 U-Boot 保证。升级引擎的 Switching 阶段执行三条 env 操作:\n\n```bash\nfw_setenv boot_slot_next b        # 下次启动槽位\nfw_setenv upgrade_available 1     # 标记有待验证的新固件\nfw_setenv bootcount 0             # 重置启动计数\n```\n\n即使在这三条命令之间掉电，U-Boot 启动脚本也能正确处理: env 未切换则继续从旧分区启动，env 已切换则进入 BootVerify 流程。\n\n### 4.3 第三层: bootcount 自动回滚\n\nU-Boot 启动脚本在每次启动时递增 bootcount，超过 bootlimit (默认 3) 则自动回滚:\n\n```bash\n# boot.scr -- U-Boot 启动逻辑\nif test \"${upgrade_available}\" = \"1\"; then\n    setexpr bootcount ${bootcount} + 1\n    saveenv\n    if test ${bootcount} -gt ${bootlimit}; then\n        echo \"Boot limit exceeded, rolling back...\"\n        # 切回原始分区\n        setenv upgrade_available 0\n        setenv bootcount 0\n        saveenv\n    else\n        setenv boot_slot ${boot_slot_next}\n    fi\nfi\n```\n\n新固件启动后，应用层调用 `engine.ConfirmBoot()` 清除 upgrade_available 和 bootcount，确认升级成功。如果新固件反复崩溃 (无法调用 ConfirmBoot)，3 次重启后 U-Boot 自动回滚到旧分区。\n\n### 4.4 掉电安全时序\n\n```\n写入非活跃分区 (当前 A 活跃, 写入 B):\n\n[安全点 1] PersistState(Writing, progress=0)\n    │\n    for each 4KB chunk:\n        write(partition_b_fd, chunk, 4096)\n        if (written % 1MB == 0):\n            [安全点 2] fsync + PersistState(Writing, progress)\n    │\n    [安全点 3] 最终 fsync + 读回 SHA-256 全量校验\n    │\n    [安全点 4] PersistState(Switching) + fw_setenv   ← 原子切换点\n    │\n    [安全点 5] PersistState(Rebooting) + reboot\n```\n\n安全点 1-3 之间掉电: 分区 A 未被修改，系统正常启动，重新开始升级。安全点 4 是原子切换点，之后掉电进入 BootVerify 流程。\n\n## 5. 升级包格式\n\n### 5.1 128 字节二进制包头\n\n```\nOffset  Size  Field\n0       4     magic[4]          \"OSP\\x01\"\n4       1     header_ver        头格式版本 (当前 = 1)\n5       1     pkg_type          0=全量, 1=差分, 2=Bootloader\n6       2     reserved_0\n8       4     hw_compat_mask    兼容硬件 bitmask (最多 32 种板型)\n12      4     fw_version        major<<24 | minor<<16 | patch\n16      4     min_version       差分升级基准版本\n20      8     payload_size      payload 字节数\n28      32    payload_sha256    payload 的 SHA-256\n60      2     signature_len     签名长度 (Ed25519 = 64)\n62      62    reserved_1        预留扩展 (压缩类型、时间戳等)\n124     4     header_crc32      前 124 字节的 CRC-32\n```\n\n设计要点:\n\n- **二进制而非 JSON**: 读取 128 字节后立即校验 (magic + CRC-32 + 版本兼容)，无解析器，无堆分配\n- **hw_compat_mask**: bitmask 替代数组，`(mask & (1u << local_hw_id))` 一次位运算完成兼容检查\n- **fw_version 编码**: `(major << 24) | (minor << 16) | patch`，直接用 `>` 比较，无需字符串解析\n\n```cpp\nstatic_assert(sizeof(PackageHeader) == 128, \"PackageHeader must be 128 bytes\");\n\nconstexpr uint32_t MakeVersion(uint8_t major, uint8_t minor, uint16_t patch) {\n    return (uint32_t(major) << 24) | (uint32_t(minor) << 16) | uint32_t(patch);\n}\n```\n\n### 5.2 三层校验\n\n| 层 | 算法 | 覆盖范围 | 用途 |\n|------|------|---------|------|\n| 1. 快速校验 | CRC-32 | 包头 124 字节 | 即时拒绝损坏/错误文件 |\n| 2. 完整性 | SHA-256 | 整个 payload | 抗碰撞，确保写入数据完整 |\n| 3. 身份认证 | Ed25519 | payload hash | 验证来源，防止篡改 |\n\nEd25519 签名仅 64 字节 (RSA-2048 为 256 字节)，验证速度在 ARM Cortex-A 上约 0.2ms。密码学操作封装了 mbedtls PSA Crypto API，运行时检测平台支持情况，不支持 Ed25519 时回退到 HMAC-SHA256 演示模式。\n\n## 6. 函数指针表 HAL\n\n不使用 virtual 基类 (遵循项目规范: 优先编译期分发)。UpgradeHAL 是一个纯 C 风格的函数指针表:\n\n```cpp\nstruct UpgradeHAL {\n    // 分区操作\n    int32_t (*open_partition)(const char* dev, int32_t flags, void* ctx);\n    ssize_t (*write_partition)(int32_t fd, const void* buf, uint32_t size, void* ctx);\n    ssize_t (*read_partition)(int32_t fd, void* buf, uint32_t size, void* ctx);\n    int32_t (*fsync_partition)(int32_t fd, void* ctx);\n    int32_t (*close_partition)(int32_t fd, void* ctx);\n\n    // Boot 环境变量\n    bool (*get_env)(const char* key, char* val, uint32_t size, void* ctx);\n    bool (*set_env)(const char* key, const char* value, void* ctx);\n\n    // 系统控制\n    void (*reboot_system)(void* ctx);\n\n    // 不透明上下文 (替代 this 指针)\n    void* ctx;\n};\n```\n\n生产环境和仿真环境只需替换函数指针:\n\n```cpp\n// 生产环境: POSIX 系统调用\nUpgradeHAL MakePosixHAL() {\n    return {PosixOpen, PosixWrite, PosixRead, PosixFsync, PosixClose,\n            PosixGetEnv, PosixSetEnv, PosixReboot, nullptr};\n}\n\n// 仿真环境: 文件模拟分区\nUpgradeHAL MakeSimHAL(SimContext* sim) {\n    return {SimOpen, SimWrite, SimRead, SimFsync, SimClose,\n            SimGetEnv, SimSetEnv, SimReboot, sim};\n}\n```\n\n与 virtual 基类对比:\n\n| 维度 | virtual 基类 | 函数指针表 |\n|------|-------------|-----------|\n| 内存布局 | vtable 指针 (8B) + 对象头 | 函数指针数组 (连续，缓存友好) |\n| 间接调用 | 通过 vtable 两次间接寻址 | 一次函数指针调用 |\n| 编译器限制 | 需要 RTTI (`-fno-rtti` 下受限) | 纯 C ABI，无 C++ 运行时依赖 |\n| 组合方式 | 继承体系 | 按需替换单个函数指针 |\n| 二进制大小 | typeinfo + vtable 额外开销 | 零额外开销 |\n\n## 7. x86 仿真层\n\n升级引擎在 x86 Linux 上可完整运行 (包括打包、升级、掉电模拟、回滚)，通过仿真层替换硬件依赖:\n\n| 组件 | 真实环境 | 仿真环境 |\n|------|---------|---------|\n| 分区 | `/dev/mmcblk0pN` | 固定大小文件 (1MB) |\n| U-Boot env | `fw_setenv` / `fw_printenv` | INI 格式文本文件 |\n| reboot | `reboot(2)` | 设置标志位，不重启进程 |\n| Watchdog | 硬件 WDT | 软件定时器 + 回调 |\n\n仿真分区的核心实现 -- 文件模拟 eMMC 块设备:\n\n```cpp\nstruct SimPartition {\n    char path[256];      // 底层文件路径\n    uint64_t size;       // 分区大小\n    bool inject_fault;   // 注入写入失败 (掉电模拟)\n};\n\nssize_t SimWritePartition(int32_t fd, const void* buf,\n                          uint32_t size, void* ctx) {\n    auto* sim = static_cast<SimContext*>(ctx);\n    if (sim->partitions[fd].inject_fault) {\n        return -1;  // 模拟掉电导致的写入失败\n    }\n    return ::write(fd, buf, size);\n}\n```\n\n仿真 Boot env -- 用文本文件替代 U-Boot 环境变量:\n\n```cpp\nbool SimGetEnv(const char* key, char* val, uint32_t size, void* ctx) {\n    auto* sim = static_cast<SimContext*>(ctx);\n    // 从 sim->env_file 中读取 key=value 对\n    // ...\n}\n\nbool SimSetEnv(const char* key, const char* value, void* ctx) {\n    auto* sim = static_cast<SimContext*>(ctx);\n    // 写入 key=value 到 sim->env_file\n    // ...\n}\n```\n\n## 8. UpgradeEngine 门面 API\n\nUpgradeEngine 将所有子组件封装为三个核心 API:\n\n```cpp\nclass UpgradeEngine {\npublic:\n    UpgradeEngine(UpgradeHAL* hal, uint32_t current_version,\n                  uint32_t local_hw_id, const uint8_t* pub_key,\n                  const char* state_dev_path) noexcept;\n\n    // 升级控制\n    Expected<void, UpgradeError> StartUpgrade(const char* pkg_path) noexcept;\n    void CancelUpgrade() noexcept;\n    Expected<void, UpgradeError> ConfirmBoot() noexcept;\n\n    // 轮询驱动 (主循环调用)\n    void SpinOnce() noexcept;\n\n    // 状态查询\n    const char* GetStateName() const noexcept;\n    uint8_t GetProgress() const noexcept;  // 0-100%\n    bool IsIdle() const noexcept;\n    UpgradeError GetLastError() const noexcept;\n\n    // 掉电恢复 (启动时调用)\n    void RecoverFromPersistentState() noexcept;\n};\n```\n\n应用层集成示例:\n\n```cpp\nint main() {\n    UpgradeHAL hal = MakePosixHAL();\n    static const uint8_t kPubKey[32] = { /* Ed25519 公钥 */ };\n\n    UpgradeEngine engine(&hal, MakeVersion(1,0,0), 3, kPubKey, \"/dev/mtd5\");\n\n    // 启动时检查掉电恢复\n    engine.RecoverFromPersistentState();\n\n    // 如果处于 BootVerify，执行自检\n    if (!engine.IsIdle() &&\n        strcmp(engine.GetStateName(), \"BootVerify\") == 0) {\n        if (RunSelfTest()) {\n            engine.ConfirmBoot();\n        } else {\n            engine.ReportBootVerifyFail();\n        }\n    }\n\n    // 触发升级\n    engine.StartUpgrade(\"/mnt/usb/fw_v2.2.0.osp\");\n\n    // 主循环\n    while (!engine.IsIdle()) {\n        engine.SpinOnce();\n        RunLidarPipeline();  // 间隙处理其他任务\n    }\n\n    if (engine.GetLastError() != UpgradeError::kOk) {\n        // 处理升级错误\n    }\n}\n```\n\n## 9. 资源预算\n\n### 9.1 内存占用\n\n| 组件 | 栈/静态 | 堆 | 说明 |\n|------|---------|-----|------|\n| UpgradeHSM (8 states) | ~256 B | 0 | StateConfig 数组编译期固定 |\n| UpgradeContext | ~520 B | 0 | 含路径缓冲和 SHA-256 上下文 |\n| PackageHeader | 128 B | 0 | 栈变量 |\n| UpgradeStateRecord | 64 B | 0 | 栈变量 |\n| 写缓冲 | 4 KB | 0 | WritingHandler 栈分配 |\n| 读回校验缓冲 | 4 KB | 0 | PartitionWriter 栈分配 |\n| CRC-32 查找表 | 1 KB | 0 | constexpr 编译期生成 |\n| SHA-256 上下文 | ~128 B | 0 | mbedtls 嵌入 Context |\n| **合计** | **~10 KB** | **0** | **热路径零堆分配** |\n\n### 9.2 I/O 开销\n\n| 操作 | 频率 | 数据量 |\n|------|------|--------|\n| 状态持久化 | 每次状态转换 (~8 次) + 每 1MB | 64B + fsync |\n| 分区写入 | 持续 | 4KB/次 |\n| 读回校验 | 一次 | 全量顺序读 |\n| fw_setenv | 3 次 | 128KB env 分区 |\n\n## 10. 演示输出\n\nx86 仿真环境下的完整升级流程 (1MB 测试固件):\n\n```\n=== osp-upgrade-engine full upgrade demo ===\n[SIM] Created partition files: slot0.bin, slot1.bin (1048576 bytes each)\n[SIM] Initialized boot env: active_slot=a, bootcount=0\n\n--- Step 1: Package creation ---\n[PACK] Generating 1048576 bytes random firmware payload\n[PACK] SHA-256: a3f2b8c1... (computed over payload)\n[PACK] Ed25519 signature: 64 bytes (HMAC-SHA256 demo mode)\n[PACK] Written upgrade package: /tmp/test_fw.osp (1048768 bytes)\n\n--- Step 2: Start upgrade ---\n[HSM] Idle -> Verifying (EvStartUpgrade)\n  Header: magic=OSP01, ver=1, type=Full, hw_mask=0x0F\n  Version: 1.0.0 -> 2.0.0, payload=1048576 bytes\n\n--- Step 3: Verification ---\n[HSM] Verifying: SHA-256 streaming... 256 chunks\n[HSM] Verifying: SHA-256 match OK\n[HSM] Verifying: Ed25519 signature OK (demo mode)\n[HSM] Verifying -> Writing\n\n--- Step 4: Writing ---\n[HSM] Writing: 0/1048576 (0%)\n[HSM] Writing: 1048576/1048576 (100%) - fsync\n[HSM] Writing: readback SHA-256 verify OK\n[HSM] Writing -> Switching\n\n--- Step 5: Slot switch ---\n[SIM] fw_setenv boot_slot_next=b\n[SIM] fw_setenv upgrade_available=1\n[SIM] fw_setenv bootcount=0\n[HSM] Switching -> Rebooting\n\n--- Step 6: Simulated reboot ---\n[SIM] Reboot requested (flag set, not actually rebooting)\n\n--- Step 7: Post-reboot recovery ---\n[RECOVER] Persistent state: Booting, target_slot=1\n[HSM] ForceTransition -> BootVerify\n\n--- Step 8: Boot verification ---\n[VERIFY] Running self-test checks...\n[VERIFY] All checks passed\n[HSM] BootVerify -> Idle (ConfirmBoot)\n[SIM] fw_setenv upgrade_available=0\n[SIM] fw_setenv bootcount=0\n\n=== Upgrade completed successfully ===\nTotal time: 19 ms\nFinal state: Idle, error: Ok\n```\n\n掉电安全测试 (5 个场景全部通过):\n\n```\n=== Power loss safety test ===\n[TEST 1/5] Power loss during Writing (25%) ... PASS (active partition intact)\n[TEST 2/5] Power loss during Writing (50%) ... PASS (active partition intact)\n[TEST 3/5] Power loss during Writing (75%) ... PASS (active partition intact)\n[TEST 4/5] Power loss during Switching      ... PASS (recovered to BootVerify)\n[TEST 5/5] BootVerify timeout (no confirm)  ... PASS (bootcount rollback)\nAll 5 power loss scenarios passed.\n```\n\n## 11. 与 newosp 生态的集成\n\nosp-upgrade-engine 通过 FetchContent 引入 newosp，复用以下组件:\n\n| newosp 组件 | 在升级引擎中的用途 |\n|-------------|-------------------|\n| `osp::StateMachine` | HSM 驱动 8 状态升级流程 |\n| `osp::Event` | 事件传递 (EvStartUpgrade, EvStepProcess 等) |\n| `osp::expected` | 错误处理 (替代异常, `-fno-exceptions` 兼容) |\n| `OSP_ASSERT` | 调试断言 (release 编译为空) |\n\n升级引擎本身是独立仓库，不污染 newosp 核心库。唯一对 newosp 做的修改是为 HSM 添加了 `ForceTransition()` API，用于掉电恢复时从外部直接转换状态。\n\n```cpp\n// newosp hsm.hpp 新增 API\nbool ForceTransition(int32_t target) noexcept {\n    if (!started_ || target < 0 ||\n        static_cast<uint32_t>(target) >= state_count_) {\n        return false;\n    }\n    TransitionTo(target);  // 标准 LCA exit/entry 路径\n    return true;\n}\n```\n\n## 12. 总结\n\nosp-upgrade-engine 用 ~3000 行 C++17 header-only 代码实现了工业级 A/B 分区固件升级。几个关键数字:\n\n- **8 个 HSM 状态**: 覆盖从空闲到回滚的完整生命周期\n- **128 字节包头**: CRC-32 + SHA-256 + Ed25519 三层校验\n- **64 字节状态记录**: raw 分区持久化，支持任意时刻掉电恢复\n- **~10KB 栈/静态内存**: 零堆分配，适合 32MB RAM 设备\n- **0 个额外线程**: SpinOnce 轮询模式，不增加线程预算\n\n三层掉电保护 (状态持久化 + U-Boot 冗余 env + bootcount 回滚) 确保了在工业现场无人值守环境下的可靠性。函数指针表 HAL 和 x86 仿真层使得完整的升级流程可以在开发机上验证，包括掉电场景。\n",
      "ctime": "1771552444",
      "mtime": "1771552444",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/embedded_over_engineering.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857388594",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式系统中的过度设计: 识别、量化与规避",
      "brief_content": "设计模式、分层架构、可扩展性在桌面/服务器领域是最佳实践, 但搬到资源受限的 MCU 上时, 每个抽象层都有可量化的代价。本文通过一次信号处理 pipeline 重构的量化分析, 提炼出三个典型的过度",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "# 嵌入式系统中的过度设计: 识别、量化与规避\n\n> 平台背景: 100 MHz ARM Cortex-M / RTOS / 25fps 实时约束 / 256KB SRAM\n\n## 1. 引言\n\n设计模式、分层架构、可扩展性——这些软件工程最佳实践在桌面和服务器领域已被广泛验证。但当它们被搬到资源受限的 MCU 上时, 适用边界在哪里?\n\n在服务器端, 一个额外的抽象层可能只增加几微秒延迟和几 KB 内存, 与 GB 级 RAM 和 GHz 级 CPU 相比可以忽略。但在 100MHz MCU + 256KB SRAM 的环境中, 同样的抽象层可能占用可用 RAM 的 4%, 热路径延迟的 0.1%。这些数字看似不大, 但它们会叠加, 且每一项都应该有明确的产品需求作为回报。\n\n**核心论点**: MCU 上的每个抽象层都有可量化的代价。架构决策应以产品需求和实测数据为驱动, 而非对 \"可扩展性\" 的直觉追求。\n\n## 2. 案例背景\n\n某嵌入式信号处理 pipeline 进行了一次大规模重构:\n\n```\n重构前: 单体文件 (~6,000 行), 57 个处理模块的初始化和参数更新集中管理\n重构后: 分层框架 (~38,000 行)\n        PipelineManager (890行) -> PipelineBase (1,266行) -> NodeBase (1,161行)\n        + MemoryPool (544行) + ResourceGenerator (940行) + 46个模块文件 (33,642行)\n```\n\n**工程收益是实在的**: 消灭了 6,000 行大文件的协作冲突; 参数配置与 DMA 配置分离; 引入静态内存池; 建立了生命周期回滚机制。这些改进解决了真实的工程问题。\n\n但在肯定收益的同时, 评审发现了几个关键设计决策**缺乏需求或数据支撑**, 为当前产品不需要的能力付出了可量化的代价。以下将这些问题抽象为三个通用的过度设计模式。\n\n## 3. 过度设计的三个典型模式\n\n### 3.1 模式一: 为不存在的动态性付费\n\n**场景**: 处理 pipeline 包含 54 个处理模块 (如滤波、增益校正、降噪等)。模块的类型和数量在编译期由配置文件的 X-Macro 完全确定, 运行期间从未增删过模块。\n\n**设计选择**: 引入了完整的动态创建基础设施:\n- **工厂模式**: `get_module_vtable()` 根据 type_id 返回虚函数表\n- **内存池**: 专用内存池管理器 (544 行), 管理模块对象的分配和释放\n- **Handle 抽象**: 每个模块对象包含 magic 魔数、handle 指针、vtable 指针等运行时管理字段\n- **魔数校验**: 每次操作前 3~4 次 `HANDLE_VALID` 宏校验\n\n但代码事实是:\n\n```c\n// 所有模块在 pipeline 创建时一次性创建, 运行期不增删\nfor (i = 0; i < module_count; i++) {\n    ret = create_module(*handle, (uint8_t)i, &pipeline->module_list[i]);\n}\n```\n\n54 个模块全部在初始化函数中一次性创建。没有动态加载、没有插件机制、没有热插拔。模块的 bypass (旁路) 是硬件寄存器级别的控制, 模块对象本身不创建也不销毁, pipeline 拓扑不变。\n\n**量化代价**:\n\n| 项目 | 代价 |\n|------|------|\n| 54 个模块管理结构体 (~96B/个) | 5,184 bytes RAM |\n| 内存池管理器 + 分配逻辑 | 544 行代码 |\n| 每次操作 3~4 次 handle 魔数校验 | ~20 cycles/次 |\n| 工厂函数 + X-Macro 查表 | 间接调用开销 |\n\n**替代方案**: const 静态函数表\n\n```c\n// 编译期确定, 零运行时管理开销\ntypedef struct {\n    error_t (*init)(const void *param_cfg, const void *dma_cfg);\n    error_t (*deinit)(void);\n    error_t (*set_param)(set_cmd_t cmd, const ctrl_args_t *args);\n} module_ops_t;\n\n// 编译器可见完整调度表, 能做常量折叠和死代码消除\nstatic const module_ops_t ops_table[MODULE_TYPE_MAX] = {\n    [MOD_FILTER]  = { filter_init,  filter_deinit,  filter_set_param  },\n    [MOD_DENOISE] = { denoise_init, denoise_deinit, denoise_set_param },\n    [MOD_ZOOM]    = { NULL, NULL, NULL },  // 空壳模块: NULL, 零框架税\n    ...\n};\n```\n\n没有 `module_impl` 结构体 (省 5.2KB), 没有 handle 魔数, 没有工厂函数。空壳模块填 NULL, 调度时直接跳过, 不创建对象、不分配内存、不付框架税。\n\n**判断标准**: 问自己——\"运行时是否真的会发生动态创建/销毁?\" 如果答案是否, 就不该为它付费。嵌入式系统中的 \"动态\" 通常指 RTOS 模块的运行时装卸 (如 Linux 的 `insmod/rmmod`), 而非固定拓扑上的对象管理。\n\n### 3.2 模式二: 凭直觉而非数据拆锁\n\n**场景**: 系统存在真实的多线程并发——主处理线程执行帧间参数批量更新, 命令线程处理外部控制指令 (模式切换、参数调整)。两者可能同时访问模块参数。\n\n**设计选择**: 54 个 per-module mutex, 加上 1 个 pipeline mutex 和 1 个内存池 mutex, 共 57 个 mutex 对象。\n\n批量更新路径 (帧间热路径):\n```\npipeline_mutex_take()\n  for (i = 0; i < 54; i++):          // 遍历全部模块槽位\n      if (mask_check(i)):              // mask 过滤\n          module_mutex_take(i)         // per-module lock\n          memcpy(params)               // 参数拷贝\n          vtable->init()               // 间接调用\n          module_mutex_release(i)\npipeline_mutex_release()\n```\n\n更新 N 个模块: **2 (pipeline) + 2N (module)** 次 mutex 操作。\n\n**但并发分析显示**: 命令线程的 `set_param` 调用方都是模式切换操作 (如翻转、DCC 模式切换), **不在帧间热路径上**。这意味着一把 pipeline mutex 就能覆盖所有并发场景——让 `set_param` 也走 pipeline mutex, 偶尔等几百微秒不影响实时性。\n\n54 个 per-module mutex 的决策**没有回答**:\n- 实际运行中, 有多少模块真正面临跨线程并发?\n- per-module 锁相比 pipeline 锁, 减少了多少等待时间?\n- 2.7KB RAM + 24us/帧 的代价, 换来了多少可量化的并发收益?\n\n**量化对比**:\n\n| 指标 | per-module 锁 (54个) | 单一 pipeline 锁 |\n|------|---------------------|-----------------|\n| mutex 对象数 | 57 | 1 |\n| RAM | 2,736 bytes | 48 bytes |\n| 热路径 mutex 次数 (更新10个模块) | 22次 | 2次 |\n| 热路径开销 | ~24 us | ~1.2 us |\n\n**判断标准**: 细粒度锁不等于更好的并发性能。拆锁需要三个前提条件:\n1. **竞态分析**: 明确哪些数据会被哪些线程同时访问\n2. **锁竞争测量**: 量化当前锁的实际等待时间\n3. **热路径区分**: 竞争是否发生在性能敏感路径上\n\n如果竞争方都在冷路径 (如模式切换), 偶尔被热路径短暂阻塞不影响实时性, 那么一把锁就够了。\"more locks = better concurrency\" 在单核 MCU 上尤其是错觉——所有线程都在同一个核上调度, 细粒度锁的收益远小于多核系统。\n\n### 3.3 模式三: 为假想需求预留架构\n\n**场景**: 设计文档注明 \"当前仅一条 pipeline, 但具备扩展性\", 实现规范将 \"多 pipeline 支持\" 列为 feature。\n\n**设计选择**: 引入 PipelineManager 层 (890 行), 维护 pipeline 数组、active_mask、pipeline_id 路由等逻辑。\n\n**但现实是**:\n- `PIPELINE_COUNT = 1`, 只有一种 pipeline 类型\n- 目标硬件只有一个信号处理核心, 物理上不支持并行 pipeline\n- 无产品需求文档说明何时需要多 pipeline\n- 890 行管理代码服务于一个可能永远不会用到的扩展点\n\n**量化代价**: 890 行代码 (Thumb-2 下约 3.5~7 KB Flash) + pipeline 数组/路由的运行时开销。更重要的是维护成本——每次修改 pipeline 行为都要穿过 Manager 层的间接调用。\n\n**判断标准**: [YAGNI (You Ain't Gonna Need It)](https://martinfowler.com/bliki/Yagni.html) 在嵌入式中比在 Web 开发中更重要, 因为代价更高。Web 服务可以在需要时热更新, MCU 固件的扩展往往意味着硬件换代。为假想的硬件扩展预留软件架构, 而该硬件可能永远不会出现, 是典型的过度设计。\n\n## 4. 量化方法: 四维评估框架\n\n每个设计决策的引入, 都应该能回答: \"为了获得 X 能力, 付出 Y 代价\"。如果 X 在产品生命周期内不会发生, 则 Y 是纯浪费。\n\n评估模板:\n\n| 维度 | 指标 | 计算方法 | 工具 |\n|------|------|---------|------|\n| **RAM** | 结构体大小 x 实例数 + 同步原语 | `sizeof(struct) * N + sizeof(mutex) * M` | sizeof / 手工统计 |\n| **ROM** | 框架代码量 (Thumb-2: ~4-8 bytes/行) | `arm-none-eabi-size` 对比增量 | 编译器输出 |\n| **CPU** | 热路径额外 cycles/帧 | mutex + 遍历 + 间接调用 + 校验 | DWT cycle counter |\n| **栈** | 调用链深度 x 帧大小 | 最深路径的累计栈帧 | `-fstack-usage` / 静态分析 |\n\n以本案例为例:\n\n```\n为了获得 \"运行时动态创建/销毁模块\" 的能力:\n  付出: 5.2KB RAM + 每操作 3-4 次 handle 验证\n  实际使用: 从未在运行时创建或销毁过模块\n  结论: 纯浪费\n\n为了获得 \"per-module 级并发保护\":\n  付出: 2.7KB RAM + 24us/帧\n  实际使用: 竞争方在冷路径, 一把锁即可覆盖\n  结论: 大部分浪费\n\n为了获得 \"多 pipeline 扩展能力\":\n  付出: 890 行管理代码 + 间接调用开销\n  实际使用: 硬件只有 1 个处理核心\n  结论: 纯浪费\n```\n\n四维汇总:\n\n| 维度 | 框架总开销 | 占比 (256KB SRAM / 40ms帧间隔) |\n|------|-----------|------|\n| RAM | ~10.9 KB (结构体 5.2 + mutex 2.7 + 错误历史 2.4 + 其他 0.6) | ~4.3% |\n| CPU | ~47 us/帧 (mutex 24 + 遍历 11 + 压栈 8 + 校验 2 + vtable 1.3) | ~0.12% |\n| 栈 | +150~270 bytes (调用链从 2-3 层增至 6-7 层) | 显著, 2-4KB 栈线程中需关注 |\n| ROM | +29,000 行 (~116-232 KB Flash) | 包含 ~6,000 行框架样板 |\n\n> CPU 0.12% 不会直接导致丢帧, 但 RAM 4.3% 和栈深度增加在资源紧张时可能成为瓶颈。更关键的是: 这些代价没有换来实际使用的能力。\n\n## 5. 遍历优化: 从全量扫描到精确分发\n\n**问题**: 即使只更新 5~10 个模块, 循环仍遍历全部 54 个槽位做 mask 检查和 NULL 判断。\n\n```c\n// 全量遍历: O(N), N = 总槽位数\nfor (i = 0; i < MODULE_COUNT; i++) {\n    if (is_module_need_update(effective_mask, i)) {\n        // 更新模块...\n    }\n}\n// 空循环体 ~26 cycles/次, 54 次中 44 次为空 = ~14 us\n```\n\n**替代**: bitmask + CLZ/CTZ 硬件指令, 只访问需要更新的模块:\n\n```c\n// 精确分发: O(popcount), 只访问 dirty 模块\nuint64_t mask = dirty_mask;\nwhile (mask) {\n    int idx = __builtin_ctzll(mask);    // 硬件 CLZ 指令, 1 cycle\n    mask &= mask - 1;                   // 清除最低位\n\n    if (ops_table[idx].init) {\n        ops_table[idx].init(get_param(cfg, idx), get_dma(cfg, idx));\n    }\n}\n```\n\n更新 10 个模块: 从 54 次循环 (14us 空循环开销) 降至 10 次精确跳转。\n\n## 6. 对齐陷阱: 脱离硬件的优化是负优化\n\n内存池代码中使用了 `CACHE_ALIGNED = 64` 对齐:\n\n```c\n#define CACHE_ALIGNED  64\ntypedef struct {\n    uint8_t data[POOL_ITEM_SIZE] __attribute__((aligned(CACHE_ALIGNED)));\n} pool_item_t;\n```\n\n64 字节对齐是为有 L1 Data Cache 的处理器设计的, 目的是避免 false sharing。但目标平台是 100MHz Cortex-M4, **没有数据缓存**。在无 D-Cache 的 MCU 上:\n- 不存在 false sharing 问题\n- 64B 对齐只会浪费 SRAM (每个对象最多浪费 63 bytes 填充)\n- 正确做法是自然对齐 (4 bytes for ARM)\n\n**教训**: 优化手段必须匹配目标硬件。从桌面/服务器代码复制过来的 Cache Line 对齐, 在无 Cache 的 MCU 上不仅无益, 还有害。\n\n## 7. 轻量替代方案\n\n上述分析指向一个核心思路: **拆文件解决协作问题, 静态分发解决性能问题, 一把锁解决并发问题**。\n\n```\npipeline.c (~300行, 唯一管理层)\n  ├── pipeline_init()       // 遍历 ops_table, 调用各模块 init\n  ├── pipeline_deinit()     // 逆序 deinit, 有回滚\n  └── pipeline_update()     // 1把 mutex + bitmask 精确分发\n\nmodule/mod_filter.c         // 每个模块独立文件 (解决协作冲突)\nmodule/mod_denoise.c\nmodule/...\nmodule/mod_registry.c       // 编译期生成: type_id -> 函数指针映射\n```\n\n核心机制:\n\n```c\nstatic struct rt_mutex pipeline_mutex;   // 全局唯一\n\n// 批量更新 (帧间热路径)\nerror_t pipeline_update(uint64_t mask, const pipeline_config_t *cfg)\n{\n    rt_mutex_take(&pipeline_mutex, RT_WAITING_FOREVER);\n    while (mask) {\n        int idx = __builtin_ctzll(mask);\n        mask &= mask - 1;\n        if (ops_table[idx].init)\n            ops_table[idx].init(get_param(cfg, idx), get_dma(cfg, idx));\n    }\n    rt_mutex_release(&pipeline_mutex);\n    return OK;\n}\n\n// 单模块设置 (模式切换, 非热路径)\nerror_t module_set_param(int idx, set_cmd_t cmd, const ctrl_args_t *args)\n{\n    rt_mutex_take(&pipeline_mutex, RT_WAITING_FOREVER);   // 同一把锁\n    error_t ret = ops_table[idx].set_param\n                  ? ops_table[idx].set_param(cmd, args) : ERR_NOT_SUPPORTED;\n    rt_mutex_release(&pipeline_mutex);\n    return ret;\n}\n```\n\n**资源对比**:\n\n| 指标 | 原重构方案 | 轻量方案 | 差异 |\n|------|-----------|---------|------|\n| 框架 RAM | ~10.9 KB | ~100 B (1个mutex + 1个ops表) | **-99%** |\n| 热路径 mutex 次数 (更新10模块) | 22次 | 2次 | **-91%** |\n| 热路径额外耗时 | ~47 us | ~3 us | **-94%** |\n| 调用链深度 | 6-7层 | 2-3层 | -4层 |\n| 源码行数 | ~38,000 | ~12,000-15,000 (估) | **-60%** |\n| 栈深度 (热路径) | 200-320 B | ~64 B | -150~256 B |\n| 模块文件数 | 46 | 46 (不变) | 协作优势保留 |\n\n保留原方案的好设计: 参数/DMA 配置分离; 静态内存分配; init/deinit 对称性 + 逆序回滚。\n\n## 8. 决策原则总结\n\n1. **需求驱动, 非模式驱动**: 每个抽象层都应指向明确的产品需求。\"具备扩展性\" 不是需求, \"支持 Sub-ISP 并行处理 (PRD v2.1, 2025 Q3)\" 才是需求。没有 PRD 支撑的扩展性, 就是过度设计。\n\n2. **数据驱动, 非直觉驱动**: 并发设计需要竞态分析、锁竞争测量和 profiling 数据。没有数据就不拆锁, 没有数据就不加锁。\"可能会有并发问题\" 不是加 54 个 mutex 的理由。\n\n3. **量化代价**: 每引入一个设计模式, 都计算四维代价 (RAM/ROM/CPU/栈)。如果代价的回报是 \"运行期从不发生的能力\", 则立即删除。\n\n4. **匹配硬件**: Cache Line 对齐只用在有 Cache 的平台; 细粒度锁只用在多核系统; Flash 预取优化只用在有预取缓冲的 MCU。脱离硬件的优化是负优化。\n\n5. **区分热冷路径**: 热路径 (帧间更新, 25fps = 40ms 间隔) 上的每个 cycle 都有意义。冷路径 (初始化、模式切换) 可以宽容——多几百微秒不影响用户体验。锁策略、遍历策略都应基于这个区分。\n\n6. **拆文件不拆层级**: 大文件的协作冲突用文件拆分解决 (每个模块独立 .c 文件), 不需要引入 Manager -> Base -> Node 三层抽象。文件是协作单元, 不是架构单元。\n\n---\n\n> 好的嵌入式架构不是模式越多越好, 而是每一行代码都能指向一个真实的产品需求, 每一个抽象层都有可量化的回报。当你发现自己在为 \"将来可能需要\" 写代码时, 停下来问: 这个 \"将来\" 有产品需求文档支撑吗? 如果没有, 最好的代码就是不写的代码。\n",
      "ctime": "1771552447",
      "mtime": "1771552447",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/embedded_streaming_data_architecture.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469489198",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式流式数据处理架构: 传感器到网络输出的全链路设计",
      "brief_content": "面向激光雷达、工业视觉、机器人等 ARM-Linux 场景，设计一套 C++17 header-only 的流式数据处理架构。覆盖数据流 (10-100 Hz 大块帧) 与控制流 (低频高可靠消息) ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 版本: v3.0 | 基础设施库: [newosp](https://github.com/DeguiLiu/newosp) v0.4.3\n> 目标平台: ARM-Linux (Cortex-A53/A72/A7) | C++17, Header-only\n> 适用场景: 激光雷达、工业视觉、机器人、边缘传感器融合\n\n---\n\n## 1. 设计背景与目标\n\n### 1.1 问题域\n\n工业嵌入式传感器系统（激光雷达、工业相机、惯导）的数据处理链路具有以下特征:\n\n- **数据流**: 传感器以 10-100 Hz 产生大块数据（单帧 100 KB - 5 MB），经过多级处理后输出\n- **控制流**: 启停、模式切换、参数下发、故障上报等低频但高可靠性要求的消息\n- **实时性**: 端到端延迟要求 us 级（控制消息）到 ms 级（数据帧）\n- **可靠性**: 7x24 不间断运行，零堆分配避免内存碎片化\n\n传统方案的典型问题:\n\n1. 数据面和控制面混用同一通道，大帧数据阻塞紧急控制消息\n2. 基于 `std::function` + `shared_ptr` 的回调机制，热路径存在堆分配\n3. 缺少优先级准入和背压控制，系统过载时关键消息被丢弃\n\n### 1.2 设计目标\n\n| 目标 | 量化指标 | 说明 |\n|------|----------|------|\n| 控制面消息延迟 | P99 < 500 ns (x86), P99 < 1.5 us (ARM) | 无锁 MPSC，Envelope 内嵌 |\n| 数据面零拷贝 | 0 次 memcpy (传感器 -> 算法) | ShmChannel SPSC RingBuffer |\n| 热路径堆分配 | 0 次 | 全链路栈分配 + 预分配 |\n| 优先级保护 | HIGH 消息零丢失 | 三级阈值准入控制 |\n| 框架 RAM 占用 | < 2 MB (不含应用缓冲) | 可通过编译期宏缩减 |\n| 外部依赖 | 零运行时依赖 | Header-only，FetchContent 仅用于测试/构建 |\n\n### 1.3 非目标\n\n| 排除项 | 理由 | 替代方案 |\n|--------|------|----------|\n| 跨主机网络通信 | 超出单板框架范畴 | newosp Transport + Discovery |\n| 动态服务发现 (DDS) | 嵌入式场景拓扑固定 | 静态配置或轻量 mDNS |\n| MSVC / Windows | 非目标平台 | GCC / Clang only |\n\n---\n\n## 2. 架构总览\n\n### 2.1 控制面 / 数据面分离\n\n本架构的核心设计原则是 **控制面与数据面分离**:\n\n```mermaid\nflowchart TB\n    subgraph CP[\"控制面 (Control Plane)\"]\n        direction LR\n        BUS[\"AsyncBus\\nMPSC Lock-free\\n优先级准入\"]\n        NODE[\"Node Pub/Sub\\nFNV-1a topic 路由\"]\n        HSM_CP[\"HSM\\n设备生命周期\"]\n    end\n\n    subgraph DP[\"数据面 (Data Plane)\"]\n        direction LR\n        SHM[\"ShmChannel\\nSPSC Zero-Copy\\nWait-free\"]\n        MEM[\"MemPool\\n预分配帧缓冲\"]\n    end\n\n    subgraph SCHED[\"调度层\"]\n        direction LR\n        RT[\"RealtimeExecutor\\nSCHED_FIFO + isolcpus\"]\n        WP[\"WorkerPool\\n三阶段退避\"]\n        TMR[\"TimerScheduler\\n周期任务\"]\n    end\n\n    subgraph APP[\"应用层\"]\n        direction LR\n        SENSOR[\"传感器驱动\"] --> PREPROC[\"预处理\"]\n        PREPROC --> ALGO[\"算法处理\"]\n        ALGO --> OUTPUT[\"数据输出\"]\n    end\n\n    APP -->|\"控制消息 < 256B\"| CP\n    APP -->|\"数据帧 > 1KB\"| DP\n    CP --> SCHED\n    DP --> SCHED\n```\n\n| 平面 | 通道 | 消息大小 | 频率 | 同步机制 | 零拷贝 |\n|------|------|----------|------|----------|--------|\n| 控制面 | AsyncBus + Node | < 256 B | < 1K msg/s | Lock-free MPSC (CAS) | N/A (值语义) |\n| 数据面 | ShmChannel | 256 B - 5 MB | 10-100 Hz | Wait-free SPSC | 是 (指针传递) |\n\n**为什么分离?** newosp 实测数据显示，当 AsyncBus 的 variant 包含 8 KB 类型时，Envelope sizeof 从 ~300 B 膨胀到 8232 B，吞吐从 5.9 M/s 降至 0.6 M/s。控制消息走 Bus（轻量 variant），数据帧走 ShmChannel（零拷贝），是架构层面的设计选择。\n\n### 2.2 newosp 模块架构\n\n```mermaid\nflowchart TB\n    subgraph L4[\"Layer 4: 应用接口\"]\n        APP_L[\"Application\\nMakeIID 编码\"]\n        POST_L[\"OspPost\\n统一投递\"]\n        LIFE_L[\"LifecycleNode\\n状态管理\"]\n    end\n\n    subgraph L3[\"Layer 3: 通信抽象\"]\n        NODE_L[\"Node\\nPub/Sub + Topic\"]\n        SVC_L[\"Service\\nRPC 请求/响应\"]\n        DISC_L[\"Discovery\\n节点发现\"]\n    end\n\n    subgraph L2[\"Layer 2: 传输与调度\"]\n        BUS_L[\"AsyncBus\\nMPSC Ring Buffer\"]\n        SHM_L[\"ShmChannel\\nSPSC RingBuffer\"]\n        EXEC_L[\"Executor\\n线程调度\"]\n        TRANS_L[\"Transport\\n网络帧\"]\n    end\n\n    subgraph L1[\"Layer 1: 基础设施\"]\n        VOCAB[\"vocabulary.hpp\\nFixedFunction/FixedVector/FixedString\"]\n        SPSC[\"spsc_ringbuffer.hpp\\nWait-free SPSC\"]\n        HSM_L[\"hsm.hpp\\n层次状态机\"]\n        BT_L[\"bt.hpp\\n行为树\"]\n        POOL[\"mem_pool.hpp\\n内存池\"]\n        TIMER[\"timer.hpp\\n定时器\"]\n    end\n\n    L4 --> L3 --> L2 --> L1\n```\n\n**关键特征**:\n- **43 个头文件**, Header-only INTERFACE 库\n- **1153 个测试**, ASan + UBSan + TSan 全通过\n- **零 std::function**: 全部使用 `FixedFunction<64>` (SBO 回调，无堆分配)\n- **零 std::string**: 使用 `FixedString<N>` 替代\n\n---\n\n## 3. 控制面: AsyncBus 消息总线\n\n### 3.1 架构设计\n\nAsyncBus 是 newosp 的核心通信组件，采用 **Lock-free MPSC (多生产者单消费者) Ring Buffer** 设计:\n\n```mermaid\nflowchart LR\n    P1[\"Node A\\nPublish\"] -->|CAS 入队| RB[\"Lock-free Ring Buffer\\n128K slots 可配置\\nEnvelope 内嵌\"]\n    P2[\"Node B\\nPublish\"] -->|CAS 入队| RB\n    P3[\"Node C\\nPublish\"] -->|CAS 入队| RB\n    RB -->|批量出队| DISP[\"Dispatcher\\n编译期类型索引\\n固定回调表\"]\n    DISP --> CB1[\"Callback 1\\nFixedFunction SBO\"]\n    DISP --> CB2[\"Callback 2\"]\n```\n\n### 3.2 零堆分配设计\n\n传统消息总线每次 Publish 至少 2 次堆分配（`make_shared<Envelope>` + `std::function` 捕获）。newosp 的 AsyncBus 通过以下手段实现热路径零堆分配:\n\n| 传统方案的堆分配 | newosp 替代方案 | 效果 |\n|-----------------|----------------|------|\n| `std::make_shared<Envelope>` | Envelope 直接内嵌在 RingBufferNode | 消除每消息堆分配 |\n| `std::unordered_map<type_index, ...>` | `std::array<CallbackSlot, N>` + 编译期 `VariantIndex` | O(1) 数组索引，无 hash |\n| `std::function` 回调 | `FixedFunction<64>` (56B SBO 存储) | 无堆溢出风险 |\n| `std::string` 消息字段 | `FixedString<N>` 栈上定长字符串 | 零堆分配 |\n| `std::vector` 订阅列表 | `FixedVector<T, N>` 栈上定容向量 | 零堆分配 |\n\n### 3.3 优先级准入与背压控制\n\nAsyncBus 的优先级机制在系统过载时保护关键消息:\n\n```mermaid\nflowchart TB\n    MSG[\"消息到达\"] --> CHK{\"队列水位\"}\n    CHK -->|\"< 60%\"| ACC[\"全部接受\"]\n    CHK -->|\"60-80%\"| DROP_L[\"丢弃 LOW\"]\n    CHK -->|\"80-99%\"| DROP_M[\"丢弃 LOW + MEDIUM\"]\n    CHK -->|\">= 99%\"| DROP_H[\"全部丢弃\"]\n```\n\n**实测验证** (突发 150,000 条消息，超过队列容量 131,072):\n\n| 优先级 | 发送 | 成功 | 丢弃率 | 设计预期 |\n|--------|:----:|:----:|:------:|----------|\n| HIGH | 30,000 | 30,000 | **0.0%** | 完全保护 (阈值 99%) |\n| MEDIUM | 39,321 | 33,642 | 12.6% | 次级保护 (阈值 80%) |\n| LOW | 39,320 | 3,640 | 47.6% | 优先丢弃 (阈值 60%) |\n\n### 3.4 性能数据\n\n**newosp AsyncBus 实测** (Ubuntu 24.04, GCC 13.3, `-O3 -march=native`, 10 轮统计):\n\n| 指标 | 数值 | 说明 |\n|------|------|------|\n| Bus 吞吐量 (x86) | 5.9 M msg/s | 控制消息，variant < 256B |\n| Bus P99 延迟 (x86) | 157 ns | 无锁设计，尾部延迟稳定 |\n| Bus 吞吐量 (ARM 估算) | 0.5 - 1.0 M msg/s | 弱内存序 + 较低主频 |\n| MemPool alloc/free | 98 M ops/s | 预分配池，零碎片 |\n| 热路径堆分配 | 0 次 | Envelope 内嵌 + FixedFunction |\n| 框架 RAM (AsyncBus) | ~520 KB | 可通过 QueueDepth 宏缩小 |\n\n**与 eventpp + Active Object 对比**:\n\n| 维度 | newosp AsyncBus | eventpp + AO (优化后) | 差距 |\n|------|:--------------:|:--------------------:|:----:|\n| 吞吐量 | 5.9 M/s | 3.1 M/s (持续) | 1.9x |\n| E2E P50 延迟 | ~157 ns | ~11,588 ns | 74x |\n| E2E P99 延迟 | ~449 ns | ~24,289 ns | 54x |\n| 热路径堆分配 | 0 次/msg | 1 次/msg (shared_ptr) | -- |\n| 优先级保护 | 三级阈值 | 无 | -- |\n| 外部依赖 | 无 | eventpp 库 | -- |\n| MISRA 合规 | 大部分 | 部分 | -- |\n\n> 注: eventpp 对比数据来自优化分支 (OPT-1~8，吞吐提升 5.3x)。newosp 在延迟和零分配方面优势显著，eventpp 在已有代码迁移场景下仍有价值。\n\n---\n\n## 4. 数据面: ShmChannel 零拷贝通道\n\n### 4.1 设计原理\n\n数据面处理大块传感器数据（点云、图像），核心需求是 **零拷贝** 和 **低延迟**:\n\n```mermaid\nflowchart LR\n    DMA[\"DMA 写入\"] --> RING[\"ShmRingBuffer\\nSPSC Wait-free\"]\n    RING -->|\"直接指针访问\\n零拷贝\"| ALGO[\"算法模块\"]\n    ALGO -->|\"Commit\\n释放 slot\"| RING\n```\n\n**传统架构 vs 零拷贝**:\n\n| 架构 | 拷贝次数 | 内存带宽浪费 (1MB x 100Hz) |\n|------|:--------:|:--------------------------:|\n| 传统 (Driver -> Middleware -> Algorithm -> Output) | 3 次 | 300 MB/s |\n| newosp (DMA -> ShmRingBuffer -> 指针访问) | 0 次 | 0 |\n\n### 4.2 ShmRingBuffer 性能\n\n| 指标 | 数值 (x86 实测) | ARM 估算 |\n|------|:---------------:|:--------:|\n| SPSC 吞吐 (256B payload) | 40 M ops/s | 5-10 M ops/s |\n| SPSC 吞吐 (4KB payload) | 2.9 M ops/s | 0.3-0.6 M ops/s |\n| 同步机制 | Wait-free (无 CAS) | 显式 acquire/release |\n\n**Cache Line 拐点**: ShmRingBuffer 在 payload 1 KB 处出现吞吐拐点（L1 Cache 边界）。建议数据面分包大小 <= 512 B 以获得最佳 SPSC 吞吐。\n\n### 4.3 Cache 一致性策略\n\n| 方案 | 实现方式 | 优点 | 缺点 | 适用场景 |\n|------|----------|------|------|----------|\n| Uncached 映射 | `dma_alloc_coherent` | 简单，无维护代码 | 访问延迟高 (~80ns) | 低频，简单系统 |\n| Cached + 手动维护 | `dma_sync_single_for_cpu/device` | 高性能 | 需严格维护 | 高频，性能敏感 |\n| **newosp 方案** | Cache line 对齐 + 显式 fence | 兼顾性能与安全 | 需理解 ARM 内存序 | 推荐 |\n\nnewosp ShmRingBuffer 的 ARM 适配:\n- 64B cache line padding 隔离 head/tail，消除 false sharing\n- 显式 `acquire`/`release` 语义，不依赖默认 `seq_cst`（ARM 上 `seq_cst` 生成额外 `dmb ish` 全屏障）\n- `trivially_copyable` 约束确保数据可安全通过共享内存传递\n\n---\n\n## 5. 调度层: RealtimeExecutor 与 WorkerPool\n\n### 5.1 调度模型\n\nnewosp 提供多种 Executor 适配不同实时性需求:\n\n| Executor 类型 | 调度策略 | CPU 亲和 | 适用场景 |\n|--------------|----------|---------|----------|\n| SingleExecutor | 单线程顺序执行 | 不绑核 | 调试、低频任务 |\n| PinnedExecutor | 单线程 + 绑核 | 指定核 | 中等实时性 |\n| **RealtimeExecutor** | SCHED_FIFO + mlockall + 绑核 | 隔离核 | **硬实时数据处理** |\n| WorkerPool | 多线程 + AdaptiveBackoff | 不绑核 | 并行计算、网络 I/O |\n\n### 5.2 RealtimeExecutor 抗干扰设计\n\n```mermaid\nflowchart LR\n    subgraph CORE1[\"隔离核 (isolcpus)\"]\n        RT[\"RealtimeExecutor\\nSCHED_FIFO, priority=90\\nmlockall\"]\n        TASK[\"传感器+算法任务\"]\n    end\n\n    subgraph CORE0[\"系统核\"]\n        SYS[\"Linux 内核 + 中断\"]\n        NET[\"网络/日志/诊断\"]\n    end\n\n    RT --> TASK\n    CORE1 -.->|\"内核不调度\\nisolcpus=1\"| CORE0\n```\n\n**关键措施**:\n\n| 措施 | 作用 |\n|------|------|\n| `isolcpus=N` | 将核心从 Linux 调度器剥离 |\n| `SCHED_FIFO` | 实时调度策略，不被普通进程抢占 |\n| `mlockall` | 锁定内存页，防止缺页中断 |\n| Stack prefault | 预写栈页面，避免首次 page fault |\n| CPU affinity | 绑核，保持 Cache 热度 |\n\n### 5.3 AdaptiveBackoff 三阶段等待\n\nWorkerPool 的等待策略平衡延迟与 CPU 功耗:\n\n| 阶段 | 行为 | 延迟 | CPU 占用 |\n|------|------|:----:|:--------:|\n| Spin | 忙等 + CPU hint (`yield`/`pause`) | 0-2 us | 100% |\n| Yield | `sched_yield()` 让出时间片 | 2-20 us | 0% |\n| Park | condition_variable 休眠 | 1-50 us | 0% |\n\n---\n\n## 6. 状态管理: 层次状态机 (HSM)\n\n### 6.1 设计选择\n\n| 维度 | switch-case | 虚函数 (GoF) | newosp HSM |\n|------|:-----------:|:-----------:|:----------:|\n| 层次嵌套 | 手动 | 手动委托 | LCA 算法自动 |\n| Guard 条件 | if-else | 虚函数重载 | FixedFunction |\n| 堆分配 | 0 | 可能 | 0 (FixedVector) |\n| 编译期类型安全 | 无 | 需 RTTI | 模板参数 |\n\n### 6.2 设备生命周期状态设计\n\n```mermaid\nstateDiagram-v2\n    [*] --> Init\n    Init --> Ready: 初始化完成\n\n    Ready --> Active: 启动命令\n    Ready --> Fault: 自检失败\n\n    Active --> Degraded: 过载\n    Active --> Fault: 硬件错误\n\n    Degraded --> Active: 负载恢复\n    Degraded --> Fault: 二次超时\n\n    Fault --> Ready: 恢复成功\n    Fault --> Shutdown: 重试耗尽\n    Shutdown --> [*]\n```\n\n**HSM 在 newosp 中的多场景应用**:\n\n| 模块 | 状态机用途 | 状态数 |\n|------|----------|:------:|\n| hsm.hpp | 通用层次状态机 | 自定义 |\n| node_manager_hsm.hpp | 节点心跳 (Connected/Suspect/Disconnected) | 3 |\n| service_hsm.hpp | 服务连接 (Idle/Listening/Active/Error) | 5 |\n| discovery_hsm.hpp | 发现流程 (Idle/Announcing/Stable/Degraded) | 4 |\n\n### 6.3 HSM + BT 组合: 启动自检流程\n\nHSM 管理设备\"处于什么状态\"，BT (行为树) 管理\"如何执行一个流程\"。两者组合使用，HSM 在状态转换时触发 BT 执行具体操作序列:\n\n```mermaid\nflowchart TB\n    subgraph HSM_LAYER[\"HSM: 设备状态管理\"]\n        INIT[\"Init\"] -->|\"触发 BT 自检\"| READY[\"Ready\"]\n        READY -->|\"启动命令\"| ACTIVE[\"Active\"]\n        ACTIVE -->|\"故障\"| FAULT[\"Fault\"]\n        FAULT -->|\"触发 BT 恢复\"| READY\n    end\n\n    subgraph BT_INIT[\"BT: 自检序列 (Init -> Ready)\"]\n        direction TB\n        SEQ[\"Sequence\"] --> CHK_HW[\"检查硬件\\n传感器/电机/温度\"]\n        SEQ --> CHK_MEM[\"检查内存\\n预分配缓冲池\"]\n        SEQ --> CHK_DMA[\"检查 DMA\\n通道就绪\"]\n        SEQ --> CHK_NET[\"检查网络\\n链路连通\"]\n    end\n\n    subgraph BT_RECOVER[\"BT: 故障恢复 (Fault -> Ready)\"]\n        direction TB\n        SEL[\"Selector\"] --> RST_DMA[\"复位 DMA\\nRetry x3\"]\n        SEL --> RST_FULL[\"完整复位\\n重建描述符链\"]\n    end\n\n    HSM_LAYER -.->|\"onEntry(Init)\"| BT_INIT\n    HSM_LAYER -.->|\"onEntry(Fault)\"| BT_RECOVER\n```\n\n**BT 节点类型及其在自检中的应用**:\n\n| 节点类型 | 行为 | 自检应用示例 |\n|----------|------|------------|\n| **Sequence** | 依次执行子节点，任一失败则整体失败 | 上电自检: 硬件 -> 内存 -> DMA -> 网络 |\n| **Selector** | 依次尝试子节点，任一成功则整体成功 | 故障恢复: 软复位 -> 硬复位 -> 降级运行 |\n| **Decorator (Retry)** | 失败时重试 N 次 | DMA 初始化最多重试 3 次 |\n| **Decorator (Timeout)** | 超时则返回失败 | 校准流程 5 秒超时 |\n| **Action** | 执行具体操作 | 检查传感器、预分配缓冲池 |\n| **Condition** | 检查条件 | 温度 < 85 C、电压正常 |\n\n**newosp BT 设计特点**:\n- 扁平数组存储 (非指针树)，缓存友好\n- 索引引用子节点，零堆分配\n- 与 HSM 通过 AsyncBus 事件交互: BT 完成 -> 发布 `SelfTestPassed` -> HSM 转换到 Ready\n\n---\n\n## 7. 典型部署: 激光雷达数据处理\n\n> 本节展示架构在激光雷达场景的部署概览。完整的 Pipeline DAG 设计、Stage 融合优化、SoA 数据布局与 NEON 向量化详见 [激光雷达高吞吐数据处理 Pipeline](../lidar_pipeline_newosp/)。\n\n### 7.1 系统架构\n\n```mermaid\nflowchart LR\n    subgraph SENSOR[\"传感器\"]\n        LIDAR[\"激光雷达\"]\n        IMU[\"IMU\"]\n    end\n\n    subgraph PROCESS[\"处理层\"]\n        ACQ[\"采集 Node\\nCore 1 隔离\"]\n        FILTER[\"滤波 Node\"]\n        FUSE[\"融合 Node\"]\n        OUT[\"输出 Node\"]\n    end\n\n    subgraph CTRL[\"控制层\"]\n        HSM_D[\"HSM 生命周期\"]\n        DIAG[\"串口诊断\"]\n        TIMER_D[\"心跳/看门狗\"]\n    end\n\n    LIDAR -->|\"ShmChannel\\n零拷贝\"| ACQ\n    IMU -->|\"ShmChannel\"| FUSE\n    ACQ -->|\"ShmChannel\"| FILTER -->|\"ShmChannel\"| FUSE -->|\"ShmChannel\"| OUT\n\n    HSM_D -->|\"AsyncBus\\n控制消息\"| ACQ & FILTER & FUSE & OUT\n    DIAG <-->|\"串口\"| HOST[\"上位机\"]\n```\n\n### 7.2 模块选型与通道划分\n\n| 数据特征 | 选择通道 | newosp 模块 | 原因 |\n|----------|----------|------------|------|\n| 控制命令 (< 256 B) | AsyncBus | Node Pub/Sub | 低频，需优先级保护 |\n| 点云数据 (1 MB/帧) | ShmChannel | SpscRingBuffer | 高频，零拷贝 |\n| 请求-响应 | Service RPC | service.hpp | 异步回调，超时控制 |\n| 周期遥测 | Timer + AsyncBus | TimerScheduler | 定时采样 |\n| 诊断通信 | 串口 | SerialTransport | CRC 校验，ACK 可靠 |\n\n---\n\n## 8. 资源预算\n\n### 8.1 newosp 框架开销\n\n| 资源 | 占用 | 说明 |\n|------|------|------|\n| .text (代码段) | ~80 KB | Header-only, 按需实例化 |\n| 运行时 RAM | < 2 MB | AsyncBus ~520 KB + 其他 |\n| 线程数 | 4-6 | Bus + Timer + Worker + 诊断 |\n| CPU 占用 | < 5% | 框架本身开销 |\n\n### 8.2 编译期配置适配\n\n| 配置场景 | Queue Depth | Cache Align | RAM |\n|----------|:-----------:|:-----------:|:---:|\n| 服务器/PC (测试) | 128K | 64B | ~16 MB |\n| ARM Linux (1GB) | 8K | 64B | ~2.7 MB |\n| ARM Linux (256MB) | 4K | 64B | ~512 KB |\n| MCU (单核, 512KB) | 256 | 关闭 | ~23 KB |\n\n### 8.3 典型激光雷达资源预算 (ARM Cortex-A53, 512 MB DDR)\n\n| 资源 | newosp | 点云缓冲 | 算法 | 系统 | 总计 |\n|------|:------:|:--------:|:----:|:----:|:----:|\n| RAM | ~2 MB | ~3 MB | 10-50 MB | ~32 MB | < 90 MB |\n| CPU | < 5% | -- | 30-60% | ~20% | < 85% |\n\n---\n\n## 9. 与同类框架对比\n\n| 维度 | newosp | eventpp + AO | ROS 2 (DDS) | QP/C |\n|------|:------:|:-----------:|:-----------:|:----:|\n| 消息延迟 (P50) | ~157 ns | ~11.6 us | ~100 us | ~1 us |\n| 吞吐量 | 5.9 M/s | 3.1 M/s | ~0.5 M/s | N/A |\n| 热路径堆分配 | 零 | 有 | 有 | 零 |\n| 优先级准入 | 三级阈值 | 无 | QoS | RTC |\n| 零拷贝 IPC | ShmChannel | 无 | iceoryx | 无 |\n| 外部依赖 | 无 | eventpp | DDS | 无 |\n| 二进制大小 | ~50 KB | ~100 KB | ~10 MB | ~20 KB |\n| MISRA 合规 | 大部分 | 部分 | 否 | 是 |\n| 目标平台 | ARM-Linux/MCU | ARM-Linux | Linux/QNX | MCU |\n\n---\n\n## 10. 总结\n\n本流式架构基于 newosp 基础设施库，通过 **控制面/数据面分离** 解决工业嵌入式传感器系统的核心矛盾:\n\n1. **控制面 (AsyncBus)**: Lock-free MPSC，零堆分配，三级优先级保护，P99 < 500 ns\n2. **数据面 (ShmChannel)**: SPSC wait-free 零拷贝，避免大帧数据阻塞控制消息\n3. **调度层 (RealtimeExecutor)**: SCHED_FIFO + isolcpus + mlockall，确定性调度\n4. **状态管理 (HSM + BT)**: HSM 管理设备状态，BT 驱动启动自检和故障恢复流程，零堆分配\n\nnewosp 的 Header-only 设计、零运行时依赖、编译期可配置的特性，使其特别适合资源受限的嵌入式 ARM-Linux 平台。所有性能数据均可通过源码复现（1153 个测试，ASan/TSan clean）。\n\n> 详细的激光雷达 Pipeline 实现（DAG 设计、Stage 融合、SoA + NEON 向量化）参见 [激光雷达高吞吐数据处理 Pipeline](../lidar_pipeline_newosp/)。\n\n---\n\n## 参考资料\n\n| 资源 | 说明 |\n|------|------|\n| [newosp](https://github.com/DeguiLiu/newosp) | 工业嵌入式 C++17 基础设施库 (v0.4.3) |\n| [newosp 设计文档](docs/design_zh.md) | 40 个模块详细设计 |\n| [newosp 性能报告](docs/benchmark_report_zh.md) | 完整基准测试数据 |\n| [newosp 激光雷达评估](docs/performance_analysis_lidar_zh.md) | 激光雷达场景性能分析 |\n| [iceoryx](https://github.com/eclipse-iceoryx/iceoryx) | 零拷贝 IPC 参考 |\n| [ARM Memory Model](https://developer.arm.com/documentation/den0024/a/Memory-Ordering) | ARM 弱内存序 |\n",
      "ctime": "1771552451",
      "mtime": "1771552451",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/fpga_arm_soc_lidar_feasibility.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853602826",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "FPGA + ARM 双核 SoC 处理激光雷达点云的可行性分析",
      "brief_content": "在 Zynq-7000 (双核 Cortex-A9 @ 667 MHz) 上处理 30 万点/秒激光雷达数据流。PL (FPGA) 负责传感器接口和 DMA 搬运，PS (ARM) 运行 Linux ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/150849448)\n>\n> 参考: [UG585 - Zynq-7000 SoC TRM](https://docs.amd.com/r/en-US/ug585-zynq-7000-SoC-TRM),\n> [newosp](https://github.com/DeguiLiu/newosp) v0.2.0,\n> [newosp 激光雷达性能评估](docs/performance_analysis_lidar_zh.md)\n>\n> 适用场景: 30 万点/秒激光雷达数据采集与处理\n\n---\n\n## 1. 设计目标\n\nZynq-7000 (双核 Cortex-A9 @ 667 MHz) 上运行 Linux, 处理激光雷达 30 万点/秒数据流。PL (FPGA) 负责传感器接口和 DMA 搬运, PS (ARM) 负责点云算法处理和网络输出。\n\n### 1.1 量化目标\n\n| 编号 | 目标 | 量化指标 | 验证方法 |\n|------|------|----------|----------|\n| G-1 | 端到端延迟 | 单帧 P99 < 5 ms | 硬件时间戳 |\n| G-2 | 数据吞吐 | >= 30 万点/秒 (4.8 MB/s) | 帧计数统计 |\n| G-3 | 零拷贝 | PL DMA -> 算法: 0 次 memcpy | 代码审查 |\n| G-4 | 零堆分配 | 热路径 malloc/free 调用 0 次 | 运行时 hook |\n| G-5 | 连续运行 | 72h 零崩溃, 零 CRC 错误 | 长稳测试 |\n| G-6 | 算力余量 | CPU 总负载 < 80% | RT 周期采样 |\n\n### 1.2 硬件约束\n\n| 项目 | 配置 |\n|------|------|\n| PS | 双核 Cortex-A9 @ 667 MHz, NEON VFPv3, 32 KB L1 I/D, 512 KB L2 |\n| PL | Artix-7 逻辑, AXI DMA (SG 模式), 150 MHz 数据通路 |\n| 内存 | 512 MB DDR3, 256 KB OCM |\n| 互联 | AXI HP0 (64-bit, 150 MHz, 峰值 1.2 GB/s), ACP (Snoop 端口) |\n| 数据格式 | 每点 16 B (x/y/z int16 + intensity + ring_id + timestamp) |\n\n---\n\n## 2. 带宽与算力分析\n\n### 2.1 数据带宽预算\n\n以 30 万点/秒, 16 B/点, 25 Hz 帧率计算:\n\n| 环节 | 带宽 | 占 DDR 峰值 (4.26 GB/s) | 裕度 |\n|------|------|:------------------------:|:----:|\n| PL DMA 写入 | 4.8 MB/s | 0.11% | > 880x |\n| CPU 读取处理 | 4.8 MB/s | 0.11% | > 880x |\n| AXI HP 端口峰值 | 1.2 GB/s | -- | 参考上限 |\n| 网络输出 | ~5 MB/s | 0.12% | 充足 |\n\n> 带宽不是瓶颈。CPU 算法处理时间和调度抖动是端到端延迟的主导因素。\n\n### 2.2 CPU 算力预算\n\n| 任务 | 单帧耗时 | 帧率 25 Hz 占用率 | 部署核心 |\n|------|:--------:|:-----------------:|----------|\n| DMA 接收 + CRC 校验 | ~0.5 ms | 1.25% | Core 1 |\n| 点云滤波 (NEON) | ~2 ms | 5% | Core 1 |\n| 坐标变换 (NEON) | ~1 ms | 2.5% | Core 1 |\n| 帧拼接 | ~0.5 ms | 1.25% | Core 1 |\n| 网络发送 | ~1 ms | 2.5% | Core 0 |\n| 系统服务 + 日志 | -- | ~10% | Core 0 |\n| **Core 1 总计** | | **~10%** | 裕度充足 |\n| **Core 0 总计** | | **~12.5%** | 裕度充足 |\n\n> 即使点云处理耗时翻倍, CPU 负载仍低于 30%, 为 100 万点/秒 (64 线雷达) 留出余量。\n\n---\n\n## 3. 软硬协同架构\n\n### 3.1 系统架构\n\n```mermaid\nflowchart LR\n    subgraph PL[\"PL: FPGA (150 MHz)\"]\n        LIDAR[\"激光雷达\\n协议解析\"] --> PACK[\"数据打包\\n定长 PointBlock\"]\n        PACK --> DMA[\"AXI DMA\\nSG 模式\"]\n    end\n\n    subgraph DDR[\"DDR3 共享内存\"]\n        RING[\"ShmRingBuffer\\nSPSC 零拷贝\\n64 slots x 1KB\"]\n    end\n\n    subgraph PS0[\"Core 0: 系统核\"]\n        NET[\"网络输出\\nUDP/TCP\"]\n        LOG[\"日志/诊断\"]\n        CTRL[\"HSM 控制\\n生命周期\"]\n    end\n\n    subgraph PS1[\"Core 1: 算法核 (isolcpus)\"]\n        ACQ[\"采集任务\\nShmChannel 读取\"]\n        FILTER[\"点云滤波\\nNEON 加速\"]\n        FUSE[\"帧拼接\\n坐标变换\"]\n    end\n\n    DMA -->|\"AXI HP0\\n零拷贝写入\"| RING\n    RING -->|\"直接指针访问\"| ACQ\n    ACQ --> FILTER --> FUSE\n    FUSE -->|\"ShmChannel\"| NET\n    CTRL -->|\"AsyncBus\\n控制消息\"| ACQ\n```\n\n### 3.2 控制面 / 数据面分离\n\n| 平面 | 通道 | 消息类型 | 频率 | 说明 |\n|------|------|----------|------|------|\n| 数据面 | ShmChannel (SPSC) | 点云 PointBlock (1 KB/块) | 25 Hz | 零拷贝, Wait-free |\n| 控制面 | AsyncBus (MPSC) | 启停/模式/参数 (< 256 B) | < 100 msg/s | 优先级准入 |\n\nnewosp 实测: AsyncBus 控制消息吞吐 5.9 M msg/s (x86), ARM 估算 0.5-1.0 M msg/s, 相对激光雷达 < 100 msg/s 的控制消息需求有 **5000x 以上裕度**。\n\n---\n\n## 4. 零拷贝数据通道\n\n### 4.1 PL-PS 共享环形缓冲\n\n利用 Zynq 的 AXI HP 端口, PL DMA 直接写入 DDR 中预分配的 ShmRingBuffer, CPU 通过指针直接访问:\n\n```mermaid\nflowchart LR\n    DMA[\"AXI DMA\\n(生产者)\"] -->|\"写 slot payload\"| RING[\"ShmRingBuffer\\nNon-cacheable 区域\\n64 slots\"]\n    RING -->|\"const PointBlock*\\n直接读取\"| CPU[\"算法任务\\n(消费者)\"]\n    CPU -->|\"更新 tail\"| RING\n```\n\n**单 slot 结构** (1 KB, cache line 对齐):\n\n| 字段 | 大小 | 说明 |\n|------|------|------|\n| seq | 4 B | 单调递增序列号 |\n| timestamp_ns | 8 B | 硬件时间戳 |\n| count + crc16 | 4 B | 点数 + CRC 校验 |\n| points[62] | 992 B | 62 点 x 16 B (int16 x/y/z + intensity + ring_id) |\n\n**内存占用**: 64 slots x 1 KB = 64 KB\n\n### 4.2 AXI 端口选择\n\n| 端口 | 特点 | 选择理由 |\n|------|------|----------|\n| **AXI HP0** (推荐) | 64-bit, Non-cacheable, 不干扰 CPU Cache | 数据量小, 带宽裕度 > 800x, 简单可靠 |\n| AXI ACP | 硬件 Snoop, Cache Coherent | Snoop 流量干扰 CPU Cache, 低速场景收益不大 |\n\n选择 HP0 + Non-cacheable 映射: 用 800x 带宽裕度换取零 cache 一致性代码, 与 Zynq-7000 双核 SMP 概要设计一致。\n\n---\n\n## 5. 实时调度与抗干扰\n\n### 5.1 核心部署\n\n使用 newosp RealtimeExecutor 确保 Core 1 的调度确定性:\n\n| 措施 | 作用 |\n|------|------|\n| `isolcpus=1` | Core 1 从 Linux 调度器剥离 |\n| `SCHED_FIFO` priority=90 | 实时调度, 不被普通进程抢占 |\n| `mlockall` | 锁定内存页, 防止缺页中断 |\n| Stack prefault | 预写栈页面, 避免首次 page fault |\n| CPU affinity | 绑核, 保持 L1/L2 Cache 热度 |\n\n### 5.2 newosp 模块映射\n\n| 功能 | newosp 模块 | 部署 |\n|------|------------|------|\n| 数据接收 | ShmChannel (SpscRingBuffer) | Core 1, PL DMA -> CPU |\n| 控制消息 | AsyncBus + Node | Core 0, HSM 驱动 |\n| 实时调度 | RealtimeExecutor | Core 1, SCHED_FIFO |\n| 系统任务 | WorkerPool | Core 0, 网络/日志 |\n| 设备状态 | HSM | Core 0, Init/Ready/Active/Fault |\n| 定时器 | TimerScheduler | Core 0, 心跳/看门狗 |\n| 诊断通道 | SerialTransport | Core 0, 串口 CRC+ACK |\n| 线程监控 | ThreadWatchdog | Core 0 |\n\n---\n\n## 6. NEON SIMD 优化策略\n\nCortex-A9 的 NEON VFPv3 是提升点云处理吞吐的关键:\n\n### 6.1 定点化计算\n\n| 方案 | 数据类型 | NEON 并行度 | 精度 | 推荐 |\n|------|----------|:----------:|------|:----:|\n| 浮点 | float32 | 4 路 | 无限制 | 否 |\n| **定点** | **int16** | **8 路** | +/- 327.67 m, 1 cm | **是** |\n\n激光雷达量程通常 < 200 m, 精度需求 1 cm, int16 (范围 +/- 327.67 m) 完全满足。NEON 并行度从 4 路 (float32) 提升到 8 路 (int16), 理论算力翻倍。\n\n### 6.2 数据布局\n\n| 布局 | 说明 | NEON 效率 | 适用 |\n|------|------|:---------:|------|\n| AoS (Array of Structs) | `{x,y,z,i}, {x,y,z,i}, ...` | 需 `vld4` 解交织 | DMA 写入默认格式 |\n| SoA (Struct of Arrays) | `{x,x,x,...}, {y,y,y,...}` | 连续加载, 效率最高 | PL 可配置输出格式 |\n\n**建议**: 若 PL 逻辑可修改, 优先输出 SoA 格式; 否则在 CPU 侧使用 `vld4.16` 解交织, 开销约 10%。\n\n---\n\n## 7. 设备生命周期\n\n```mermaid\nstateDiagram-v2\n    [*] --> PowerOn\n    PowerOn --> SelfTest: 上电完成\n    SelfTest --> Calibrating: 自检通过\n    SelfTest --> Fault: 自检失败\n\n    Calibrating --> Running: 校准完成\n    Calibrating --> Fault: 校准超时\n\n    Running --> Standby: 停止命令\n    Running --> Fault: 运行异常\n\n    Standby --> Running: 启动命令\n    Standby --> PowerOff: 关机命令\n\n    Fault --> SelfTest: 恢复命令\n    Fault --> PowerOff: 关机命令\n\n    PowerOff --> [*]\n```\n\n使用 newosp HSM 管理设备状态, 覆盖上电自检、激光器校准、正常运行、故障恢复全流程。\n\n---\n\n## 8. 资源预算\n\n以 Zynq-7020 (512 MB DDR3) 为例:\n\n| 资源 | newosp 框架 | 点云缓冲 | 算法 | Linux 系统 | 总计 |\n|------|:-----------:|:--------:|:----:|:----------:|:----:|\n| RAM | ~2 MB | ~3 MB | 10-50 MB | ~32 MB | < 90 MB |\n| CPU | < 5% | -- | 10-20% | ~15% | < 40% |\n| .text | ~80 KB | -- | 1-5 MB | ~8 MB | < 14 MB |\n\n> 框架层资源占用极低, 为点云算法和未来扩展 (64 线雷达) 留出充足空间。\n\n---\n\n## 9. 可行性结论\n\n| 维度 | 评估 | 裕度 |\n|------|------|:----:|\n| DDR 带宽 | 4.8 MB/s vs 4.26 GB/s | > 880x |\n| CPU 算力 | ~22% vs 200% (双核) | > 8x |\n| newosp 控制消息 | < 100 msg/s vs 500K msg/s (ARM) | > 5000x |\n| 内存占用 | < 90 MB vs 512 MB | > 5x |\n\n**结论**: Zynq-7000 + newosp 方案在所有维度上均满足 30 万点/秒激光雷达需求, 且有充足裕度。通过 NEON 定点化和 SoA 数据布局优化, 可进一步支持 100 万点/秒 (64 线雷达) 场景。\n\n---\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/150849448)\n",
      "ctime": "1771552454",
      "mtime": "1771552454",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/lidar_pipeline_newosp.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357778458",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "激光雷达高吞吐数据处理 Pipeline: 模块化架构与 NEON 向量化",
      "brief_content": "本文展示如何用 newosp C++17 header-only 基础设施库构建激光雷达等高吞吐传感器的 DAG 数据处理 Pipeline。数据面采用 SPSC 直连 + Handle 传递实现真零",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 基础设施库: [newosp](https://github.com/DeguiLiu/newosp) v0.4.3 (1153 tests, ASan/TSan/UBSan clean)\n> 目标平台: ARM-Linux (Cortex-A53/A72/A7) | C++17, Header-only\n> 适用场景: 激光雷达点云处理、工业视觉、机器人传感器融合、边缘计算\n\n---\n\n## 1. 背景与问题域\n\n### 1.1 高吞吐传感器数据的挑战\n\n激光雷达等高吞吐传感器每秒产生数十万至数百万个数据点，典型的处理流水线包括:\n\n```\n采集 → 预处理 → 距离计算 → 串扰去除 → 鬼影消除 → 噪声滤波 → 分割 → 封装输出\n```\n\n这条 Pipeline 面临的核心工程挑战:\n\n| 挑战 | 约束条件 | 典型指标 |\n|------|----------|----------|\n| 延迟 | 单帧处理须在传感器周期内完成 | < 10 ms (100 Hz) |\n| 吞吐 | 全速率无丢帧 | 300K~1M points/s |\n| 内存带宽 | ARM Cortex-A53 LPDDR4 ~6.4 GB/s | 数据面零拷贝 |\n| 内存占用 | 嵌入式平台 RAM 有限 | < 100 KB 静态 + 零堆分配 |\n| 确定性 | 实时系统不可有不确定延迟 | 无 malloc、无锁竞争 |\n| 可维护性 | 算法迭代频繁，模块需解耦 | 节点可独立替换 |\n\n### 1.2 传统方案的局限\n\n纯 C 语言 + QPC (Quantum Platform C) 风格的方案广泛用于 MCU/RTOS 平台:\n\n- 每个 Node 是一个 QActive 主动对象，内部运行 switch-case 状态机\n- 节点间通过 void* 事件队列传递数据\n- 共享内存 + 手写 SPSC 环形缓冲实现零拷贝\n- linker section (`__attribute__((section))`) 编译期插件注册\n\n这种方案在 MCU 裸机上运行良好，但迁移到 ARM-Linux 后暴露多个问题:\n\n1. **类型安全缺失**: `void*` 事件指针无编译期类型检查，强制转换错误只能在运行时发现\n2. **手动生命周期管理**: 引用计数依赖人工维护，忘记释放导致泄漏，多释放导致 crash\n3. **状态机维护困难**: 5+ 状态的 switch-case 随着需求增长变成数百行意大利面条代码\n4. **测试基础设施薄弱**: 断言宏散落各处，无统一测试框架\n5. **代码复用率低**: 每个项目重新实现环形缓冲、内存池、状态机\n\n---\n\n## 2. 架构总览: 数据面与控制面分离\n\n本 Pipeline 采用 **数据面与控制面分离** 架构。控制面/数据面分离的通用设计原理、AsyncBus MPSC 消息总线、ShmChannel 零拷贝通道、RealtimeExecutor 实时调度等基础设施的详细介绍参见 [工业嵌入式流式数据处理架构设计](../Streaming_Architecture_Design/)。本节聚焦激光雷达 Pipeline 的具体拓扑设计。\n\n**核心原则**: Pipeline 每个 stage 的 producer/consumer 关系是 1:1，MPSC 的 CAS 竞争在此场景下是多余开销。数据面用 SPSC 直连 (~5 ns)，控制面用 AsyncBus 处理诊断和扇入/扇出场景。\n\n### 2.1 Pipeline 架构图\n\n```mermaid\nflowchart TB\n    subgraph \"Data Plane -- SPSC Direct Connect\"\n        ACQ[采集<br/>DMA + Pool] -->|\"SPSC&lt;Handle&gt;\"| PRECALC[预处理+距离计算<br/>融合 Stage]\n        PRECALC -->|\"SPSC&lt;Handle&gt;\"| XTALK[串扰去除<br/>HSM 状态管理]\n        XTALK -->|\"SPSC&lt;Handle&gt;\"| GHOST[鬼影消除<br/>多帧历史]\n        GHOST -->|\"SPSC&lt;Handle&gt;\"| FILTSEG[滤波+分割<br/>融合 Stage]\n        FILTSEG -->|\"SPSC&lt;Handle&gt;\"| PKG[封装输出<br/>Transport]\n    end\n\n    subgraph \"Control Plane -- AsyncBus\"\n        BUS[AsyncBus<br/>诊断/控制/扇入扇出]\n        SHELL[Shell 诊断<br/>Console/UART/Telnet]\n        WDG[ThreadWatchdog<br/>故障检测]\n    end\n\n    BUS -.->|统计查询| ACQ & PRECALC & XTALK & GHOST & FILTSEG\n    SHELL -.->|命令注入| BUS\n    WDG -.->|心跳监控| ACQ & PRECALC & XTALK & GHOST & FILTSEG\n```\n\n原始 8 个 stage 经过**融合优化**减至 5 个:\n- **PreCalc**: 预处理 + 距离计算 (连续数学运算，无状态切换)\n- **FilterSeg**: 噪声滤波 + 数据分割 (都是逐点操作)\n- **XTalk**: 串扰去除 (需 HSM 状态管理，独立)\n- **Ghost**: 鬼影消除 (需多帧历史缓冲，独立)\n\n### 2.2 数据流: Handle 传递实现真零拷贝\n\n传统方案声称\"零拷贝\"但实际每个 stage 都在拷贝整帧数据。以 1024 点帧 (16 KB SoA) 为例:\n\n| 方案 | 每帧拷贝量 | 5 stage x 100 Hz | 内存带宽 |\n|------|-----------|------------------|----------|\n| variant 逐级拷贝 | 16 KB x 5 = 80 KB | 8 MB/s | ~1.3% LPDDR4 |\n| **Handle 传递** | **6B x 5 = 30B** | **3 KB/s** | **~0%** |\n\nHandle 传递的核心: SPSC ring buffer 只传递 6 字节的 `FrameHandle`，数据本体始终留在 `ObjectPool` 中，各 stage 通过 index 原地读写:\n\n```cpp\n// Handle: 仅 6 字节，在 SPSC 中传递\nstruct FrameHandle {\n  uint16_t pool_index;    // ObjectPool 中的槽位\n  uint32_t frame_id;      // 帧号 (全链路追踪)\n};\n\n// 数据本体: 留在 Pool 中，各 stage 原地读写\nusing FramePool = osp::ObjectPool<PointCloudSoA, 32>;  // 32 帧预分配\nusing StageRing = osp::SpscRingbuffer<FrameHandle, 32>; // 每 slot 仅 6B\n\n// stage 间传递 Handle，不拷贝数据\nStageRing acq_to_precalc;\nStageRing precalc_to_xtalk;\nStageRing xtalk_to_ghost;\n// ...\n```\n\n数据流时序:\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│ 1. 采集: pool.Create() → 获得 PointCloudSoA* (pool_index=3) │\n│ 2. DMA 直接写入 pool[3].x[], pool[3].y[], pool[3].z[]       │\n│ 3. Push(FrameHandle{3, frame_id}) 到 acq_to_precalc SPSC    │\n│ 4. PreCalc: Peek() 取 Handle → pool[3] 原地距离计算         │\n│ 5. Push(Handle{3, ...}) 到 precalc_to_xtalk SPSC            │\n│ 6. ... 各 stage 通过 Handle 访问同一块内存 ...                │\n│ 7. 最后一个 stage 完成后: pool.Destroy(pool[3])              │\n└──────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## 3. 数据布局: SoA 替代 AoS\n\n### 3.1 为什么 AoS 不适合点云处理\n\n传统 AoS (Array of Structures) 布局:\n\n```cpp\n// AoS: 每个点的 x/y/z/intensity 连续存储\nstruct Point { float x, y, z, intensity; };\nstruct RawFrame { uint32_t id; Point points[1024]; };  // 16 KB\n```\n\n距离计算 `d = sqrt(x*x + y*y + z*z)` 遍历所有点的 x 分量时，每次加载一个 cache line (64B) 只取到 4 个 float 中的 1 个 (利用率 25%)。对 ARM NEON 来说，`vld1q_f32` 加载的 4 个 float 分属 4 个不同的点，无法直接做 SIMD 运算。\n\n### 3.2 SoA 布局\n\n```cpp\n// SoA: 同一分量连续存储，NEON 友好\nstruct PointCloudSoA {\n  uint32_t frame_id;\n  uint32_t count;                       // 有效点数\n  alignas(16) float x[1024];            // NEON vld1q_f32 连续加载 4 个 x\n  alignas(16) float y[1024];\n  alignas(16) float z[1024];\n  alignas(16) float intensity[1024];\n  uint64_t timestamp_ns;                // osp::SteadyNowNs()\n};\n// sizeof = 16400B, alignas(16) 确保 NEON 对齐加载\n```\n\nSoA 下距离计算用 NEON intrinsics:\n\n```cpp\n#include <arm_neon.h>\n\nvoid ComputeDistance(PointCloudSoA& cloud) {\n  for (uint32_t i = 0; i < cloud.count; i += 4) {\n    float32x4_t vx = vld1q_f32(&cloud.x[i]);\n    float32x4_t vy = vld1q_f32(&cloud.y[i]);\n    float32x4_t vz = vld1q_f32(&cloud.z[i]);\n\n    // d^2 = x*x + y*y + z*z\n    float32x4_t d2 = vmlaq_f32(vmlaq_f32(vmulq_f32(vx, vx),\n                                           vy, vy), vz, vz);\n    // d = 1/sqrt(d^2) * d^2 = sqrt(d^2), 用 vrsqrteq 近似\n    float32x4_t inv = vrsqrteq_f32(d2);\n    float32x4_t dist = vmulq_f32(d2, inv);\n\n    vst1q_f32(&cloud.intensity[i], dist);  // in-place 覆写\n  }\n}\n```\n\n性能对比 (Cortex-A53 @ 1.2 GHz, 1024 points):\n\n| 布局 | Cache line 利用率 | NEON 加速 | 单帧耗时 |\n|------|------------------|-----------|----------|\n| AoS + 标量 | 25% | 无 | ~12 us |\n| **SoA + NEON** | **100%** | **4x** | **~3 us** |\n\n### 3.3 In-place 处理\n\nSoA 布局的另一个优势: 多个 stage 可以**原地修改同一个 buffer**，避免格式转换拷贝:\n\n```cpp\n// 串扰去除: 原地修改 intensity\nvoid RemoveCrosstalk(PointCloudSoA& cloud) {\n  for (uint32_t i = 0; i < cloud.count; ++i) {\n    cloud.intensity[i] -= crosstalk_table[i];  // in-place\n  }\n}\n\n// 噪声滤波: 原地修改 x/y/z\nvoid FilterNoise(PointCloudSoA& cloud) {\n  // median filter on x[], y[], z[] -- in-place\n}\n```\n\n不需要 `RawFrame → Processed → Filtered` 的类型转换链，所有 stage 操作同一个 `PointCloudSoA`。\n\n---\n\n## 4. 核心子系统设计\n\n### 4.1 SPSC 直连: 数据面通信\n\n每对相邻 stage 之间用一个 `SpscRingbuffer<FrameHandle, N>` 直连:\n\n```cpp\n// stage 间 SPSC 直连，每 slot 仅 6B\nusing StageRing = osp::SpscRingbuffer<FrameHandle, 32, /*FakeTSO=*/false>;\n\n// 生产者 stage\nvoid PreCalcStage::Process() {\n  if (auto* handle = input_.Peek()) {      // 零拷贝读取 Handle\n    auto& cloud = pool_[handle->pool_index];\n    ComputeDistance(cloud);                 // 原地处理\n    output_.Push(*handle);                 // 6B Handle 传递\n    input_.Discard();                      // 释放上游 slot\n  }\n}\n\n// 消费者 stage\nvoid XTalkStage::Process() {\n  if (auto* handle = input_.Peek()) {\n    auto& cloud = pool_[handle->pool_index];\n    RemoveCrosstalk(cloud);\n    output_.Push(*handle);\n    input_.Discard();\n  }\n}\n```\n\nSPSC vs MPSC Bus 性能对比 (Cortex-A53 @ 1.2 GHz, Handle 传递):\n\n| 通信方式 | 单消息延迟 | 操作 | 适用场景 |\n|---------|-----------|------|---------|\n| **SPSC (FrameHandle)** | **~5 ns** | load/store + acquire/release | **1:1 stage 直连** |\n| Bus (variant Publish) | ~30 ns | CAS + variant visit + callback | 扇入/扇出/控制面 |\n| Bus (ProcessBatchWith) | ~2 ns/msg (批量均摊) | 同上，batch=256 均摊 | 高吞吐广播 |\n\n> 性能数据测试条件: Cortex-A53 1.2 GHz, GCC 12 -O2, 单线程 benchmark, 10M 次迭代取中位数。SPSC 传递 6B FrameHandle; Bus 传递 8B variant (最小 payload)。实际 payload 越大差距越大。\n\n### 4.2 AsyncBus: 控制面与扇入/扇出\n\nAsyncBus 不用于线性 Pipeline 数据面，但在多传感器扇入和诊断命令注入场景不可替代。AsyncBus 的 Lock-free MPSC 设计、零堆分配机制、优先级准入控制的完整介绍参见 [工业嵌入式流式数据处理架构设计 -- AsyncBus](../Streaming_Architecture_Design/#3-控制面-asyncbus-消息总线)。\n\n在激光雷达 Pipeline 中，AsyncBus 的典型用法:\n\n- **多传感器扇入**: 多个激光雷达传感器各自 Publish 到同一 Bus，融合节点统一 ProcessBatch\n- **诊断命令注入**: Shell 通过 Bus 下发运行时参数调整 (如滤波阈值)，Pipeline stage 定期 ProcessBatchWith 检查\n\n### 4.3 层次状态机: 有状态 Stage 的管理\n\n并非所有 stage 都是无状态的逐点处理。串扰去除需要维护校准状态，故障恢复需要重试逻辑。HSM 的通用设计 (LCA 转换、Guard 条件、Entry/Exit) 和 HSM + BT 组合模式参见 [工业嵌入式流式数据处理架构设计 -- 状态管理](../Streaming_Architecture_Design/#6-状态管理-层次状态机-hsm)。\n\n在激光雷达串扰去除 stage 中，HSM 的具体应用:\n\n```cpp\nenum class XTalkState : uint8_t {\n  kIdle, kProcessing, kCalibrating, kError\n};\nenum class XTalkEvent : uint8_t {\n  kFrameIn, kCalibReq, kCalibDone, kFail, kRetry\n};\n\nusing XTalkHsm = osp::HsmStateMachine<XTalkState, XTalkEvent, 8>;\nXTalkHsm hsm;\n\n// 声明式状态层次\nhsm.SetParent(XTalkState::kCalibrating, XTalkState::kProcessing);\n\n// Guard 条件: 重试不超过 3 次\nhsm.AddTransition(XTalkState::kError, XTalkEvent::kRetry,\n                   XTalkState::kProcessing,\n                   [](auto& ctx) { return ctx.retry_count < 3; });\n\n// Entry/Exit 自动性能计时\nhsm.OnEntry(XTalkState::kProcessing, [](auto&) { start_perf_timer(); });\nhsm.OnExit(XTalkState::kProcessing, [](auto&) { record_perf_metrics(); });\n```\n\n```mermaid\nstateDiagram-v2\n    [*] --> Idle\n\n    state Processing {\n        [*] --> Active\n        Active --> Calibrating : kCalibReq\n        Calibrating --> Active : kCalibDone\n    }\n\n    Idle --> Active : kFrameIn\n    Active --> Error : kFail\n    Error --> Active : kRetry [retry < 3]\n    Error --> Idle : kRetry [retry >= 3]\n```\n\nHSM 声明式转换替代 switch-case 后，新增状态只需添加一行 `AddTransition`，维护复杂度从 O(states x events) 降至 O(transitions)。\n\n### 4.4 内存池: ObjectPool + Handle 模式\n\n```cpp\n// 预分配 32 帧 PointCloudSoA，零堆分配\nusing FramePool = osp::ObjectPool<PointCloudSoA, 32>;\nFramePool pool;\n\n// 采集 stage: 分配帧\nauto* cloud = pool.Create();  // O(1), placement new\nuint16_t idx = pool.IndexOf(cloud);\n\n// DMA 直接写入 pool 槽位\ndma_transfer(sensor_fd, cloud->x, cloud->count * sizeof(float));\n// ...\n\n// 构造 Handle 送入 SPSC\nFrameHandle handle{idx, frame_id};\nacq_to_precalc.Push(handle);\n\n// 最后一个 stage: 释放帧\npool.Destroy(&pool[handle.pool_index]);  // O(1), placement delete\n```\n\n### 4.5 实时调度与看门狗\n\nRealtimeExecutor 的 SCHED_FIFO + isolcpus + mlockall 设计详见 [工业嵌入式流式数据处理架构设计 -- 调度层](../Streaming_Architecture_Design/#5-调度层-realtimeexecutor-与-workerpool)。以下是激光雷达 Pipeline 的具体线程分配:\n\n```cpp\n// Stage 线程分配 (4 核 Cortex-A53)\n// CPU0: 采集 (DMA 中断亲和)\n// CPU1: PreCalc + XTalk (融合，计算密集)\n// CPU2: Ghost + FilterSeg (融合，内存密集)\n// CPU3: 封装输出 + Shell 诊断\n\n// 看门狗监控每个 stage 线程\nosp::ThreadWatchdog<8> watchdog;\nwatchdog.SetTimeout(50);  // 50ms 超时 (100Hz 帧率的半周期)\nwatchdog.OnTimeout([](uint32_t thread_id) {\n    osp::FaultCollector::Report(0x01010001, thread_id);\n});\n```\n\n---\n\n## 5. 流水线并行\n\n### 5.1 串行 vs 并行\n\n如果所有 stage 运行在同一线程上，单帧处理链是串行的:\n\n```\n时间 →  T0        T1        T2\n线程0: [ACQ+PRE+XTALK+GHOST+FILT+PKG][F0]\n                             [ACQ+PRE+XTALK+GHOST+FILT+PKG][F1]\n                                                      [ACQ+PRE+...][F2]\n```\n\n单帧耗时 = 所有 stage 之和。如果总耗时接近 10ms 预算 (100 Hz)，没有余量。\n\n### 5.2 多级流水线并行\n\n每个 stage 一个线程 + SPSC 直连，不同 stage 处理不同帧:\n\n```\n时间 →  T0      T1      T2      T3      T4\n线程0: ACQ[F0] ACQ[F1] ACQ[F2] ACQ[F3] ACQ[F4]\n线程1:         PRE[F0] PRE[F1] PRE[F2] PRE[F3]\n线程2:                 XTK[F0] XTK[F1] XTK[F2]\n线程3:                         PKG[F0] PKG[F1]\n```\n\n帧延迟增加 (从 1 帧变为 N 帧，N = stage 数)，但**吞吐翻倍**: 稳态下每个时间单位输出 1 帧，瓶颈取决于最慢的 stage 而非总和。\n\n对于激光雷达等非交互式场景，3-4 帧延迟 (30-40 ms @ 100 Hz) 完全可接受。\n\n### 5.3 Stage 融合减少线程数\n\n4 核 Cortex-A53 不适合 8 个线程。通过算法依赖分析融合 stage:\n\n| 原始 Stage | 融合策略 | 原因 |\n|-----------|---------|------|\n| 预处理 + 距离计算 | **融合为 PreCalc** | 连续数学运算，无外部状态 |\n| 噪声滤波 + 数据分割 | **融合为 FilterSeg** | 都是逐点操作，数据局部性好 |\n| 串扰去除 | **独立** | 需 HSM 状态管理，有校准流程 |\n| 鬼影消除 | **独立** | 需多帧历史缓冲 |\n\n融合后 5 个 stage + 1 个控制线程 = 4 个数据面线程 + 1 控制线程，映射到 4 核:\n\n```\nCPU0: 采集 stage (DMA 中断亲和)\nCPU1: PreCalc + XTalk (绑核，计算密集型)\nCPU2: Ghost + FilterSeg (绑核，内存密集型)\nCPU3: 封装输出 + Shell 诊断 (控制面)\n```\n\n---\n\n## 6. 调试与监控\n\n### 6.1 Shell 诊断命令\n\nnewosp 的 `shell_commands.hpp` 提供零侵入诊断桥接:\n\n```cpp\n// 一行代码注册诊断命令\nosp::shell_cmd::RegisterWatchdog(watchdog);\nosp::shell_cmd::RegisterPool(pool, \"frame_pool\");\n\n// Console/UART/Telnet 中执行\n// osp> osp_watchdog\n// [osp_watchdog] 4 threads monitored, 0 timeouts\n// osp> osp_pool\n// [osp_pool] frame_pool: 28/32 available, 4 in-use\n```\n\n13 个内置诊断命令覆盖: 看门狗、故障、总线统计、工作线程池、传输层、串口、HSM 节点、服务、发现、生命周期、QoS、内存池。\n\n三种后端:\n- **DebugShell**: TCP telnet (远程调试, `#if OSP_HAS_NETWORK`)\n- **ConsoleShell**: stdin/stdout (本地终端, 始终可用)\n- **UartShell**: 串口 (工业现场, 始终可用)\n\n### 6.2 全链路追踪\n\n每个 `FrameHandle` 携带 `frame_id`，各 stage 可记录处理时间:\n\n```cpp\nstruct StageMetrics {\n  uint32_t processed_count = 0;\n  uint64_t total_ns = 0;\n  uint64_t max_ns = 0;\n\n  void Record(uint64_t elapsed_ns) {\n    ++processed_count;\n    total_ns += elapsed_ns;\n    if (elapsed_ns > max_ns) max_ns = elapsed_ns;\n  }\n\n  uint64_t AvgNs() const {\n    return processed_count > 0 ? total_ns / processed_count : 0;\n  }\n};\n```\n\n---\n\n## 7. 方案对比\n\n| 维度 | 纯 C / QPC | newosp C++17 (本文方案) |\n|------|-----------|------------------------|\n| **数据面通信** | void* 事件队列 (MPSC) | SPSC 直连 + Handle (1:1 专用) |\n| **控制面通信** | 同上 (混用) | AsyncBus (MPSC, 仅扇入/扇出/诊断) |\n| **零拷贝** | 手写引用计数 | Handle 传递 (6B), 数据原地读写 |\n| **数据布局** | AoS | SoA (NEON 友好, alignas(16)) |\n| **类型安全** | void* 强转 | std::variant + visitor (控制面) |\n| **内存管理** | 手动 alloc/free | ObjectPool RAII (O(1) 固定块) |\n| **状态机** | switch-case (扁平) | LCA HSM (层次, guard, entry/exit) |\n| **编译期配置** | #define 宏 | 模板参数 (QueueDepth, MaxStates) |\n| **流水线并行** | 手动 pthread | Stage-per-thread + CPU 绑核 |\n| **测试** | 手写断言 | Catch2 (1153 tests) |\n| **Sanitizer** | 无 | ASan + TSan + UBSan 全绿 |\n\n---\n\n## 8. 部署示例\n\n```cpp\n#include \"osp/spsc_ringbuffer.hpp\"\n#include \"osp/mem_pool.hpp\"\n#include \"osp/hsm.hpp\"\n#include \"osp/bus.hpp\"\n#include \"osp/watchdog.hpp\"\n#include \"osp/shell.hpp\"\n#include \"osp/shell_commands.hpp\"\n#include \"osp/platform.hpp\"\n\n// SoA 点云数据\nstruct PointCloudSoA {\n  uint32_t frame_id;\n  uint32_t count;\n  alignas(16) float x[1024];\n  alignas(16) float y[1024];\n  alignas(16) float z[1024];\n  alignas(16) float intensity[1024];\n  uint64_t timestamp_ns;\n};\n\n// Handle: 仅 6 字节在 SPSC 中流转\nstruct FrameHandle {\n  uint16_t pool_index;\n  uint32_t frame_id;\n};\n\n// 基础设施\nusing FramePool = osp::ObjectPool<PointCloudSoA, 32>;\nusing StageRing = osp::SpscRingbuffer<FrameHandle, 32>;\n\n// Pipeline stage (示例: 距离计算)\nclass PreCalcStage {\n public:\n  PreCalcStage(FramePool& pool, StageRing& in, StageRing& out)\n      : pool_(pool), input_(in), output_(out) {}\n\n  void Run() {\n    while (running_.load(std::memory_order_relaxed)) {\n      heartbeat_.Beat();\n      if (auto* h = input_.Peek()) {\n        uint64_t t0 = osp::SteadyNowNs();\n        auto& cloud = pool_[h->pool_index];\n        ComputeDistance(cloud);              // SoA + NEON, in-place\n        output_.Push(*h);                   // 6B Handle\n        input_.Discard();\n        metrics_.Record(osp::SteadyNowNs() - t0);\n      } else {\n        std::this_thread::yield();\n      }\n    }\n  }\n\n private:\n  FramePool& pool_;\n  StageRing& input_;\n  StageRing& output_;\n  std::atomic<bool> running_{true};\n  osp::ThreadHeartbeat heartbeat_;\n  StageMetrics metrics_;\n};\n\nint main() {\n  // 1. 基础设施\n  FramePool pool;\n  StageRing acq_to_precalc, precalc_to_xtalk, xtalk_to_ghost,\n            ghost_to_filtseg, filtseg_to_pkg;\n\n  // 2. 创建各 stage (省略完整实现)\n  PreCalcStage precalc(pool, acq_to_precalc, precalc_to_xtalk);\n\n  // 3. 看门狗\n  osp::ThreadWatchdog<8> watchdog;\n  watchdog.SetTimeout(50);\n\n  // 4. Shell 诊断\n  osp::ConsoleShell console;\n  osp::shell_cmd::RegisterWatchdog(watchdog);\n  console.Start();\n\n  // 5. 启动 stage 线程 (每 stage 绑核)\n  std::thread t1([&] {\n    // CPU1 affinity + SCHED_FIFO\n    precalc.Run();\n  });\n\n  // ... 其他 stage 线程 ...\n\n  t1.join();\n  return 0;\n}\n```\n\n---\n\n## 9. 总结\n\n1. **数据面 SPSC 直连，控制面 Bus 分离**: 线性 Pipeline 的 1:1 stage 间用 SPSC 直连 (~5 ns)，AsyncBus 仅用于扇入/扇出和诊断注入。避免把通用消息总线误用为 Pipeline 数据通道。\n\n2. **Handle 传递实现真零拷贝**: SPSC 只传 6B FrameHandle，数据本体留在 ObjectPool 中原地读写。消除逐级 16 KB 拷贝，内存带宽从 ~8 MB/s 降至 ~3 KB/s。\n\n3. **SoA 布局 + NEON**: 点云数据按分量连续存储，ARM NEON `vld1q_f32` 一次处理 4 点，距离计算吞吐提升 ~4x。\n\n4. **Stage-per-thread 流水线并行**: 各 stage 独立线程 + SPSC 连接，稳态吞吐取决于最慢 stage (非串行总和)。4 核 A53 通过 stage 融合映射为 4 数据面线程。\n\n5. **LCA 层次状态机**: 有状态 stage (串扰去除、校准) 用 HSM 管理，声明式转换替代 switch-case 意大利面条。\n\n6. **工程化保障**: 1153 个 Catch2 测试 + ASan/TSan/UBSan CI + Shell 多后端诊断，基础设施经过充分验证。\n\n---\n\n## 参考\n\n- [工业嵌入式流式数据处理架构设计](../Streaming_Architecture_Design/) -- 控制面/数据面分离、AsyncBus、ShmChannel、RealtimeExecutor、HSM+BT 通用架构设计\n- [newosp GitHub](https://github.com/DeguiLiu/newosp) -- C++17 header-only 嵌入式基础设施库\n- [newosp 设计文档](https://github.com/DeguiLiu/newosp/blob/main/docs/design_zh.md) -- 完整架构设计\n- QP/C Framework -- 量子平台 C 事件驱动框架\n- CyberRT / ROS2 -- 机器人中间件参考架构\n",
      "ctime": "1771552457",
      "mtime": "1771552457",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/mcu_secondary_bootloader.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469505582",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "MCU 二级 Bootloader 设计: 状态机驱动的 A/B 分区 OTA 与安全启动",
      "brief_content": "在工业 MCU 产品中，固件更新失败意味着设备变砖，安全启动漏洞意味着固件被篡改。本文设计一个裸机环境下的二级 Bootloader，用状态机驱动 A/B 分区 OTA (含 Scratch 分区原子",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 1. 问题: 为什么需要二级 Bootloader\n\n在工业 MCU 产品 (传感器模组、电机控制器、边缘网关) 的全生命周期中，固件更新和安全启动是两个绕不过去的需求:\n\n- **现场升级**: 设备部署到产线后，修复 bug 或增加功能只能通过 OTA (Over-The-Air) 或串口升级。如果更新过程中断电，设备必须能自动恢复，而非变砖。\n- **安全启动**: 设备暴露在物理环境中，攻击者可能替换 Flash 中的固件。Bootloader 必须在加载应用前验证固件的完整性和真实性。\n- **版本管理**: 新固件上线后出现严重缺陷，必须能回滚到上一个已知稳定的版本。\n\n一级 Bootloader (通常固化在 ROM 或受保护的 Flash 区域) 功能极其有限 -- 它只做最基本的硬件初始化和镜像跳转。上述复杂功能需要一个功能更丰富的**二级 Bootloader (Secondary Bootloader, SBL)** 来承担。\n\nSBL 运行在裸机环境下 (无 RTOS)，这意味着不能依赖操作系统的线程调度、互斥锁、消息队列。所有并发逻辑 -- 通信协议解析、固件写入、超时监控 -- 必须在一个主循环中用状态机协调完成。\n\n## 2. 系统架构\n\n### 2.1 三级信任链\n\n安全启动的核心是**信任链 (Chain of Trust)**: 每一级在跳转到下一级之前，都必须验证下一级的完整性。\n\n```mermaid\nsequenceDiagram\n    participant PBL as 一级 Bootloader\n    participant SBL as 二级 Bootloader\n    participant HSM as 硬件安全模块\n    participant APP as 应用程序\n\n    Note over PBL: 上电/复位 → 初始化\n    PBL->>HSM: 验证 SBL 镜像签名\n    HSM-->>PBL: 签名结果\n    PBL->>PBL: 防回滚检查 (版本号)\n    alt SBL 验证通过\n        PBL->>SBL: 跳转至 SBL 入口\n        Note over SBL: 初始化外设、MPU、状态机\n        SBL->>SBL: 读取启动标志，选择 Active 分区\n        SBL->>SBL: 解析 App 镜像 Header + TLV\n        SBL->>HSM: 验证 App 镜像签名\n        HSM-->>SBL: 签名结果\n        SBL->>SBL: 防回滚检查 (App 版本号)\n        SBL->>APP: 跳转至 App\n        Note over APP: App 自检 → 通知 SBL 清零启动计数\n    else 验证失败\n        PBL->>PBL: 故障处理 (故障灯 + 日志)\n    end\n```\n\n- **一级 Bootloader**: 固化在受保护区域，职责最小化 -- 验证 SBL 镜像签名，通过则跳转，失败则进入安全模式。\n- **二级 Bootloader**: 本文的设计目标。裸机运行，承担 A/B 分区管理、固件更新、安全验证、通信协议处理。\n- **应用程序**: 启动后执行自检，成功则通知 SBL 清零启动计数器，为自动回滚机制提供依据。\n\n### 2.2 模块依赖\n\nSBL 在设计上复用主应用的 HAL 和驱动，自行实现任务调度与事件管理，不依赖任何 RTOS。\n\n```mermaid\ngraph TD\n    SBL[二级 Bootloader 核心]\n    SM[状态机框架]\n    RB[Ring Buffer]\n    HAL[硬件抽象层]\n    UART[UART 驱动]\n    I2C[I2C 驱动]\n    FLASH[Flash 驱动]\n    CRYPTO[安全库]\n\n    SBL --> SM\n    SBL --> RB\n    SBL --> HAL\n    SBL --> CRYPTO\n    HAL --> UART\n    HAL --> I2C\n    HAL --> FLASH\n```\n\n关键设计约束:\n\n- **零 RTOS 依赖**: 主循环 + 中断驱动 + 状态机，替代线程和消息队列。\n- **复用 HAL**: 定时器、中断控制器、Flash 接口等与主应用共用，降低开发成本。\n- **模块化**: 通信、更新、验证各自封装为独立状态机，通过事件松耦合。\n\n## 3. A/B 分区与 OTA 更新\n\n### 3.1 分区规划\n\nA/B 分区方案是 OTA 更新的主流选择: 一个分区运行当前固件，另一个分区接收新固件。更新完成后切换启动标志，失败则自动回滚。\n\n```\nFlash 布局:\n┌──────────────────────────────┐\n│  一级 Bootloader (只读)       │  受写保护\n├──────────────────────────────┤\n│  二级 Bootloader             │\n├──────────────────────────────┤\n│  配置区 (NVM)                │  启动标志 + 版本号 + 计数器\n├──────────────────────────────┤\n│  Slot A (Active)             │  当前运行的固件\n├──────────────────────────────┤\n│  Slot B (Inactive)           │  接收新固件的分区\n├──────────────────────────────┤\n│  Scratch (临时)              │  原子交换用，至少 1 个扇区\n└──────────────────────────────┘\n```\n\n配置区使用固定结构存储在 NVM 中:\n\n```c\ntypedef struct {\n    uint32_t magic;              /* 固定魔数 */\n    uint32_t version;            /* 配置版本 */\n    uint32_t active_slot;        /* 0=SlotA, 1=SlotB */\n    uint32_t boot_count;         /* 启动计数器 */\n    uint32_t rollback_version;   /* 防回滚最低版本号 */\n    uint32_t flags;              /* 标志位 */\n    uint32_t crc32;              /* 配置校验 */\n} sbl_config_t;\n```\n\n### 3.2 简单更新流程\n\n最基本的 A/B 更新流程:\n\n```mermaid\nstateDiagram-v2\n    direction LR\n    [*] --> Idle\n\n    Idle --> Receiving : 收到更新请求\n    Receiving --> Verifying : 数据接收完成\n    Verifying --> Installing : 验证通过\n    Verifying --> Idle : 验证失败\n    Installing --> Rebooting : 切换启动标志\n    Rebooting --> [*]\n```\n\n- **Idle**: 等待更新命令。\n- **Receiving**: 通过 UART/I2C/USB 逐块写入 Inactive 分区。\n- **Verifying**: 对写入后的镜像做哈希校验和签名验证。\n- **Installing**: 将启动标志切换到 Inactive 分区 (此分区变为 Active)。\n- **Rebooting**: 重启并加载新固件。\n\n这个方案有一个致命缺陷: **切换启动标志的瞬间断电**。如果标志写到一半 (例如 NVM 写入需要多个 Flash 字)，设备可能同时丢失两个分区的可用性。\n\n### 3.3 原子交换: Scratch 分区方案\n\n为彻底杜绝更新过程中断电导致的变砖，引入 Scratch 分区实现**原子性交换**: 交换要么完全成功，要么可以从任意中断点恢复。\n\n核心思想: 逐扇区交换 Slot A 和 Slot B 的内容，Scratch 作为临时中转。每完成一个扇区的交换，持久化进度状态。断电后重启时，SBL 检测到未完成的交换任务，从上次中断的位置继续。\n\n```mermaid\nstateDiagram-v2\n    direction TB\n    [*] --> UPDATE_IDLE\n    UPDATE_IDLE --> UPDATE_RECEIVING : 收到更新命令\n    UPDATE_RECEIVING --> UPDATE_VALIDATING : 接收完成\n    UPDATE_RECEIVING --> UPDATE_ERROR : 超时/错误\n\n    UPDATE_VALIDATING --> UPDATE_SWAPPING : 验证通过\n    UPDATE_VALIDATING --> UPDATE_ROLLBACK : 验证失败\n\n    state UPDATE_SWAPPING {\n        direction LR\n        [*] --> COPY_A_TO_SCRATCH\n        COPY_A_TO_SCRATCH --> COPY_B_TO_A : 当前扇区\n        COPY_B_TO_A --> COPY_SCRATCH_TO_B\n        COPY_SCRATCH_TO_B --> COPY_A_TO_SCRATCH : 下一扇区\n        COPY_SCRATCH_TO_B --> SWAP_DONE : 全部完成\n    }\n\n    UPDATE_SWAPPING --> UPDATE_REBOOT : 交换完成\n    UPDATE_ERROR --> UPDATE_IDLE : 错误处理\n    UPDATE_ROLLBACK --> UPDATE_IDLE : 回滚完成\n    UPDATE_REBOOT --> [*] : 系统重启\n```\n\n每个扇区的交换过程:\n\n1. 将 Active 分区的第 N 个扇区复制到 Scratch。\n2. 将 Inactive 分区的第 N 个扇区复制到 Active 分区。\n3. 将 Scratch 中的数据 (原 Active 内容) 复制到 Inactive 分区。\n4. 更新进度状态到 NVM。\n\n如果在步骤 1-3 的任意位置断电，下次启动时 SBL 读取 NVM 中的进度状态，从中断点继续执行。由于 Scratch 中始终保存着原 Active 分区的扇区数据，任何步骤的中断都不会导致数据丢失。\n\n这个方案的代价是: 更新耗时增加 (需要 3 倍的 Flash 操作量)，且需要额外的 Scratch 空间 (至少 1 个扇区大小)。对于 Flash 容量有限的 MCU，需要权衡是否值得。\n\n### 3.4 自动回滚\n\n自动回滚通过启动计数器实现:\n\n```c\n/* SBL 启动流程中 */\nvoid sbl_boot_app(void) {\n    sbl_config_t *cfg = nvm_get_config();\n\n    /* 递增启动计数器 */\n    cfg->boot_count++;\n    nvm_save_config(cfg);\n\n    if (cfg->boot_count >= BOOT_COUNT_THRESHOLD) {  /* 典型值: 3 */\n        /* 新固件多次启动失败，回滚到另一个分区 */\n        cfg->active_slot = (cfg->active_slot == 0U) ? 1U : 0U;\n        cfg->boot_count = 0U;\n        nvm_save_config(cfg);\n    }\n\n    /* 跳转到 Active 分区的 App */\n    jump_to_app(get_slot_address(cfg->active_slot));\n}\n```\n\nApp 端的职责: 成功完成自检后，通过写入一个约定的内存标志位或直接调用 SBL 提供的接口，将 `boot_count` 清零。如果 App 持续崩溃 (启动后卡死、看门狗复位)，`boot_count` 会在 SBL 每次尝试启动时递增，达到阈值后自动切换到旧分区。\n\n## 4. 固件镜像格式与安全验证\n\n### 4.1 TLV 标准化镜像格式\n\n传统做法是将签名和版本信息硬编码在镜像的固定偏移位置。这种方式在需要扩展新的安全特性 (例如增加加密支持、依赖声明) 时非常僵化。\n\nSBL 采用 `Header + Payload + TLV` 三段式结构，借鉴了 [MCUboot](https://github.com/mcu-tools/mcuboot) 的设计:\n\n```\n镜像布局:\n┌──────────────────────────────┐\n│  Image Header (固定长度)      │  魔数 + 版本 + 大小 + 标志\n├──────────────────────────────┤\n│  Payload (应用程序二进制)      │  实际的 App 代码\n├──────────────────────────────┤\n│  Protected TLVs              │  受签名保护的元数据\n├──────────────────────────────┤\n│  Unprotected TLVs            │  不受签名保护的元数据\n└──────────────────────────────┘\n```\n\nHeader 结构:\n\n```c\nstruct image_header {\n    uint32_t magic;              /* 固定魔数, 0x96f3b83d */\n    uint32_t load_addr;          /* 镜像加载地址 */\n    uint16_t hdr_size;           /* 头部大小 (便于未来扩展) */\n    uint16_t protect_tlv_size;   /* 受保护 TLV 区域大小 */\n    uint32_t img_size;           /* Payload 大小 */\n    uint32_t flags;              /* 标志位 (加密等) */\n    struct {\n        uint8_t major;\n        uint8_t minor;\n        uint16_t revision;\n        uint32_t build_num;\n    } version;\n} __attribute__((packed));\n```\n\nTLV (Tag-Length-Value) 条目:\n\n```c\nstruct image_tlv_info {\n    uint16_t magic;              /* TLV 区域魔数 */\n    uint16_t tlv_tot_len;        /* 所有 TLV 条目总长度 */\n} __attribute__((packed));\n\nstruct image_tlv {\n    uint8_t  tlv_type;           /* Tag: 条目类型 */\n    uint8_t  _pad;\n    uint16_t tlv_len;            /* Length: Value 的长度 */\n    /* Value: tlv_len 字节的实际数据 */\n} __attribute__((packed));\n\n/* TLV 类型定义 */\n#define IMAGE_TLV_SHA256        0x10   /* 镜像哈希 */\n#define IMAGE_TLV_ECDSA_P256    0x22   /* ECDSA-P256 签名 */\n#define IMAGE_TLV_DEPENDENCY    0x50   /* 依赖声明 (App 依赖某个 SBL 版本) */\n```\n\nTLV 的扩展性体现在: 未来增加新的安全特性 (例如 AES-256 加密标志、多签名支持)，只需定义新的 TLV 类型，SBL 的解析代码不需要修改结构体 -- 遍历 TLV 链表时跳过不认识的类型即可。\n\n### 4.2 安全启动验证状态机\n\nSBL 的安全启动验证是一个多步骤流程，用状态机表达比 if-else 嵌套更清晰，且每个状态都有明确的失败处理路径:\n\n```mermaid\nstateDiagram-v2\n    direction TB\n    [*] --> BOOT_INIT\n    BOOT_INIT --> LOAD_CONFIG : 硬件初始化完成\n    LOAD_CONFIG --> SELECT_SLOT : 配置加载成功\n    LOAD_CONFIG --> BOOT_ERROR : 配置损坏\n\n    SELECT_SLOT --> PARSE_HEADER : 选择 Active 分区\n    PARSE_HEADER --> PARSE_TLV : Header 校验通过\n    PARSE_HEADER --> TRY_BACKUP : Header 校验失败\n\n    PARSE_TLV --> VERIFY_HASH : TLV 解析完成\n    VERIFY_HASH --> VERIFY_SIGNATURE : 哈希匹配\n    VERIFY_HASH --> TRY_BACKUP : 哈希不匹配\n\n    VERIFY_SIGNATURE --> CHECK_VERSION : 签名验证通过\n    VERIFY_SIGNATURE --> TRY_BACKUP : 签名验证失败\n\n    CHECK_VERSION --> JUMP_APP : 版本检查通过\n    CHECK_VERSION --> TRY_BACKUP : 版本回滚\n\n    TRY_BACKUP --> SELECT_SLOT : 切换到备份分区\n    TRY_BACKUP --> BOOT_ERROR : 无可用分区\n\n    JUMP_APP --> [*] : 跳转到应用程序\n    BOOT_ERROR --> SAFE_MODE : 进入安全模式\n```\n\n验证流程:\n\n1. **PARSE_HEADER**: 检查魔数、头部大小、镜像大小是否在合理范围内。\n2. **PARSE_TLV**: 遍历 TLV 区域，提取 SHA256 哈希值和签名数据。\n3. **VERIFY_HASH**: 计算 `Header + Payload` 的 SHA256，与 TLV 中存储的哈希值比对。\n4. **VERIFY_SIGNATURE**: 使用预置的公钥验证 `Header + Payload + Protected TLVs` 的 ECDSA-P256 签名。\n5. **CHECK_VERSION**: 与 NVM 中存储的最低允许版本比较，拒绝降级。\n\n### 4.3 防回滚保护\n\n防回滚的核心是一个单调递增的版本号，存储在 NVM 的受保护区域:\n\n```c\nint sbl_verify_firmware_version(const struct image_header *header) {\n    uint32_t min_allowed = nvm_read_min_version();\n\n    if (header->version.build_num < min_allowed) {\n        return -1;  /* 拒绝: 版本低于最低允许值 */\n    }\n\n    return 0;\n}\n```\n\n新固件通过完整验证并成功启动后，SBL 将 `min_allowed_version` 更新为当前固件的版本号。此后，任何版本号更低的固件都无法通过验证 -- 即使攻击者获取了旧版本的签名固件。\n\n`min_allowed_version` 所在的 NVM 区域应配置硬件写保护 (如果 MCU 支持)，并附加 CRC 校验防止意外损坏。\n\n### 4.4 MPU 内存保护\n\n裸机环境下，SBL 在启动时配置 MPU (Memory Protection Unit) 保护关键区域:\n\n- **Bootloader 代码区**: 设为只读 + 可执行，防止固件更新过程中误写 SBL 自身。\n- **配置区 (NVM)**: 设为读写，但仅 SBL 的配置管理模块有写权限。\n- **App 分区**: 更新时设为可写，验证通过后设为只读 + 可执行。\n- **外设寄存器区**: 设为设备内存属性 (Device-nGnRnE)，禁止推测访问。\n\n## 5. 通信协议: ISR → Ring Buffer → 状态机\n\nSBL 与上位机之间的通信 (UART/I2C/USB) 是固件更新的数据通路。通信协议的设计需要在裸机环境下兼顾实时性和可靠性。\n\n### 5.1 三层解耦架构\n\n传统做法是在中断服务程序 (ISR) 中直接处理协议解析，这会导致 ISR 执行时间过长，影响其他中断的响应。SBL 采用 ISR → Ring Buffer → 主循环状态机的三层解耦:\n\n```\n┌─────────────┐     ┌─────────────┐     ┌─────────────┐\n│  ISR (生产者) │ ──→ │ Ring Buffer  │ ──→ │ 主循环 (消费者) │\n│  从 FIFO 搬运 │     │ SPSC 无锁队列│     │ 状态机解析协议 │\n└─────────────┘     └─────────────┘     └─────────────┘\n       |                                       |\n  中断上下文                              主循环上下文\n  O(1) 操作                              可执行复杂逻辑\n```\n\nISR 的唯一职责: 将硬件 FIFO 中的字节搬运到 Ring Buffer，然后退出。\n\n```c\n/* ISR 回调 -- 以 uart_statemachine_ringbuffer_linux 项目的模式为例 */\nstatic void uart_isr_callback(uint8_t port, uint32_t int_status) {\n    uint8_t byte;\n\n    while (uart_hal_rx_available(port)) {\n        uart_hal_try_get_byte(port, &byte);\n        spsc_queue_push(&uart_rx_queue, &byte, 1U);\n    }\n}\n```\n\n### 5.2 SPSC Ring Buffer\n\nRing Buffer 是 ISR 和主循环之间的唯一共享数据结构。由于 ISR 是唯一的生产者、主循环是唯一的消费者，这是一个经典的 SPSC (Single Producer Single Consumer) 场景，可以用无锁实现。\n\n以 [uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) 项目中的 `spsc_queue.h` 为例:\n\n```c\ntypedef struct {\n    uint32_t size;             /* 缓冲区大小 (必须是 2 的幂) */\n    uint32_t mask;             /* 快速取模掩码 (size - 1) */\n    volatile uint32_t head;    /* 消费者读指针 (仅消费者修改) */\n    volatile uint32_t tail;    /* 生产者写指针 (仅生产者修改) */\n    uint8_t *buffer;           /* 缓冲区指针 */\n} spsc_queue_t;\n```\n\n关键设计点:\n\n- **Size 必须是 2 的幂**: 用 `index & mask` 替代 `index % size`，避免除法运算 (在 Cortex-M0 上没有硬件除法器)。\n- **Head/tail 分离**: `head` 只被消费者修改，`tail` 只被生产者修改。不需要锁。\n- **内存屏障**: 在 ARM 上，写入数据后、更新 tail 前需要 DMB 指令，确保消费者看到的数据是完整的。在单核 MCU 上 (ISR 和主循环跑在同一个核上)，编译器屏障 (`__asm volatile(\"\" ::: \"memory\")`) 通常就够了。\n\n```c\n/* Push: ISR 调用 */\nstatic inline int32_t spsc_queue_push(spsc_queue_t *q, const uint8_t *data, uint32_t len) {\n    uint32_t tail = q->tail;\n    uint32_t head = q->head;\n\n    if ((q->size - (tail - head)) < len) {\n        return SPSC_QUEUE_FAIL;  /* 空间不足 */\n    }\n\n    uint32_t pos = tail & q->mask;\n    uint32_t first = spsc_queue_min(len, q->size - pos);\n    memcpy(&q->buffer[pos], data, first);\n    if (first < len) {\n        memcpy(q->buffer, &data[first], len - first);  /* 环绕 */\n    }\n\n    SPSC_QUEUE_DMB();  /* 确保数据写入完成后再更新 tail */\n    q->tail = tail + len;\n    return SPSC_QUEUE_OK;\n}\n```\n\n### 5.3 协议帧格式\n\nSBL 使用分层帧格式，支持简单帧 (用于基本命令) 和扩展帧 (用于 OTA 数据传输):\n\n```\n简单帧:\n┌──────┬────────┬──────┬─────┬──────────┬─────────┬──────┐\n│ 0xAA │ LEN(2B)│ CLASS│ CMD │ DATA[N]  │ CRC16(2B)│ 0x55 │\n│ 帧头  │ 小端序  │ 命令类 │ 命令 │ 可变数据  │ CCITT   │ 帧尾  │\n└──────┴────────┴──────┴─────┴──────────┴─────────┴──────┘\n```\n\n命令类定义:\n\n| 命令类 | 值   | 用途 |\n|--------|------|------|\n| SYS    | 0x01 | 系统命令 (版本查询、重启) |\n| SPI    | 0x02 | SPI Flash 操作 |\n| DIAG   | 0x03 | 诊断命令 |\n| OTA    | 0x04 | 固件更新 (START/DATA/END/VERIFY) |\n| CONFIG | 0x10 | 配置管理 |\n\nCRC16-CCITT 覆盖 `CLASS + CMD + DATA` 部分，使用查表法实现 O(n) 计算:\n\n```c\nstatic inline uint16_t uart_calc_crc16(const uint8_t *data, uint32_t len) {\n    uint16_t crc = 0x0000U;\n\n    for (uint32_t i = 0U; i < len; i++) {\n        crc = (uint16_t)((crc << 8) ^ crc16_table[(uint8_t)((crc >> 8) ^ data[i])]);\n    }\n    return crc;\n}\n```\n\n### 5.4 两种协议解析方案\n\n[uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) 项目实现并对比了两种协议解析方案，两种方案在 SBL 场景下各有适用范围。\n\n#### 方案一: 缓冲区滑窗扫描\n\n主循环周期性从 Ring Buffer 批量读取数据到本地缓冲区，然后用滑动窗口扫描帧头、校验帧尾和 CRC。\n\n```c\nvoid rb_parser_process(rb_parser_t *parser) {\n    uint8_t buffer[64];\n    uint32_t len;\n\n    /* 从 Ring Buffer 批量读取 */\n    len = spsc_queue_pop(&parser->queue, buffer, sizeof(buffer));\n    if (len == 0U) {\n        return;\n    }\n\n    /* 追加到内部缓冲区 */\n    memcpy(&parser->buf[parser->buf_len], buffer, len);\n    parser->buf_len += len;\n\n    /* 滑窗扫描: 查找帧头 0xAA */\n    while (parser->buf_len >= SIMPLE_FRAME_MIN_LEN) {\n        if (parser->buf[0] != SIMPLE_FRAME_HEADER) {\n            /* 丢弃非帧头字节，滑窗前移 */\n            memmove(parser->buf, &parser->buf[1], parser->buf_len - 1);\n            parser->buf_len--;\n            continue;\n        }\n\n        /* 提取长度字段 */\n        uint16_t payload_len = parser->buf[1] | (parser->buf[2] << 8);\n        uint32_t frame_len = 1 + 2 + payload_len + 2 + 1;  /* 头+长度+数据+CRC+尾 */\n\n        if (parser->buf_len < frame_len) {\n            break;  /* 数据不完整，等待更多数据 */\n        }\n\n        /* 校验帧尾 */\n        if (parser->buf[frame_len - 1] != SIMPLE_FRAME_TAIL) {\n            memmove(parser->buf, &parser->buf[1], parser->buf_len - 1);\n            parser->buf_len--;\n            continue;\n        }\n\n        /* CRC 校验 */\n        uint16_t crc_calc = uart_calc_crc16(&parser->buf[3], payload_len);\n        uint16_t crc_recv = parser->buf[3 + payload_len]\n                          | (parser->buf[4 + payload_len] << 8);\n\n        if (crc_calc == crc_recv) {\n            /* 帧有效，提取并回调 */\n            dispatch_frame(parser, &parser->buf[3], payload_len);\n        }\n\n        /* 移除已处理的帧 */\n        memmove(parser->buf, &parser->buf[frame_len], parser->buf_len - frame_len);\n        parser->buf_len -= frame_len;\n    }\n}\n```\n\n**优点**: 实现简单直观，CPU 占用低 (主循环批量处理)，适合固定格式协议。\n\n**缺点**: `memmove` 操作在每次丢弃字节时移动整个缓冲区；状态隐含在代码逻辑中，扩展复杂协议困难。\n\n#### 方案二: 层次状态机 (HSM) 逐字节解析\n\n每个字节到达触发一个事件，状态机根据当前状态处理:\n\n```mermaid\nstateDiagram-v2\n    [*] --> IDLE\n    IDLE --> LEN_LO : 收到 0xAA\n    LEN_LO --> LEN_HI : 收到长度低字节\n    LEN_HI --> PAYLOAD : 收到长度高字节\n    PAYLOAD --> CRC_LO : 数据收满\n    CRC_LO --> CRC_HI : 收到 CRC 低字节\n    CRC_HI --> TAIL : 收到 CRC 高字节\n    TAIL --> IDLE : 0x55 (帧完成)\n    TAIL --> IDLE : 非 0x55 (帧错误)\n    PAYLOAD --> IDLE : 超时\n```\n\n使用 [uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) 项目中的 HSM 框架:\n\n```c\n/* 状态定义 */\nstatic const hsm_state_t state_idle;\nstatic const hsm_state_t state_len_lo;\nstatic const hsm_state_t state_len_hi;\nstatic const hsm_state_t state_payload;\nstatic const hsm_state_t state_crc_lo;\nstatic const hsm_state_t state_crc_hi;\nstatic const hsm_state_t state_tail;\n\n/* IDLE 状态的转换表 */\nstatic const hsm_transition_t idle_transitions[] = {\n    { EVT_BYTE_RECEIVED, &state_len_lo, guard_is_header, NULL, SM_TRANSITION_EXTERNAL },\n};\n\n/* PAYLOAD 状态的转换表 */\nstatic const hsm_transition_t payload_transitions[] = {\n    { EVT_BYTE_RECEIVED, &state_crc_lo, guard_payload_complete, action_store_byte,\n      SM_TRANSITION_EXTERNAL },\n    { EVT_BYTE_RECEIVED, NULL, NULL, action_store_byte, SM_TRANSITION_INTERNAL },\n    { EVT_TIMEOUT, &state_idle, NULL, action_report_timeout, SM_TRANSITION_EXTERNAL },\n};\n\n/* Guard: 检查是否收到帧头 0xAA */\nstatic bool_t guard_is_header(hsm_t *sm, const hsm_event_t *event) {\n    uint8_t byte = *(uint8_t *)event->context;\n    return (byte == SIMPLE_FRAME_HEADER) ? TRUE : FALSE;\n}\n```\n\n主循环中逐字节驱动状态机:\n\n```c\nvoid process_uart_events(void) {\n    uint8_t buffer[64];\n    uint32_t len = spsc_queue_pop(&uart_rx_queue, buffer, sizeof(buffer));\n\n    for (uint32_t i = 0U; i < len; i++) {\n        hsm_event_t event = { .id = EVT_BYTE_RECEIVED, .context = &buffer[i] };\n        hsm_dispatch(&protocol_sm, &event);\n    }\n}\n```\n\n**优点**: 状态转换显式声明 (数据驱动)，支持层次化复杂协议，自恢复能力强 (任何异常状态都有明确的回退路径)，便于单元测试。\n\n**缺点**: 实现复杂度高于滑窗方案，每个字节都触发一次状态机分发 (但在 Cortex-M 上开销约为微秒级，远低于 UART 字节间隔)。\n\n#### 方案选择建议\n\n| 场景 | 推荐方案 |\n|------|---------|\n| 简单定长协议，命令种类少 | 滑窗扫描 |\n| 多层复杂协议 (简单帧 + UCI 扩展帧) | HSM |\n| 需要支持超时、重传、会话管理 | HSM |\n| 资源极度受限 (< 4KB RAM) | 滑窗扫描 |\n| 需要独立测试协议解析逻辑 | HSM |\n\nSBL 的通信协议通常涉及 OTA 数据传输 (需要序列号、分块校验、超时重传)，复杂度足以使 HSM 方案成为更优选择。\n\n### 5.5 中断配置优化\n\nISR + Ring Buffer 架构的性能取决于中断触发策略:\n\n- **FIFO 水线 (Watermark)**: 不要将触发级别设为 1 字节。设为 4 或 8 字节可以减少中断频率。例如 115200 baud 下每秒约 11520 字节，1 字节触发意味着 11520 次中断/秒，8 字节触发则降到约 1440 次/秒。\n- **接收超时中断 (RTO)**: 当最后一个字节到达后超过 N 个字符时间没有新数据，触发超时中断。这确保帧尾的最后几个字节 (不足 FIFO 水线) 也能被及时处理。\n- **DMA**: 如果硬件支持，DMA 可以将数据直接搬运到 Ring Buffer，ISR 只需更新 tail 指针。这将 ISR 的开销从 O(n) (逐字节搬运) 降到 O(1) (更新指针)。\n\n## 6. 主循环: 裸机协作式调度\n\nSBL 运行在裸机环境下，所有业务逻辑通过状态机在主循环中协作执行:\n\n```c\nvoid sbl_main_loop(void) {\n    while (1) {\n        /* 1. 处理硬件中断产生的事件 */\n        process_uart_events();\n\n        /* 2. 驱动各业务状态机 */\n        hsm_dispatch(&protocol_sm, &tick_event);      /* 协议解析 */\n        hsm_dispatch(&update_sm, &tick_event);         /* 固件更新 */\n        hsm_dispatch(&secure_boot_sm, &tick_event);    /* 安全启动 */\n\n        /* 3. 看门狗喂狗 */\n        watchdog_feed();\n\n        /* 4. 低功耗处理 */\n        if (no_pending_events()) {\n            __WFI();  /* Wait For Interrupt: CPU 休眠直到下一个中断 */\n        }\n    }\n}\n```\n\n各状态机之间通过事件松耦合: 协议解析状态机解析到 OTA_START 命令后，向固件更新状态机发送 `UPDATE_START_EVENT`；固件更新状态机完成所有扇区写入后，向安全验证状态机发送 `VALIDATE_EVENT`。\n\n这种架构的本质是**事件驱动的协作式多任务**: 每个状态机在一次调度中只处理一个事件然后返回，不会长时间霸占 CPU。对于 SBL 的工作负载 (通信速率远低于 CPU 处理速度)，这足以保证实时性。\n\n## 7. RTOS 迁移: 兼容层设计\n\n如果 SBL 需要复用基于 RTOS (例如 RT-Thread) 编写的已有代码，可以通过兼容层将 RTOS API 替换为裸机实现:\n\n```c\n/* rt_compat.h -- RTOS API 兼容层 */\n\n/* 内存管理: 直接映射到标准库 */\n#define rt_malloc(size)       malloc(size)\n#define rt_calloc(n, s)       calloc(n, s)\n#define rt_free(ptr)          free(ptr)\n\n/* 线程同步: 裸机下简化为空操作 */\n#define rt_mutex_init(m)      (0)\n#define rt_mutex_take(m, t)   (0)\n#define rt_mutex_release(m)   (0)\n\n/* 链表操作: 提供裸机版本 */\ntypedef struct rt_list_node {\n    struct rt_list_node *next;\n    struct rt_list_node *prev;\n} rt_list_t;\n\nstatic inline void rt_list_init(rt_list_t *l) {\n    l->next = l;\n    l->prev = l;\n}\n\nstatic inline void rt_list_insert_after(rt_list_t *l, rt_list_t *n) {\n    l->next->prev = n;\n    n->next = l->next;\n    l->next = n;\n    n->prev = l;\n}\n```\n\n兼容层的局限性: mutex 简化为空操作意味着代码不再线程安全。在裸机环境下这通常不是问题 (只有 ISR 和主循环两个执行上下文)，但必须确保被复用的代码中没有依赖 RTOS 调度的时序假设 (例如 `rt_thread_delay` 必须替换为硬件定时器)。\n\n## 8. 状态机框架选型\n\nSBL 中每个业务模块 (通信协议、固件更新、安全启动、配置管理) 都由独立的状态机驱动。选择合适的状态机框架对代码质量有直接影响。\n\n### 8.1 为什么用状态机而非 switch-case\n\n传统做法:\n\n```c\n/* 原始的 if-else / switch 结构 */\nstatic int step = 0;\nint firmware_update_process(const uint8_t *data, uint32_t len) {\n    switch (step) {\n        case 0:  /* 准备阶段 */\n            if (prepare_partition()) { step = 1; }\n            else { goto error; }\n            break;\n        case 1:  /* 接收阶段 */\n            /* ... 复杂的嵌套逻辑 ... */\n            break;\n        /* ... 更多 case ... */\n    }\nerror:\n    /* 错误清理逻辑分散在各处 */\n}\n```\n\n问题: 状态隐含在 `step` 变量中，转换条件分散在代码逻辑中，添加新状态需要修改多处代码，错误处理路径不统一。\n\n状态机框架将状态、转换、动作显式声明为数据:\n\n```c\n/* 数据驱动的状态定义 */\nstatic const hsm_transition_t update_idle_transitions[] = {\n    { EVT_UPDATE_START, &state_receiving, NULL, action_prepare, SM_TRANSITION_EXTERNAL },\n};\n\nstatic const hsm_transition_t update_receiving_transitions[] = {\n    { EVT_DATA_RECEIVED, NULL, NULL, action_write_block, SM_TRANSITION_INTERNAL },\n    { EVT_DATA_COMPLETE, &state_validating, NULL, NULL, SM_TRANSITION_EXTERNAL },\n    { EVT_TIMEOUT, &state_error, NULL, action_report_timeout, SM_TRANSITION_EXTERNAL },\n};\n```\n\n每个状态的行为由其转换表完全定义。添加新状态只需增加一个转换表，不影响其他状态的代码。\n\n### 8.2 HSM 框架核心 API\n\n[uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) 项目中包含一个轻量的层次状态机框架 (`hsm_method/state_machine.h`)，核心接口:\n\n```c\n/* 初始化状态机 */\nvoid hsm_init(hsm_t *sm, const hsm_state_t *initial_state,\n              const hsm_state_t **entry_path_buffer, uint8_t buffer_size,\n              void *user_data, hsm_action_fn unhandled_hook);\n\n/* 分发事件 -- 在主循环中调用 */\nbool_t hsm_dispatch(hsm_t *sm, const hsm_event_t *event);\n\n/* 查询当前状态 */\nconst char *hsm_get_current_state_name(const hsm_t *sm);\nbool_t hsm_is_in_state(const hsm_t *sm, const hsm_state_t *state);\n```\n\n状态定义支持层次关系 (子状态继承父状态的转换):\n\n```c\nstruct hsm_state {\n    const hsm_state_t *parent;           /* 父状态，NULL 表示顶层 */\n    hsm_action_fn entry_action;          /* 进入动作 */\n    hsm_action_fn exit_action;           /* 退出动作 */\n    const hsm_transition_t *transitions; /* 转换表 */\n    size_t num_transitions;              /* 转换数量 */\n    const char *name;                    /* 调试用名称 */\n};\n```\n\nHSM 的层次特性在 SBL 中的价值: 例如固件更新的所有子状态 (Receiving、Validating、Swapping) 共享一个父状态 Updating，父状态定义了公共的超时处理和取消逻辑，子状态无需重复。\n\n## 9. 总结与工程权衡\n\n回顾 SBL 的设计，几个核心权衡:\n\n**安全性 vs 更新速度**。原子交换方案需要 3 倍的 Flash 操作量 (A→Scratch、B→A、Scratch→B)，且需要额外的 Scratch 空间。如果 Flash 容量充裕且对更新可靠性要求高，这是正确的选择。如果 Flash 紧张且可以接受小概率的更新失败 (通过自动回滚恢复)，简单方案即可。\n\n**状态机 vs 简单流程**。状态机框架引入了学习成本和代码量。对于只有 3-4 个状态的简单协议，switch-case 可能更直接。但当业务复杂度增长 (多种帧格式、超时重传、会话管理)，状态机的结构优势会迅速体现。SBL 恰好处在这个复杂度拐点上。\n\n**复用 vs 重写**。复用主应用的 HAL 和驱动可以降低开发成本，但要注意 RTOS 兼容层的局限性 -- mutex 空操作意味着原代码中依赖锁保护的临界区失去了保护。需要逐一审查被复用代码的并发假设。\n\n**TLV vs 固定格式**。TLV 的灵活性在 SBL 的长生命周期中非常有价值 -- 产品可能需要在不更换 SBL 的情况下支持新的安全特性。代价是解析代码略微复杂，但 TLV 遍历本身只是一个简单的循环。\n\n> 参考:\n> - [uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) -- UART 协议解析 Demo (Ring Buffer + HSM 两种方案)\n> - [state_machine](https://github.com/DeguiLiu/state_machine) -- 轻量层次状态机框架\n> - [MCUboot](https://github.com/mcu-tools/mcuboot) -- TLV 镜像格式参考\n",
      "ctime": "1771552461",
      "mtime": "1771552461",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/newosp_concurrency_io_architecture.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038355494",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "如何设计嵌入式并发架构: newosp 的事件驱动 + 固定线程池方案",
      "brief_content": "面向 4 核 ARM-Linux、32-256MB RAM、-fno-exceptions 的工业嵌入式场景，newosp 选择了事件驱动消息总线 + 固定线程预算 + 可移植 I/O 抽象的并发架构",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 配套代码: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) -- header-only C++17 嵌入式基础设施库\n>\n> 相关文章:\n> - [工业传感器数据流水线: newosp C++17 零堆分配事件驱动架构实战](../newosp_event_driven_architecture/) -- AsyncBus/HSM/SPSC 核心实现 + 流水线案例\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- WorkerPool 内部的 SPSC 队列\n> - [无锁编程核心原理: 从 CAS 到三种队列模式](../lockfree_programming_fundamentals/) -- CAS/MPSC/SPSC 原理\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- ShmRingBuffer I/O 集成\n>\n> CSDN 原文:\n> - [C++ 多线程与协程优化阻塞型任务](https://blog.csdn.net/stallion5632/article/details/143887766)\n> - [Linux I/O 多路复用与异步 I/O 对比](https://blog.csdn.net/stallion5632/article/details/143675999)\n\n## 1. 约束与方案选择\n\nnewosp 面向的典型硬件是 4 核 ARM Cortex-A (激光雷达、机器人、边缘计算)，32-256MB RAM，编译选项 `-fno-exceptions -fno-rtti`，未来需要移植到 RT-Thread MCU。在这个约束下，并发架构必须满足: **线程数编译期确定** (4-8 个，不随任务数增长)、**热路径零堆分配** (Publish → Dispatch → 回调全程无 malloc)、**I/O 层可移植** (不绑定 epoll)。\n\nnewosp 的回答是三层解耦:\n\n- **AsyncBus**: CAS 无锁 MPSC 环形缓冲，替代 mutex + queue 的线程间通信\n- **Executor/WorkerPool**: 固定线程预算的调度层，替代\"每任务一线程\"\n- **IoPoller**: epoll/poll 编译期选择，I/O 就绪通知与业务逻辑解耦\n\n### 为什么不用协程\n\nstate-threads 实验 (1000x1000 矩阵乘法 + 1us 阻塞) 显示协程在阻塞密集场景下比纯多线程快 4.5 倍 (3.3s vs 14.9s)。但工业嵌入式有两个硬伤: **栈内存不可控** -- 有栈协程需要 4-64KB/协程，1000 协程 = 4-64MB，在 32-256MB 系统中无法接受，且栈深度编译期无法预测; **`-fno-exceptions` 冲突** -- Boost.Fiber/Coroutine2 不兼容，兼容的 state-threads/libco 是纯 C 库，与 C++17 类型系统 (variant, optional, constexpr) 没有集成。\n\n### 为什么不直接用 epoll\n\nepoll 是网络 I/O 的最优方案，但直接在 epoll 回调中处理业务会导致三个问题: **不可移植** (RT-Thread 只有 POSIX poll); **回调耦合** (epoll_wait → recv → parse → dispatch → process 层层嵌套，难以独立测试); **缺少消息语义** (epoll 只管 fd 就绪，不提供类型路由、优先级准入、背压控制)。newosp 保留 epoll 做 I/O 通知，但将业务逻辑抽离到消息总线层。\n\n## 2. 架构设计\n\n### 2.1 三层职责\n\n```\n                        ┌──────────────────────────────────┐\n                        │         应用层 (Node/StaticNode)  │\n                        │  Publish()  Subscribe<T>()       │\n                        └──────────┬───────────────────────┘\n                                   │ std::variant<Types...>\n                        ┌──────────▼───────────────────────┐\n                        │     AsyncBus (无锁 MPSC 环形缓冲) │\n                        │  CAS publish → batch consume     │\n                        │  优先级准入 + 背压控制             │\n                        └──────────┬───────────────────────┘\n                                   │\n              ┌────────────────────┼────────────────────┐\n              │                    │                     │\n    ┌─────────▼────────┐ ┌────────▼────────┐ ┌─────────▼────────┐\n    │  SingleThread     │ │  PinnedExecutor │ │   WorkerPool     │\n    │  Executor         │ │  RealtimeExec   │ │  (Dispatcher + N │\n    │  (调试/单核)      │ │  (SCHED_FIFO)   │ │   Worker SPSC)   │\n    └──────────────────┘ └─────────────────┘ └──────────────────┘\n                                   │\n                        ┌──────────▼───────────────────────┐\n                        │       IoPoller (I/O 事件循环)     │\n                        │  Linux: epoll  │  通用: poll()    │\n                        └──────────────────────────────────┘\n```\n\n**AsyncBus** 是消息骨干: 多个生产者 (传感器线程、网络线程、定时器) 通过 CAS 无锁发布消息到共享环形缓冲; 单消费者 (Executor) 批量取出并分发到 Node/StaticNode 的回调。\n\n**Executor** 是调度层: 决定\"哪个线程执行 ProcessBatch\"。SingleThread 在调用线程阻塞执行; PinnedExecutor 绑定到指定 CPU 核心; RealtimeExecutor 启用 SCHED_FIFO + mlockall + 自定义栈。\n\n**IoPoller** 是 I/O 适配层: 将 fd 就绪事件转化为消息发布，自身不处理业务逻辑。\n\n### 2.2 AsyncBus: CAS 发布与批量消费\n\n```cpp\ntemplate <typename PayloadVariant,\n          uint32_t QueueDepth = 4096,    // 2 的幂\n          uint32_t BatchSize = 256>\nclass AsyncBus;\n```\n\n消息以**信封** (32B header + variant payload) 存储在缓存行对齐的环形缓冲中:\n\n```cpp\nstruct alignas(64) RingBufferNode {\n    std::atomic<uint32_t> sequence;          // CAS 序号控制\n    MessageEnvelope<PayloadVariant> envelope; // header + payload\n};\n```\n\n**发布路径** (多生产者，lock-free):\n\n```\nProducer 0 ─┐\nProducer 1 ──┼── CAS(producer_pos_) ──> 写入 Envelope ──> release store(sequence)\nProducer 2 ─┘\n```\n\n生产者通过 `compare_exchange_weak(acq_rel)` 竞争序列号，获胜者写入对应 slot，最后用 `release store` 发布。无 mutex、无 spinlock。\n\n**消费路径** (单消费者，Run-to-Completion):\n\n```cpp\nuint32_t ProcessBatch() {\n    for (uint32_t i = 0; i < kBatchSize; ++i) {\n        auto* node = &ring_[consumer_pos_ & kMask];\n        if (node->sequence.load(acquire) != consumer_pos_ + 1) break;\n\n        __builtin_prefetch(&ring_[(consumer_pos_ + 1) & kMask], 0, 1);\n        DispatchToCallbacks(node->envelope);\n\n        node->sequence.store(consumer_pos_ + kQueueDepth, release);\n        ++consumer_pos_;\n    }\n}\n```\n\n批量消费减少原子操作频率，prefetch 预取下一 slot 减少 cache miss。\n\n**两种分发模式**:\n\n| 模式 | 机制 | ns/msg (P50) |\n|------|------|---:|\n| StaticNode (编译期) | `std::visit` 跳转表，编译器可内联 | ~2 |\n| Node (运行时) | FixedFunction 回调表，SharedSpinLock | ~30 |\n\nStaticNode 的 Handler 在编译期确定，编译器为每个 variant alternative 生成直接调用。Node 适合需要运行时动态订阅的场景，回调存储在 `FixedFunction<Sig, 32>` (32 字节 SBO，编译期 `static_assert` 拒绝超限 lambda)。\n\n### 2.3 零堆分配保证\n\n热路径 (Publish → ProcessBatch → 回调执行) 中零 `malloc`/`free`，通过三个机制:\n\n**环形缓冲预分配**: Bus 构造时一次性分配 `RingBufferNode[QueueDepth]` 数组，后续消息写入只是覆盖已有 slot:\n\n```\n内存布局 (QueueDepth=4096):\n┌───────────────────────────────────────────────┐\n│  RingBufferNode[0]  │  [1]  │  ...  │  [4095] │  ← 构造时分配，运行时零分配\n│  alignas(64)        │       │       │         │\n└───────────────────────────────────────────────┘\n```\n\n**FixedFunction SBO**: 替代 `std::function`，32 字节内联缓冲，超限捕获**编译期报错**:\n\n```cpp\ntemplate <typename Signature, size_t BufferSize = 2 * sizeof(void*)>\nclass FixedFunction;\n\n// Bus 内部使用 32B SBO\nusing CallbackType = FixedFunction<void(const EnvelopeType&), 4 * sizeof(void*)>;\n// sizeof(void*) = 8 → 32B，足够存储 [this + 1 指针] 的 lambda\n```\n\n`std::function` 在 lambda 超过 SBO 阈值 (通常 16-32B，实现依赖) 时会隐式堆分配。FixedFunction 将这个\"可能\"变成\"编译期拒绝\"。\n\n**std::variant 值语义**: 消息作为 variant 直接 move 进 Envelope，无间接指针，无引用计数:\n\n```cpp\n// 传统方案: shared_ptr<Frame> → control block 堆分配 + 原子引用计数\n// newosp: variant<RawFrame, ControlCmd, ...> → 直接嵌入 Envelope，sizeof 编译期确定\n```\n\n### 2.4 线程预算\n\nnewosp 典型部署的线程分布:\n\n| 组件 | 线程数 | CPU 亲和性 | 职责 |\n|------|--------|-----------|------|\n| TimerScheduler | 1 | -- | 定时任务调度 |\n| DebugShell | 1+2 | -- | TCP telnet 监听 + 最多 2 会话 |\n| AsyncLog | 1 | -- | 异步日志写盘 |\n| Executor | 1 | CPU 2 (Pinned) | 消息调度 (SpinOnce 循环) |\n| WorkerPool | 1+N | CPU 3+ | Dispatcher + N Worker |\n| **合计** | **6+N** | 确定性 | N 通常 = 2-4 |\n\n对比:\n\n```\n传统多线程:     线程数 = 任务数 (10 个传感器 = 10 个线程)\n协程:           线程数固定，但协程数/栈内存不可控\nnewosp:         线程数 = 编译期常量，内存预算可精确计算\n```\n\n### 2.5 内存预算\n\n| 组件 | 内存占用 | 分配方式 |\n|------|----------|----------|\n| AsyncBus (4096 slots) | ~320 KB | 预分配环形缓冲 (取决于 variant sizeof) |\n| WorkerPool (4 workers x 1024 SPSC) | ~64 KB | 预分配 SPSC 队列 |\n| Node (16 subscriptions) | ~1 KB | 栈数组 |\n| IoPoller (64 events) | ~512 B | 内部缓冲 |\n| **热路径合计** | **~386 KB** | **零 malloc** |\n\n### 2.6 背压控制\n\n当 Bus 队列压力增大时，低优先级消息被拒绝发布:\n\n```\n队列占用 >= 60%: 拒绝 kLow (遥测、统计)\n队列占用 >= 80%: 拒绝 kMedium (常规数据)\n队列占用 >= 99%: 拒绝 kHigh (仅保留控制命令)\n```\n\n实现上，生产者先检查**本地缓存**的消费位置 (relaxed 读，无 cache line 竞争):\n\n```cpp\nuint32_t depth = producer_pos_.load(relaxed) - cached_consumer_pos_;\nif (depth >= AdmissionThreshold(priority)) {\n    // 缓存可能过时，重新读取真实消费位置 (acquire)\n    cached_consumer_pos_ = consumer_pos_.load(acquire);\n    depth = producer_pos_.load(relaxed) - cached_consumer_pos_;\n    if (depth >= AdmissionThreshold(priority)) {\n        return false;  // 丢弃\n    }\n}\n```\n\n低负载时完全避免对消费者原子变量的争用 (cached hit)。高负载时按优先级逐级丢弃，控制命令几乎不受影响。\n\n### 2.7 Executor 家族\n\n四种执行模型覆盖从调试到工业实时的全场景:\n\n```cpp\n// 1. 单线程阻塞 (调试/单核)\nosp::SingleThreadExecutor<Payload> exec;\nexec.Spin();\n\n// 2. 后台线程 + 休眠策略\nosp::StaticExecutor<Payload, osp::PreciseSleepStrategy> exec(strategy);\nexec.Start();\n\n// 3. CPU 绑核\nosp::PinnedExecutor<Payload, osp::YieldSleepStrategy> exec(/*cpu=*/2);\nexec.Start();\n\n// 4. 工业实时\nosp::RealtimeConfig cfg;\ncfg.sched_policy = SCHED_FIFO;\ncfg.sched_priority = 80;\ncfg.lock_memory = true;     // mlockall\ncfg.cpu_affinity = 3;\nosp::RealtimeExecutor<Payload, osp::PreciseSleepStrategy> exec(cfg);\nexec.Start();\n```\n\nRealtimeExecutor 初始化序列: `mlockall()` → CPU affinity → SCHED_FIFO → 自定义栈 → 进入 ProcessBatch 循环。高精度休眠使用 `clock_nanosleep(CLOCK_MONOTONIC, TIMER_ABSTIME)` 实现亚毫秒精度。\n\n**PreciseSleepStrategy**: 三参数自适应 (default/min/max sleep_ns)，有消息时快速唤醒，空闲时降低功耗。\n\n### 2.8 WorkerPool: 两级无锁流水线\n\n当单消费者线程处理不过来时，WorkerPool 提供多 Worker 并行:\n\n```\nAsyncBus (MPSC)\n    │\n    ▼\nDispatcher Thread (ProcessBatch → Round-Robin 分发)\n    │\n    ├──→ Worker[0] SPSC (1024 depth, wait-free)\n    ├──→ Worker[1] SPSC\n    └──→ Worker[N] SPSC\n```\n\n**第一级 MPSC**: 所有生产者 CAS 发布到共享 Bus。\n\n**第二级 Per-Worker SPSC**: Dispatcher 从 Bus 取出消息，Round-Robin 分发到各 Worker 的 SPSC 队列。Worker 线程从自己的 SPSC 消费，**无任何锁竞争**。\n\nWorker 空闲时三阶段退避: Spin (1-64 次 CPU relax) → Yield (4 次) → Sleep (50us)。有消息到来立即回退到 Spin。\n\n```cpp\nosp::WorkerPool<Payload> pool({.name = \"sensor\", .worker_num = 4});\npool.RegisterHandler<SensorData>([](const SensorData& d, const auto&) {\n    heavy_computation(d);\n});\npool.Start();  // 4 Worker + 1 Dispatcher = 5 线程\n```\n\n## 3. I/O 集成\n\n### 3.1 IoPoller: 编译期后端选择\n\nIoPoller 在编译期根据平台选择后端，API 完全统一:\n\n```cpp\nosp::IoPoller poller;\npoller.Add(tcp_fd, osp::IoEvent::kReadable);\npoller.Add(serial_fd, osp::IoEvent::kReadable);\n\nwhile (running) {\n    auto result = poller.Wait(/*timeout_ms=*/100);\n    if (!result.has_value()) continue;\n    for (uint32_t i = 0; i < result.value(); ++i) {\n        auto& ev = poller.Results()[i];\n        if (ev.events & osp::IoEvent::kReadable) {\n            handle_fd(ev.fd);\n        }\n    }\n}\n```\n\n| 平台 | 后端 | 复杂度 | 选择条件 |\n|------|------|--------|---------|\n| Linux | epoll | O(1) | `__linux__` 定义时 |\n| macOS/BSD | kqueue | O(1) | `__APPLE__` 定义时 |\n| 通用 | poll | O(n) | fallback |\n\n嵌入式 fd 数量通常 < 100，O(n) poll 在此规模下与 O(1) epoll 差异可忽略 (<1us)。IoPoller 保证核心逻辑可移植到 RT-Thread (支持 POSIX poll)，同时在 Linux 自动使用 epoll。\n\n### 3.2 I/O 线程与业务线程解耦\n\nI/O 线程只做三件事: **等待 fd 就绪 → 读取数据 → 发布消息**。不持有业务状态，不需要锁:\n\n```\nI/O 线程                               Executor 线程\n─────────                              ────────────\nIoPoller.Wait()                        ProcessBatch()\n    │                                      │\n    ├── recv(fd, buf, len)                 ├── StaticNode::Handler\n    ├── ParseFrame(buf)                    │   void operator()(const SensorData& d, ...)\n    ├── Deserialize → SensorData           │   {  process(d);  }\n    └── bus.Publish(SensorData{...})  ────>│\n                                           │\n    (零业务逻辑，纯 I/O)                  (零 I/O，纯业务)\n```\n\n分离带来两个好处:\n1. **I/O 线程极轻量**: recv + publish，无阻塞风险\n2. **业务可独立测试**: StaticNode Handler 接收消息和 Header，不依赖 socket/fd\n\n完整的 Transport 接收路径:\n\n```cpp\nvoid TransportReceiver::Run() {\n    osp::IoPoller poller;\n    poller.Add(socket_fd_, osp::IoEvent::kReadable);\n\n    while (running_) {\n        auto result = poller.Wait(100);\n        if (!result.has_value() || result.value() == 0) continue;\n\n        uint8_t buf[kMaxFrameSize];\n        ssize_t n = ::recv(socket_fd_, buf, sizeof(buf), 0);\n        if (n <= 0) continue;\n\n        FrameHeaderV1 header;\n        if (!ParseFrame(buf, n, &header)) continue;\n\n        auto payload = Deserialize(buf + sizeof(header), header.type_idx);\n        if (payload.has_value()) {\n            bus_.Publish(std::move(payload.value()), header.sender_id);\n        }\n    }\n}\n```\n\n## 4. 端到端示例: 传感器采集系统\n\n```cpp\n#include <osp/bus.hpp>\n#include <osp/static_node.hpp>\n#include <osp/executor.hpp>\n#include <osp/io_poller.hpp>\n#include <osp/shutdown.hpp>\n\n// ── 消息类型 (POD, trivially_copyable) ────────────────────────\nstruct SensorReading {\n    uint32_t sensor_id;\n    float value;\n    uint64_t timestamp_ns;\n};\nstruct ProcessedResult {\n    uint32_t sensor_id;\n    float filtered_value;\n    uint8_t quality;\n};\nstruct AlarmEvent {\n    uint32_t sensor_id;\n    uint8_t level;\n    char message[64];\n};\n\nusing Payload = std::variant<SensorReading, ProcessedResult, AlarmEvent>;\nusing Bus = osp::AsyncBus<Payload>;\n\nstatic_assert(std::is_trivially_copyable_v<SensorReading>);\nstatic_assert(std::is_trivially_copyable_v<ProcessedResult>);\nstatic_assert(std::is_trivially_copyable_v<AlarmEvent>);\n\n// ── Handler (编译期绑定) ──────────────────────────────────────\nstruct ProcessingHandler {\n    Bus& bus;\n    float ema_alpha = 0.3f;\n    float ema_value = 0.0f;\n\n    void operator()(const SensorReading& r, const osp::MessageHeader&) {\n        // 指数移动平均滤波\n        ema_value = ema_alpha * r.value + (1.0f - ema_alpha) * ema_value;\n        uint8_t quality = (std::abs(r.value - ema_value) < 1.0f) ? 95 : 60;\n\n        ProcessedResult result{r.sensor_id, ema_value, quality};\n        bus.Publish(Payload(result), /*sender_id=*/2);\n    }\n\n    void operator()(const ProcessedResult& r, const osp::MessageHeader&) {\n        // 质量低于阈值时报警\n        if (r.quality < 50) {\n            AlarmEvent alarm{};\n            alarm.sensor_id = r.sensor_id;\n            alarm.level = 1;\n            std::snprintf(alarm.message, sizeof(alarm.message),\n                         \"quality=%u below threshold\", r.quality);\n            bus.Publish(Payload(alarm), /*sender_id=*/2);\n        }\n    }\n\n    void operator()(const AlarmEvent& a, const osp::MessageHeader&) {\n        OSP_LOG_WARN(\"Alarm\", \"sensor=%u level=%u: %s\",\n                     a.sensor_id, a.level, a.message);\n    }\n};\n\n// ── Main ──────────────────────────────────────────────────────\nint main() {\n    auto& shutdown = osp::ShutdownManager::Instance();\n    auto& bus = Bus::Instance();\n\n    // 处理节点 (StaticNode, 编译期分发)\n    ProcessingHandler handler{bus};\n    osp::StaticNode<Payload, ProcessingHandler> processor(\"processor\", 2, handler);\n\n    // I/O 采集节点\n    osp::Node<Payload> sensor_io(\"sensor_io\", 1);\n\n    // I/O 线程: IoPoller → recv → Publish\n    std::thread io_thread([&]() {\n        osp::IoPoller poller;\n        poller.Add(sensor_fd, osp::IoEvent::kReadable);\n\n        while (!shutdown.IsShutdown()) {\n            auto result = poller.Wait(100);\n            if (!result.has_value() || result.value() == 0) continue;\n\n            for (uint32_t i = 0; i < result.value(); ++i) {\n                auto& ev = poller.Results()[i];\n                if (ev.events & osp::IoEvent::kReadable) {\n                    SensorReading reading{};\n                    ssize_t n = ::read(ev.fd, &reading, sizeof(reading));\n                    if (n == sizeof(reading)) {\n                        reading.timestamp_ns = osp::SteadyNowNs();\n                        sensor_io.Publish(reading);\n                    }\n                }\n            }\n        }\n    });\n\n    // 消息调度: CPU 2 绑核，PreciseSleep 降低空闲功耗\n    osp::PreciseSleepStrategy sleep_strategy(\n        1'000'000ULL,   // 默认 1ms\n        100'000ULL,     // 最小 100us\n        10'000'000ULL   // 最大 10ms\n    );\n    osp::PinnedExecutor<Payload, osp::PreciseSleepStrategy> executor(2, sleep_strategy);\n    executor.Start();\n\n    shutdown.WaitForShutdown();\n    executor.Stop();\n    io_thread.join();\n    return 0;\n}\n```\n\n**线程分布**:\n\n```\nCPU 0: Linux 内核 + 系统服务\nCPU 1: I/O 线程 (IoPoller + recv + Publish)\nCPU 2: 消息调度 (PinnedExecutor, ProcessBatch → StaticNode)\nCPU 3: 备用 (WorkerPool Worker / 日志 / Shell)\n\n合计: 3 线程，确定性\n```\n\n**消息流**:\n\n```\nsensor_fd (硬件)\n    │\n    ▼\nIoPoller.Wait() → recv → SensorReading → bus.Publish()\n                                              │\n    processor (StaticNode) ←──────────────────┘\n        │\n        ├── operator()(SensorReading) → EMA 滤波 → ProcessedResult → Publish\n        │\n        ├── operator()(ProcessedResult) → 质量检查 → AlarmEvent → Publish\n        │\n        └── operator()(AlarmEvent) → OSP_LOG_WARN\n```\n\n**性能数据** (ARM Cortex-A72, 4 核 1.5GHz):\n\n| 指标 | 数值 | 说明 |\n|------|------|------|\n| StaticNode 分发延迟 (P50) | ~2 ns | std::visit 直接跳转 |\n| Node 回调延迟 (P50) | ~30 ns | FixedFunction 间接调用 |\n| Publish 延迟 (P50) | ~15 ns | CAS + memcpy envelope |\n| 端到端延迟 (Publish → Handler) | ~50 ns | 含 ProcessBatch 调度 |\n| Bus 吞吐 (单生产者) | ~60M msg/s | QueueDepth=4096 |\n| Bus 吞吐 (4 生产者) | ~40M msg/s | CAS 竞争开销 |\n| 热路径堆分配 | 0 | FixedFunction SBO + variant 值语义 |\n\n## 5. 与传统方案对比\n\n| 维度 | mutex + queue | epoll 回调 | newosp 事件总线 |\n|------|:------------:|:----------:|:--------------:|\n| 线程间同步 | mutex (futex slow path) | 单线程无需 | CAS 无锁 MPSC |\n| 消息存储 | std::queue (堆分配) | 自行管理 | 预分配环形缓冲 |\n| 回调机制 | std::function (可能堆分配) | 裸函数指针/回调 | FixedFunction SBO / std::visit |\n| 类型安全 | void* 或 std::any | 自行管理 | std::variant 编译期路由 |\n| 背压 | 无界队列或阻塞 | 自行实现 | 优先级准入 (60/80/99%) |\n| I/O 可移植 | N/A | epoll 专有 | epoll/kqueue/poll 自动选择 |\n| 可测试性 | 线程竞态难测 | 依赖 fd mock | Node 纯消息测试 |\n| 延迟 (P50) | ~1-5 us | ~100-500 ns | ~2 ns (StaticNode) |\n\n核心差异: 传统方案的 `std::mutex` futex slow path 和 `std::queue` 堆分配是热路径上的两个主要不确定性来源。newosp 用 CAS 环形缓冲消除了前者，用 variant 值语义消除了后者。\n\n## 参考资料\n\n1. [newosp GitHub 仓库](https://github.com/DeguiLiu/newosp) -- C++17 header-only 嵌入式基础设施库\n2. [C++ 多线程与协程优化阻塞型任务](https://blog.csdn.net/stallion5632/article/details/143887766) -- state-threads 实验\n3. [Linux I/O 多路复用与异步 I/O 对比](https://blog.csdn.net/stallion5632/article/details/143675999) -- 五种 I/O 模型\n4. [Cyber RT 协程实现](https://zhuanlan.zhihu.com/p/365838048) -- Baidu Apollo 协程架构\n",
      "ctime": "1771552464",
      "mtime": "1771552464",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/newosp_event_driven_architecture.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038371878",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "如何设计传感器数据流水线: newosp 事件驱动 + 零堆分配方案",
      "brief_content": "以激光雷达点云处理流水线为主线，展示 newosp C++17 事件驱动架构如何解决工业传感器系统的三大工程难题: 零堆分配消息传递 (CAS 无锁 MPSC + variant 值语义)、可建模的状",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> newosp GitHub: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp)\n>\n> 本文基于 newosp v0.2.0，1114 test cases (26085 assertions)，ASan/TSan/UBSan 全部通过。\n>\n> 相关文章:\n> - [嵌入式并发的第四条路: 为什么多线程、协程和 epoll 都不够用](../newosp_concurrency_io_architecture/) -- 三条并发路径的局限与事件驱动方案\n> - [无锁编程核心原理: 从 CAS 到三种队列模式](../lockfree_programming_fundamentals/) -- AsyncBus 底层的无锁原理\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- newosp SPSC 的逐行代码分析\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- ShmRingBuffer 的工程实践\n> - [newosp ospgen: YAML 驱动的 C++17 零堆消息代码生成](../newosp_ospgen_codegen/) -- Bus/Node 消息类型的自动生成\n> - [C 语言层次状态机框架: 从过程驱动到数据驱动](../c_hsm_data_driven_framework/) -- C 语言 HSM 的演进路径\n> - [嵌入式线程间消息传递重构: MCCC 无锁消息总线](../mccc_message_passing/) -- newosp AsyncBus 的前身 MCCC\n>\n> CSDN 原文: [newosp 深度解析: C++17 事件驱动架构](https://blog.csdn.net/stallion5632)\n\n## 1. 问题: 传感器数据处理的三重困境\n\n工业传感器系统 (激光雷达、深度相机、工业视觉) 面临三个相互矛盾的工程需求:\n\n**确定性**: 1kHz+ 采样率要求热路径微秒级延迟，一次 `malloc` 或 `mutex` slow path 就可能导致帧丢失。\n\n**安全性**: 传感器有复杂的硬件状态 (初始化、采集中、校准、异常恢复)。if-else 嵌套到第三层就无法维护，需要可建模、可测试的状态管理。\n\n**可组合性**: 数据从 DMA 采集到最终输出要经过 5-6 个处理阶段，每个阶段可能由不同开发者负责。阶段之间需要解耦，同时不能引入共享状态和锁竞争。\n\n传统方案的选择:\n\n| 方案 | 缺陷 |\n|------|------|\n| `shared_ptr<Frame>` + `mutex` + `deque` | 堆分配 control block + futex slow path，热路径不确定 |\n| 回调链 + `std::function` | SBO 溢出时堆分配，回调嵌套难以测试 |\n| 手写 enum + switch 状态机 | 状态数增长时 O(n^2) 转换，无法继承默认行为 |\n\nnewosp 是面向 ARM-Linux 嵌入式平台的 C++17 header-only 基础设施库 ([GitHub](https://github.com/DeguiLiu/newosp))，41 个模块覆盖从消息总线到状态机的全栈需求。本文以**激光雷达点云处理流水线**为主线，展示这些模块如何协同工作。\n\n## 2. 流水线全景: 从 DMA 到输出\n\n### 2.1 架构\n\n```\nDMA/ISR ──> Acquisition ──> Preprocess ──> Compute ──> Filter ──> Package\n            (采集)         (预处理)      (距离计算)  (滤波)    (封装)\n            HSM 管理       去串扰/鬼影    深度转换    噪声消除   帧聚合\n```\n\n每个阶段是一个 `StaticNode` (编译期绑定 Handler)，阶段间通过共享的 `AsyncBus` 通信。数据以 `std::variant` 值语义在 Bus 的环形缓冲中传递，**全程零堆分配**。\n\n### 2.2 消息类型\n\n所有消息必须 `trivially_copyable` (SPSC/ShmRingBuffer `memcpy` 安全):\n\n```cpp\nstruct RawFrame {\n    uint32_t seq;\n    uint32_t timestamp_us;\n    uint16_t adc_values[256];\n    uint16_t point_count;\n    uint8_t  channel_id;\n    uint8_t  padding[1];\n};\n\nstruct ComputedFrame {\n    uint32_t seq;\n    uint32_t timestamp_us;\n    float    distances[256];\n    float    intensities[256];\n    uint16_t valid_count;\n    uint8_t  channel_id;\n    uint8_t  padding[1];\n};\n\n// 中间阶段: PreprocessedFrame, FilteredFrame, PackagedResult (结构类似)\n// 控制消息\nstruct PipelineControl {\n    enum class Action : uint8_t { kStart = 0, kStop, kReset, kCalibrate };\n    Action action;\n    uint8_t channel_id;\n};\n\n// 流水线 Payload\nusing SensorPayload = std::variant<\n    RawFrame, PreprocessedFrame, ComputedFrame,\n    FilteredFrame, PackagedResult, PipelineControl>;\n\n// 编译期保证\nstatic_assert(std::is_trivially_copyable_v<RawFrame>);\nstatic_assert(std::is_trivially_copyable_v<ComputedFrame>);\n```\n\n**为什么用 variant 值语义而不是 `shared_ptr`**: `shared_ptr<Frame>` 的 control block 需要堆分配，引用计数的原子操作在 ARM 上也有可观开销。variant 将帧数据 (固定大小 POD) 直接嵌入 Bus 的 Envelope 中，一次 `memcpy` 完成发布，`sizeof` 编译期确定。\n\n### 2.3 流水线装配\n\n```cpp\nauto& bus = osp::AsyncBus<SensorPayload>::Instance();\n\n// 每个阶段 = StaticNode<Payload, Handler>\nosp::StaticNode<SensorPayload, AcquisitionHandler>  acq_node(\"acquisition\", 1, acq_handler);\nosp::StaticNode<SensorPayload, PreprocessHandler>   prep_node(\"preprocess\", 2, prep_handler);\nosp::StaticNode<SensorPayload, ComputeHandler>      comp_node(\"compute\", 3, comp_handler);\nosp::StaticNode<SensorPayload, FilterHandler>       filt_node(\"filter\", 4, filt_handler);\nosp::StaticNode<SensorPayload, PackageHandler>      pack_node(\"package\", 5, pack_handler);\n\n// 单线程顺序调度 (延迟最确定)\nwhile (!shutdown.IsShutdown()) {\n    acq_node.SpinOnce();    // DMA/ISR → RawFrame\n    prep_node.SpinOnce();   // RawFrame → PreprocessedFrame\n    comp_node.SpinOnce();   // PreprocessedFrame → ComputedFrame\n    filt_node.SpinOnce();   // ComputedFrame → FilteredFrame\n    pack_node.SpinOnce();   // FilteredFrame → PackagedResult\n}\n```\n\n也可以按计算密度分配到不同 CPU 核心:\n\n```cpp\n// I/O 密集阶段 → CPU 0，计算密集阶段 → CPU 1\nstd::thread io_thread([&]() {\n    while (!shutdown.IsShutdown()) { acq_node.SpinOnce(); prep_node.SpinOnce(); }\n});\nstd::thread compute_thread([&]() {\n    while (!shutdown.IsShutdown()) {\n        comp_node.SpinOnce(); filt_node.SpinOnce(); pack_node.SpinOnce();\n    }\n});\n```\n\n### 2.4 Handler 示例: 预处理阶段\n\n每个 Handler 是一个实现了 `operator()` 重载的 struct，编译器通过 `std::visit` 生成直接跳转表 (零间接调用):\n\n```cpp\nstruct PreprocessHandler {\n    osp::AsyncBus<SensorPayload>* bus;\n\n    void operator()(const RawFrame& raw, const osp::MessageHeader&) {\n        PreprocessedFrame pf{};\n        pf.seq = raw.seq;\n        pf.timestamp_us = raw.timestamp_us;\n\n        // 去串扰 + 去鬼影 (具体算法省略)\n        pf.valid_count = remove_crosstalk_and_ghost(\n            raw.adc_values, raw.point_count, pf.cleaned_values);\n\n        bus->Publish(SensorPayload(pf), /*sender_id=*/2);\n    }\n\n    template <typename T>\n    void operator()(const T&, const osp::MessageHeader&) {}  // 其他类型忽略\n};\n```\n\n### 2.5 端到端延迟追踪\n\n每帧携带 `seq` + `timestamp_us`，在最终阶段计算流水线延迟:\n\n```cpp\nvoid operator()(const FilteredFrame& ff, const osp::MessageHeader&) {\n    uint32_t latency_us = osp::SteadyNowUs() - ff.timestamp_us;\n    if (latency_us > 1000) {  // 超过 1ms 告警\n        OSP_LOG_WARN(\"Pipeline\", \"high latency: seq=%u %u us\", ff.seq, latency_us);\n    }\n    // ... 正常封装处理\n}\n```\n\n## 3. AsyncBus: 支撑流水线的无锁消息总线\n\n流水线中每个 `StaticNode` 调用 `bus->Publish()` 发布消息，调用 `SpinOnce()` 消费消息。这两个操作由 AsyncBus 的 CAS 无锁 MPSC 环形缓冲支撑。\n\n### 3.1 核心数据结构\n\n```cpp\ntemplate <typename PayloadVariant,\n          uint32_t QueueDepth = 4096,    // 必须是 2 的幂\n          uint32_t BatchSize = 256>\nclass AsyncBus;\n```\n\n消息以**信封** (header + variant payload) 存储在缓存行对齐的环形缓冲中:\n\n```cpp\nstruct MessageHeader {\n    uint64_t msg_id;           // 全局递增 ID\n    uint64_t timestamp_us;     // 微秒时间戳\n    uint32_t sender_id;        // 发送者节点 ID\n    uint32_t topic_hash;       // FNV-1a 32-bit hash\n    MessagePriority priority;  // kLow / kMedium / kHigh\n};\n\nstruct alignas(64) RingBufferNode {\n    std::atomic<uint32_t> sequence;  // 序号控制 (CAS 的核心)\n    MessageEnvelope<PayloadVariant> envelope;\n};\n```\n\n### 3.2 CAS 发布: 多生产者无锁竞争\n\n多个 `StaticNode` (可能在不同线程) 同时发布消息，通过 CAS 循环竞争环形缓冲的写入位置:\n\n```\nProducer 0 ─┐\nProducer 1 ──┼── CAS Publish ──> Ring Buffer ──> ProcessBatch() ──> 类型分发\nProducer 2 ─┘   (无锁竞争)      (sequence-based)   (批量消费)      (variant visit)\n```\n\n关键内存序: 生产者用 `acq_rel` CAS 抢占位置，用 `release` store 发布数据; 消费者用 `acquire` load 读取数据。完整实现见 [bus.hpp](https://github.com/DeguiLiu/newosp/blob/main/include/osp/bus.hpp)。\n\n### 3.3 优先级准入控制\n\n传感器流水线中，控制命令 (启停、校准) 的优先级高于数据帧。当 Bus 队列压力增大时，AsyncBus 按优先级逐级丢弃:\n\n```\n队列深度\n│  ████████████████████  100%\n│  ██████████████████    99%  ← kHigh 阈值 (控制命令)\n│  ██████████████        80%  ← kMedium 阈值 (常规数据)\n│  ██████████            60%  ← kLow 阈值 (遥测/统计)\n```\n\n生产者先检查本地缓存的消费位置 (relaxed 读，无 cache line 竞争)，只有接近阈值时才重新读取真正的消费位置 (acquire 读)。低负载时完全避免对消费者原子变量的争用。\n\n### 3.4 编译期分发: StaticNode vs Node\n\nnewosp 提供两种消费模式:\n\n| 模式 | 机制 | ns/msg (P50) |\n|------|------|---:|\n| **StaticNode** (编译期) | `std::visit` 跳转表 | ~2 |\n| Node (运行时) | FixedFunction 回调表 | ~30 |\n\nStaticNode 的 Handler 在编译期确定，编译器为每个 variant alternative 生成直接调用，无 FixedFunction 间接调用、无 SharedSpinLock、无回调表遍历。流水线的 5 个处理阶段全部使用 StaticNode。\n\n**FixedFunction**: 需要运行时动态订阅的场景使用 Node 模式，回调存储在 `FixedFunction<void(const Envelope&), 32>` 中 -- 32 字节 SBO 缓冲，编译期 `static_assert` 拒绝超限 lambda，**杜绝 `std::function` 的隐式堆分配**。\n\n## 4. HSM: 采集阶段的状态管理\n\n流水线的 Acquisition 阶段需要管理传感器硬件状态。平面 FSM 在这里不够用: 设备的 Idle/Acquiring/Validating 三个子状态都需要响应 \"Deactivate\" 事件 (关闭设备)，平面 FSM 需要为每个子状态都写一条相同的转换。\n\n### 4.1 层次状态机: 继承与覆盖\n\nnewosp 的 `StateMachine<Context, MaxStates>` 通过状态嵌套解决这一问题:\n\n```\nAcquisition HSM (6 个状态)\n├── Inactive         ← 设备未启动\n├── Active (父状态)  ← 处理 Deactivate (所有子状态继承)\n│   ├── Idle         ← 等待 DMA 完成信号\n│   ├── Acquiring    ← 正在接收 DMA 数据\n│   └── Validating   ← 校验帧完整性\n└── Error            ← 硬件异常 (DMA 超时/CRC 错误)\n```\n\n子状态未处理的事件自动**冒泡**到父状态。Active 父状态只需定义一次 Deactivate 处理:\n\n```cpp\n// Active 父状态: 一次定义，三个子状态 (Idle/Acquiring/Validating) 共享\ninline osp::TransitionResult HandleActive(AcqContext& ctx, osp::Event& e) {\n    if (e.id == kEvtDeactivate) {\n        return ctx.sm->RequestTransition(ctx.idx_inactive);\n    }\n    return osp::TransitionResult::kUnhandled;  // 继续冒泡\n}\n```\n\n### 4.2 LCA 转换算法\n\n状态转换的核心是**最近公共祖先 (LCA)** 计算: 从源状态到 LCA 依次执行 Exit 动作，再从 LCA 到目标状态依次执行 Entry 动作。newosp 使用**深度归一化**实现:\n\n1. 计算源和目标的深度\n2. 将较深的状态上移到同一层\n3. 同步上移直到找到公共祖先\n4. 执行 Exit 路径 (source → LCA) 和 Entry 路径 (LCA → target)\n\nExit/Entry 路径使用栈上固定数组 (`int32_t path[32]`)，整个转换过程零堆分配。完整实现见 [hsm.hpp](https://github.com/DeguiLiu/newosp/blob/main/include/osp/hsm.hpp)。\n\n### 4.3 Guard 条件\n\nnewosp 在状态配置中内置 Guard 函数指针。事件派发时，先检查 Guard 条件，返回 false 则跳过该状态直接冒泡:\n\n```cpp\nstruct StateConfig {\n    const char* name;\n    int32_t parent_index;                         // -1 = 根\n    TransitionResult (*handler)(Context&, Event&);\n    void (*on_entry)(Context&);\n    void (*on_exit)(Context&);\n    bool (*guard)(const Context&, Event&);        // Guard 条件\n};\n```\n\n这使得\"仅在特定条件下才处理事件\"可以声明式表达，而非在 handler 内部硬编码 if 判断。\n\n### 4.4 采集 HSM 与 Handler 的集成\n\nAcquisitionHandler 将 Bus 消息转化为 HSM 事件:\n\n```cpp\nstruct AcquisitionHandler {\n    AcqContext* ctx;\n\n    void operator()(const PipelineControl& ctrl, const osp::MessageHeader&) {\n        osp::Event e{ctrl.action == PipelineControl::Action::kStart\n                         ? kEvtActivate : kEvtDeactivate};\n        ctx->sm->Dispatch(e);\n    }\n\n    template <typename T>\n    void operator()(const T&, const osp::MessageHeader&) {}\n};\n```\n\nHSM 内部的状态处理函数在适当时机通过 `bus->Publish()` 发布 RawFrame，驱动下游流水线。**消息总线和状态机各司其职**: Bus 负责阶段间解耦通信，HSM 负责阶段内状态管理。\n\n### 4.5 零堆分配保证\n\n| 组件 | 存储方式 |\n|------|---------|\n| 状态配置 | `std::array<StateConfig, MaxStates>` |\n| 转换路径 | 栈上 `int32_t path[32]` |\n| 事件 | 值语义 Event (栈分配) |\n| Handler | 函数指针 (非 std::function) |\n| 内存开销 | ~500B (16 状态) |\n\n## 5. SPSC 环形缓冲: 模块间的零拷贝通道\n\nnewosp 的 `SpscRingbuffer` 是一个通用的、类型化的 wait-free SPSC 组件，在多个模块中复用:\n\n| 集成点 | 元素类型 | 容量 |\n|--------|---------|------|\n| WorkerPool 工作线程 | `MessageEnvelope<PayloadVariant>` | 1024 |\n| 串口字节缓冲 | `uint8_t` | 4096 |\n| 网络帧缓冲 | `RecvFrameSlot` | 32 |\n| 统计通道 | `ShmStats` (48B) | 16 |\n\n### 5.1 编译期双路径\n\n```cpp\ntemplate <typename T, size_t BufferSize, bool FakeTSO = false>\nclass SpscRingbuffer {\n    bool PushBatch(const T* buf, size_t count) {\n        if constexpr (std::is_trivially_copyable_v<T>) {\n            // POD: memcpy 批量拷贝 (处理 wrap-around 分两段)\n            std::memcpy(&data_buff_[head_offset], buf, first_part * sizeof(T));\n        } else {\n            // 非 POD: 逐元素 move\n            for (size_t i = 0; i < count; ++i) {\n                data_buff_[(head + i) & kMask] = std::move(buf[i]);\n            }\n        }\n    }\n};\n```\n\n`if constexpr` 在编译期选择 memcpy (POD) 或逐元素 move (非 POD) 路径。传感器流水线中的所有消息类型都是 `trivially_copyable`，走 memcpy 快路径。\n\n### 5.2 FakeTSO: 单核 MCU 优化\n\n```cpp\nstatic constexpr std::memory_order AcquireOrder() {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_acquire;\n}\n```\n\n| FakeTSO | Acquire/Release | 适用场景 |\n|---------|-----------------|----------|\n| false | acquire / release | 多核 ARM-Linux |\n| true | relaxed / relaxed | 单核 MCU (RT-Thread) |\n\n单核 MCU 上，ISR 和线程之间的内存可见性由 `ISB` 隐式保证，将 acquire/release 降级为 relaxed 节省 ARM `DMB` 指令开销。\n\n### 5.3 缓存行对齐\n\n```cpp\nstruct alignas(64) PaddedIndex {\n    std::atomic<size_t> value{0};\n};\nPaddedIndex head_;  // 生产者独占\n// --- 64 字节边界 ---\nPaddedIndex tail_;  // 消费者独占\n```\n\n生产者和消费者的索引分布在不同缓存行，消除 false sharing。\n\n### 5.4 延迟计算\n\n```cpp\ntemplate <typename Callable>\nbool PushFromCallback(Callable&& callback) {\n    if (IsFull()) return false;  // 队列满则跳过\n    data_buff_[head & kMask] = callback();  // 延迟计算\n    head_.value.store(head + 1, ReleaseOrder());\n    return true;\n}\n```\n\n传感器采集场景: 如果下游消费者跟不上，`PushFromCallback` 直接跳过 ADC 读取，避免无意义的硬件操作。\n\n完整 SPSC 实现分析见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/)。\n\n## 6. 生命周期与调度\n\n### 6.1 LifecycleNode: 16 状态 HSM 驱动\n\nnewosp 的 `LifecycleNode` 内置了一个 **16 状态的层次状态机**，将节点生命周期本身建模为 HSM:\n\n```\nAlive (根状态)\n├── Unconfigured (Initializing / WaitingConfig)\n├── Configured\n│   ├── Inactive (Standby / Paused)\n│   └── Active (Starting / Running / Degraded)\n├── Error (Recoverable / Fatal)\n└── Finalized (终态)\n```\n\nLifecycleNode 继承自 Node，支持粗粒度 (4 状态) 和细粒度 (16 状态) 双层视图，内置 FaultReporter 注入点。HSM 实例使用 placement new 在预分配的对齐存储中构造，零堆分配。\n\n### 6.2 Executor 调度家族\n\n流水线的调度策略由 Executor 决定。newosp 提供四种执行模型:\n\n| Executor | 特点 | 适用场景 |\n|----------|------|---------|\n| SingleThread | 阻塞调用线程 | 调试、单核 |\n| Static | 后台线程 + 休眠策略 | 通用场景 |\n| Pinned | CPU 绑核 | 确定性调度 |\n| **Realtime** | SCHED_FIFO + mlockall + CPU affinity | 工业实时 |\n\nRealtimeExecutor 初始化序列: `mlockall()` → CPU affinity → SCHED_FIFO → 自定义栈 → 进入 ProcessBatch 循环。高精度休眠使用 `clock_nanosleep(CLOCK_MONOTONIC, TIMER_ABSTIME)` 实现亚毫秒级精度。\n\n详细的线程模型、WorkerPool 二级排队、IoPoller I/O 集成见 [newosp 嵌入式并发与 I/O 架构](../newosp_concurrency_io_architecture/)。\n\n## 7. 跨模块集成\n\n### 7.1 数据流全景\n\n```\n传感器线程 ─┐\n控制线程  ──┼── AsyncBus::Publish() ─── [CAS MPSC Ring Buffer] ───┐\n网络线程  ─┘   (无锁竞争)              (4096 slots, 缓存行对齐)      │\n                                                                     │\n                              ┌──── ProcessBatch() 单消费者 ─────────┘\n                              │\n                              ▼\n                    Node 类型路由 (FNV-1a topic hash)\n                              │\n                    ┌─────────┼─────────┐\n                    │         │         │\n                    ▼         ▼         ▼\n              StaticNode   Node     WorkerPool\n              (零开销)   (动态订阅)  (SPSC 分发)\n                    │         │         │\n                    ▼         ▼         ▼\n                HSM/BT    回调处理    并行计算\n```\n\n### 7.2 可靠性闭环\n\nnewosp 的 Watchdog 和 FaultCollector 职责正交:\n\n- **Watchdog**: 检测问题 (线程心跳超时)\n- **FaultCollector**: 处理问题 (分级上报 + hook 决策: kHandled / kEscalate / kDefer / kShutdown)\n\n两者通过应用层 wiring 组合，没有内部依赖。流水线的 Acquisition HSM 通过 FaultReporter 向 FaultCollector 上报硬件异常 (DMA 超时、CRC 错误)。\n\n### 7.3 模块选择指南\n\n| 场景 | 推荐方案 |\n|------|---------|\n| 简单传感器数据流 | Node + AsyncBus + SingleThreadExecutor |\n| 高吞吐多生产者 | StaticNode + AsyncBus<PV, 4096, 256> + PinnedExecutor |\n| 多级流水线处理 | 多个 StaticNode + 共享 Bus + 顺序 SpinOnce |\n| 复杂状态管理 | StateMachine (手动) 或 LifecycleNode (标准生命周期) |\n| 实时控制 | RealtimeExecutor (SCHED_FIFO) + PreciseSleepStrategy |\n| 跨进程 IPC | ShmChannel + ShmRingBuffer (零拷贝共享内存) |\n\n### 7.4 迁移路径: Linux → RT-Thread\n\nnewosp 核心模块保持 POSIX API 边界清晰:\n\n| 模块 | Linux 依赖 | RT-Thread 适配 |\n|------|-----------|---------------|\n| SPSC | 无 (纯 C++ atomic) | `FakeTSO = true` |\n| HSM | 无 (纯 C++) | 直接使用 |\n| AsyncBus | 无 (CAS 原子操作) | 直接使用 |\n| Executor | pthread, SCHED_FIFO | 映射到 RT-Thread 线程 API |\n| ShmTransport | shm_open, mmap | 不适用 (单进程) |\n\n## 8. 设计原则总结\n\n| 原则 | 实现手段 |\n|------|---------|\n| **零全局状态** | Bus 依赖注入，非全局单例 |\n| **栈优先，零堆分配** | FixedFunction SBO / FixedVector / FixedString / variant 值语义 |\n| **无锁/最小锁** | CAS MPSC + wait-free SPSC + SharedSpinLock |\n| **编译期分发** | 模板参数化 + `if constexpr` + `std::visit` 跳转表 |\n| **类型安全** | `std::variant` + `expected<V,E>` + `static_assert` trivially_copyable |\n| **`-fno-exceptions -fno-rtti`** | 全代码库兼容，`Validate()` 返回 bool 而非抛异常 |\n\n**为什么不用对象池**。避免热路径 `malloc` 的另一种常见方案是对象池 (`mutex` + `queue<shared_ptr>`)。对象池确实比裸分配快约 60%，但在 newosp 的场景中仍有三个代价: mutex 在每次 acquire/release 上引入 futex 开销 (~20-40ns)，`shared_ptr` 原子引用计数在单向数据流中完全多余，`std::queue` 动态增长破坏编译期内存预算。newosp 用预分配环形缓冲 (slot 覆写，零 malloc) + variant 值语义 (无引用计数) + CAS/wait-free (无 mutex) 彻底消除了这三项开销。对象池适合生命周期不确定的共享对象 (连接池、线程池)，不适合单向流动的消息通道。详见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) 和 [对象池在嵌入式热路径上的三个隐性成本](../object_pool_hidden_costs/)。\n\n这些原则贯穿整条传感器流水线: variant 保证消息类型安全，CAS 保证并发发布安全，HSM 保证状态转换安全，`static_assert` 保证跨平台 sizeof 一致。每个\"安全\"都是编译期或硬件级保证，不是运行时约定。\n\n## 参考资料\n\n1. [newosp GitHub 仓库](https://github.com/DeguiLiu/newosp) -- C++17 header-only 嵌入式基础设施库\n2. [ROS2 Lifecycle Node Design](https://design.ros2.org/articles/node_lifecycle.html)\n3. [事件驱动架构的嵌入式激光雷达点云数据处理](https://blog.csdn.net/stallion5632/article/details/150624229)\n4. Miro Samek, *Practical UML Statecharts in C/C++*, 2nd Edition\n",
      "ctime": "1771552467",
      "mtime": "1771552467",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/osp_upgrade_engine_design.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857404978",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "工业固件 A/B 分区升级引擎: HSM 驱动 + 三层掉电保护设计",
      "brief_content": "面向工业嵌入式的固件 A/B 分区升级引擎设计与实现。以 osp::StateMachine 驱动 8 阶段升级流程，通过 raw 分区状态持久化 + U-Boot 冗余环境变量原子切换 + boot",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 项目仓库: [osp-upgrade-engine](https://gitee.com/liudegui/osp-upgrade-engine) (C++17 header-only, 32/32 tests pass)\n> 依赖库: [newosp](https://github.com/DeguiLiu/newosp) (1153 tests, ASan/TSan/UBSan clean)\n> 目标平台: ARM-Linux (Cortex-A53/A72) | 32-256 MB RAM | C++17\n> 适用场景: 激光雷达固件升级、机器人 OTA、边缘计算设备、工业现场无人值守环境\n\n---\n\n## 1. 问题域与设计选择\n\n### 1.1 工业嵌入式固件升级的硬约束\n\n激光雷达、机器人、边缘计算等工业设备在现场无人值守，固件升级面临三个硬约束:\n\n| 约束 | 典型指标 | 技术影响 |\n|------|----------|--------|\n| **掉电安全** | 任意时刻断电不能变砖 | 需要 3+ 层持久化保护 |\n| **资源受限** | 32-256 MB RAM, 无 D-Bus | 禁止外部重依赖框架 |\n| **可验证性** | 升级后必须自检确认 | 新固件启动失败自动回滚 |\n\n传统 Linux OTA 方案 (SWUpdate、RAUC) 依赖链重，不适用:\n\n| 方案 | 依赖 | 内存占用 | 进程模型 | 掉电保护 |\n|------|------|---------|--------|--------|\n| **SWUpdate/RAUC** | D-Bus, systemd, GLib, libcurl | ~10-50 MB | 独立 daemon | update_state 文件 |\n| **osp-upgrade-engine** | newosp (header-only) | < 73 KB | 嵌入应用进程 | raw 分区 + U-Boot env + bootcount |\n\n### 1.2 设计决策的工程权衡\n\n**选择 HSM 而非事件循环**: 固件升级流程严格线性 (Idle → Verifying → Writing → Switching → Rebooting → BootVerify → Rollback → Idle)，状态转换有明确的前后依赖。HSM 的显式状态定义和 LCA 转换机制使掉电恢复的状态跳转更容易推导。\n\n**选择函数指针表而非虚函数**: 遵循项目规范 (编译期分发优先)，零间接调用开销，同一份代码可轻松切换生产环境 (POSIX HAL) 和仿真环境 (SimHAL)。\n\n**选择 raw 分区而非文件系统**: 避免文件系统日志和日志 commit 的不确定性，每次状态转换前原子写入 64B 记录到固定偏移，确定性掉电安全。\n\n**选择 SpinOnce 轮询而非额外线程**: 不增加线程预算，升级在应用进程内执行，每次处理 4KB chunk，主循环可在 SpinOnce 间隙处理其他任务。\n\n---\n\n## 2. 架构总览\n\n### 2.1 三层掉电保护机制\n\n```\n┌──────────────────────────────────────────────────────────────┐\n│ 第 1 层: Raw 分区状态持久化                                   │\n│ • 每次 HSM 状态转换前 pwrite(state_fd, &record, 64, 0) +    │\n│   fsync(state_fd)                                            │\n│ • 64B UpgradeStateRecord (magic + state + CRC-32)           │\n│ • 启动恢复: RecoverFromPersistentState() 读取上次未完成状态  │\n│ • 保护范围: 任意阶段掉电重启后能精确恢复                      │\n└──────────────────────────────────────────────────────────────┘\n\n┌──────────────────────────────────────────────────────────────┐\n│ 第 2 层: U-Boot 冗余环境变量原子切换                          │\n│ • U-Boot 原生支持冗余 env (两个副本交替写入)                 │\n│ • fw_setenv boot_slot_next / upgrade_available / bootcount   │\n│ • 启动分区切换的原子性由 U-Boot 保证                         │\n│ • 保护范围: Switching 阶段即使多次掉电也能正确切换或保持旧值 │\n└──────────────────────────────────────────────────────────────┘\n\n┌──────────────────────────────────────────────────────────────┐\n│ 第 3 层: bootcount 自动回滚机制                              │\n│ • U-Boot 每次启动递增 bootcount                             │\n│ • bootcount > bootlimit (默认 3) 时自动回滚到旧分区         │\n│ • 新固件调用 ConfirmBoot() 清除 upgrade_available 和 count  │\n│ • 保护范围: 新固件反复崩溃无法调用 ConfirmBoot 时自动回滚   │\n└──────────────────────────────────────────────────────────────┘\n```\n\n### 2.2 8 阶段 HSM 状态转换图\n\n```mermaid\nstateDiagram-v2\n    [*] --> Idle\n\n    Idle --> Verifying: StartUpgrade\\n[版本+硬件兼容检查]\n    Verifying --> Writing: SHA-256+Ed25519\\n通过\n    Verifying --> Idle: 校验失败 / Cancel\n\n    Writing --> Switching: 写入完成+\\n读回校验通过\n    Writing --> Idle: 写入失败\n\n    Switching --> Rebooting: env 切换完成\n    Rebooting --> BootVerify: reboot 完成恢复\n\n    BootVerify --> Idle: ConfirmBoot\\n(自检通过)\n    BootVerify --> Rollback: 自检失败 /\\nWatchdog 超时\n\n    Rollback --> Idle: 回滚完成\n```\n\n核心设计:\n- **扁平结构** (parent_index = -1): 无层级嵌套，线性流程不需要 LCA 跨层转换\n- **持久化边界**: 每个黑色箭头转换前都 fsync 状态到 raw 分区\n- **掉电恢复路径**: 启动时读取持久化状态，用 `ForceTransition()` 直接跳转到中断点\n\n### 2.3 存储布局\n\n典型 8GB eMMC 分区表:\n\n```\nmmcblk0p1  bootloader        2 MB    U-Boot SPL + U-Boot\nmmcblk0p2  env              128 KB   U-Boot 冗余环境变量 (2 副本)\nmmcblk0p3  recovery          32 MB   最小恢复系统\nmmcblk0p4  rootfs_a           1 GB   主系统 A 分区 (当前活跃)\nmmcblk0p5  rootfs_b           1 GB   主系统 B 分区 (升级目标)\nmmcblk0p6  config            64 MB   持久化配置 (不随升级擦除)\nmmcblk0p7  data             剩余     用户数据 + 升级包暂存\nmmcblk0p8  upgrade_state     64 KB   升级状态 (raw, 无 FS)\n```\n\n**upgrade_state 的设计权衡**: raw 分区直接 pwrite/fsync，避免文件系统日志的不确定性。每次转换前的 fsync 确保掉电时已持久化的状态被硬件保证写入。\n\n---\n\n## 3. 核心设计细节\n\n### 3.1 128 字节二进制包头格式\n\n```\n偏移   大小   字段               说明\n0      4      magic[4]          \"OSP\\x01\" 魔数 + 版本\n4      1      header_ver        包头格式版本 (当前 = 1)\n5      1      pkg_type          0=全量, 1=差分, 2=Bootloader\n8      4      hw_compat_mask    硬件兼容性 bitmask (最多 32 种板型)\n12     4      fw_version        major<<24 | minor<<16 | patch\n16     4      min_version       差分升级基准版本\n20     8      payload_size      payload 字节数\n28     32     payload_sha256    SHA-256 校验值\n60     2      signature_len     签名长度 (Ed25519 = 64)\n62     62     reserved_1        预留扩展字段\n124    4      header_crc32      前 124 字节的 CRC-32\n```\n\n**设计要点**:\n\n| 特性 | 与 JSON 对比 | 优势 |\n|------|-------------|------|\n| 二进制格式 | JSON 需解析库 | 无依赖，即时校验 |\n| 128B 固定长 | JSON 变长 | 栈分配，无堆分配 |\n| CRC-32 即时校验 | JSON 全量 DOM | 快速拒绝损坏文件 |\n| hw_compat_mask | JSON 数组遍历 | `(mask & 1u<<id)` 单次位运算 |\n| fw_version 编码 | 字符串比较 | 直接 `>` 数值比较 |\n\n### 3.2 三层校验机制\n\n| 层 | 算法 | 覆盖范围 | 用途 |\n|------|------|---------|------|\n| 1. 快速校验 | CRC-32 | 包头 124B | 即时拒绝损坏/伪造包 |\n| 2. 完整性 | SHA-256 | 整个 payload | 抗碰撞，确保写入无误 |\n| 3. 身份认证 | Ed25519 | payload SHA-256 | 验证来源，防止中间人攻击 |\n\nEd25519 签名仅 64 字节 (vs RSA-2048 256B)，ARM Cortex-A 验证速度约 0.2ms，mbedtls PSA Crypto API 运行时检测硬件支持，不支持时回退到 HMAC-SHA256 演示模式。\n\n### 3.3 函数指针表 HAL 的零虚函数设计\n\n```cpp\nstruct UpgradeHAL {\n    // 分区操作\n    int32_t (*open_partition)(const char* dev, int32_t flags, void* ctx);\n    ssize_t (*write_partition)(int32_t fd, const void* buf, uint32_t size, void* ctx);\n    ssize_t (*read_partition)(int32_t fd, void* buf, uint32_t size, void* ctx);\n    int32_t (*fsync_partition)(int32_t fd, void* ctx);\n    int32_t (*close_partition)(int32_t fd, void* ctx);\n\n    // Boot 环境变量\n    bool (*get_env)(const char* key, char* val, uint32_t size, void* ctx);\n    bool (*set_env)(const char* key, const char* value, void* ctx);\n\n    // 系统控制\n    void (*reboot_system)(void* ctx);\n\n    // 不透明上下文 (替代 this 指针)\n    void* ctx;\n};\n```\n\n**vs 虚函数对比**:\n\n| 维度 | virtual 基类 | 函数指针表 |\n|------|-------------|-----------|\n| 内存布局 | vtable 指针 (8B) + RTTI | 函数指针数组 (连续，缓存友好) |\n| 间接调用 | vtable 两次间接寻址 | 一次函数指针调用 |\n| 编译器支持 | 需要 RTTI (`-fno-rtti` 受限) | 纯 C ABI，无 C++ 运行时 |\n| 组合方式 | 继承体系 (刚性) | 按需替换单个函数指针 (灵活) |\n\n仿真环境只需替换函数指针: `SimHAL::open = SimOpenPartition` 等，无需继承层级，易于单元测试。\n\n### 3.4 SpinOnce 轮询驱动模式\n\n固件升级的 Verifying 和 Writing 状态需处理数百 MB 大文件，不能在一次 handler 调用中完成。引入 `kEvStepProcess` 事件，每次 SpinOnce 驱动处理 4KB chunk:\n\n```cpp\n// 主循环驱动 (激光雷达采集线程)\nwhile (!engine.IsIdle()) {\n    engine.SpinOnce();           // 处理 1 个 4KB chunk (~100 μs)\n    RunLidarPipeline();          // 其他实时任务不被阻塞\n}\n```\n\nWritingHandler 示例:\n\n```cpp\nTransitionResult WritingHandler(UpgradeContext& ctx, const Event& event) {\n    if (event.id == kEvStepProcess) {\n        if (ctx.bytes_written >= ctx.total_size) {\n            // 写入完成: fsync + 读回 SHA-256 校验\n            ctx.pw_ptr->Fsync();\n            auto rb = ctx.pw_ptr->VerifyReadback(...);\n            return GetSM(ctx)->RequestTransition(ctx.idx_switching);\n        }\n\n        // 读取下一个 4KB chunk\n        uint8_t chunk[4096];\n        ssize_t n = ::read(ctx.pkg_fd, chunk, sizeof(chunk));\n        ctx.pw_ptr->WriteChunk(chunk, n);\n        ctx.bytes_written += n;\n\n        // 每 1MB 持久化一次进度 (掉电恢复的断点)\n        if (ctx.bytes_since_last_persist >= 1048576U) {\n            PersistCurrentState(ctx, StateIdx::kStateWriting);\n            ctx.bytes_since_last_persist = 0;\n        }\n        return TransitionResult::kHandled;\n    }\n    return TransitionResult::kUnhandled;\n}\n```\n\n---\n\n## 4. 掉电恢复的完整路径\n\n### 4.1 启动时的恢复决策树\n\n```cpp\nvoid RecoverFromPersistentState() noexcept {\n    StatePersister persist(ctx_.state_fd);\n    auto res = persist.LoadState();\n    if (!res) return;  // magic/CRC 无效 → 无升级进行\n\n    StateIdx persisted = static_cast<StateIdx>(res.value().state);\n    switch (persisted) {\n        case StateIdx::kStateWriting:\n            // 分析: 写入分区未完成，活跃分区完好\n            // 恢复: 清除状态，启动后重新开始升级\n            persist.ClearState();\n            break;\n\n        case StateIdx::kStateSwitching:\n        case StateIdx::kStateBooting:\n            // 分析: env 可能已切换，新固件已启动\n            // 恢复: ForceTransition 到 BootVerify，继续自检\n            sm_.ForceTransition(ctx_.idx_boot_verify);\n            break;\n\n        case StateIdx::kStateRollback:\n            // 分析: 回滚中断\n            // 恢复: 继续回滚流程\n            sm_.ForceTransition(ctx_.idx_rollback);\n            break;\n\n        default:\n            persist.ClearState();\n            break;\n    }\n}\n```\n\n### 4.2 掉电时序与安全点\n\n```\n[安全点 1] PersistState(Writing, progress=0) + fsync\n    ↓\n    for each 4KB chunk:\n        write(partition_b_fd, chunk)\n\n[安全点 2] if (written % 1MB == 0): fsync + PersistState(...)\n    ↓\n[安全点 3] 最终 fsync + 读回全量 SHA-256 校验\n    ↓\n[安全点 4] PersistState(Switching) + fw_setenv (U-Boot 原子)\n    ↓\n[安全点 5] PersistState(Rebooting) + reboot(2)\n```\n\n**安全分析**:\n- 点 1-3 之间掉电: 分区 A 未动，系统启动后重新开始升级\n- 点 4 掉电: U-Boot 已原子切换或未切换，启动后恢复到 BootVerify 继续自检\n- 点 5 掉电: 新固件启动失败 3 次后 U-Boot bootcount 机制自动回滚\n\n---\n\n## 5. x86 仿真层与单元测试\n\n升级引擎在 x86 Linux 上完整运行 (包括掉电模拟)，通过仿真 HAL:\n\n```cpp\n// 生产环境: POSIX 系统调用\nUpgradeHAL hal = MakePosixHAL();\n\n// 仿真环境: 文件模拟分区 + 软件故障注入\nUpgradeHAL sim_hal = MakeSimHAL(&sim_ctx);\nsim_hal.ctx = &sim_ctx;  // 注入掉电故障、env 读写状态等\n```\n\n演示结果 (1MB 测试固件):\n\n```\n=== Full Upgrade Demo ===\n[HSM] Idle -> Verifying -> Writing -> Switching -> Rebooting\n[HSM] BootVerify -> Idle\nTotal time: 19 ms\nStatus: OK\n\n=== Power Loss Safety Tests ===\n[TEST 1/5] Power loss during Writing (25%) ... PASS\n[TEST 2/5] Power loss during Writing (50%) ... PASS\n[TEST 3/5] Power loss during Writing (75%) ... PASS\n[TEST 4/5] Power loss during Switching     ... PASS\n[TEST 5/5] BootVerify timeout → rollback    ... PASS\nAll 5 tests passed.\n```\n\n---\n\n## 6. 与 newosp 生态的融合\n\nosp-upgrade-engine 通过 FetchContent 复用 newosp 核心组件:\n\n| newosp 组件 | 用途 | 集成点 |\n|-------------|------|--------|\n| osp::StateMachine | HSM 驱动 8 状态流程 | UpgradeHSM 模板实例化 |\n| osp::Event | 事件传递 | kEvStartUpgrade, kEvStepProcess |\n| osp::expected | 错误处理 | StartUpgrade() 返回值 |\n| osp::Sha256Calculator | 流式 SHA-256 | Verifying 状态 |\n\n**唯一修改**: newosp HSM 新增 `ForceTransition()` API，用于掉电恢复时从外部跳转状态:\n\n```cpp\nbool ForceTransition(int32_t target) noexcept {\n    if (!started_ || target < 0 ||\n        static_cast<uint32_t>(target) >= state_count_) {\n        return false;\n    }\n    TransitionTo(target);  // 执行标准 LCA exit/entry 路径\n    return true;\n}\n```\n\n---\n\n## 7. 资源预算与性能指标\n\n### 7.1 内存占用\n\n| 组件 | 栈/静态 | 堆 | 说明 |\n|------|---------|-----|------|\n| UpgradeHSM | 256 B | 0 | StateConfig 数组编译期固定 |\n| UpgradeContext | 520 B | 0 | 路径缓冲 + SHA-256 上下文 |\n| 包头解析 | 128 B | 0 | 栈分配 |\n| 状态记录 | 64 B | 0 | 每次持久化 |\n| 写缓冲 | 4 KB | 0 | WritingHandler 栈分配 |\n| 读回校验缓冲 | 4 KB | 0 | PartitionWriter 栈分配 |\n| CRC-32 表 | 1 KB | 0 | constexpr 编译期 |\n| SHA-256 上下文 | 128 B | 0 | mbedtls 嵌入 |\n| **合计** | **~10 KB** | **0** | **全程零堆分配** |\n\n### 7.2 时间开销\n\n| 操作 | 典型耗时 | 备注 |\n|------|---------|------|\n| SpinOnce (4KB chunk) | ~100-200 μs | 含分区读写 |\n| CRC-32 校验 (128B 头) | ~5 μs | 查表 |\n| SHA-256 增量 (4KB 块) | ~40 μs | mbedtls 优化 |\n| Ed25519 签名验证 | ~0.2 ms | ARM Cortex-A 指令集 |\n| U-Boot env 切换 | ~5-10 ms | fw_setenv 执行 |\n| 完整升级 (1GB) | ~100-150 s | 100% 网络带宽 |\n\n---\n\n## 8. 总结与未来方向\n\nosp-upgrade-engine 用 ~3000 行 C++17 header-only 代码实现了工业级固件升级，核心数字:\n\n- **8 个 HSM 状态**: 从 Idle 到 Rollback 的完整生命周期\n- **128 字节包头**: CRC-32 + SHA-256 + Ed25519 三层校验\n- **64 字节持久化**: raw 分区记录，支持任意时刻掉电恢复\n- **~10 KB 内存**: 零堆分配，32MB RAM 设备可用\n- **0 个额外线程**: SpinOnce 轮询，不增加线程预算\n\n**三层掉电保护** (状态持久化 + U-Boot 冗余 env + bootcount 回滚) 确保了工业现场无人值守环境下的可靠性。**函数指针表 HAL** 和 **x86 仿真层** 使得完整升级流程可在开发机上验证，包括掉电场景。\n\n**相关设计参考**:\n- [C 语言层次状态机框架](../c_hsm_data_driven_framework/) -- HSM 转换表与 LCA 算法\n- [激光雷达高吞吐数据处理 Pipeline](../lidar_pipeline_newosp/) -- 零拷贝 + SpinOnce 驱动模式\n- [newosp 事件驱动架构深度解析](../newosp_event_driven_architecture/) -- AsyncBus 与 HSM 核心实现\n",
      "ctime": "1771552471",
      "mtime": "1771552471",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "architecture/rtos_vs_linux_heterogeneous_soc.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469521966",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "RTOS vs Linux 异构选型: 三核 SoC 上的双系统设计",
      "brief_content": "RK3506J 集成三核 Cortex-A7 (1.0 GHz) + Cortex-M0，支持 Linux + RTOS 异构部署。本文分析 AMP 架构下的核间通信 (RPMsg/共享内存)、实时性",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/154877100)\n>\n> 参考: [RK3506 Datasheet](https://www.rock-chips.com/uploads/pdf/RK3506.pdf),\n> [newosp](https://github.com/DeguiLiu/newosp) v0.2.0\n>\n> 适用场景: 激光雷达、工业视觉、机器人控制器、边缘传感器融合\n\n---\n\n## 1. 设计目标\n\nRK3506J 提供 3 个 Cortex-A7 (1.2 GHz) + 1 个 Cortex-M0 (200 MHz) 的异构多核硬件。本文给出面向工业传感器产品 (激光雷达、工业相机) 的两种部署方案概要设计，并给出选型建议。\n\n### 1.1 量化目标\n\n| 编号 | 目标 | 量化指标 | 验证方法 |\n|------|------|----------|----------|\n| G-1 | 电机控制实时性 | 中断响应 < 10 us | M0 GPIO 示波器 |\n| G-2 | 数据处理延迟 | 端到端 P99 < 5 ms | 硬件时间戳 |\n| G-3 | 核间通信延迟 | Mailbox 单程 < 50 us | IPC 延迟测试 |\n| G-4 | 系统启动时间 | < 2 s (方案一) / < 500 ms (方案二) | 上电到首帧 |\n| G-5 | 连续运行稳定性 | 72h 零崩溃、零内存泄漏 | 长稳压测 |\n| G-6 | 热路径零堆分配 | malloc/free 调用 0 次 | 运行时 hook |\n\n### 1.2 硬件约束\n\n| 项目 | 配置 |\n|------|------|\n| A 核组 | 3x Cortex-A7 @ 1.2 GHz, 32 KB L1 I/D, Thumb-2, NEON VFPv4 |\n| M 核 | 1x Cortex-M0 @ 200 MHz, 无 Cache, 无硬件除法, 无 DSP |\n| 内存 | 256 MB - 512 MB DDR3/DDR3L |\n| 核间通信 | Hardware Mailbox (4 通道), 共享内存 (SRAM / DDR) |\n| 外设 | SPI x4, I2C x6, UART x6, USB 2.0, RGMII, SDIO |\n| 编译器 | arm-none-eabi-gcc (M0), arm-linux-gnueabihf-gcc (A7) |\n\n---\n\n## 2. 总体架构\n\n### 2.1 异构多核职责划分\n\nRK3506J 的异构设计天然适合 \"硬实时 + 高算力\" 场景:\n\n```mermaid\nflowchart TB\n    subgraph M0[\"M0 核: 硬实时控制 (200 MHz)\"]\n        MOTOR[\"电机控制\\nPWM + 编码器\"]\n        SAFETY[\"安全监控\\n过温/过流保护\"]\n        TRIGGER[\"采集触发\\n同步信号\"]\n    end\n\n    subgraph A7[\"A7 核组: 数据处理 (3x 1.2 GHz)\"]\n        A7_0[\"A7-0: 系统核\\n中断分发 / 网络 / 日志\"]\n        A7_1[\"A7-1: 采集核\\n传感器数据接收\"]\n        A7_2[\"A7-2: 算法核\\n点云处理 / 滤波\"]\n    end\n\n    subgraph IPC[\"核间通信\"]\n        MBOX[\"Hardware Mailbox\\n4 通道\"]\n        SHMEM[\"共享内存\\n控制命令 + 状态\"]\n    end\n\n    M0 <-->|\"Mailbox + SRAM\"| IPC\n    IPC <-->|\"DDR 共享区\"| A7\n```\n\n### 2.2 核心分工\n\n| 核心 | 职责 | 实时性要求 | 典型任务 |\n|------|------|:----------:|----------|\n| **M0** | 硬实时控制 | < 10 us | 电机 PWM、编码器读取、安全保护、采集触发 |\n| **A7-0** | 系统服务 | 非实时 | Linux 内核、网络协议栈、日志、串口诊断 |\n| **A7-1** | 数据采集 | 软实时 | SPI/LVDS 接收、DMA 管理、数据校验 |\n| **A7-2** | 算法处理 | 软实时 | 点云滤波、坐标变换、NEON 加速 |\n\n---\n\n## 3. 方案一: Linux + RTOS 混合部署 (推荐)\n\n### 3.1 系统架构\n\n```mermaid\nflowchart LR\n    subgraph M0_RTOS[\"M0: RT-Thread / FreeRTOS\"]\n        M_MOTOR[\"MotorTask\\nPrio 最高\"]\n        M_SAFE[\"SafetyTask\"]\n        M_IPC[\"IPCTask\\nMailbox 收发\"]\n    end\n\n    subgraph A7_LINUX[\"A7 核组: Linux 5.10+\"]\n        subgraph CORE0[\"A7-0: 系统核\"]\n            NET[\"网络/诊断\"]\n            LOG[\"日志/遥测\"]\n            CTRL[\"控制节点\\nnewosp HSM\"]\n        end\n        subgraph CORE1[\"A7-1: 采集核 (isolcpus)\"]\n            ACQ[\"采集任务\\nSCHED_FIFO\"]\n        end\n        subgraph CORE2[\"A7-2: 算法核 (isolcpus)\"]\n            ALGO[\"算法任务\\nSCHED_FIFO + NEON\"]\n        end\n    end\n\n    M_IPC <-->|\"Mailbox\"| CTRL\n    ACQ -->|\"ShmChannel\\nSPSC 零拷贝\"| ALGO\n    ALGO -->|\"AsyncBus\\n控制消息\"| NET\n    CTRL -->|\"AsyncBus\"| ACQ\n```\n\n### 3.2 newosp 模块映射\n\n| 功能 | newosp 模块 | 部署位置 | 说明 |\n|------|------------|----------|------|\n| 控制消息路由 | AsyncBus + Node | A7-0 | MPSC 无锁, 优先级准入 |\n| 数据面零拷贝 | ShmChannel (SPSC) | A7-1 -> A7-2 | Wait-free, cache line 对齐 |\n| 设备状态管理 | HSM | A7-0 | Init/Ready/Active/Fault/Shutdown |\n| 实时调度 | RealtimeExecutor | A7-1, A7-2 | SCHED_FIFO + mlockall + 绑核 |\n| 并行处理 | WorkerPool | A7-2 | 多线程点云处理 |\n| 定时任务 | TimerScheduler | A7-0 | 心跳、看门狗、遥测 |\n| 串口诊断 | SerialTransport | A7-0 | CRC-CCITT + ACK |\n| 线程监控 | ThreadWatchdog | A7-0 | 关键线程存活检测 |\n\n### 3.3 核间通信设计\n\nM0 与 A7 之间通过 Hardware Mailbox + 共享 SRAM 通信:\n\n| 通道 | 方向 | 用途 | 消息格式 |\n|------|------|------|----------|\n| Mailbox CH0 | M0 -> A7 | 电机状态上报 | 16B 定长 (转速 + 编码器 + 温度) |\n| Mailbox CH1 | A7 -> M0 | 电机控制命令 | 16B 定长 (目标转速 + 模式) |\n| Mailbox CH2 | M0 -> A7 | 安全告警 | 8B (告警码 + 时间戳) |\n| Mailbox CH3 | A7 -> M0 | 采集触发同步 | 4B (触发计数) |\n\n**协议约定**:\n- Mailbox 中断触发, 非轮询\n- 共享 SRAM 区域存放详细数据, Mailbox 仅传递通知和索引\n- M0 侧使用原子操作 + memory barrier, A7 侧使用 `acquire/release` 语义\n\n### 3.4 内存分区\n\n| 区域 | 起始地址 | 大小 | 归属 | 用途 |\n|------|----------|------|------|------|\n| M0 Code + Data | 0x0000_0000 | 128 KB | M0 独占 | RTOS + 应用 |\n| 共享 SRAM | 0x0002_0000 | 64 KB | M0 + A7 | Mailbox 数据区 |\n| Linux Kernel | 0x6000_0000 | 128 MB | A7 独占 | 内核 + 根文件系统 |\n| newosp 框架 | -- | ~2 MB | A7 用户态 | AsyncBus + ShmChannel |\n| 数据缓冲 | -- | ~10 MB | A7 用户态 | 点云帧缓冲 |\n| DMA 缓冲 | CMA 区域 | 4 MB | A7 DMA | SPI/DMA 接收缓冲 |\n\n### 3.5 优缺点分析\n\n| 维度 | 评估 |\n|------|------|\n| 开发效率 | 高 -- Linux 生态成熟, 驱动/网络/调试工具丰富 |\n| 实时性 | 中 -- A7 侧依赖 isolcpus + SCHED_FIFO, 非硬实时 |\n| 算力利用 | 高 -- 3 个 A7 核全部可用于数据处理 |\n| 启动时间 | 慢 -- Linux 启动 ~2 s |\n| 内存占用 | 高 -- Linux 基础 ~32 MB |\n| 维护成本 | 低 -- Linux 应用层开发, 调试手段丰富 |\n\n---\n\n## 4. 方案二: 全 RTOS 部署 (极致实时)\n\n### 4.1 系统架构\n\n```mermaid\nflowchart LR\n    subgraph M0_RTOS[\"M0: RT-Thread\"]\n        M2_MOTOR[\"MotorTask\"]\n        M2_IPC[\"IPCTask\"]\n    end\n\n    subgraph A7_RTOS[\"A7 核组: RT-Thread SMP\"]\n        subgraph CORE0_R[\"A7-0: 控制核\"]\n            R_CTRL[\"ControlTask\\nPrio 60\"]\n            R_NET[\"LwIP NetTask\\nPrio 50\"]\n            R_LOG[\"LogTask\\nPrio 30\"]\n        end\n        subgraph CORE1_R[\"A7-1: 采集核 (绑核)\"]\n            R_ACQ[\"IngestTask\\nPrio 90\"]\n        end\n        subgraph CORE2_R[\"A7-2: 算法核 (绑核)\"]\n            R_PROC[\"ProcessTask\\nPrio 85\"]\n            R_PUB[\"PublishTask\\nPrio 80\"]\n        end\n    end\n\n    M2_IPC <-->|\"Mailbox\"| R_CTRL\n    R_ACQ -->|\"SPSC Ring\\n无锁\"| R_PROC\n    R_PROC -->|\"SPSC Ring\"| R_PUB\n    R_PUB -->|\"结果队列\"| R_NET\n```\n\n### 4.2 任务部署矩阵\n\n| 核心 | 任务 | 优先级 | 栈 | 触发方式 | 亲和绑定 |\n|------|------|:------:|:--:|----------|:--------:|\n| A7-0 | ControlTask | 60 | 2 KB | Mailbox 中断 | 是 |\n| A7-0 | NetTask (LwIP) | 50 | 4 KB | 周期 100 Hz | 是 |\n| A7-0 | LogTask | 30 | 2 KB | 周期 10 Hz | 是 |\n| A7-1 | IngestTask | 90 | 2 KB | DMA 完成信号量 | 是 |\n| A7-2 | ProcessTask | 85 | 4 KB | SPSC Ring 非空 | 是 |\n| A7-2 | PublishTask | 80 | 2 KB | SPSC Ring 非空 | 是 |\n\n### 4.3 数据通道\n\nA7 核间采用 SPSC 无锁 Ring Buffer 传递数据 (所有权转移模型):\n\n| 属性 | 机制 |\n|------|------|\n| 无 ABA 问题 | 单生产者单消费者, 无 CAS |\n| 无数据撕裂 | uint32_t 对齐, ARM 原子 LDR/STR |\n| 内存序正确 | DMB 保证数据/索引写入顺序 |\n| 无 false sharing | head/tail 间 32B padding |\n\n### 4.4 优缺点分析\n\n| 维度 | 评估 |\n|------|------|\n| 开发效率 | 低 -- 需自行移植 LwIP/USB 协议栈, 无现成驱动 |\n| 实时性 | 高 -- 全系统确定性调度, 中断响应 < 15 us |\n| 算力利用 | 高 -- 3 个 A7 核 + NEON, 无 Linux 内核开销 |\n| 启动时间 | 快 -- < 500 ms |\n| 内存占用 | 低 -- RTOS 基础 < 512 KB |\n| 维护成本 | 高 -- 所有协议栈需自行维护和调试 |\n\n---\n\n## 5. 方案决策矩阵\n\n| 维度 | 权重 | 方案一 (Linux+RTOS) | 方案二 (全 RTOS) |\n|------|:----:|:-------------------:|:----------------:|\n| 开发效率 | 30% | 9 | 4 |\n| 实时性 | 25% | 6 | 9 |\n| 算力利用 | 15% | 8 | 9 |\n| 启动时间 | 10% | 5 | 9 |\n| 内存效率 | 10% | 5 | 9 |\n| 维护成本 | 10% | 8 | 4 |\n| **加权总分** | **100%** | **7.15** | **6.75** |\n\n### 5.1 推荐路径\n\n```mermaid\nflowchart LR\n    P1[\"Phase 1\\n方案一原型\\nLinux + M0 RTOS\"] --> P2[\"Phase 2\\n性能验证\\n延迟/抖动/吞吐\"]\n    P2 -->|\"达标\"| SHIP[\"交付\\n方案一\"]\n    P2 -->|\"不达标\"| P3[\"Phase 3\\n热点迁移\\n关键路径迁至 RT-Thread\"]\n    P3 --> P4[\"Phase 4\\n全 RTOS 部署\\n方案二\"]\n```\n\n**建议**:\n\n1. **首选方案一** (Linux + M0 RTOS) -- 开发效率高, 生态成熟, 适合快速原型和首版交付\n2. **方案二作为演进目标** -- 当方案一无法满足延迟/抖动要求时, 逐步将热点迁移到 RT-Thread SMP\n3. **渐进式迁移** -- 先在 Linux 上用 newosp RealtimeExecutor (isolcpus + SCHED_FIFO) 尝试优化, 若仍不足再考虑全 RTOS\n\n---\n\n## 6. 资源预算\n\n### 6.1 方案一资源预算\n\n| 资源 | M0 | A7 核组 | 总计 |\n|------|:--:|:-------:|:----:|\n| RAM | ~32 KB | ~48 MB (Linux+newosp+缓冲) | ~48 MB |\n| Flash | ~64 KB | ~32 MB (内核+根文件系统) | ~32 MB |\n| CPU 占用 | < 30% | A7-0 < 40%, A7-1/2 < 70% | -- |\n\n### 6.2 方案二资源预算\n\n| 资源 | M0 | A7 核组 | 总计 |\n|------|:--:|:-------:|:----:|\n| RAM | ~32 KB | ~4 MB (RTOS+LwIP+缓冲) | ~4 MB |\n| Flash | ~64 KB | ~2 MB (RTOS 镜像) | ~2 MB |\n| CPU 占用 | < 30% | A7-0 < 30%, A7-1/2 < 70% | -- |\n\n---\n\n## 7. 总结\n\n核心设计决策:\n\n1. **M0 专责硬实时**: 电机控制、安全保护等微秒级响应任务固定在 M0, 与应用层完全隔离\n2. **Hardware Mailbox 核间通信**: 中断驱动、低延迟, 共享 SRAM 传递详细数据\n3. **方案一优先**: 利用 Linux 生态快速交付, newosp 的 RealtimeExecutor + ShmChannel 在用户态提供软实时保障\n4. **渐进式演进**: 通过量化验证 (延迟/抖动/吞吐) 驱动方案选择, 避免过度设计\n\n---\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/154877100)\n",
      "ctime": "1771552474",
      "mtime": "1771552474",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "interview/senior_embedded_c_language_interview_questions.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267161126",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 C 语言深度面试题: 系统与架构",
      "brief_content": "高级嵌入式 C 语言面试题集，涵盖 volatile 本质、内存对齐、链接脚本、中断安全、DMA 一致性等底层核心知识。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "# Senior Embedded C Interview Questions (System & Architecture)\n\n> **岗位**: 高级嵌入式软件工程师 / 嵌入式架构师\n> **范围**: C 语言深度、裸机/RTOS 通用架构、硬件抽象\n> **原则**: 不限特定 MCU 型号或 OS 版本，考察通用工程原理\n\n---\n\n## 一、C 语言与底层机制 (Deep C)\n\n### Q1: Volatile 的本质与编译器重排\n**题目**: 仅知道 `volatile` 用于寄存器访问是不够的。请解释 `volatile` 关键字在 (1) 编译器指令重排 (2) CPU 乱序执行 (3) 多线程共享变量 三种场景下的作用与局限性。\n\n**答案提示**:\n- **编译器重排**: `volatile` 阻止编译器优化读写操作，并保证 `volatile` 变量间的访问顺序不被编译器改变。\n- **CPU 乱序**: `volatile` **不包含** 内存屏障 (Memory Barrier) 指令。在乱序执行架构 (ARM/RISC-V) 上，硬件仍可能重排读写指令。\n- **多线程**: `volatile` 不保证原子性 (RMW 操作)，也不保证线程间的同步可见性（缺乏 Happens-Before 语义）。\n- **结论**: 寄存器映射必须用 `volatile`；多核/DMA 同步必须配合 `Memory Barrier` 或原子操作。\n\n### Q2: 内存对齐与总线错误\n**题目**: 什么是非对齐访问 (Unaligned Access)？为什么某些架构会触发硬件异常？如何在 C 语言中处理网络协议栈中的非对齐数据包？\n\n**答案提示**:\n- **原理**: 处理器总线通常按字 (Word) 寻址。读取跨边界的 4 字节数据可能需要 2 次总线周期（效率低）或硬件不支持直接触发 Fault（如部分 RISC 架构）。\n- **场景**: 接收到的网络包头可能紧接着以太网头，导致 payload 地址非 4 字节对齐。\n- **处理**:\n  1. `memcpy`: 编译器内置优化，处理非对齐最安全。\n  2. `__attribute__((packed))`: 告诉编译器该结构体紧凑排列，编译器会自动生成逐字节读取的代码（牺牲性能换安全）。\n  3. **禁止**: 直接强转指针 `(uint32_t*)buffer` 访问，这是未定义行为且极易 Crash。\n\n### Q3: 严格别名规则 (Strict Aliasing)\n**题目**: 下面的代码有什么风险？编译器开启 `-O3` 优化时会发生什么？\n```c\nuint32_t process_data(uint32_t* ptr, float* fptr) {\n    *ptr = 0x12345678;\n    *fptr = 1.0f;\n    return *ptr; // 编译器可能直接返回 0x12345678\n}\n```\n\n**答案提示**:\n- **规则**: C 标准规定不同类型的指针（除了 `char*`）不能指向同一块内存。\n- **后果**: 编译器认为 `ptr` 和 `fptr` 指向不同地址，因此判定 `*fptr` 的写入不会影响 `*ptr` 的值，从而将 `return *ptr` 优化为直接返回寄存器中的旧值 `0x12345678`。\n- **修复**: 使用 `union` 或 `memcpy` 进行类型双关 (Type Punning)，或使用 `-fno-strict-aliasing`（不推荐）。\n\n### Q4: 位操作与读改写 (RMW) 原子性\n**题目**: 在裸机中断环境下，对一个硬件寄存器的特定位进行置位操作 `REG |= (1 << 5)` 是安全的吗？为什么？\n\n**答案提示**:\n- **非原子性**: `|=` 实际上是 `LOAD -> OR -> STORE` 三条指令。\n- **竞态条件**:\n  1. 主循环读取 REG (值 A)。\n  2. 发生中断，ISR 修改了 REG 的第 3 位 (值 B)。\n  3. 中断返回。\n  4. 主循环计算 `A | (1<<5)` 并写入，**覆盖了 ISR 对第 3 位的修改**。\n- **解决**:\n  - 关中断保护。\n  - 使用硬件支持的位带操作 (Bit-banding) 或原子置位寄存器 (如 `GPIO_BSRR` Set/Reset 分离寄存器)。\n\n### Q5: 可重入 (Reentrancy) vs 线程安全\n**题目**: 标准库中的 `strtok` 和 `malloc` 是可重入的吗？编写 ISR 代码时应如何判断函数的可调用性？\n\n**答案提示**:\n- **strtok**: 不可重入，内部维护静态指针保存状态。ISR 中调用会破坏主线程的解析状态。应使用 `strtok_r`。\n- **malloc**: 线程安全（通常有锁）但不可重入。ISR 中调用若遇到锁被主线程持有，会导致死锁或系统崩溃。\n- **ISR 准则**:\n  1. 不访问全局变量（除非 volatile + 原子/关中断）。\n  2. 不调用不可重入函数（标准 I/O, 堆内存）。\n  3. 不调用阻塞函数。\n\n### Q6: 结构体填充与序列化\n**题目**: 定义通信协议结构体时，如何保证不同位宽（32位/64位）处理器之间的兼容性？\n\n**答案提示**:\n- **问题**: 编译器会自动填充 (Padding) 以满足对齐要求，导致 `sizeof` 和内存布局不一致。\n- **策略**:\n  1. **手动填充**: 显式添加 `uint8_t reserved[]` 占位，使所有成员天然对齐。\n  2. **取消对齐**: 使用 `#pragma pack(1)`，但需注意访问效率。\n  3. **定长类型**: 必须使用 `<stdint.h>` 中的 `uint32_t` 等，禁用 `long` / `int`。\n  4. **序列化库**: 最稳妥方式是使用序列化代码（Protobuf/手动移位），而非直接发送结构体内存。\n\n### Q7: 指针与数组的退化\n**题目**: 在函数参数中 `void func(int arr[10])` 和 `void func(int* arr)` 有区别吗？`sizeof(arr)` 的结果是什么？\n\n**答案提示**:\n- **退化**: 在函数参数列表中，数组声明自动退化为指针。两者完全等价。\n- **Sizeof**: 函数内部 `sizeof(arr)` 返回的是指针大小 (4 或 8)，而不是数组总大小。\n- **最佳实践**: 传递数组时，永远同时传递长度参数 `size_t len`，或使用包含长度的结构体封装。\n\n### Q8: 未定义行为 (UB) 陷阱\n**题目**: 解释有符号整数溢出 (Signed Overflow) 在 C 语言中的定义。编译器可能利用它做什么优化？\n\n**答案提示**:\n- **定义**: 有符号溢出是 **未定义行为 (UB)**，而无符号溢出是模运算（Defined）。\n- **优化陷阱**: 编译器假设 UB 永远不会发生。例如 `if (a + 100 < a)`，编译器会直接优化为 `false`，导致溢出检查代码失效。\n- **安全检查**: 必须在运算前检查：`if (a > INT_MAX - 100)`。\n\n---\n\n## 二、通用架构与并发 (Architecture)\n\n### Q9: 中断处理模型 (Top-half / Bottom-half)\n**题目**: 为什么 ISR 应该尽可能短？如果通过中断接收大量数据且需要复杂处理，应如何设计架构？\n\n**答案提示**:\n- **原因**: ISR 运行时通常会屏蔽同级或低级中断，过长执行会增加**中断延迟 (Latency)**，导致其他外设数据丢失。\n- **设计模式**:\n  - **Top-half (ISR)**: 仅做最小硬件操作（清标志、拷贝数据到 RingBuffer、置信号量），立即退出。\n  - **Bottom-half (Task)**: 应用层任务被信号量唤醒，处理复杂逻辑（解析、CRC、存储）。\n- **裸机方案**: 在 ISR 中置标志位，主循环 (`while(1)`) 中检测标志位执行处理。\n\n### Q10: 临界区保护策略\n**题目**: 保护共享资源时，关中断 (Disable Interrupts) 和 互斥锁 (Mutex) 各有什么优缺点？适用场景分别是什么？\n\n**答案提示**:\n- **关中断**:\n  - *优点*: 速度极快 (CPU 指令)，适用于 ISR 和任务间同步。\n  - *缺点*: 停止系统响应，必须极短时间（数微秒）；多核系统无法阻止其他核访问。\n- **互斥锁**:\n  - *优点*: 仅阻塞竞争任务，不影响中断和非竞争任务；支持优先级继承。\n  - *缺点*: 上下文切换开销大，不能在 ISR 中使用。\n- **自旋锁 (Spinlock)**:\n  - 多核系统专用，短时间忙等待。\n\n### Q11: 优先级反转 (Priority Inversion)\n**题目**: 描述优先级反转现象。除了优先级继承协议 (PIP)，在系统设计层面（不依赖 OS 特性）如何避免此问题？\n\n**答案提示**:\n- **现象**: 高优先级任务等锁，锁被低优先级持有，中优先级抢占低优先级 -> 高优先级被间接阻塞。\n- **设计避免**:\n  1. **锁分离**: 不同优先级的任务尽量不共享同一把锁。\n  2. **无锁队列**: 使用 Lock-free RingBuffer 通信，完全消除锁。\n  3. **服务器模式**: 共享资源由由一个专用任务（高优先级）管理，其他任务通过消息队列发送请求，避免直接争抢资源。\n\n### Q12: 生产者-消费者与环形缓冲区\n**题目**: 设计一个适用于 UART DMA 接收的无锁环形缓冲区 (Ring Buffer)。如何判断“满”与“空”？原子性如何保证？\n\n**答案提示**:\n- **模型**: 单生产者 (DMA/ISR) -> 单消费者 (Task)。\n- **索引**: 维护 `head` (写) 和 `tail` (读) 索引。\n- **空/满**: `head == tail` 为空；`(head + 1) % size == tail` 为满（浪费一个槽位区分）。\n- **原子性**:\n  - 在 32 位 CPU 上，对齐的 `uint32_t` 索引读写是原子的。\n  - 必须使用 `volatile` 修饰索引。\n  - 必须注意**内存屏障**：写入数据 -> Barrier -> 更新 head，防止乱序导致消费者读到未更新的数据。\n\n### Q13: 栈溢出检测与估算\n**题目**: 在没有 MMU 的 MCU 上，如何检测任务栈溢出？如何估算一个任务需要的栈空间？\n\n**答案提示**:\n- **检测**:\n  1. **堆栈涂抹 (Stack Painting)**: 初始化时将栈填满魔数 (0xDEADBEEF)，运行时统计末端魔数剩余量。\n  2. **硬件看门狗**: 设置栈底为硬件 MPU 保护区或观察点 (Watchpoint)，触碰即 Fault。\n- **估算**:\n  1. 静态分析 (Call graph): 局部变量 + 函数调用层级 + 中断上下文开销。\n  2. 避免递归、避免大数组局部变量（改用静态/堆）。\n\n### Q14: 看门狗 (Watchdog) 的多级设计\n**题目**: 简单的“喂狗”只能防止死机。如何设计看门狗策略来监控“任务死锁”或“逻辑流异常”？\n\n**答案提示**:\n- **窗口看门狗 (WWDG)**: 限制喂狗必须在特定时间窗口内，防止死循环狂喂狗。\n- **逻辑监控 (Task Monitor)**:\n  - 建立一个监控中心。\n  - 每个任务在关键逻辑点上报“心跳”或“状态”。\n  - 监控中心确认所有任务都在规定时间内刷新了状态，才喂硬件看门狗。\n  - 若某任务超时，记录日志并软复位。\n\n### Q15: 动态内存 (Malloc) 在嵌入式中的风险\n**题目**: 为什么硬实时系统通常禁止使用 `malloc/free`？如果必须使用动态内存，应采取什么替代方案？\n\n**答案提示**:\n- **风险**:\n  1. **时间不确定**: 分配时间随碎片化程度变化 (非 O(1))。\n  2. **内存碎片**: 长期运行可能导致无连续大块内存。\n  3. **非重入**: 标准库实现通常有锁。\n- **替代**:\n  1. **静态内存池 (Block Pool)**: 预分配固定大小块（如 32B, 128B 池），O(1) 分配释放，无外部碎片。\n  2. **启动时分配**: 初始化阶段 `malloc` 一次，运行阶段不再释放。\n\n### Q16: 启动流程 (Startup Sequence)\n**题目**: 在 `main()` 函数执行之前，Startup Code (启动文件) 完成了哪些具体工作？\n\n**答案提示**:\n1. **中断向量表**: 设置堆栈指针 (SP) 和复位处理函数 (Reset_Handler)。\n2. **Data 段搬运**: 将已初始化全局变量从 Flash 复制到 RAM。\n3. **BSS 段清零**: 将未初始化全局变量所在的 RAM 区域清零。\n4. **系统初始化**: 配置时钟、FPU、外部总线 (SystemInit)。\n5. **C 库初始化**: 构造静态对象 (C++)、初始化堆管理器。\n6. **跳转**: 跳转到 `main()`。\n\n### Q17: Cache 一致性 (Coherency)\n**题目**: 在带有 Cache 的系统中使用 DMA 传输数据，为什么会出现数据错误？如何解决？\n\n**答案提示**:\n- **问题**: CPU 读写的是 Cache 中的副本，DMA 读写的是物理内存 (DDR/SRAM)。\n- **场景 A (CPU写 -> DMA读)**: CPU 写在 Cache 中未回写 (Dirty)，DMA 搬运了旧数据。\n  - *解法*: 启动 DMA 前执行 **Cache Clean (Flush)**。\n- **场景 B (DMA写 -> CPU读)**: DMA 更新了内存，CPU 读取 Cache 中的旧值 (Stale)。\n  - *解法*: DMA 完成后执行 **Cache Invalidate**。\n- **方案**: 使用 MPU 将 DMA 缓冲区设为 Non-cacheable (牺牲性能换简便)。\n\n### Q18: 回调函数与上下文指针\n**题目**: 为什么设计回调接口时，通常要求传递一个 `void* context` 参数？\n\n**答案提示**:\n- **目的**: 闭包模拟 / 对象绑定。\n- **场景**: 只有函数指针无法区分是哪个对象触发的回调（例如 3 个串口共用一个 ISR 处理函数）。\n- **用法**: 注册时 `RegisterCallback(func_ptr, &my_obj)`；回调时 `func_ptr` 接收 `my_obj` 指针，强转回 `struct Serial*` 进行操作。这实现了 C 语言的面向对象多态。\n\n### Q19: 状态机设计模式\n**题目**: 对比 switch-case 状态机和函数指针表状态机 (Table-driven) 的优劣。\n\n**答案提示**:\n- **Switch-case**:\n  - *优*: 简单直观，编译器易优化，逻辑集中。\n  - *劣*: 状态多时代码过长，难以维护局部变量。\n- **函数指针表**:\n  - *优*: 结构清晰，O(1) 跳转，易于扩展（动态替换状态行为）。\n  - *劣*: 无法内联优化，每个状态函数与其上下文分离，代码碎片化。\n- **推荐**: 简单逻辑用 switch，复杂协议栈用查表/层次状态机 (HSM)。\n\n### Q20: 宏 (Macro) 的陷阱与最佳实践\n**题目**: C 语言中宏 (`#define`) 非常强大但也极易出错。请解释以下三个问题：\n1. 为什么多语句宏应该用 `do { ... } while(0)` 包裹？\n2. 宏参数在宏体中出现两次会有什么副作用（Side Effect）？\n3. 对比宏函数与 `static inline` 函数的优劣。\n\n**答案提示**:\n- **do-while(0) 惯用法**:\n  - *目的*: 确保宏在使用时表现得像一个独立的语句，特别是在 `if` 分支中且不带花括号时。\n  - *示例*: `#define LOG(x) { log(x); flush(); }` 在 `if(err) LOG(e); else ...` 中会导致 else 悬空语法错误。包裹后则安全。\n- **副作用 (Side Effects)**:\n  - *场景*: `#define MIN(a, b) ((a) < (b) ? (a) : (b))`\n  - *风险*: 调用 `MIN(i++, j++)` 会导致 `i` 或 `j` 自增两次，逻辑错误。\n  - *解决*: 使用 `({ ... })` GNU 扩展（Statement Expression）或改用 `static inline`。\n- **Macro vs Inline**:\n  - **宏**:\n    - *优*: 无类型检查（泛型）、可操作符号（`#` 字符串化, `##` 连接）、编译期常量折叠。\n    - *劣*: 无调试符号、副作用风险、无作用域限制。\n  - **Inline 函数**:\n    - *优*: 强类型检查、无副作用风险、可调试、遵循作用域规则。\n    - *劣*: 必须匹配类型（C11 `_Generic` 可部分解决）。\n- **结论**: 优先使用 `static inline`，仅在需要代码生成、字符串化或处理 `__FILE__`/`__LINE__` 时使用宏。\n",
      "ctime": "1771552477",
      "mtime": "1771552477",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "interview/senior_embedded_software_engineer_interview_questions.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853619210",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "高级嵌入式软件工程师面试题: 架构设计与工程深度",
      "brief_content": "20 道精选高级嵌入式软件工程师面试题，考察消息总线架构、RTOS 调度、内存管理、多核同步等核心能力。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "# Senior Embedded Software Engineer Interview Questions\n\n> **岗位**: 高级嵌入式软件工程师\n> **技术栈**: C/C++14, RTOS, 多核处理器\n> **说明**: 20道精选题目，考察架构设计能力与工程深度\n\n---\n\n## 一、架构设计类\n\n### Q1: 消息总线架构\n\n**题目**: 设计一个高性能消息总线，需支持：高频数据流、控制指令、状态上报、紧急信号。请说明核心组件和关键设计决策。\n\n**答案提示**:\n- **分层架构**：应用层 → 消息总线 → 硬件抽象层\n- **核心组件**：\n  | 组件 | 职责 |\n  |------|------|\n  | 事件调度器 | 多路复用监听多个事件源，统一驱动整个系统 |\n  | 数据令牌 | 零拷贝的数据传递单元，RAII 自动管理生命周期 |\n  | 事件分发器 | 根据事件类型解复用，分发到对应处理器 |\n  | 状态机 | 控制逻辑管理 |\n\n- **关键设计决策**：\n  - 紧急信号应**绕过队列**或使用**优先级准入控制**\n  - 不同实时性要求的事件应走不同路径\n  - 批量处理接口优于单事件接口：减少函数调用开销\n\n---\n\n### Q2: 事件系统的耦合度设计\n\n**题目**: 事件系统中，发布者和订阅者之间的耦合度如何设计？有哪些权衡？\n\n**答案提示**:\n| 耦合程度 | 实现方式 | 优点 | 缺点 |\n|---------|---------|------|------|\n| 强耦合 | 直接函数调用 | 简单、类型安全、可调试 | 难扩展、编译依赖 |\n| 中耦合 | 静态注册回调表 | 确定性高、无动态内存 | 不支持运行时增删 |\n| 弱耦合 | 动态订阅+Topic | 灵活、可热插拔 | 运行时开销、类型不安全 |\n\n**设计考量**：\n- 订阅者数量是否固定？→ 固定用静态表，变化用动态注册\n- 发布者是否需要知道订阅结果？→ 需要则考虑确认机制\n- 订阅者崩溃是否影响其他订阅者？→ 需要隔离机制\n\n---\n\n### Q3: 并发模型选型\n\n**题目**: 嵌入式系统中有哪些并发模型？它们各自的适用场景和优劣是什么？\n\n**答案提示**:\n\n| 模型 | 原理 | 优势 | 劣势 | 适用场景 |\n|------|------|------|------|---------|\n| **抢占式多线程** | OS调度，时间片轮转 | 真并行、编程直观 | 锁竞争、上下文切换、优先级反转 | 计算密集型、多核 |\n| **协作式** | 用户态调度，主动让出 | 无锁、切换开销极低 | 不能抢占、单核 | I/O密集、资源受限 |\n| **事件驱动** | 事件循环+回调 | 无锁、确定性高 | 回调嵌套深、不能阻塞 | 高频I/O、实时系统 |\n\n**Active Object 模式**：\n- **逻辑上**：多个独立模块，看起来并行工作\n- **物理上**：常见有两类实现\n    - 单线程事件循环（共享栈，锁最少）\n    - 每对象一线程+消息队列（更隔离，但仍需同步）\n- **核心洞察**：通过“队列 + 串行处理”降低共享状态竞争，而不是天然“零锁”\n\n**选型决策树**：\n```\n需要多核并行？\n├─ 是 → 抢占式多线程\n└─ 否 → 需要顺序异步流程？\n         ├─ 是 → 协程/用户态线程\n         └─ 否 → 事件驱动 / Active Object\n```\n\n---\n\n### Q4: 事件优先级与背压控制\n\n**题目**: 系统中有不同实时性要求的事件，如何设计优先级机制？生产者速度超过消费者时如何处理？\n\n**答案提示**:\n\n**优先级分层**：\n| 实时等级 | 处理方式 | 典型用途 |\n|---------|---------|----------|\n| 硬实时 | 中断直接回调，不入队列 | 紧急停止 |\n| 软实时 | 高优先级队列 | 控制指令 |\n| 非实时 | 普通队列，可批量处理 | 日志、遥测 |\n\n**容量预留策略**（优先级准入控制）：\n```\n队列深度:  0%        60%        80%        99%       100%\n           ├──────────┼──────────┼──────────┼──────────┤\nHIGH:      │ Accept   │ Accept   │ Accept   │ Accept   │\nMEDIUM:    │ Accept   │ Accept   │ Accept   │ Drop     │\nLOW:       │ Accept   │ Accept   │ Drop     │ Drop     │\n```\n\n**说明：准入阈值 vs 告警阈值**\n- **准入阈值**：决定是否接收某优先级消息（例如 60/80/99）\n- **告警阈值**：用于监控与运维告警（可与准入一致，也可单独设置，如 75/90）\n- 工程实践中两者可以不同，但必须在文档和代码中显式区分，避免策略歧义\n\n**背压控制四级状态**：\n| 状态 | 队列深度 | 策略 |\n|------|---------|------|\n| NORMAL | 0-60% | 全部接受 |\n| WARNING | 60-80% | 丢弃 LOW |\n| CRITICAL | 80-99% | 仅接受 HIGH |\n| FULL | 99-100% | 全部丢弃 |\n\n---\n\n## 二、数据传递与零拷贝\n\n### Q5: 零拷贝与所有权设计\n\n**题目**: 传统消息队列有多次内存拷贝，如何设计零拷贝机制？数据的归属权如何管理？\n\n**答案提示**:\n\n**传统方案的问题**：\n```\n发布者 → 拷贝 → 队列 → 拷贝 → 接收者（两次拷贝）\n1MB × 2次拷贝 × 100Hz = 200MB/s 内存带宽浪费\n```\n\n**零拷贝令牌设计**：\n```c\n/* C语言实现 */\ntypedef struct {\n    uint8_t* data;\n    uint32_t size;\n    uint64_t timestamp;\n    struct BufferPool* pool;  /* 所属内存池 */\n} DataToken;\n\n/* 获取令牌 */\nDataToken* Token_Acquire(BufferPool* pool);\n\n/* 归还令牌（必须调用，否则泄漏） */\nvoid Token_Release(DataToken* token);\n\n/* C++可用RAII自动归还 */\n```\n\n**所有权转移规则**：\n| 阶段 | 所有者 | 允许操作 |\n|------|--------|----------|\n| 已分配 | 发布者 | 填充内容 |\n| 已发布 | 调度层 | 路由、应用策略 |\n| 已派发 | 接收者 | 处理内容 |\n| 已处理 | 内存池 | 回收重用 |\n\n**设计精髓**：\n- 禁止拷贝 → 编译器强制零拷贝\n- 显式归还 → C语言需手动调用Release\n- 引用计数 → 多消费者场景需要计数管理\n- 内存池回收 → 避免频繁malloc/free\n\n---\n\n### Q6: 并发读写的数据一致性\n\n**题目**: 生产者正在写入数据，消费者同时读取，如何保证不会读到不完整数据？\n\n**答案提示**:\n\n**问题本质**：多字节数据的读写不是原子操作，可能读到\"半新半旧\"的脏数据。\n\n**保护方案**：\n| 方案 | 原理 | 开销 | 适用场景 |\n|------|------|------|---------|\n| 双缓冲 | 写A读B，原子切换索引 | 2倍内存 | 高频更新 |\n| 深拷贝 | 入队时完整拷贝 | 拷贝时间 | 数据量小 |\n| 原子操作 | 硬件保证原子性 | 极低 | ≤机器字长 |\n| 所有权转移 | 同一时刻只有一方持有 | 零 | 零拷贝架构 |\n\n**零拷贝架构的解法**：\n- 通过**所有权转移**彻底消除并发读写\n- 生产者填充完成后才发布，发布后不再持有引用\n- 消费者收到后独占访问，天然无竞争\n- **核心思路**：不是\"保护并发访问\"，而是\"从设计上消除并发访问\"\n\n---\n\n## 三、内存管理\n\n### Q7: 静态分配 vs 动态分配 vs 内存池\n\n**题目**: 事件系统的内存用静态分配、动态分配还是内存池？如何选择？\n\n**答案提示**:\n| 策略 | 优点 | 缺点 | 适用场景 |\n|------|-----|------|---------|\n| 静态分配 | 确定性高、无碎片 | 不灵活、浪费空间 | 安全关键系统 |\n| 动态分配 | 灵活、按需分配 | 碎片、泄漏、延迟不确定 | 非实时场景 |\n| 内存池 | O(1)分配释放、无碎片 | 块大小固定 | **实时系统首选** |\n\n**内存池设计要点**：\n- 预分配固定大小的内存块\n- 分配/释放均为 O(1)\n- 峰值后内存使用稳定\n- 按缓存行对齐（64字节），对 DMA 和 CPU 缓存友好\n- **分片减少竞争**：每个 CPU 核心有首选分片（Per-Core Shard），避免多核同时竞争同一个空闲链表\n\n---\n\n### Q8: 内存泄漏的排查与预防\n\n**题目**: 嵌入式系统长期运行后内存缓慢增长，如何排查？设计上如何避免？\n\n**答案提示**:\n\n**常见泄漏原因**：\n| 原因 | 表现 |\n|------|------|\n| 回调注册后未注销 | 订阅者累积 |\n| 异步消息发送后未释放 | 生命周期混乱 |\n| 错误路径未释放 | 异常处理遗漏 |\n| 循环引用 | 引用计数无法归零 |\n\n**设计层面预防**：\n| 策略 | 原理 |\n|------|------|\n| 静态分配 | 编译时确定，运行时不分配 |\n| 内存池 | 固定块复用，峰值后稳定 |\n| RAII | 构造获取、析构释放，自动配对 |\n| weak_ptr | 打破循环引用 |\n| 组件基类析构自动注销 | 组件基类析构时自动注销所有订阅，防止悬空回调 |\n\n**验证手段**：监控借出/归还次数是否相等，池中可用块数是否恢复初始值。\n\n---\n\n### Q9: 内存对齐与缓存优化\n\n**题目**: 嵌入式多线程系统中，内存对齐有哪些作用？什么是伪共享（False Sharing）？如何避免？\n\n**答案提示**:\n\n**内存对齐的作用**：\n| 类型 | 作用 | 示例 |\n|------|------|------|\n| 字节对齐 | 硬件访问效率、原子操作要求 | 4字节int按4对齐 |\n| 缓存行对齐 | 防止伪共享 | alignas(64) |\n| DMA对齐 | 硬件DMA传输要求 | 通常32/64字节 |\n\n**伪共享（False Sharing）问题**：\n```\n❌ 无对齐：多个变量共享缓存行\n┌──────────────────────────────────────────┐\n│ running_ │ state_ │ counter_ │ ...      │  ← 64字节缓存行\n└──────────────────────────────────────────┘\n→ 线程A修改running_，线程B的state_缓存失效！\n→ 性能下降 10-50%\n\n✅ 有对齐：每个变量独占缓存行\n┌────────────────────┐  ┌────────────────────┐\n│ running_ (64B)     │  │ state_ (64B)       │\n└────────────────────┘  └────────────────────┘\n→ 线程A修改running_，不影响线程B\n```\n\n**解决方案**：\n```c\n/* C语言：使用编译器扩展或手动填充 */\nstruct MultiThreadedData {\n    volatile int running;\n    char padding1[60];          /* 填充到64字节 */\n    volatile int state;\n    char padding2[60];\n    volatile uint64_t counter;\n    char padding3[56];\n};\n\n/* C++11: 使用alignas */\n/* alignas(64) std::atomic<bool> running_; */\n```\n\n**重要澄清：`volatile` 不是并发同步原语**：\n- `volatile` 主要用于 **MMIO寄存器访问** 或防止编译器优化掉读写\n- 线程并发可见性与顺序保证应使用 **atomic + memory order**\n- 多线程共享状态请优先使用 `std::atomic`、锁、或无锁协议，不要用 `volatile` 代替\n\n**DMA + Cache 一致性（高频面试点）**：\n| 场景 | 典型问题 | 处理策略 |\n|------|---------|---------|\n| CPU写→DMA读 | DMA读到旧数据 | 发送前做 cache clean / writeback |\n| DMA写→CPU读 | CPU读到旧缓存 | 接收后做 cache invalidate |\n| 非一致性平台 | CPU与DMA视图不一致 | 明确缓存维护边界，必要时用 non-cacheable 区 |\n\n**工程要点**：\n- 对齐（32/64B）解决的是访问效率与硬件要求，不等于自动缓存一致性\n- 必须在驱动或HAL层定义统一的 cache maintenance API，避免业务层散落调用\n\n**结构体布局优化**：\n```c\n/* ❌ 差：24字节，浪费10字节填充 */\nstruct Bad { char a; double b; char c; int d; };\n\n/* ✅ 好：16字节，按大小降序排列 */\nstruct Good { double b; int d; char a; char c; };\n```\n\n---\n\n## 四、多线程与同步\n\n### Q10: 优先级反转\n\n**题目**: 什么是优先级反转？在事件系统中如何避免？\n\n**答案提示**:\n- **问题**：低优先级任务持锁 → 中优先级任务抢占 → 高优先级任务等锁被阻塞\n- **著名案例**：火星探路者号任务重置\n\n**解决方案**：\n| 方案 | 原理 | 适用场景 |\n|------|------|---------|\n| 优先级继承 | 持锁任务临时提升到等待者最高优先级 | RTOS互斥锁 |\n| 优先级天花板 | 锁预设最高优先级 | 静态分析可确定 |\n| **无锁设计** | 使用CAS原子操作，避免锁 | Lock-free数据结构 |\n| **事件驱动** | 串行化共享状态访问，减少锁依赖 | Active Object |\n\n**为什么事件驱动/无锁更适合**：\n- 可显著降低“锁导致的优先级反转”概率\n- 但仍需关注 **CPU饥饿**、**高优先级事件被低优先级长回调阻塞**、**队列拥塞**\n- 真实系统通常要配合：限时回调、抢占点设计、背压/丢弃策略、监控告警\n\n---\n\n### Q11: 死锁分析与预防\n\n**题目**: 事件系统中哪些场景容易产生死锁？如何从设计上避免？\n\n**答案提示**:\n\n**典型死锁场景**：\n| 场景 | 原因 | 解决方案 |\n|------|------|---------|\n| 回调中发布事件 | 持锁发布→等待同一锁 | 发布前释放锁，或用异步队列 |\n| 回调中注销自己 | 遍历时修改列表需要锁 | 延迟删除，遍历结束后处理 |\n| 跨模块循环依赖 | A等B的锁，B等A的锁 | 统一加锁顺序，或用消息解耦 |\n| 同步请求-响应 | 请求方阻塞等响应 | 异步回调+超时机制 |\n\n**设计层面预防**：\n- 回调执行时是否持锁？→ 持锁简单但死锁风险高\n- 是否允许回调中再次发布事件？→ 允许则需可重入设计\n- 是否有全局锁顺序规范？→ 多锁场景必须规定顺序\n\n---\n\n### Q12: Lock-free 数据结构与生产者-消费者模型\n\n**题目**: 什么是无锁（Lock-free）数据结构？SPSC、SPMC、MPSC、MPMC 四种生产者-消费者模型有什么区别？各自的无锁实现有哪些关键技术？并说明为什么某些场景选择 `acquire/release` 而不是 `seq_cst`。\n\n**答案提示**:\n\n**Lock-free 定义**：\n- 至少有一个线程能在有限步骤内完成操作\n- 不使用互斥锁，依赖原子操作实现同步\n- 即使某个线程被挂起，其他线程仍能继续执行\n\n**四种生产者-消费者模型对比**：\n| 模型 | 生产者 | 消费者 | 复杂度 | 典型场景 |\n|------|--------|--------|--------|---------|\n| **SPSC** | 1 | 1 | 最低 | ISR→处理任务、传感器采集管道 |\n| **SPMC** | 1 | N | 中 | 数据广播、一写多读的状态共享 |\n| **MPSC** | N | 1 | 中 | 多模块日志汇聚、集中式消息总线 |\n| **MPMC** | N | N | 最高 | 通用线程池任务队列、内存池 |\n\n**各模型无锁实现的关键技术**：\n\n| 模型 | 核心技术 | 为什么 |\n|------|---------|--------|\n| **SPSC** | 环形缓冲区 + `acquire/release` 内存序 | 单读单写无竞争，仅需内存屏障保证可见性，无需 CAS |\n| **SPMC** | 环形缓冲区 + CAS 竞争消费端 | 多消费者竞争出队位置，需 CAS 仲裁 |\n| **MPSC** | CAS 竞争生产端 + 单消费者无竞争读 | 多生产者竞争入队位置，消费端天然无竞争 |\n| **MPMC** | CAS 竞争双端 + 序列号（sequence） | 生产和消费都有竞争，需序列号标记槽位状态 |\n\n**SPSC 环形缓冲区**（最简单，零 CAS）：\n```c\n/* 仅需 acquire/release 内存序，无需 CAS */\nbool SPSC_Enqueue(SPSCQueue* q, void* item) {\n    uint32_t next = (q->write_pos + 1) % q->capacity;\n    if (next == atomic_load_explicit(&q->read_pos, memory_order_acquire))\n        return false;  /* 满 */\n    q->buffer[q->write_pos] = item;\n    atomic_store_explicit(&q->write_pos, next, memory_order_release);\n    return true;\n}\n```\n\n**为什么常用 `acquire/release` 而非 `seq_cst`**：\n- `acquire/release` 能满足生产-消费可见性约束，开销通常更低\n- `seq_cst` 提供全局总序，语义更强但代价更高\n- 选择原则：先证明最小内存序满足正确性，再考虑是否需要更强语义\n\n**实现时必须交代的三件事**：\n- 如何避免或检测 **ABA**（tag/version/hazard pointer）\n- 如何规避 **伪共享**（关键原子变量分离缓存行）\n- 如何验证内存序正确性（压测 + 竞态检测 + 长稳测试）\n\n**MPMC 无锁队列**（最复杂，需 CAS + 序列号）：\n```c\nbool MPMC_Enqueue(Queue* q, void* item) {\n    uint32_t pos;\n    do {\n        pos = q->producer_pos;\n        if (q->buffer[pos % SIZE].seq != pos)\n            return false;  /* 队列满 */\n    } while (!CAS(&q->producer_pos, pos, pos + 1));\n    q->buffer[pos % SIZE].data = item;\n    q->buffer[pos % SIZE].seq = pos + 1;  /* 标记已填充 */\n    return true;\n}\n/* MPSC 与此类似，但消费端无需 CAS，单线程直接读取 */\n```\n\n**选型决策**：\n```\n需要多生产者？\n├─ 否 → 需要多消费者？\n│        ├─ 否 → SPSC（最优性能，零CAS）\n│        └─ 是 → SPMC\n└─ 是 → 需要多消费者？\n         ├─ 否 → MPSC（推荐：集中式消息总线）\n         └─ 是 → MPMC（最通用，开销最大）\n```\n\n> **工程建议**：能用 SPSC 就不用 MPSC，能用 MPSC 就不用 MPMC。每多一端竞争，复杂度和开销都显著增加。嵌入式消息总线通常选 **MPSC**（多模块发布 → 单线程调度），而非 MPMC。\n\n**为什么 MPSC 在嵌入式中最常用**：\n| 对比维度 | MPSC Lock-free | 有锁队列 (mutex) |\n|---------|----------------|------------------|\n| 入队延迟 | 数百 ns 级 | 数百 ns ~ 数 μs（锁竞争时劣化） |\n| 尾部延迟 | 稳定（无阻塞） | 抖动大（锁竞争导致 P99 劣化数倍） |\n| 上下文切换 | 极少（不阻塞） | 频繁（锁等待触发调度） |\n| 系统态开销 | 极低（无内核调用） | 高（mutex 涉及 futex 系统调用） |\n| 优先级反转 | 无 | 有风险 |\n| 适用场景 | 实时系统、安全关键 | 简单场景、非实时 |\n\n**MPSC/MPMC 的额外挑战与解决方案**：\n| 挑战 | 问题 | 解决方案 |\n|------|------|---------|\n| ABA 问题 | CAS 误判值未变 | Tagged pointer（附加版本号） |\n| 伪共享 | 生产者/消费者位置共享缓存行 | `alignas(64)` 分离到不同缓存行 |\n| 高竞争 | 多核同时 CAS 同一位置 | 分片（Per-Core Shard），每核优先访问本地分片 |\n\n**CAS (Compare-And-Swap) 原理**：\n```c\n/* GCC内置原子操作 */\nint old_val = __sync_val_compare_and_swap(&value, expected, desired);\n/* C11标准 */\natomic_compare_exchange_weak(&value, &expected, desired);\n```\n\n**内存序选择**（C++11 `std::memory_order`）：\n| 内存序 | 语义 | 典型用途 |\n|--------|------|----------|\n| `relaxed` | 仅保证原子性，不保证顺序 | 计数器、统计信息 |\n| `acquire` | 读屏障，后续读写不会重排到此之前 | SPSC 消费者读取 write_pos |\n| `release` | 写屏障，之前读写不会重排到此之后 | SPSC 生产者更新 write_pos |\n| `acq_rel` | 同时具备 acquire 和 release | MPSC/MPMC 的 CAS 操作 |\n| `seq_cst` | 全局顺序一致（默认，开销最大） | 需要全局可见顺序时 |\n\n**无锁 vs 有锁权衡**：\n| 维度 | 无锁 | 有锁 |\n|------|------|------|\n| 延迟 | 低且稳定 | 可能阻塞 |\n| 吞吐量 | 高竞争时更好 | 低竞争时更好 |\n| 复杂度 | 高（ABA问题、内存屏障） | 低 |\n| 优先级反转 | 无 | 有风险 |\n| 适用场景 | 高并发、实时系统 | 简单场景 |\n\n**ABA 问题**：线程读到值 A，被抢占后其他线程将值改为 B 再改回 A，CAS 误判为未修改。解决方案：附加版本号（tagged pointer）或使用 hazard pointer。\n\n---\n\n## 五、面向对象与语言选型\n\n### Q13: C/C++ 选型与多态实现\n\n**题目**: 事件系统用 C 还是 C++ 实现？C 语言如何实现面向对象？C++ 运行时多态和编译时多态有什么区别？\n\n**答案提示**:\n\n**C vs C++ 选型**：\n| 条件 | 推荐选择 | 原因 |\n|------|---------|------|\n| 有安全规范约束 | 受限C或受限C++ | 取决于规范目标、工具链与团队能力 |\n| 资源极度受限 | C语言 | 无运行时开销 |\n| 复杂业务逻辑 | C++子集 | RAII、模板更安全 |\n| 团队无C++经验 | C语言 | 降低风险 |\n\n**补充建议**：\n- 很多量产项目采用 MISRA C + 少量C++，或 MISRA/AUTOSAR C++ 子集\n- 关键不是语言本身，而是“可审计子集 + 编码规范 + 工具链闭环”\n\n**C语言面向对象实现**：\n```c\n// 手工虚函数表\ntypedef struct {\n    void (*on_event)(void* self, Event* e);\n    void (*destroy)(void* self);\n} EventHandlerVTable;\n\ntypedef struct {\n    const EventHandlerVTable* vtable;  // 虚函数表指针\n    // ... 其他成员\n} EventHandler;\n\n// 调用虚函数\nhandler->vtable->on_event(handler, &event);\n```\n\n**C++ 运行时多态 vs 编译时多态**：\n| 维度 | 运行时多态 (virtual) | 编译时多态 (模板) |\n|------|---------------------|------------------|\n| 派发时机 | 运行时 | 编译时 |\n| 能否内联 | 不能 | 可以 |\n| 内存开销 | 虚指针 8 字节 | 零 |\n| 适用场景 | 类型运行时确定 | 类型编译时已知 |\n\n**嵌入式 C++ 子集（推荐）**：\n| 类别 | 特性 |\n|------|------|\n| **推荐** | 类、模板、RAII、引用、强类型枚举、移动语义 |\n| **谨慎** | 虚函数、std::function、STL容器 |\n| **避免** | 异常、RTTI、多重继承、iostream |\n\n---\n\n## 六、状态机与并行计算\n\n### Q14: 状态机选型\n\n**题目**: 什么场景下应该使用状态机？switch 状态机、状态模式、模板化 HSM 各有什么优劣？\n\n**答案提示**:\n\n**什么时候需要状态机**：\n| 信号 | 说明 |\n|------|------|\n| 行为依赖历史 | 同一事件在不同状态下有不同响应 |\n| 状态转换有约束 | 不是任意状态都能互相切换 |\n| 需要进入/退出动作 | 进入或离开状态时需执行特定操作 |\n\n**三种实现对比**：\n| 实现方式 | 优势 | 劣势 | 适用场景 |\n|---------|------|------|---------|\n| **switch-case** | 简单直观、零开销 | 状态多时难维护 | 状态少（<5） |\n| **状态模式(OOP)** | 开闭原则、多态扩展 | 虚函数开销、类爆炸 | 状态行为差异大 |\n| **模板化HSM** | 编译时优化、支持层次 | 学习成本高 | 复杂嵌入式系统 |\n\n**模板化 HSM 核心思想**：\n- 用模板参数传递上下文类型，编译器可直接调用+内联\n- 层次结构：状态可有父状态，未处理事件自动向上传递\n- 编译时确定调用目标，对指令缓存友好\n\n---\n\n### Q15: 多核并行设计\n\n**题目**: 嵌入式系统中，什么场景需要多核并行？单核事件驱动和多核并行如何协作？\n\n**答案提示**:\n\n**单核 vs 多核**：\n| 维度 | 单核事件驱动 | 多核并行 |\n|------|------------|---------|\n| 适用任务 | I/O密集、事件响应 | 计算密集、数据并行 |\n| 同步开销 | 无锁、零开销 | 需要锁/原子/屏障 |\n| 确定性 | 高 | 低（调度不确定） |\n| 编程复杂度 | 中 | 高（竞态、死锁） |\n\n**何时必须用多核**：\n| 场景 | 原因 |\n|------|------|\n| 算法耗时超过帧间隔 | 单核处理不完 |\n| 硬实时+软实时共存 | 硬实时核不能被干扰 |\n| 异构多核 | 应用核+实时核分工 |\n\n**典型双核分工**：\n```\n应用核（Linux）           实时核（RTOS/裸机）\n┌─────────────────┐    ┌─────────────────┐\n│ 业务逻辑         │    │ 硬实时控制       │\n│ 数据后处理       │◄──►│ 传感器采集       │\n│ 通信/存储/UI    │IPC │ 安全监控         │\n└─────────────────┘    └─────────────────┘\n```\n\n**跨核通信**：\n| 机制 | 特点 | 适用场景 |\n|------|------|---------|\n| 共享内存+内存屏障 | 最快、零拷贝 | 大数据传递 |\n| 硬件信号量/邮箱 | 轻量级通知 | 事件通知 |\n\n---\n\n## 七、可靠性与容错设计\n\n### Q16: 故障隔离与熔断\n\n**题目**: 事件系统中，如何防止单个回调故障影响整个系统？\n\n**答案提示**:\n\n**故障类型**：\n| 类型 | 表现 | 影响 |\n|------|------|------|\n| 回调崩溃 | 空指针、非法访问 | 进程崩溃 |\n| 回调死循环 | CPU 100% | 阻塞所有事件 |\n| 回调超时 | 执行时间过长 | 影响实时性 |\n\n**隔离策略**：\n| 层级 | 机制 | 代价 |\n|------|------|------|\n| 进程级 | 独立进程+IPC | 开销大 |\n| 线程级 | 不同线程处理 | 同步开销 |\n| 回调级 | 看门狗+异常捕获 | 无法防止崩溃 |\n\n**熔断器状态机**：\n```\n[正常] ──失败率超阈值──► [熔断] ──超时后──► [试探]\n  ▲                                          │\n  └──────────────试探成功────────────────────┘\n```\n\n---\n\n### Q17: 回调安全与生命周期\n\n**题目**: 异步回调系统中，如何防止回调时对象已被销毁（悬空回调）？\n\n**答案提示**:\n\n**问题场景**：\n```c\n/* ❌ 危险：对象销毁后回调仍被触发 */\ntypedef struct {\n    void (*callback)(void* ctx, Event* e);\n    void* context;  /* 可能指向已释放的内存！ */\n} Subscription;\n```\n\n**C语言解决方案**：\n```c\n/* 方案1：注销时置空 + 调用前检查 */\ntypedef struct {\n    void (*callback)(void* ctx, Event* e);\n    void* context;\n    volatile int valid;  /* 有效标志 */\n} SafeSubscription;\n\nvoid Unsubscribe(SafeSubscription* sub) {\n    sub->valid = 0;       /* 先置无效 */\n    sub->callback = NULL;\n    sub->context = NULL;\n}\n\nvoid Dispatch(SafeSubscription* sub, Event* e) {\n    if (sub->valid && sub->callback) {\n        sub->callback(sub->context, e);\n    }\n}\n\n/* 方案2：引用计数 */\ntypedef struct Component {\n    int ref_count;\n    /* ... */\n} Component;\n\nvoid Component_AddRef(Component* c) { c->ref_count++; }\nvoid Component_Release(Component* c) {\n    if (--c->ref_count == 0) free(c);\n}\n```\n\n**关键点**：\n- C语言：注销时置空回调指针 + 调用前检查\n- C语言：引用计数管理生命周期\n- C++：可用 weak_ptr 自动检测对象存活\n- 通用：组件析构时必须注销所有订阅\n\n---\n\n### Q18: 批处理与吞吐量优化\n\n**题目**: 高频事件场景下，如何通过批处理提升系统吞吐量？\n\n**答案提示**:\n\n**问题**：N 个事件触发 N 次函数调用，调度开销大。\n\n**批处理设计**：\n```c\nuint32_t ProcessBatch(EventQueue* queue, uint32_t max_count) {\n    uint32_t processed = 0;\n    while (processed < max_count) {\n        Event* event = Queue_TryDequeue(queue);\n        if (event == NULL) break;\n        ProcessEvent(event);\n        processed++;\n    }\n    return processed;\n}\n```\n\n**批处理的价值**：\n| 价值 | 说明 |\n|------|------|\n| 减少函数调用开销 | N 个事件 1 次调用 vs N 次调用 |\n| 提高缓存命中率 | 连续处理相关数据，指令缓存热 |\n| 突发负载平滑 | 短时大量事件不造成调度风暴 |\n| 减少上下文切换 | 一次处理多个，减少调度次数 |\n\n**批大小选择**：小批量（16-64）延迟低；大批量（1024+）吞吐高但延迟增加。实时系统需权衡。\n\n**吞吐-延迟权衡（Throughput-Latency Tradeoff）**：\n\n系统设计中最经典的权衡之一：**提升吞吐量的手段往往会增加单条消息的端到端延迟**。根本原因是\"攒批\"与\"立即响应\"天然矛盾。\n\n| 策略 | 吞吐量 | E2E 延迟 | 原因 |\n|------|--------|---------|------|\n| 消费者频繁唤醒 | 低 | 低 | 每次处理少量消息，等待时间短 |\n| 消费者延迟唤醒 | 高 | 高 | 攒一批再处理，队列中等待更久 |\n| 小批量处理 | 低 | 低 | 调度开销大，但响应快 |\n| 大批量处理 | 高 | 高 | 摊薄调度开销，但队尾消息等待久 |\n| 自适应 spin + futex | 高 | 中-高 | spin 阶段攒消息，减少系统调用 |\n| 无锁轮询 (busy-poll) | 高 | 极低 | 持续轮询零等待，但独占 CPU 核心 |\n\n**消费者等待策略是关键杠杆**：\n\n```\n策略A: 频繁唤醒（低延迟优先）\n  condvar.wait(lock, timeout)  →  处理 1-N 条  →  condvar.wait...\n  ✅ 延迟低（亚微秒级）  ❌ 吞吐受限  ❌ 频繁 futex 系统调用\n\n策略B: 自适应 spin + 延迟唤醒（高吞吐优先）\n  spin(N) → 攒消息 → 批量处理 → spin...\n  ❌ 延迟高（微秒~十微秒级）  ✅ 吞吐高  ✅ 极少系统调用\n\n策略C: Lock-free 持续轮询（兼顾延迟与吞吐）\n  while(!stop) { if(有消息) 立即处理; yield; }\n  ✅ 延迟极低（百纳秒级）  ✅ 吞吐高  ❌ 独占一个 CPU 核心\n```\n\n> 同一套队列和数据结构，仅改变消费者等待策略，就能产生数量级的延迟差异。\n> 这不是 bug，而是经典的吞吐-延迟权衡。\n\n**选型指南**：\n\n| 场景 | 优先指标 | 推荐策略 |\n|------|---------|---------|\n| 紧急停止、安全关键 | **延迟** | 无锁轮询，或高优先级绕过队列 |\n| 传感器数据流处理 | 吞吐 + 可接受延迟 | 自适应 spin + 批处理 |\n| 日志、遥测上报 | **吞吐** | 大批量 + 延迟唤醒 |\n| 通用消息总线 | 兼顾 | Lock-free 轮询 + 固定 batch |\n\n**面试回答要点**：\n- 说出\"吞吐-延迟权衡\"这个概念，说明两者不可兼得的根本原因（攒批 vs 立即响应）\n- 指出**消费者等待策略**是决定权衡点的关键杠杆\n- 能针对具体场景给出选型建议，不要笼统地说\"越快越好\"\n\n---\n\n### Q19: 跨模块通信模式与同步/异步设计\n\n**题目**: 嵌入式系统中，模块间通信有哪些模式？如何选型？中断上下文中的通信有哪些限制？\n\n**答案提示**:\n\n**三大通信模式对比**：\n| 模式 | 原理 | 优点 | 缺点 | 适用场景 |\n|------|------|------|------|---------|\n| 同步调用 | 直接函数调用，调用方阻塞等返回 | 简单直观、时序确定 | 耦合高、阻塞调用方 | 模块间强依赖、低延迟要求 |\n| 异步消息 | 通过队列/邮箱传递消息，非阻塞 | 解耦、不阻塞发送方 | 延迟不确定、需处理超时 | 跨线程/跨核、事件驱动架构 |\n| 共享内存 | 多模块直接读写同一块内存 | 零拷贝、带宽最高 | 需同步保护、易出竞态 | 大数据传递、多核通信 |\n\n**中断上下文的通信限制**：\n| 限制 | 原因 | 后果 |\n|------|------|------|\n| ❌ 不能阻塞（mutex/sem_wait） | 中断无法被调度器切换 | 死锁、系统挂起 |\n| ❌ 不能调用 malloc/free | 堆管理器通常非可重入 | 数据损坏 |\n| ❌ 不能执行耗时操作 | 阻塞其他中断和任务 | 实时性丧失 |\n| ✅ 可以写无锁队列 | CAS 原子操作不阻塞 | 安全 |\n| ✅ 可以发“ISR专用通知” | 使用 RTOS FromISR API | 安全 |\n| ✅ 可以设置标志位/发送通知 | 原子写操作 | 安全 |\n\n**RTOS 语义注意**：\n- 不要泛化使用 `sem_post`；应使用各RTOS定义的 ISR 专用API\n    - 例如 FreeRTOS: `xSemaphoreGiveFromISR`\n    - CMSIS-RTOS: 对应 ISR-safe 接口\n\n**ISR → 任务无锁桥接（推荐模板）**：\n| 组件 | 建议 |\n|------|------|\n| 队列模型 | SPSC ring（ISR单生产者，任务单消费者） |\n| 队列容量 | 依据峰值中断突发 + 任务最坏阻塞时长估算 |\n| 水位线 | low/high watermark，用于降级与告警 |\n| 丢包策略 | 满队列时按优先级丢弃或覆盖最旧，并记录drop计数 |\n\n**典型策略**：\n- ISR 只做“采样/搬运/入队/通知”，不做重计算\n- 任务侧批处理出队，超时驱动 + 水位自适应\n- 监控指标至少包含：queue depth、high watermark、drop count、处理延迟\n\n**Top-half / Bottom-half 分离模式**：\n```c\n/* Top-half：中断上下文，极短 */\nvoid ISR_SensorDataReady(void) {\n    DataToken* token = Pool_TryAcquire(&pool);  /* 无锁获取 */\n    if (token) {\n        DMA_Read(token->data, SENSOR_ADDR, SIZE);\n        Queue_Enqueue_ISR(&isr_queue, token);   /* 无锁入队 */\n    }\n    OS_EventSet(EVENT_SENSOR);  /* 通知 Bottom-half */\n}\n\n/* Bottom-half：任务上下文，可阻塞 */\nvoid Task_SensorProcess(void* arg) {\n    while (1) {\n        OS_EventWait(EVENT_SENSOR, TIMEOUT_MS);\n        DataToken* token;\n        while ((token = Queue_Dequeue(&isr_queue)) != NULL) {\n            ProcessSensorData(token);   /* 耗时处理 */\n            Pool_Release(&pool, token); /* 归还内存池 */\n        }\n    }\n}\n```\n\n**异步系统中实现同步语义**：\n\n| 方案 | 原理 | 优点 | 缺点 | 适用场景 |\n|------|------|------|------|---------|\n| 信号量阻塞 | 请求时创建信号量，响应时释放 | 简单直观 | 阻塞调用线程 | RTOS 任务间 |\n| Future/Promise | 异步操作返回 Future，调用方按需等待结果 | 现代 C++ 原生支持、可组合 | C++11 起、有堆分配 | 复杂异步流程编排 |\n| 协程 | 用户态挂起/恢复，看似同步实则异步 | 代码线性可读、无回调嵌套 | 需语言/库支持（C++20/自实现） | 多步异步流程 |\n| 回调+状态机 | 响应触发状态转换 | 完全异步、无阻塞 | 逻辑分散、调试困难 | 资源受限的裸机系统 |\n\n**超时策略设计**：\n| 策略 | 实现 | 适用场景 |\n|------|------|---------|\n| 固定超时 | 每次请求相同超时值 | 简单场景 |\n| 指数退避 | 重试间隔 1s→2s→4s→8s... | 网络/总线通信 |\n| 自适应超时 | 基于历史响应时间动态调整 | 负载波动大的系统 |\n| 看门狗兜底 | 硬件定时器，超时则复位 | 安全关键系统最后防线 |\n\n**关键设计要点**：\n| 要点 | 说明 |\n|------|------|\n| 请求 ID | 全局唯一，用于关联请求和响应（多请求并发时不混淆） |\n| 超时必须有 | 防止永久等待，任何阻塞操作都必须有超时机制 |\n| 中断安全 | 中断中只能用非阻塞操作（无锁队列、sem_post、标志位） |\n| 请求方不持锁 | 请求方不应持有响应方需要的锁，否则死锁 |\n\n---\n\n### Q20: 类型安全与 void* 的风险\n\n**题目**: C/C++ 事件系统中如何保证类型安全？void* 类型擦除有什么风险？什么是对象切片？\n\n**答案提示**:\n\n**void* 类型擦除的风险**：\n```c\n/* ❌ void* 类型擦除：运行时才发现错误 */\nvoid PublishEvent(int event_id, void* data);\n\nSensorData sensor = {1.0f, 2.0f, 3.0f};\nPublishEvent(EVENT_CONFIG, &sensor);  /* 类型错误！编译通过，运行崩溃 */\n```\n\n**类型安全方案对比**：\n| 方案 | 实现 | 安全性 | 开销 |\n|------|------|--------|------|\n| void* + 枚举标记 | 运行时检查类型标记 | 中 | 低 |\n| 联合体(union) | 手动管理当前类型 | 中 | 低 |\n| 每类型独立函数 | PublishSensor() / PublishConfig() | 高 | 零 |\n| C++ 模板 | 编译时类型检查 | 高 | 零 |\n| C++ 模板特化 | 每种事件类型特化订阅接口，类型不匹配则编译报错 | 最高 | 零 |\n\n**C语言类型安全设计（tagged union）**：\n```c\ntypedef enum { PAYLOAD_SENSOR, PAYLOAD_CONFIG, PAYLOAD_CMD } PayloadType;\n\ntypedef struct {\n    PayloadType type;  /* 类型标记 */\n    union {\n        SensorData sensor;\n        ConfigData config;\n        CommandData command;\n    } data;\n} EventPayload;\n\n/* 安全访问 */\nint GetSensorData(const EventPayload* p, SensorData* out) {\n    if (p->type != PAYLOAD_SENSOR) return -1;\n    *out = p->data.sensor;\n    return 0;\n}\n```\n\n**对象切片问题（C++）**：\n```cpp\nclass Event { public: int type; virtual ~Event() = default; };\nclass SensorEvent : public Event { public: float data[3]; };\n\n// ❌ 按值传递：派生类数据被\"切掉\"\nvoid HandleEvent(Event e) {  // 对象切片！\n    // e 只有 Event 部分，SensorEvent::data 丢失\n}\n\n// ✅ 按指针/引用传递\nvoid HandleEvent(const Event& e) {  // 正确\n    if (auto* sensor = dynamic_cast<const SensorEvent*>(&e)) {\n        // 安全访问 sensor->data\n    }\n}\n```\n\n**预防对象切片**：\n| 规则 | 说明 |\n|------|------|\n| 指针/引用传递 | 多态对象**禁止按值传递** |\n| virtual 析构 | 基类析构函数必须 virtual |\n| = delete | 可删除基类拷贝构造防止切片 |\n\n**C语言的\"多态\"实现**：\n```c\n/* 手工虚函数表 */\ntypedef struct {\n    void (*handle)(void* self, Event* e);\n    void (*destroy)(void* self);\n} HandlerVTable;\n\ntypedef struct {\n    const HandlerVTable* vtable;  /* 虚函数表指针 */\n    /* ... 其他成员 */\n} EventHandler;\n\n/* 调用\"虚函数\" */\nhandler->vtable->handle(handler, &event);\n```\n\n**C++ 四种类型转换**：\n| 转换 | 用途 | 安全性 | 示例 |\n|------|------|--------|------|\n| static_cast | 已知安全的转换 | 中 | 数值类型、向上转型 |\n| dynamic_cast | 运行时多态检查 | 高 | 向下转型（需RTTI） |\n| const_cast | 移除/添加 const | 低 | 兼容旧 API |\n| reinterpret_cast | 位模式重解释 | 最低 | 硬件寄存器、序列化 |\n\n**补充（禁用 RTTI 时）**：\n- 若项目禁用 RTTI（常见于嵌入式），避免 `dynamic_cast`\n- 可改用 tagged union / `std::variant` / 手工类型标签 + 显式分发\n\n**设计原则**：\n1. 优先用类型特定函数，避免 void*\n2. 必须用 void* 时，配合类型枚举标记\n3. 多态对象始终用指针/引用传递\n4. C++ 基类析构函数声明为 virtual\n5. 类型转换选择最严格的方式\n\n---\n\n## 附录：实时性与可测性补充（面试加分）\n\n**WCET（Worst-Case Execution Time）与可测性要点**：\n- 事件链路预算 = 入队 + 排队 + 出队 + 回调处理 + 关键同步\n- 预算方法：先静态上界估算，再用压力测试验证 P99/P999 与最坏值\n- 关键监控：每阶段时延、队列高水位、丢弃率、超时次数\n- 验证手段：长稳压测、故障注入、时钟同步打点、离线统计报告\n- 面试回答建议：给出“预算表 + 实测数据 + 裕量策略”，比只讲原理更有说服力\n\n---\n\n## 附录：面试评分参考\n\n| 等级 | 表现 |\n|------|------|\n| **优秀** | 能主动提出权衡、边界条件、实际工程经验 |\n| **良好** | 能回答核心要点，理解设计原理 |\n| **及格** | 知道基本概念，但缺乏深度 |\n| **不及格** | 概念混淆或无法回答 |\n\n**加分项**：\n- 能结合具体项目经验说明\n- 能指出常见错误和陷阱\n- 能给出量化分析（如性能数据）\n- 能提出多种方案并比较优劣\n- 了解 RTOS 调度、内存池、零拷贝、中断处理、缓存对齐等嵌入式核心概念\n\n---\n\n## 附录：核心概念速查表\n\n### 同步原语对比\n\n| 原语 | 开销 | 适用场景 | 注意事项 |\n|------|------|----------|----------|\n| 互斥锁(mutex) | 中 | 临界区保护 | 可能死锁、优先级反转 |\n| 信号量(semaphore) | 中 | 资源计数、同步 | 可能优先级反转 |\n| 自旋锁(spinlock) | 低 | 短临界区 | 浪费CPU、禁止睡眠 |\n| 原子操作(atomic) | 极低 | 简单计数/标志 | 仅限简单操作 |\n| 禁中断 | 极低 | 最短临界区 | 影响实时性 |\n\n### 常见陷阱清单\n\n| 陷阱 | 后果 | 预防措施 |\n|------|------|----------|\n| 伪共享 | 性能下降50% | 缓存行对齐/填充 |\n| 优先级反转 | 高优先级饿死 | 优先级继承/无锁设计 |\n| 栈溢出 | 数据损坏/崩溃 | 栈保护/静态分析 |\n| 悬空指针 | 崩溃 | 置NULL/引用计数 |\n| 死锁 | 系统挂起 | 锁顺序/超时机制 |\n| 内存泄漏 | 资源耗尽 | 内存池/静态分配 |\n| 竞态条件 | 数据不一致 | 原子操作/临界区 |\n\n### 嵌入式性能优化检查清单\n\n- [ ] 热点数据是否缓存行对齐？\n- [ ] 是否存在不必要的内存拷贝？\n- [ ] 锁的粒度是否合适？\n- [ ] 中断处理是否足够短？\n- [ ] 是否使用内存池替代动态分配？\n- [ ] 关键路径是否避免了系统调用？\n- [ ] 数据结构是否对缓存友好？\n- [ ] 是否考虑了DMA对齐要求？\n",
      "ctime": "1771552480",
      "mtime": "1771552480",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "ipc/cpp_py_shmbuf.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469538350",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "跨语言共享内存 IPC: C++ 与 Python 的零拷贝数据通道设计",
      "brief_content": "工业视觉系统中，C++ 采集 1080p/4K 视频，Python 处理深度学习。传统 TCP/socket 方案的序列化开销高达 10ms，共享内存是唯一能做到真正零拷贝的方案。本文详解 cpp_p",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 项目仓库: [cpp_py_shmbuf](https://gitee.com/liudegui/cpp_py_shmbuf) (C++14 header-only, Python 3.8+)\n> 参考设计: [ringbuffer](https://gitee.com/liudegui/ringbuffer) (lock-free SPSC 模式)\n> 对标方案: [cpp-ipc](https://github.com/mutouyun/cpp-ipc) (MPMC 方案)\n> 典型应用: 工业视觉、激光雷达融合、边缘计算网关\n\n---\n\n## 1. 问题域: 为什么需要共享内存 IPC\n\n### 1.1 工业视觉的架构约束\n\n典型工业视觉系统采用分工设计:\n\n```\n[相机]\n  ↓ USB3.0 / GigE\n[C++ 驱动层]  (低延迟采集，NEON 加速预处理)\n  ↓ IPC\n[Python 应用层] (OpenCV, TensorFlow, 算法灵活)\n  ↓\n[云端/本地存储]\n```\n\n**为什么这样分工**:\n- **C++ 采集**: 接管相机驱动、硬件同步、帧率控制，毫秒级精度\n- **Python 处理**: 快速原型迭代，丰富的 AI/CV 库 (TensorFlow, OpenCV)\n- **IPC 瓶颈**: 进程边界的数据传递，1080p BGR 帧 = 6.2 MB，30 FPS = 180 MB/s\n\n### 1.2 四种 IPC 方案的对比\n\n1080p BGR 帧 (1920×1080×3 = 6.2 MB, 30 FPS):\n\n| 方案 | 机制 | 拷贝次数 | 序列化开销 | 延迟 | 可行性 |\n|------|------|--------|----------|------|--------|\n| **TCP socket** | 内核缓冲 | 4 (user→kernel→kernel→user) | 无 | 低 | 勉强 (CPU 30%+) |\n| **Unix domain socket** | 内核缓冲 | 2 | 无 | 低 | 可行 (CPU 15%) |\n| **Protobuf + TCP** | 编解码 | 2 + 编码 | 高 (6MB→10ms) | 高 | 不可行 (CPU 50%+) |\n| **共享内存** | 虚拟地址映射 | **0 (同一物理页)** | **无** | **纳秒** | **理想** (CPU <1%) |\n\n**关键区别**:\n- 前三种方案都涉及内核态/用户态切换或序列化编解码\n- 共享内存: 两个进程的虚拟地址指向同一块物理内存，写入方的 `memcpy` 对消费方立即可见，**无内核参与，无数据拷贝**\n\n### 1.3 为什么不用现成的 IPC 库\n\n| 库 | 问题 | 成本 |\n|----|------|------|\n| Boost.Interprocess | 编译慢 (30+ 分钟)、部署复杂、仅 C++ 支持 | 高 |\n| zeromq | MPMC 设计过度、引入消息队列复杂性 | 中 |\n| gRPC | 网络 RPC 框架，IPC 只是副产品，序列化开销存在 | 高 |\n| Redis | 外部进程依赖、不适合嵌入式 | 高 |\n\n**cpp_py_shmbuf 的定位**: 仅针对 SPSC (Single Producer, Single Consumer) 场景的最小可行实现，零依赖，跨语言原生支持。\n\n---\n\n## 2. 为什么这样做: 设计约束分析\n\n### 2.1 跨语言的原子性约束\n\nC++ 的 `std::atomic<uint32_t>` 在共享内存中对 Python **不可见**。Python 的 `struct.pack_into` 操作的是原始字节，无法理解 C++ 原子操作的语义。\n\n```\n共享内存是 POD (Plain Old Data)，不能包含 C++ 对象。\n```\n\n**解决方案: 原始字节 + 约定协议**\n\n```cpp\n// C++ 端: 原始 uint32_t\nstruct RingHeader {\n    uint32_t head;      // Little-endian, producer 写\n    uint32_t tail;      // Little-endian, consumer 写\n    uint32_t capacity;  // 2 的幂, 只读\n    uint32_t reserved;  // 对齐填充\n};\n\n// Python 端: struct.pack_into\nstruct.pack_into('<I', buf, 0, head_value)  # 同样的小端 uint32\n```\n\n**内存屏障保证**:\n- **C++ 端**: `atomic_thread_fence(acquire/release)` 在关键操作前后插入屏障\n- **Python 端**: CPython GIL (全局解释器锁) + x86/ARM 上对齐 `uint32` 写入天然原子性\n\n### 2.2 消除竞态的 buf_full flag\n\n早期设计用 `buf_full` 标志位区分 \"缓冲区空\" 和 \"缓冲区满\"（两者都是 head == tail）:\n\n```\nempty:  head == tail && !buf_full\nfull:   head == tail && buf_full\n```\n\n这个 `buf_full` 被生产者和消费者同时读写，容易竞态:\n\n```\n[时刻 1] Producer 读 head = 100, tail = 100, buf_full = false (发现缓冲区空)\n[时刻 2] Consumer 读 head = 100, tail = 100, buf_full = false (发现缓冲区空)\n  ↓ (网络延迟、CPU 调度抖动)\n[时刻 3] Producer 写入一条消息，设 buf_full = true，更新 head = 108\n[时刻 4] Consumer 继续执行，但已过时的状态导致错误处理\n```\n\n**新设计: 借鉴 ringbuffer 的单调递增索引**\n\n```cpp\navailable_to_read  = head - tail              // 可读字节数\navailable_to_write = capacity - (head - tail) // 可写字节数\nempty: head == tail\nfull:  (head - tail) == capacity\n```\n\n关键优势:\n1. **索引单调递增**, 永不重置为 0\n2. **自然溢出安全**: `uint32_t` 自然溢出在 4GB 处，对于 MB 级缓冲区完全安全\n3. **消除 flag**: 用数学关系（差值）代替竞态 flag，天然避免竞态\n\n**数学证明**:\n\n```\n假设 capacity = 16 (mask = 0xF)\n\n写入 10 字节:\n  head = 0, tail = 0, available = 0 → 16 字节\n  写入后: head = 10, tail = 0, available = 10 字节\n\n再写入 8 字节:\n  head = 10, tail = 0, available = 10 → 6 字节 (不足，拒绝)\n\n自然溢出场景 (head 已达到 uint32_max):\n  head = 4294967290, tail = 4294967280\n  available = 4294967290 - 4294967280 = 10 字节 ✓ (正确)\n\n  自动溢出后:\n  head = (4294967290 + 10) % 2^32 = 4, tail = 4294967280 (仍是旧值，稍后会读到新的 tail)\n  available = 4 - 4294967280 = 4 - 4294967280 (u32 减法)\n           = 4 + (2^32 - 4294967280) = 4 + 16 = 20... (不对?)\n\n  实际上 u32 减法是定义好的:\n  a - b (mod 2^32) 等于 a + (~b + 1) mod 2^32\n\n  当 head 大循环回来时，tail 也应该跟着大循环，差值始终正确。\n```\n\n### 2.3 消息格式的设计\n\n为了支持变长消息，采用 **长度前缀** 格式:\n\n```\n[4 字节 LE 长度][payload]\n\n例: 发送 \"hello\" (5 字节)\n    共享内存: [05 00 00 00] [h e l l o]\n               (Little-endian 5)\n```\n\n**为什么是 4 字节而非变长编码**:\n1. 固定大小，无需扫描，快速\n2. 便于 Python `struct.unpack` 直接解析\n3. 足以表示 2GB 单条消息（4GB 容量的缓冲区实际容量会更小）\n\n---\n\n## 3. 设计方案: 架构与实现\n\n### 3.1 共享内存布局\n\n```\n总大小 = N + 16 (N 必须是 2 的幂, 如 1048576 = 1MB)\n\n┌─────────────────────────────────────────────────┐\n│ 偏移 0-3:   head (uint32_t LE)                  │\n│             Producer 写, Consumer 读            │\n│             单调递增索引，用于发信号             │\n├─────────────────────────────────────────────────┤\n│ 偏移 4-7:   tail (uint32_t LE)                  │\n│             Consumer 写, Producer 读            │\n│             单调递增索引，用于流控              │\n├─────────────────────────────────────────────────┤\n│ 偏移 8-11:  capacity (uint32_t LE)              │\n│             创建时写入，之后只读                 │\n│             = N (数据区大小)                   │\n├─────────────────────────────────────────────────┤\n│ 偏移 12-15: reserved (对齐填充)                 │\n├─────────────────────────────────────────────────┤\n│ 偏移 16-(16+N-1): data area                     │\n│             环形缓冲数据区                       │\n│             存储 [4B len][payload] 格式消息     │\n└─────────────────────────────────────────────────┘\n```\n\n**设计权衡**:\n- **head/tail 分别由单端独占写入**: 天然避免 false sharing (不需要锁)\n- **capacity 只读**: 避免运行时修改，简化同步逻辑\n- **16 字节头部**: 无缓存行对齐 (arm-64 缓存行 64B，无必要)\n\n### 3.2 C++ 实现框架\n\n```cpp\nnamespace shm {\n\n// 跨平台共享内存\nclass SharedMemory {\n  // POSIX: shm_open + mmap\n  // Windows: CreateFileMappingA + MapViewOfFile\n  // RAII: 析构时 munmap / UnmapViewOfFile\n};\n\n// 字节级环形缓冲 (SPSC, lock-free)\nclass ByteRingBuffer {\n  // 绑定到共享内存\n  ByteRingBuffer(void* base, uint32_t size, bool is_producer);\n\n  // Producer API\n  bool Write(const void* data, uint32_t len);\n  uint32_t WriteableBytes() const;\n\n  // Consumer API\n  uint32_t Read(void* out, uint32_t max_len);\n  bool HasData() const;\n\nprivate:\n  // 原始指针, 无 C++ 对象\n  RingHeader* header_;\n  uint8_t* data_;\n  uint32_t mask_;\n};\n\n// 高层 API\nclass ShmProducer {\n  ShmProducer(const char* name, uint32_t capacity);\n  bool Write(const void* data, uint32_t len);\n};\n\nclass ShmConsumer {\n  explicit ShmConsumer(const char* name);\n  uint32_t Read(void* out, uint32_t max_len);\n};\n\n}  // namespace shm\n```\n\n### 3.3 Python 实现\n\n```python\nimport multiprocessing.shared_memory as mm\nimport struct\n\nclass ByteRingBuffer:\n    HEADER_SIZE = 16\n\n    def __init__(self, buf: memoryview, is_producer: bool = False):\n        self.buf = buf\n        self.mask = struct.unpack_from('<I', buf, 8)[0] - 1\n        self.is_producer = is_producer\n\n    def write(self, data: bytes) -> bool:\n        \"\"\"Write [4B len LE][payload]\"\"\"\n        head = struct.unpack_from('<I', self.buf, 0)[0]\n        tail = struct.unpack_from('<I', self.buf, 4)[0]\n\n        available = self.mask + 1 - (head - tail)\n        total = len(data) + 4\n        if available < total:\n            return False\n\n        # Write length prefix\n        struct.pack_into('<I', self.buf, self.HEADER_SIZE + (head & self.mask), len(data))\n        # Write payload (处理 wrap-around)\n        self._write_bytes(head + 4, data)\n\n        # Update head (Python GIL + aligned write = atomic)\n        struct.pack_into('<I', self.buf, 0, head + total)\n        return True\n\n    def read(self) -> Optional[bytes]:\n        \"\"\"Read one message\"\"\"\n        tail = struct.unpack_from('<I', self.buf, 4)[0]\n        head = struct.unpack_from('<I', self.buf, 0)[0]\n\n        if head - tail < 4:\n            return None  # Not enough for length prefix\n\n        # Read length\n        msg_len = struct.unpack_from('<I', self.buf,\n                                    self.HEADER_SIZE + (tail & self.mask))[0]\n        if head - tail < 4 + msg_len:\n            return None  # Not enough for payload\n\n        # Read payload\n        payload = self._read_bytes(tail + 4, msg_len)\n\n        # Update tail\n        struct.pack_into('<I', self.buf, 4, tail + 4 + msg_len)\n        return payload\n\nclass ShmProducer:\n    def __init__(self, name: str, capacity: int):\n        self.shm = mm.SharedMemory(name=name, create=True,\n                                   size=capacity + 16)\n        # Initialize header\n        self.ring = ByteRingBuffer(self.shm.buf, is_producer=True)\n\n    def write(self, data: bytes) -> bool:\n        return self.ring.write(data)\n\nclass ShmConsumer:\n    def __init__(self, name: str):\n        self.shm = mm.SharedMemory(name=name, create=False)\n        self.ring = ByteRingBuffer(self.shm.buf, is_producer=False)\n\n    def read(self) -> Optional[bytes]:\n        return self.ring.read()\n```\n\n### 3.4 内存序保证\n\n**C++ Producer 写入**:\n\n```cpp\nbool ByteRingBuffer::Write(const void* data, uint32_t len) {\n  // [Step 1] 读本端索引 (relaxed, 无需屏障)\n  uint32_t head = header_->head;\n\n  // [Step 2] 获取对端索引前的屏障 (acquire)\n  std::atomic_thread_fence(std::memory_order_acquire);\n  uint32_t tail = header_->tail;\n\n  // [Step 3] 检查可写空间\n  uint32_t available = capacity_ - (head - tail);\n  uint32_t total = len + 4;\n  if (available < total) return false;\n\n  // [Step 4] 写数据 (memcpy, 非原子)\n  WriteRaw(head, &len, 4);           // length prefix\n  WriteRaw(head + 4, data, len);     // payload\n\n  // [Step 5] 写本端索引前的屏障 (release)\n  std::atomic_thread_fence(std::memory_order_release);\n\n  // [Step 6] 发信号给对端 (release 后)\n  header_->head = head + total;\n  return true;\n}\n```\n\n**Python Consumer 读取**:\n\n```python\ndef read(self) -> Optional[bytes]:\n    # Python GIL 已保证序列化，但为了对齐 C++ 的语义，\n    # 我们按照 acquire-release 的顺序读取\n\n    # [Step 1] 读本端索引 (own variable, no barrier)\n    tail = struct.unpack_from('<I', self.buf, 4)[0]\n\n    # [Step 2] Implicit barrier (GIL + aligned read is atomic on x86/ARM)\n    head = struct.unpack_from('<I', self.buf, 0)[0]\n\n    # ... 读消息 ...\n\n    # [Step 3] 写本端索引 (with implicit barrier)\n    struct.pack_into('<I', self.buf, 4, new_tail)\n```\n\n---\n\n## 4. 性能与可行性\n\n### 4.1 吞吐量基准 (x86-64, GCC 13, -O2)\n\n| 消息大小 | 吞吐量 (单线程) | 跨线程吞吐 | 延迟 (r/w) |\n|---------|----------------|---------|------------|\n| 64 B | 2.1 GB/s (35M msg/s) | 0.5 GB/s (9M msg/s) | 11 ns |\n| 1 KB | 3.2 GB/s (3.4M msg/s) | 3.9 GB/s (4.1M msg/s) | 52 ns |\n| 4 KB | 3.2 GB/s (830K msg/s) | 5.7 GB/s (1.5M msg/s) | 169 ns |\n| 6 MB (1080p) | 2.5 GB/s (423 FPS) | 4.4 GB/s (763 FPS) | - |\n\n**1080p 30 FPS 的可行性**:\n- 所需带宽: 1920×1080×3 × 30 = 180 MB/s\n- 跨线程能力: 4.4 GB/s\n- 占用比例: 180 / 4400 = **4%**\n- 估计 CPU 占用: **< 1%** (剩余容量充足)\n\n### 4.2 对标 socket 方案\n\n```\nTCP socket (loopback) 方案:\n  - 内核态/用户态切换 2 次\n  - 缓冲区拷贝 4 次\n  - 1080p 30 FPS: CPU 占用 30-50%\n\n共享内存方案:\n  - 无内核态切换\n  - 无数据拷贝\n  - 1080p 30 FPS: CPU 占用 < 1%\n```\n\n---\n\n## 5. 使用场景\n\n### 5.1 工业视觉 (1080p/4K 实时处理)\n\n```\n[GigE 相机]\n  ↓\n[C++ 驱动: 采集 + 预处理]\n  ↓ (共享内存, < 1% CPU)\n[Python: OpenCV + TensorFlow]\n  ↓\n[本地/云端推理]\n```\n\n**关键指标**: 30 FPS 无帧丢失，端到端延迟 < 50ms\n\n### 5.2 多模态传感器融合 (LiDAR + 相机 + 毫米波)\n\n```\n[LiDAR 驱动 (C++)] → 点云 (20Hz, 100KB)\n                    ↓\n                 [共享内存总线]\n                    ↓\n[相机驱动 (C++)] → 图像 (30Hz, 6MB) → [Python 融合算法]\n                    ↓\n[毫米波驱动 (C++)] → 雷达数据 (100Hz, 1KB)\n```\n\n多个生产者写入不同的消息到共享内存，Python 端按时间戳融合。需要 MPMC 环形缓冲 (超出本项目范围，可用 [cpp-ipc](https://github.com/mutouyun/cpp-ipc))。\n\n### 5.3 边缘计算网关\n\n```\n[传感器数据采集 (C++, 高频)]\n  ↓ (共享内存, 零拷贝)\n[本地推理 (Python + ONNX)]\n  ↓ (可选压缩、加密)\n[云端上传 (Python + 网络)]\n```\n\n数据面用共享内存 (高速, 低延迟)，控制面用 gRPC/socket (配置、统计)。\n\n---\n\n## 6. 跨语言协议约束\n\n为了确保 C++ 和 Python 的数据一致性，必须遵守以下约定:\n\n| 约束 | 原因 | 违反后果 |\n|------|------|--------|\n| **同一架构** (不跨字节序) | uint32_t LE 直接读写 | 数据损坏 |\n| **对齐 uint32 读写** | x86/ARM 对齐写原子 | 撕裂写 (partial write) |\n| **CPython (有 GIL)** | struct.pack_into 的原子性保证 | PyPy 下竞态 |\n| **SPSC 模式** | 只有一个生产者、一个消费者 | 竞态导致数据丢失 |\n| **同一物理机** | 共享内存仅限单机 | 网络通信需改方案 |\n\n**若需跨越这些约束**:\n- 多消费者 → [cpp-ipc](https://github.com/mutouyun/cpp-ipc) 的 MPMC\n- 网络通信 → zeromq / gRPC\n- PyPy 支持 → 加 `multiprocessing.Lock`\n- 跨字节序 → 显式序列化 (Protobuf 等)\n\n---\n\n## 7. 总结与对标\n\n**cpp_py_shmbuf 的定位**: 工业嵌入式中 **SPSC 场景的最优 IPC**，专注于零拷贝、零依赖、跨语言原生。\n\n| 特性 | cpp_py_shmbuf | Boost.Interprocess | cpp-ipc | Socket |\n|------|----------------|-------------------|---------|--------|\n| 零拷贝 | ✓ | ✓ | ✓ | ✗ (2-4 拷贝) |\n| C++ 依赖 | 无 | Boost (重) | 无 | POSIX |\n| Python 支持 | ✓ (原生) | ✗ | ✗ | ✓ |\n| SPSC | ✓ (优化) | ✓ | ✓ | - |\n| MPMC | ✗ | ✓ | ✓ | - |\n| 编译耗时 | 秒级 | 分钟级 | 秒级 | - |\n| 推荐场景 | SPSC 实时 | 通用共享内存 | MPMC 实时 | 远程通信 |\n\n**相关技术参考**:\n- [ringbuffer 设计](https://gitee.com/liudegui/ringbuffer) -- 单调递增索引、power-of-2 mask\n- [激光雷达 Pipeline](../architecture/lidar_pipeline_newosp/) -- 真零拷贝的 Handle 传递\n- [newosp 并发架构](../architecture/newosp_event_driven_architecture/) -- AsyncBus MPSC 消息总线\n",
      "ctime": "1771552484",
      "mtime": "1771552484",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/copilot_terminal_auto_approve.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857421362",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "VS Code Copilot 终端命令自动审批的安全配置",
      "brief_content": "通过分层白名单策略配置 VS Code Copilot 终端命令自动审批，平衡 AI 编程助手的效率与安全性。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 问题背景\n\nAI 编程助手频繁请求终端命令审批是效率瓶颈。VS Code 的 `chat.tools.terminal.autoApprove` 提供白名单机制，允许自动批准预定义的安全命令。\n\n## 安全模型\n\n采用白名单策略（默认拒绝），而非黑名单（无法穷举所有危险命令如 `curl | bash`、fork bomb 等）。\n\n## 分层配置策略\n\n完整配置文件可直接下载: [copilot_auto_approve_settings.jsonc](/tech-notes/files/copilot_auto_approve_settings.jsonc)\n\n配置分为五层，从宽松到严格：\n\n| 层级 | 匹配方式 | 覆盖范围 |\n|------|---------|---------|\n| 第一层 | Substring Match | 无副作用只读命令 (grep/awk/sed/make/git/cat 等) |\n| 第二层 | Regex (行首+管道链) | 文件管理/系统监控/编译器/脚本解释器 |\n| 第三层 | Regex | 本地脚本执行 (./build.sh) |\n| 第四层 | Regex | 安全删除 (构建产物/缓存/临时文件) |\n| 第五层 | 兜底拒绝 | 所有未匹配的 rm 操作 |\n\n### 关键正则说明\n\n第二层通用操作白名单，匹配行首或管道/逻辑与/分号之后的命令：\n\n```json\n\"/^(\\\\s*|.*[\\\\|\\\\&\\\\;]\\\\s*)(cd|ls|pwd|cp|mv|mkdir|find|gcc|g\\\\+\\\\+|python3?|node|docker|kubectl)(\\\\s+.*)?$/\": {\n  \"approve\": true,\n  \"matchCommandLine\": true\n}\n```\n\n- `^`：行首匹配\n- `.*[\\\\|\\\\&\\\\;]\\\\s*`：管道链中的命令\n- `\\\\b` 或 `(\\\\s+.*)?$`：防止误匹配（如 `rm` 不匹配 `rmdir`）\n\n第四层安全删除，仅允许构建产物和缓存：\n\n```json\n\"/^(\\\\s*|.*[\\\\|\\\\&\\\\;]\\\\s*)rm\\\\s+(-rf\\\\s+)?\n  (build.*|out|dist|target|node_modules|\\\\.cache|__pycache__|\n   .*\\\\.(o|a|so|tmp|log|bak)|CMakeCache\\\\.txt)(\\\\s.*)?$/\": {\n  \"approve\": true\n}\n```\n\n第五层兜底拒绝所有其他 rm：\n\n```json\n\"rm\": false\n```\n\n## 风险评估：看似安全实则危险\n\n| 命令 | 风险 | 缓解 |\n|------|------|------|\n| `curl URL \\| bash` | 下载并执行远程脚本 | 先下载审查再执行 |\n| `find -exec rm {}` | 匹配规则有误时删除重要文件 | 先预览匹配结果 |\n| `xargs cat` | 文件名含特殊字符导致注入 | 使用 `-print0 \\| xargs -0` |\n\n## 自定义扩展\n\n根据项目需要添加规则：\n\n```json\n{\n  // 项目构建脚本\n  \"^\\\\./scripts/(build|test|deploy)\\\\.sh$\": {},\n  // Docker (只读操作)\n  \"^docker\\\\s+(build|run|ps|logs|inspect)\\\\b\": {},\n  // Kubernetes (只读操作)\n  \"^kubectl\\\\s+(get|describe|logs)\\\\b\": {},\n  // 数据库 (只读查询)\n  \"^psql\\\\s+.*\\\\s+-c\\\\s+\\\"SELECT\\\\b\": {}\n}\n```\n\n禁止 `docker rm -f`、`kubectl delete`、`INSERT/UPDATE/DELETE/DROP` 等写操作，需人工确认。\n\n## Claude Code 对比\n\nClaude Code 使用 `.claude/settings.json` 的 `allowedTools` 控制工具类型（如 `Bash`），而非具体命令。粒度更粗，`Bash` 工具允许执行任意 shell 命令。建议生产环境移除 `Bash`，只保留 `Read`、`Grep` 等只读工具。\n\n## 安全建议\n\n- 沙箱隔离：在 devcontainer 中运行 AI Agent，限制网络出站\n- Prompt Injection 防御：AI 读取不受信任内容时可能被诱导执行危险操作，需静态分析 + 人工审核\n- 团队管理：将配置纳入 `.vscode/settings.json` 版本管理，定期审计规则\n",
      "ctime": "1771552487",
      "mtime": "1771552487",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/design_diagram_tool_selection.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857437746",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "设计文档画图工具选型",
      "brief_content": "从部署模式、版本管理、CI/CD 集成等工程实践维度对比 Mermaid、draw.io、飞书画图，给出轻量级场景与复杂高保真场景的选型建议。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 问题背景\n\n技术文档中的架构图、时序图、状态机图是设计沟通的核心载体。工具选型需要平衡以下矛盾：\n\n- 版本管理友好性 vs 视觉表现力\n- 本地编辑便利性 vs 团队协作效率\n- Markdown 集成度 vs 复杂图形能力\n- 开源免费 vs 商业支持\n\n本文从嵌入式系统开发团队的实际需求出发，对比主流工具的工程实践适配度。\n\n## 工具对比矩阵\n\n| 维度 | Mermaid | draw.io | 飞书画图 |\n|------|---------|---------|----------|\n| 部署模式 | 纯文本 (JS 渲染) | 桌面/Web/VSCode | 在线 SaaS |\n| 收费模式 | 开源免费 | 开源免费 | 企业版收费 |\n| 导出格式 | SVG/PNG (需工具链) | SVG/PNG/PDF | PNG (有水印) |\n| Markdown 集成 | 原生支持 (代码块) | 需嵌入图片 | 需嵌入图片 |\n| 版本管理 | Git 友好 (纯文本) | .drawio XML 可 diff | 不支持 |\n| 编辑方式 | 代码 | 拖拽 | 拖拽 |\n| 学习曲线 | 低 (语法简单) | 低 (所见即所得) | 低 |\n| 复杂图形能力 | 弱 (受语法限制) | 强 (自由布局) | 中 |\n| CI/CD 集成 | 易 (mermaid-cli) | 中 (headless 导出) | 不支持 |\n| 协作能力 | 代码审查 | 本地文件共享 | 实时协作 |\n\n## 核心差异分析\n\n### 1. CI/CD 自动化渲染\n\n**Mermaid 工具链集成**：\n\n```bash\nnpm install -g @mermaid-js/mermaid-cli\nmmdc -i docs/architecture.mmd -o docs/architecture.svg\n```\n\n**GitHub Actions 示例**：\n\n```yaml\n- name: Render Mermaid diagrams\n  uses: docker://minlag/mermaid-cli:latest\n  with:\n    args: -i docs/architecture.mmd -o docs/architecture.svg\n```\n\n### 2. 复杂图形表现力\n\n**Mermaid 的局限性**：\n\n- 自动布局算法无法精细控制节点位置\n- 不支持自定义图标和复杂样式\n- 大型状态机图（50+ 状态）布局混乱\n\n**适用场景**：流程图（< 20 节点）、时序图（< 10 参与者）、简单状态机（< 15 状态）\n\n**draw.io 的优势**：自由拖拽布局、像素级对齐、丰富的图标库（AWS/Azure/网络设备）、支持多页签。\n\n**典型案例**：嵌入式系统硬件连接图、复杂网络拓扑、高保真 UI 原型。\n\n### 3. 团队协作模式\n\n**代码审查驱动（Mermaid）**：图形变更通过 Pull Request 审查，评论直接关联到代码行，适合分布式团队异步协作。\n\n**实时协作驱动（飞书画图）**：多人同时编辑，冲突自动合并，适合头脑风暴和快速原型，但无法纳入代码仓库版本管理。\n\n**混合方案**：初期设计用飞书画图快速迭代 → 方案稳定后迁移到 draw.io 或 Mermaid → 最终版本提交到 Git 仓库。\n\n## 选型决策树\n\n```mermaid\ngraph TD\n    Start[需要画图] --> Q1{是否需要版本管理}\n    Q1 -->|是| Q2{图形复杂度}\n    Q1 -->|否| Feishu[飞书画图]\n\n    Q2 -->|简单| Q3{是否需要 Markdown 集成}\n    Q2 -->|复杂| Drawio[draw.io]\n\n    Q3 -->|是| Mermaid[Mermaid]\n    Q3 -->|否| Mermaid\n```\n\n## 实践建议\n\n### 1. 文档工程规范\n\n**目录结构**：\n\n```\ndocs/\n├── diagrams/\n│   ├── src/           # draw.io 源文件\n│   │   ├── architecture.drawio\n│   │   └── deployment.drawio\n│   ├── architecture.svg\n│   ├── deployment.svg\n│   └── state_machine.mmd\n├── design.md          # 嵌入 Mermaid 代码块\n└── README.md\n```\n\n**提交规范**：Mermaid 代码直接嵌入 Markdown；draw.io 源文件和导出文件同时提交；SVG 优先于 PNG（矢量可缩放）。\n\n### 2. 工具链配置\n\n**VSCode 插件推荐**：Mermaid Preview、Draw.io Integration\n\n**Pre-commit Hook**：\n\n```bash\n#!/bin/bash\n# .git/hooks/pre-commit\nfor mmd in $(git diff --cached --name-only --diff-filter=ACM | grep '\\.mmd$'); do\n    svg=\"${mmd%.mmd}.svg\"\n    mmdc -i \"$mmd\" -o \"$svg\"\n    git add \"$svg\"\ndone\n```\n\n### 3. 性能优化\n\n**Mermaid 大图优化**：拆分子图（subgraph）、使用 LR（左右布局）替代 TD（上下布局）、避免过多交叉连线。\n\n**draw.io 文件管理**：单个文件不超过 50 个对象、使用图层（Layers）组织复杂图形、定期清理未使用的样式和连接器。\n\n## 典型场景推荐\n\n| 场景 | 推荐工具 | 理由 |\n|------|----------|------|\n| 架构设计文档 | Mermaid | Markdown 原生集成，版本管理友好 |\n| 详细设计评审 | draw.io | 高保真表现，支持复杂布局 |\n| API 时序图 | Mermaid | 语法简洁，自动布局 |\n| 硬件连接图 | draw.io | 自定义图标，精确布局 |\n| 快速原型讨论 | 飞书画图 | 实时协作，无需本地工具 |\n\n## Mermaid 性能与限制\n\n大型图表（超过 50 个节点）渲染性能下降明显，建议拆分为多个子图。浏览器端渲染可能导致页面卡顿，CI 渲染为 SVG 可规避此问题。复杂布局（如交叉边）的自动排版效果有限，此时 draw.io 更合适。\n\n## 结论\n\n**轻量级场景（80% 的日常需求）**：\n\n- 首选 Mermaid\n- 优势：零部署成本，Git 友好，Markdown 原生支持\n- 限制：接受自动布局的不完美\n\n**复杂高保真场景（20% 的关键设计）**：\n\n- 首选 draw.io\n- 优势：专业表现力，自由布局，丰富图标库\n- 代价：需要额外的版本管理策略\n\n**不推荐飞书画图用于正式文档**：无法纳入代码仓库、导出格式受限（PNG 有水印）、仅适合临时讨论和头脑风暴。\n\n## 参考资源\n\n- Mermaid 官方文档: https://mermaid.js.org/\n- draw.io 桌面版: https://github.com/jgraph/drawio-desktop\n- mermaid-cli: https://github.com/mermaid-js/mermaid-cli\n",
      "ctime": "1771552490",
      "mtime": "1771552490",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/embedded_ssh_scp_automation.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853635594",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "告别手动输密码: 嵌入式 SSH/SCP 自动化方案",
      "brief_content": "嵌入式 Linux 开发中频繁需要在宿主机和目标板之间传输文件、远程调试。本文从实际需求出发，对比 Expect 脚本、sshpass、SSH 密钥认证三种自动化方案的实现与安全性，然后介绍 SSH ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [Linux Shell: 使用 Expect 自动化 SCP 和 SSH 连接的 Shell 脚本详解](https://blog.csdn.net/stallion5632/article/details/142489557)\n\n## 1. 问题场景\n\n嵌入式 Linux 开发的典型工作流：\n\n```\n宿主机 (x86 Ubuntu)                  目标板 (ARM Linux)\n┌──────────────────┐    SSH/SCP     ┌──────────────────┐\n│  交叉编译         │ ──────────→   │  /opt/app/        │\n│  cmake --build   │               │  运行、调试        │\n│  单元测试         │ ←────────── │  日志、core dump   │\n└──────────────────┘    SCP/rsync   └──────────────────┘\n```\n\n每次编译后需要将二进制文件 SCP 到目标板、SSH 登录重启服务、拉取日志回宿主机分析。手动输入密码的重复操作在日均数十次的开发迭代中严重影响效率。\n\n## 2. 方案一: Expect 自动化\n\nExpect 是基于 Tcl 的交互自动化工具，通过模式匹配和自动应答实现非交互式操作。\n\n### 2.1 SSH 自动登录\n\n```bash\n#!/bin/bash\n# ssh_auto.sh\nexport TERM=xterm-256color\nip='192.168.1.10'\npassword='your_password'\n\nssh-keygen -f \"$HOME/.ssh/known_hosts\" -R \"${ip}\" 2>/dev/null\n\nexpect -c '\n  set timeout 10\n  set password \"'\"$password\"'\"\n  spawn ssh -o StrictHostKeyChecking=no root@'\"$ip\"'\n  expect {\n    \"*yes/no*\" { send \"yes\\r\"; exp_continue }\n    \"*password:*\" { send \"$password\\r\"; exp_continue }\n    eof\n  }\n  interact\n'\n```\n\n### 2.2 SCP 上传/下载\n\n```bash\n# 上传\nexpect -c '\n  set timeout 30\n  set password \"'\"$password\"'\"\n  spawn scp -o StrictHostKeyChecking=no '\"$file\"' root@'\"$ip\"':'\"$dest\"'\n  expect {\n    \"*password:*\" { send \"$password\\r\"; exp_continue }\n    eof\n  }\n'\n\n# 下载\nexpect -c '\n  spawn scp -o StrictHostKeyChecking=no root@'\"$ip\"':'\"$remote_file\"' '\"$dest\"'\n  expect {\n    \"*password:*\" { send \"$password\\r\"; exp_continue }\n    eof\n  }\n'\n```\n\n### 2.3 局限性\n\n| 问题 | 说明 |\n|------|------|\n| 密码明文 | 硬编码在脚本中，任何有读权限的用户都能看到 |\n| 进程可见 | `ps aux` 可能显示命令行中的密码 |\n| 多层转义 | Bash + Tcl 双层引号处理，密码含特殊字符时极易出错 |\n| 无断点续传 | SCP 传输中断后必须重新开始 |\n| 绕过主机验证 | `StrictHostKeyChecking=no` 禁用了中间人攻击防护 |\n\nExpect 适合临时使用或密码无法更改的遗留系统。\n\n## 3. 方案二: sshpass\n\nsshpass 是专为 SSH 密码自动化设计的工具，比 Expect 更简洁：\n\n```bash\n# 安装\nsudo apt install sshpass\n\n# SSH 登录\nsshpass -p 'your_password' ssh root@192.168.1.10\n\n# SCP 上传/下载\nsshpass -p 'your_password' scp ./app root@192.168.1.10:/opt/\nsshpass -p 'your_password' scp root@192.168.1.10:/var/log/app.log ./\n```\n\n### 3.1 密码传递的安全层级\n\n| 方式 | 命令 | 安全性 | 风险 |\n|------|------|:------:|------|\n| `-p` 命令行 | `sshpass -p 'pwd' ssh ...` | 最低 | `ps` 和 shell history 可见 |\n| `-f` 文件 | `sshpass -f /path/to/pwfile ssh ...` | 中等 | 文件权限需设为 `0400` |\n| `-e` 环境变量 | `SSHPASS=pwd sshpass -e ssh ...` | 较高 | 用完后应 `unset SSHPASS` |\n\n推荐文件方式：\n\n```bash\necho 'your_password' > ~/.ssh/.board_pwd\nchmod 0400 ~/.ssh/.board_pwd\nsshpass -f ~/.ssh/.board_pwd ssh root@192.168.1.10\n```\n\n### 3.2 sshpass vs Expect\n\n| 维度 | sshpass | Expect |\n|------|:-------:|:------:|\n| SSH/SCP 专用 | 是 | 通用交互自动化 |\n| 代码量 | 一行命令 | 10+ 行脚本 |\n| 特殊字符处理 | 无需额外转义 | Bash + Tcl 双层转义 |\n| 复杂交互 (sudo, 菜单) | 不支持 | 支持 |\n\n仅自动化 SSH/SCP 密码输入时，sshpass 比 Expect 更简洁。\n\n## 4. 方案三: SSH 密钥认证 (推荐)\n\nSSH 公钥认证是自动化登录的工业标准方案。无密码传输、无明文存储、抗暴力破解。\n\n### 4.1 密钥生成与部署\n\n```bash\n# 1. 生成 Ed25519 密钥对\nssh-keygen -t ed25519 -C \"dev@workstation\" -f ~/.ssh/id_ed25519_board\n\n# 2. 部署公钥到目标板\nssh-copy-id -i ~/.ssh/id_ed25519_board.pub root@192.168.1.10\n\n# 3. 验证免密登录\nssh -i ~/.ssh/id_ed25519_board root@192.168.1.10\n```\n\n### 4.2 权限要求\n\n| 路径 | 权限 | 说明 |\n|------|:----:|------|\n| `~/.ssh/` | `700` | 仅所有者可读写执行 |\n| `~/.ssh/authorized_keys` | `600` | 仅所有者可读写 |\n| `~/.ssh/id_ed25519` (私钥) | `600` | 仅所有者可读写 |\n\n### 4.3 ssh-agent 管理密钥\n\n如果私钥设置了 passphrase，使用 ssh-agent 在会话期间缓存解密后的私钥：\n\n```bash\neval \"$(ssh-agent -s)\"\nssh-add ~/.ssh/id_ed25519_board\n# 后续所有 SSH/SCP 操作自动使用缓存的密钥\n```\n\n### 4.4 安全性对比\n\n| 维度 | Expect / sshpass | SSH 密钥 |\n|------|:----------------:|:--------:|\n| 密码/密钥传输 | 每次通过网络传输密码 | 仅传输公钥签名，私钥不离开宿主机 |\n| 暴力破解 | 可被穷举 | Ed25519: 2^128 安全级别 |\n| 中间人攻击 | `StrictHostKeyChecking=no` 禁用防护 | 主机密钥验证 + 密钥签名双重保护 |\n| 明文存储 | 脚本/文件中存在明文密码 | 私钥可加密 (passphrase) |\n| 凭证泄露影响 | 密码泄露 = 完全控制 | 公钥泄露无影响，私钥泄露可立即吊销 |\n\n## 5. SSH Config: 统一管理多台设备\n\n在 `~/.ssh/config` 中配置别名，避免记忆 IP 和参数：\n\n```ssh\n# ~/.ssh/config\n\nHost board\n    HostName 192.168.1.10\n    User root\n    IdentityFile ~/.ssh/id_ed25519_board\n    IdentitiesOnly yes\n    StrictHostKeyChecking accept-new\n\nHost lab-gateway\n    HostName 10.0.0.1\n    User engineer\n    IdentityFile ~/.ssh/id_ed25519_work\n\nHost lab-board\n    HostName 192.168.100.10\n    User root\n    ProxyJump lab-gateway\n    IdentityFile ~/.ssh/id_ed25519_board\n\nHost *\n    AddKeysToAgent yes\n    ServerAliveInterval 60\n    ServerAliveCountMax 3\n    ConnectTimeout 10\n```\n\n配置后的使用：\n\n```bash\nssh board                          # 自动查找 IP、用户名、密钥\nscp ./app board:/opt/              # SCP 上传\nssh lab-board                      # 通过跳板机登录实验室目标板\nscp ./firmware.bin lab-board:/tmp/ # 通过跳板机 SCP\n```\n\n### 5.1 关键配置项\n\n| 配置项 | 说明 |\n|--------|------|\n| `IdentitiesOnly yes` | 仅使用指定的密钥文件，不尝试 agent 中的其他密钥 |\n| `StrictHostKeyChecking accept-new` | 首次连接自动接受并保存主机密钥，后续连接验证 |\n| `ServerAliveInterval 60` | 每 60 秒发送心跳，防止 NAT 超时断连 |\n| `AddKeysToAgent yes` | 首次使用密钥时自动添加到 ssh-agent |\n\n### 5.2 ProxyJump 跳板机\n\nProxyJump 实现端到端加密的跳板连接，私钥始终留在宿主机上：\n\n```bash\n# 命令行方式\nssh -J engineer@10.0.0.1 root@192.168.100.10\nscp -J engineer@10.0.0.1 ./app root@192.168.100.10:/opt/\n\n# 多级跳板\nssh -J bastion1,bastion2 root@target\n```\n\n| 方式 | 私钥位置 | 安全风险 |\n|------|---------|---------|\n| `ProxyJump` | 始终在宿主机 | 跳板机无法窃取私钥 |\n| `ForwardAgent yes` | 转发到跳板机 | 跳板机 root 用户可劫持 agent |\n\n推荐使用 ProxyJump。\n\n## 6. rsync: 增量同步\n\nrsync 使用 delta 算法，仅传输变化的部分。\n\n### 6.1 基本用法\n\n```bash\n# 同步目录到目标板 (增量传输)\nrsync -avz --progress ./build/output/ board:/opt/app/\n\n# 从目标板拉取日志\nrsync -avz board:/var/log/app/ ./logs/\n\n# 通过跳板机同步\nrsync -avz ./build/output/ lab-board:/opt/app/\n```\n\n### 6.2 常用选项\n\n| 选项 | 说明 |\n|------|------|\n| `-a` | 归档模式: 递归、保留权限/时间戳/符号链接 |\n| `-v` | 显示传输过程 |\n| `-z` | 传输时压缩 |\n| `--progress` | 显示进度 |\n| `--delete` | 删除目标端多余的文件 (镜像同步) |\n| `--exclude '*.o'` | 排除中间文件 |\n\n### 6.3 性能对比\n\n| 场景 | SCP | rsync |\n|------|:---:|:-----:|\n| 首次传输 10 MB 二进制 | 1.5 s | 1.8 s (校验开销) |\n| 修改 1 KB 后重新传输 | 1.5 s (全量) | 0.3 s (增量) |\n| 传输中断后恢复 | 从头开始 | `--partial` 断点续传 |\n\n嵌入式迭代开发中，rsync 的增量传输可以将部署时间缩短 80% 以上。\n\n## 7. 实用脚本: 一键部署\n\n```bash\n#!/bin/bash\n# deploy.sh -- 编译并部署到目标板\n# 用法: ./deploy.sh [board|lab-board]\n\nset -euo pipefail\n\nTARGET=${1:-board}\nBUILD_DIR=\"./build\"\nREMOTE_DIR=\"/opt/app\"\nBINARY=\"my_app\"\n\necho \"=== Building ===\"\ncmake --build \"$BUILD_DIR\" --target \"$BINARY\" -j\"$(nproc)\"\n\necho \"=== Deploying to $TARGET ===\"\nrsync -avz --progress \\\n    --exclude '*.o' \\\n    --exclude 'CMakeFiles' \\\n    \"$BUILD_DIR/$BINARY\" \\\n    \"$TARGET:$REMOTE_DIR/\"\n\necho \"=== Restarting service ===\"\nssh \"$TARGET\" \"systemctl restart my_app || $REMOTE_DIR/$BINARY &\"\n\necho \"=== Done ===\"\n```\n\n这个脚本不包含任何密码、IP 地址或密钥路径，所有连接参数由 `~/.ssh/config` 管理。\n\n## 8. 方案选择决策树\n\n```\n需要自动化 SSH/SCP?\n│\n├── 能否部署密钥到目标板?\n│   ├── 是 → SSH 密钥认证 + SSH Config + rsync (推荐)\n│   └── 否 (权限/策略限制)\n│       ├── 能否安装 sshpass?\n│       │   ├── 是 → sshpass -f (文件方式)\n│       │   └── 否 → Expect 脚本 (最后手段)\n│       └── 需要复杂交互 (sudo/菜单)?\n│           └── 是 → Expect 脚本\n│\n├── 需要通过跳板机?\n│   └── SSH Config + ProxyJump\n│\n├── 频繁传输文件?\n│   ├── 目标板有 rsync → rsync -avz\n│   └── 目标板无 rsync → scp\n│\n└── 安全性要求高?\n    └── SSH 密钥 + StrictHostKeyChecking + 禁用 PasswordAuthentication\n```\n\n## 9. 安全加固\n\n生产环境建议：禁用目标板密码登录 (`/etc/ssh/sshd_config: PasswordAuthentication no`)、使用 Ed25519 密钥、启用主机密钥验证 (`StrictHostKeyChecking accept-new`)、为私钥设置 passphrase。\n",
      "ctime": "1771552493",
      "mtime": "1771552493",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/git_advanced_workflow_guide.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469554734",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "Git 高级工作流完全指南",
      "brief_content": "从分支管理到历史整理，从团队协作到高级技巧，系统掌握 Git 工作流中的关键操作：rebase、cherry-pick、bisect、reflog、worktree 等核心命令的实战应用与最佳实践。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 概述\n\nGit 作为分布式版本控制系统，提供了丰富的分支管理和历史整理工具。本文整合了 rebase、分支操作、Gerrit 工作流、交互式历史编辑等核心技术，并深入探讨 cherry-pick、bisect、reflog、worktree 等高级特性，帮助开发者构建清晰的提交历史和高效的团队协作流程。\n\n## 一、分支管理基础\n\n### 1.1 分支重命名\n\n```bash\ngit branch -m new_name\ngit branch -m old_name new_name\n\ngit push origin :old_name\ngit push origin -u new_name\ngit push origin new_name --force-with-lease\n```\n\n注意：远程分支重命名需通知团队成员，使用 `--force-with-lease` 比 `--force` 更安全。\n\n### 1.2 分支文件比较\n\n```bash\ngit diff main..feature -- path/to/file\ngit diff origin/main -- src/\ngit diff --name-only main..feature\n```\n\n## 二、历史整理与 Rebase\n\n### 2.1 Rebase vs Merge\n\n```mermaid\ngraph LR\n    A[main: C1] --> B[main: C2]\n    B --> C[main: C3]\n    A --> D[feature: C4]\n    D --> E[feature: C5]\n\n    subgraph \"Merge 结果\"\n    C --> F[Merge Commit]\n    E --> F\n    end\n\n    subgraph \"Rebase 结果\"\n    C --> G[C4']\n    G --> H[C5']\n    end\n```\n\n| 操作 | 提交历史 | 冲突解决 | 适用场景 |\n|------|---------|---------|---------|\n| Merge | 保留分支结构，产生合并提交 | 一次性解决所有冲突 | 公共分支合并、保留完整历史 |\n| Rebase | 线性历史，无合并提交 | 逐个提交解决冲突 | 私有分支整理、保持历史清晰 |\n\n### 2.2 标准 Rebase 流程\n\n```bash\ngit checkout feature\ngit rebase main\n\ngit add <resolved_files>\ngit rebase --continue\ngit rebase --abort\n\ngit push --force-with-lease origin feature\n```\n\n### 2.3 交互式 Rebase\n\n```bash\ngit rebase -i HEAD~3\n```\n\n编辑器中可用操作：pick（保留）、reword（修改信息）、edit（修改内容）、squash（合并）、fixup（合并且丢弃信息）、drop（删除）。\n\n### 2.4 Autosquash 工作流\n\n```bash\ngit commit --fixup=abc1234\ngit rebase -i --autosquash HEAD~5\ngit config --global rebase.autosquash true\n```\n\n## 三、团队协作与 Gerrit 工作流\n\n### 3.1 避免 Merge 提交的 Pull 策略\n\n```bash\ngit pull --rebase origin master\ngit config --global pull.rebase true\n\ngit add -u\ngit rebase --continue\ngit rebase --skip\n```\n\n### 3.2 Gerrit 工作流与分支覆盖\n\nGerrit 通过 `commit-msg` hook 为每个提交生成 Change-Id，用于跟踪同一逻辑变更的多个版本（Patch Set）。\n\n| 维度 | Change-Id | Commit SHA |\n|------|-----------|------------|\n| 生成时机 | commit-msg hook | Git 内部 |\n| 唯一性 | 逻辑变更唯一 | 提交快照唯一 |\n| 可变性 | 不变（除非手动修改） | 每次 amend/rebase 都变 |\n| 用途 | 跟踪同一变更的多个版本 | 标识具体提交 |\n\n| 命名空间 | 用途 | 结果 |\n|----------|------|------|\n| `refs/for/branch` | 提交到 Gerrit 评审 | 创建 Change，等待评审 |\n| `refs/heads/branch` | 直接推送到分支 | 绕过评审，需管理员权限 |\n\n**分支覆盖操作**\n\n```bash\ngit checkout branch_b\ngit reset --hard origin/branch_b\ngit checkout origin/branch_a -- .\ngit add .\ngit commit --amend\ngit push origin HEAD:refs/for/branch_b\n```\n\n**Gerrit 常见错误**\n\n| 错误 | 原因 | 解决方案 |\n|------|------|---------|\n| `missing Change-Id` | 未安装 commit-msg hook | `curl -Lo .git/hooks/commit-msg <gerrit>/tools/hooks/commit-msg && chmod +x` |\n| `no new changes` | Change-Id 与已有 Change 重复 | `git commit --amend` 修改 Change-Id 最后一位 |\n| `no common ancestry` | 分支无共同祖先 | `git merge --allow-unrelated-histories` |\n\n**git-review 简化推送**\n\n```bash\npip install git-review\ngit review\ngit review -d 12345\n```\n\n### 3.3 修改提交作者信息\n\n```bash\ngit commit --amend --author=\"Name <email@example.com>\"\n\ngit rebase -i HEAD~3\ngit commit --amend --author=\"...\"\ngit rebase --continue\n```\n\n## 四、高级技巧\n\n### 4.1 Cherry-pick：选择性应用提交\n\n```bash\ngit cherry-pick abc1234\ngit cherry-pick A..B\ngit cherry-pick A^..B\n\ngit add <resolved_files>\ngit cherry-pick --continue\ngit cherry-pick --abort\n```\n\n注意：Cherry-pick 会创建新的 commit SHA，可能导致重复提交问题。适用场景：hotfix 应用到多个版本分支、选择性合并功能。\n\n### 4.2 Bisect：二分查找 Bug\n\n```bash\ngit bisect start\ngit bisect bad\ngit bisect good v1.0.0\ngit bisect good\ngit bisect reset\n```\n\n**自动化 Bisect**\n\n```bash\ngit bisect start HEAD v1.0.0\ngit bisect run ./test_script.sh\n```\n\n### 4.3 Reflog：安全网与误操作恢复\n\n```bash\ngit reflog\ngit reflog show feature\n\ngit branch -D feature\ngit checkout -b feature abc1234\n\ngit reset --hard HEAD~3\ngit reset --hard HEAD@{1}\n```\n\n### 4.4 Stash：临时保存工作进度\n\n```bash\ngit stash\ngit stash push -m \"WIP: feature X\"\ngit stash push -u\ngit stash list\ngit stash apply\ngit stash pop\ngit stash drop stash@{0}\ngit stash clear\n```\n\n### 4.5 Worktree：多工作目录\n\n```bash\ngit worktree add ../project-feature feature-branch\ngit worktree add --detach ../project-test HEAD~5\ngit worktree list\ngit worktree remove ../project-feature\ngit worktree prune\n```\n\n使用场景：同时开发多个功能分支、在不同分支间快速切换测试、代码审查时保持当前工作不受影响、并行构建不同版本。\n\n### 4.6 子模块管理\n\n```bash\ngit clone --recurse-submodules https://github.com/user/repo.git\ngit submodule update --remote\n```\n\n### 4.7 SSH 权限切换\n\n```bash\ngit remote set-url origin git@github.com:user/repo.git\ngit remote set-url origin https://github.com/user/repo.git\n```\n\n## 五、常见错误与解决方案\n\n| 错误场景 | 症状 | 解决方案 |\n|---------|------|---------|\n| Rebase 冲突过多 | 需要逐个提交解决冲突 | 使用 `git rebase --abort` 后改用 `git merge` |\n| 强制推送覆盖他人提交 | `git push --force` 导致协作者丢失提交 | 使用 `--force-with-lease`，推送前先 `git fetch` |\n| Cherry-pick 重复提交 | 同一更改在多个分支有不同 SHA | 使用 `git merge` 或 `git rebase` 保持 SHA 一致 |\n| Detached HEAD 状态 | 切换到特定提交后无法提交 | `git checkout -b new-branch` 创建分支保存工作 |\n| Submodule 未初始化 | 子模块目录为空 | `git submodule update --init --recursive` |\n\n## 六、最佳实践\n\n### 6.1 提交历史管理\n\n- 原子提交：每个提交只做一件事，便于 revert 和 cherry-pick\n- 清晰的提交信息：遵循 Conventional Commits 规范（feat/fix/docs/refactor）\n- 定期 rebase：私有分支定期 rebase 到主分支，避免大规模冲突\n- 避免公共分支 rebase：已推送到远程的公共分支不要 rebase\n\n### 6.2 分支策略\n\n- 主分支保护：main/master 分支设置保护规则，禁止直接推送\n- 功能分支命名：使用 `feature/`, `bugfix/`, `hotfix/` 前缀\n- 短生命周期：功能分支尽快合并，避免长期分离\n\n### 6.3 团队协作\n\n- Code Review：使用 Pull Request 或 Gerrit 进行代码审查\n- CI/CD 集成：自动运行测试，确保提交质量\n- 沟通机制：强制推送前通知团队成员\n\n| 维度 | Gerrit | GitHub PR | GitLab MR |\n|------|--------|-----------|-----------|\n| 评审粒度 | 单个提交 | 分支级别 | 分支级别 |\n| 变更跟踪 | Change-Id | PR 编号 | MR 编号 |\n| 修改方式 | amend + force push | 新提交追加 | 新提交追加 |\n| 历史清洁度 | 高（强制 squash） | 中（可选 squash） | 中（可选 squash） |\n| 学习曲线 | 陡峭 | 平缓 | 平缓 |\n| 适用场景 | 大型企业、严格评审 | 开源社区、快速迭代 | DevOps 集成 |\n\n### 6.4 安全操作\n\n- 备份重要分支：执行危险操作前创建备份分支\n- 使用 --force-with-lease：替代 `--force`，避免覆盖他人提交\n- 熟悉 reflog：掌握误操作恢复方法\n\n**关键原则**\n\n1. 私有分支可以随意 rebase，公共分支谨慎操作\n2. 强制推送前务必确认无他人依赖\n3. 保持提交历史清晰，便于代码审查和问题追溯\n4. 善用工具（bisect、reflog、worktree）提升效率\n5. 团队协作需要明确的工作流规范和沟通机制\n",
      "ctime": "1771552496",
      "mtime": "1771552496",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/linux_dev_commands_cheatsheet.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469571118",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640385980137480
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "Linux 开发常用命令与脚本速查手册",
      "brief_content": "整合 Git 操作、文件管理、系统监控、网络诊断、Docker 容器、FFmpeg 处理、自动化脚本等常用命令与最佳实践，提供开箱即用的解决方案和改进建议。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## Git 操作速查\n\n### 清理工作区\n\n```bash\ngit clean -f          # 删除未跟踪文件\ngit clean -fd         # 删除未跟踪文件和目录\ngit clean -xfd        # 删除未跟踪文件、目录和被 .gitignore 忽略的文件\n```\n\n### 解决冲突的标准流程\n\n```bash\ngit stash             # 暂存本地修改\ngit pull              # 拉取远程更新\ngit stash pop         # 恢复本地修改（可能产生冲突）\n```\n\n### 克隆包含子模块的仓库\n\n```bash\ngit clone --recursive <repository_url>                # 一次性克隆主仓库和所有子模块\ngit submodule update --init --recursive               # 已克隆仓库后初始化子模块\n```\n\n### 撤销与还原\n\n```bash\ngit reset --hard <commit_hash>    # 重置到指定提交（危险操作，会丢失本地修改）\ngit checkout -- <file_path>       # 还原单个文件到最新提交状态\ngit checkout -- <directory_path>  # 还原整个目录\n```\n\n### 批量更新多个仓库（改进版）\n\n```bash\n#!/bin/bash\n# update_all_repos.sh - 批量更新当前目录下所有 Git 仓库\n\nset -euo pipefail\n\nLOG_FILE=\"update_repos_$(date +%Y%m%d_%H%M%S).log\"\nFAILED_REPOS=()\n\nmapfile -t GIT_DIRS < <(find \"$(pwd)\" -type d -name \".git\" -exec dirname {} \\;)\necho \"Found ${#GIT_DIRS[@]} repositories\" | tee -a \"$LOG_FILE\"\n\nfor repo in \"${GIT_DIRS[@]}\"; do\n    echo \"----------------------------------------\" | tee -a \"$LOG_FILE\"\n    echo \"Updating: $repo\" | tee -a \"$LOG_FILE\"\n    if cd \"$repo\"; then\n        if git reset --hard >> \"$LOG_FILE\" 2>&1 && git pull >> \"$LOG_FILE\" 2>&1; then\n            echo \"✓ Success\" | tee -a \"$LOG_FILE\"\n        else\n            echo \"✗ Failed\" | tee -a \"$LOG_FILE\"\n            FAILED_REPOS+=(\"$repo\")\n        fi\n    else\n        echo \"✗ Cannot access directory\" | tee -a \"$LOG_FILE\"\n        FAILED_REPOS+=(\"$repo\")\n    fi\ndone\n\necho \"========================================\" | tee -a \"$LOG_FILE\"\necho \"Update completed. Log saved to: $LOG_FILE\" | tee -a \"$LOG_FILE\"\nif [ ${#FAILED_REPOS[@]} -gt 0 ]; then\n    echo \"Failed repositories:\" | tee -a \"$LOG_FILE\"\n    printf '%s\\n' \"${FAILED_REPOS[@]}\" | tee -a \"$LOG_FILE\"\n    exit 1\nfi\n```\n\n并行执行版本:\n\n```bash\n#!/bin/bash\n# update_all_repos_parallel.sh - 并行更新仓库\n\nexport LOG_FILE=\"update_repos_$(date +%Y%m%d_%H%M%S).log\"\n\nupdate_repo() {\n    local repo=$1\n    {\n        echo \"Updating: $repo\"\n        cd \"$repo\" && git reset --hard && git pull && echo \"✓ $repo\" || echo \"✗ $repo\"\n    } >> \"$LOG_FILE\" 2>&1\n}\n\nexport -f update_repo\n\nfind \"$(pwd)\" -type d -name \".git\" -exec dirname {} \\; | \\\n    xargs -P 4 -I {} bash -c 'update_repo \"$@\"' _ {}\n\necho \"Update completed. Log: $LOG_FILE\"\n```\n\n## 文件与磁盘管理\n\n### 查找大文件\n\n```bash\nsudo find . -type f -size +100M -print0 | xargs -0 ls -lh    # 查找大于 100M 的文件\nsudo find . -type f -exec du -h {} + | sort -rh | head -n 20 # 按大小排序显示前 20 个文件\n```\n\n### 磁盘使用分析\n\n```bash\ndu -h --max-depth=1 | sort -rh    # 当前目录各子目录占用空间（按大小排序）\nsudo journalctl --vacuum-time=7d  # 清理 systemd journal 日志（保留最近 7 天）\n```\n\n### 文件搜索与过滤\n\n```bash\ngrep -r \"pattern\" --exclude-dir={.git,node_modules,build}    # grep 排除特定目录\nfind . -type f -name \"*.cpp\"                                  # 查找特定类型文件\nrsync -av --exclude='*.o' --exclude='*.a' src/ dest/         # 复制文件排除特定类型\n```\n\n## 系统信息与监控\n\n### 查看 GLIBC 和 GLIBCXX 版本\n\n```bash\nldd --version                                                      # 查看系统 GLIBC 版本\nstrings /usr/lib/x86_64-linux-gnu/libstdc++.so.6 | grep GLIBCXX  # 查看 GLIBCXX 版本\n```\n\n### CPU 信息查看\n\n```bash\nlscpu     # 查看 CPU 详细信息\nnproc     # 查看 CPU 核心数\nhtop      # 交互式 CPU 监控\n```\n\n### GPU 监控\n\n```bash\nwatch -n 1 nvidia-smi    # NVIDIA GPU 实时监控\nnvidia-smi --query-gpu=timestamp,name,utilization.gpu,memory.used,memory.total \\\n    --format=csv -l 5 >> gpu_monitor.log    # 持续记录 GPU 使用情况到日志\n```\n\n### 进程与端口管理\n\n```bash\nsudo lsof -i :8080                      # 查看占用特定端口的进程\nsudo kill -9 $(sudo lsof -t -i:8080)   # 杀死占用端口的进程\npstree -p                               # 查看进程树\n```\n\n## 网络诊断与测试\n\n### 网络连通性检测脚本（改进版）\n\n```bash\n#!/bin/bash\n# network_monitor.sh - 网络连通性监控与告警\n\nset -euo pipefail\n\nif [ $# -ne 2 ]; then\n    echo \"Usage: $0 <interface> <target_ip>\"\n    exit 1\nfi\n\nINTERFACE=$1\nTARGET_IP=$2\nLOG_DIR=\"/var/log/network_monitor\"\nLOG_FILE=\"$LOG_DIR/monitor_$(date +%Y%m%d).log\"\nALERT_FILE=\"$LOG_DIR/alerts.log\"\nFAIL_COUNT=0\nALERT_THRESHOLD=3\n\nmkdir -p \"$LOG_DIR\"\n\nlog_message() {\n    local level=$1\n    local message=$2\n    echo \"[$(date \"+%Y-%m-%d %H:%M:%S\")] [$level] $message\" | tee -a \"$LOG_FILE\"\n}\n\nsend_alert() {\n    echo \"[$(date)] ALERT: $1\" >> \"$ALERT_FILE\"\n}\n\ncheck_interface() {\n    if ethtool \"$INTERFACE\" 2>/dev/null | grep -q \"Link detected: yes\"; then\n        log_message \"INFO\" \"Interface $INTERFACE is UP\"\n        return 0\n    else\n        log_message \"ERROR\" \"Interface $INTERFACE is DOWN\"\n        return 1\n    fi\n}\n\ncheck_connectivity() {\n    if ping -c 1 -s 1024 -W 1 \"$TARGET_IP\" &>/dev/null; then\n        log_message \"INFO\" \"Ping $TARGET_IP success\"\n        FAIL_COUNT=0\n        return 0\n    else\n        log_message \"ERROR\" \"Ping $TARGET_IP failed\"\n        ((FAIL_COUNT++))\n        return 1\n    fi\n}\n\nlog_message \"INFO\" \"Network monitor started (interface=$INTERFACE, target=$TARGET_IP)\"\n\nwhile true; do\n    if ! check_interface || ! check_connectivity; then\n        if [ $FAIL_COUNT -ge $ALERT_THRESHOLD ]; then\n            send_alert \"Network connectivity lost for $FAIL_COUNT consecutive checks\"\n        fi\n    fi\n    sleep 2\ndone\n```\n\n### cURL 测试\n\n```bash\ncurl -X POST http://localhost:8080/api/test -H \"Content-Type: application/json\" -d '{\"key\":\"value\"}'    # 测试 HTTP 接口\ncurl -v http://example.com                                                                                # 显示详细请求信息\ncurl -w \"@curl-format.txt\" -o /dev/null -s http://example.com                                            # 测试响应时间\n```\n\n### Apache Bench 压力测试\n\n```bash\nab -n 10000 -c 100 http://localhost:8080/                                      # 100 并发，总共 10000 请求\nab -n 1000 -c 10 -p data.json -T application/json http://localhost:8080/api   # POST 请求压测\n```\n\n## Docker 容器管理\n\n### 容器批量操作\n\n```bash\ndocker stop $(docker ps -q)           # 停止所有运行中的容器\ndocker rm $(docker ps -aq)            # 删除所有已停止的容器\ndocker image prune -a                 # 删除所有未使用的镜像\ndocker system prune -a --volumes      # 清理所有未使用的资源\n```\n\n### 容器信息查询\n\n```bash\ndocker inspect -f '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}' <container_name>    # 查看容器 IP 地址\ndocker stats                                                                                      # 查看容器资源使用情况\ndocker logs --tail 100 -f <container_name>                                                        # 查看容器日志（最近 100 行）\n```\n\n## FFmpeg 多媒体处理\n\n### 流媒体推送\n\n```bash\nffmpeg -re -i input.mp4 -c copy -f flv rtmp://server/live/stream                                      # RTMP 推流\nffmpeg -re -i input.mp4 -c:v libx264 -preset ultrafast -c:a aac -f rtsp rtsp://server:8554/stream    # RTSP 推流\n```\n\n### 视频格式转换\n\n```bash\nffmpeg -i input.mp4 -c:v libx264 -preset medium -crf 23 -c:a aac -b:a 128k output.mp4    # MP4 转 H.264 编码\nffmpeg -i input.mp4 -vn -c:a copy output.aac                                              # 提取音频\nffprobe -v error -show_format -show_streams input.mp4                                     # 查看媒体文件详细信息\n```\n\n## 编译与构建\n\n### 多核编译\n\n```bash\nmake -j$(nproc)                       # 使用所有 CPU 核心编译\ncmake --build build -- -j$(nproc)    # CMake 构建时指定并行度\nmake -j$(($(nproc) / 2))             # 限制最大并行数（避免内存不足）\n```\n\n### 后台运行与日志\n\n```bash\nnohup ./long_running_task > output.log 2>&1 &    # nohup 后台运行并记录日志\njobs                                              # 查看后台任务\nbg                                                # 将暂停的任务转到后台继续运行\n```\n\n## 自动化脚本\n\n### 循环执行命令\n\n```bash\nwhile true; do ./your_command; sleep 5; done    # 每 5 秒执行一次\nwatch -n 5 ./your_command                       # 使用 watch 命令（更简洁）\n```\n\n### 用户管理\n\n```bash\nsudo adduser username                    # 创建新用户（交互式）\nsudo useradd -r -s /bin/false serviceuser    # 创建系统用户（非交互式）\nsudo usermod -aG sudo username           # 添加用户到 sudo 组\nsudo userdel -r username                 # 删除用户及其主目录\n```\n\n## 参考资源\n\n- [Advanced Bash-Scripting Guide](https://tldp.org/LDP/abs/html/)\n- [systemd.service — Service unit configuration](https://www.freedesktop.org/software/systemd/man/systemd.service.html)\n- [FFmpeg Documentation](https://ffmpeg.org/documentation.html)\n- [Docker CLI Reference](https://docs.docker.com/engine/reference/commandline/cli/)\n",
      "ctime": "1771552500",
      "mtime": "1771552500",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/vmware_sogou_focus_fix.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857454130",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "VMware 虚拟机搜狗输入法焦点跳转问题分析与解决",
      "brief_content": "深入分析 VMware 虚拟机中搜狗输入法候选词窗口导致鼠标焦点跳回宿主机的根本原因，涵盖 VMware 鼠标抓取机制、Fcitx 输入法框架特性、X11/Wayland 协议差异，提供分层排查方案和",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 问题现象\n\n在 VMware Workstation/Player 虚拟机（Ubuntu 22.04）中使用搜狗输入法时，候选词窗口弹出瞬间鼠标焦点跳回宿主机，需手动点击虚拟机窗口重新获取焦点。该问题在 Wayland 会话下尤为明显，严重影响输入体验。\n\n## 根本原因分析\n\n### VMware 鼠标抓取机制\n\nVMware 通过 `motionGrab` 和 `motionUngrab` 机制管理虚拟机与宿主机之间的鼠标控制权：\n\n1. **Grab 阶段**：鼠标进入虚拟机窗口后，VMware Tools 捕获鼠标事件，将宿主机鼠标坐标映射到虚拟机坐标系\n2. **Ungrab 触发条件**：\n   - 用户按下 `Ctrl+Alt` 组合键\n   - 检测到虚拟机内窗口焦点异常切换（如全屏应用、置顶窗口）\n   - 虚拟机内弹出系统级对话框（权限提示、通知）\n\n搜狗输入法候选词窗口触发 ungrab 的关键因素：\n\n- **置顶属性**：候选词窗口设置 `_NET_WM_STATE_ABOVE` 属性，覆盖在所有窗口之上\n- **窗口类型**：Fcitx 将候选词窗口标记为 `_NET_WM_WINDOW_TYPE_POPUP_MENU`，VMware Tools 误判为系统级弹窗\n- **焦点转移**：候选词窗口短暂获取输入焦点（用于处理数字键选词），触发 VMware 的 auto-ungrab 保护机制\n\n```mermaid\nsequenceDiagram\n    participant User as 用户\n    participant App as 应用窗口\n    participant Fcitx as Fcitx 框架\n    participant Sogou as 搜狗候选词窗口\n    participant VMware as VMware Tools\n    participant Host as 宿主机\n\n    User->>App: 输入触发\n    App->>Fcitx: 请求输入法\n    Fcitx->>Sogou: 创建候选词窗口 (POPUP_MENU + ABOVE)\n    Sogou->>VMware: 窗口映射事件 (MapNotify)\n    VMware->>VMware: 检测置顶窗口 + 焦点转移\n    VMware->>Host: 触发 auto-ungrab\n    Host->>User: 鼠标焦点返回宿主机\n    User->>App: 手动点击重新获取焦点\n```\n\n### Fcitx 框架特性\n\nFcitx（Flexible Input Method Framework）是 Linux 下主流输入法框架，搜狗输入法基于 Fcitx4 构建：\n\n| 特性 | Fcitx4 | Fcitx5 | IBus |\n|------|--------|--------|------|\n| 候选词窗口实现 | 独立 X11 窗口 (置顶) | Wayland subsurface / X11 窗口 | GTK/Qt 嵌入式组件 |\n| 窗口管理器交互 | 直接操作 X11 属性 | 通过 Wayland 协议 | 依赖工具包事件循环 |\n| 焦点管理 | 主动抢占输入焦点 | 协议协商焦点 | 被动接收焦点 |\n| VMware 兼容性 | 差（触发 ungrab） | 中等（Wayland 下改善） | 好（无置顶窗口） |\n\n搜狗输入法的候选词窗口通过 `XSetWindowAttributes` 设置 `override_redirect = True`，绕过窗口管理器直接控制窗口位置和层级，这种激进策略在物理机上提升响应速度，但在虚拟化环境中与 VMware 的窗口监控逻辑冲突。\n\n### Wayland vs X11 协议差异\n\n| 维度 | X11 | Wayland |\n|------|-----|---------|\n| 窗口层级控制 | 客户端可直接设置 `_NET_WM_STATE_ABOVE` | 由 compositor 统一管理，客户端无法强制置顶 |\n| 焦点管理 | 客户端可通过 `XSetInputFocus` 抢占焦点 | 焦点由 compositor 分配，客户端只能请求 |\n| 输入法协议 | XIM / Fcitx 自定义协议 | `zwp_input_method_v2` 标准协议 |\n| VMware Tools 集成 | 完整支持（直接监听 X11 事件） | 部分支持（依赖 XWayland 桥接） |\n\n在 Wayland 会话下，搜狗输入法通过 XWayland 运行，候选词窗口的置顶请求需经过 Wayland compositor 转换，增加了与 VMware Tools 的交互复杂度。X11 会话下 VMware Tools 可直接监听窗口事件，误判概率反而降低。\n\n## 解决方案（按优先级排序）\n\n### 方案 1：禁用 VMware 自动释放机制（推荐）\n\n修改 VMware 配置文件，禁用 auto-ungrab 功能：\n\n**步骤 1**：编辑全局配置（所有虚拟机生效）\n\n```bash\n# VMware Workstation\nsudo vim /etc/vmware/config\n\n# VMware Player\nsudo vim ~/.vmware/preferences\n```\n\n添加以下配置：\n\n```ini\npref.motionGrab = \"FALSE\"\npref.motionUngrab = \"FALSE\"\n```\n\n**步骤 2**：编辑虚拟机配置（单个虚拟机生效）\n\n```bash\n# 关闭虚拟机后编辑 .vmx 文件\nvim ~/vmware/Ubuntu22.04/Ubuntu22.04.vmx\n```\n\n添加以下配置：\n\n```vmx\nmks.gamingMouse.policy = \"gaming\"\nmks.gamingMouse.ungrabOnEscape = \"FALSE\"\n```\n\n**配置说明**：\n\n- `motionGrab/motionUngrab`：控制鼠标抓取/释放行为\n- `gamingMouse.policy`：启用游戏模式，减少自动释放触发\n- `ungrabOnEscape`：禁用 ESC 键释放（可选，避免误触）\n\n**适用场景**：\n\n- 虚拟机主要用于开发，不需要频繁切换宿主机\n- 可接受通过 `Ctrl+Alt` 手动释放鼠标\n\n### 方案 2：切换到 X11 会话\n\n在登录界面选择 \"Ubuntu on Xorg\" 会话：\n\n```bash\n# 查看当前会话类型\necho $XDG_SESSION_TYPE\n\n# 安装 X11 会话（如未安装）\nsudo apt install xorg\n\n# 注销后在登录界面右下角选择 \"Ubuntu on Xorg\"\n```\n\n**原理**：X11 下 VMware Tools 对窗口事件的监听更精确，搜狗候选词窗口的置顶行为不会触发误判。\n\n**权衡**：\n\n- 优点：无需修改配置，兼容性最好\n- 缺点：放弃 Wayland 的安全性和性能优势（HiDPI、触摸手势）\n\n## 参考资料\n\n- [VMware KB: Mouse and Keyboard Release Behavior](https://kb.vmware.com/s/article/1033)\n- [Fcitx Wiki: Wayland Support](https://fcitx-im.org/wiki/Wayland)\n- [freedesktop.org: Input Method Protocol](https://wayland.app/protocols/input-method-unstable-v2)\n",
      "ctime": "1771552503",
      "mtime": "1771552503",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "misc/vscode_remote_dev_setup.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357794842",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 C++ 远程开发环境: 从 SSH 到交叉调试",
      "brief_content": "面向嵌入式 ARM-Linux 开发者的 VS Code 远程开发完整方案。涵盖 SSH 免密登录与连接复用、clangd 替代 gtags 实现精确代码索引、gdbserver 交叉调试配置、以及网",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原始案例: [VSCode C++ 开发效率优化](https://blog.csdn.net/stallion5632/article/details/141927756)\n\n---\n\n## 1. SSH 连接配置\n\n### 1.1 密钥生成与部署\n\n```bash\n# 生成 Ed25519 密钥 (比 RSA 更短更安全)\nssh-keygen -t ed25519 -C \"dev@embedded\"\n\n# 部署公钥到目标板\nssh-copy-id -i ~/.ssh/id_ed25519.pub user@arm-board\n```\n\n若目标板不支持 `ssh-copy-id`:\n\n```bash\ncat ~/.ssh/id_ed25519.pub | ssh user@arm-board \"mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >> ~/.ssh/authorized_keys && chmod 600 ~/.ssh/authorized_keys\"\n```\n\n### 1.2 SSH Config\n\n```ssh-config\n# 嵌入式开发板\nHost arm-board\n    HostName 192.168.1.100\n    User root\n    IdentityFile ~/.ssh/id_ed25519\n    ServerAliveInterval 60\n    ServerAliveCountMax 3\n\n# 通过跳板机访问内网开发板\nHost arm-internal\n    HostName 10.0.0.50\n    User root\n    ProxyJump jumphost\n```\n\n### 1.3 连接复用 (ControlMaster)\n\n首次连接建立主连接，后续复用 socket，减少握手开销:\n\n```ssh-config\nHost *\n    ControlMaster auto\n    ControlPath ~/.ssh/sockets/%r@%h:%p\n    ControlPersist 10m\n```\n\nVS Code Remote-SSH 有时与 ControlMaster 冲突导致连接挂起，遇到问题时对特定 Host 禁用:\n\n```ssh-config\nHost arm-board\n    ControlMaster no\n```\n\n---\n\n## 2. 代码索引: clangd 替代 gtags\n\n原文推荐 gtags + GNU Global 加速\"查找所有引用\"。现在 clangd 是更好的方案:\n\n| 维度 | gtags | clangd |\n|------|-------|--------|\n| 索引精度 | 文本匹配，宏展开后误报 | 编译器前端，语义级精确 |\n| 跳转准确性 | 模板/重载经常跳错 | 完全理解 C++ 语义 |\n| 增量更新 | 需手动 `global -u` | 保存文件自动更新 |\n| 交叉编译 | 不理解 `-I` `-D` | 读取 `compile_commands.json` |\n\n### 2.1 生成 compile_commands.json\n\n```bash\n# CMake 项目\ncmake -B build -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\n\n# Makefile 项目 (用 bear 包装)\nsudo apt install bear\nbear -- make -j$(nproc)\n```\n\n### 2.2 交叉编译场景\n\n项目根目录创建 `.clangd`:\n\n```yaml\nCompileFlags:\n  Add:\n    - --target=aarch64-linux-gnu\n    - -I/opt/toolchain/aarch64-linux-gnu/include\n  Remove:\n    - -mfpu=*\n    - -march=*\n```\n\n### 2.3 VS Code 配置\n\n安装 clangd 扩展，禁用微软 C/C++ 扩展的 IntelliSense 避免冲突:\n\n```json\n{\n    \"clangd.arguments\": [\n        \"--background-index\",\n        \"--clang-tidy\",\n        \"--header-insertion=iwyu\",\n        \"-j=4\"\n    ],\n    \"C_Cpp.intelliSenseEngine\": \"disabled\"\n}\n```\n\n使用 clangd 后不再需要手动维护 `c_cpp_properties.json` 中的 `includePath`，所有信息从 `compile_commands.json` 自动获取。\n\n---\n\n## 3. 远程调试: gdbserver 交叉调试\n\n编译在宿主机 (x86)，运行在目标板 (ARM)，通过 gdbserver 交叉调试。\n\n### 3.1 launch.json\n\n```json\n{\n    \"version\": \"0.2.0\",\n    \"configurations\": [{\n        \"name\": \"Remote ARM Debug\",\n        \"type\": \"cppdbg\",\n        \"request\": \"launch\",\n        \"program\": \"${workspaceFolder}/build/your_program\",\n        \"MIMode\": \"gdb\",\n        \"miDebuggerPath\": \"/opt/toolchain/bin/aarch64-linux-gnu-gdb\",\n        \"miDebuggerServerAddress\": \"192.168.1.100:2345\",\n        \"setupCommands\": [\n            {\n                \"text\": \"-enable-pretty-printing\",\n                \"ignoreFailures\": true\n            },\n            {\n                \"text\": \"-gdb-set sysroot /opt/toolchain/aarch64-linux-gnu/libc\",\n                \"ignoreFailures\": false\n            }\n        ],\n        \"preLaunchTask\": \"deploy-and-start-gdbserver\"\n    }]\n}\n```\n\n关键参数:\n- `miDebuggerPath`: 交叉工具链中的 GDB，不是宿主机的 `/usr/bin/gdb`\n- `sysroot`: 让 GDB 找到目标板共享库符号，否则无法解析 libc 调用栈\n\n### 3.2 自动部署 + 启动 gdbserver\n\n`.vscode/tasks.json`:\n\n```json\n{\n    \"version\": \"2.0.0\",\n    \"tasks\": [{\n        \"label\": \"deploy-and-start-gdbserver\",\n        \"type\": \"shell\",\n        \"command\": \"bash\",\n        \"args\": [\"-c\", \"scp build/your_program root@192.168.1.100:/tmp/ && ssh root@192.168.1.100 'killall -q gdbserver; gdbserver :2345 /tmp/your_program' &\"],\n        \"isBackground\": true,\n        \"problemMatcher\": []\n    }]\n}\n```\n\n按 F5 即可: scp 部署 → 启动 gdbserver → GDB 连接 → 断点调试。\n\n### 3.3 替代方案: Remote-SSH 直连\n\n目标板资源充足 (RAM > 512MB) 时，直接用 Remote-SSH 连接目标板，调试配置简化为本地调试，省去交叉调试的复杂性。\n\n---\n\n## 4. 文件共享\n\n| 方案 | 性能 | 复杂度 | 适用场景 |\n|------|------|--------|---------|\n| VMware HGFS | 高 | 低 | 虚拟机开发 |\n| NFS | 高 | 中 | 局域网共享 |\n| SSHFS | 中 | 低 | 远程临时访问 |\n| rsync + inotify | 高 | 中 | 交叉编译同步 |\n\n嵌入式交叉编译推荐 rsync 自动同步:\n\n```bash\ninotifywait -mr build/ -e close_write | while read path action file; do\n    rsync -avz build/your_program root@192.168.1.100:/tmp/\ndone\n```\n\nVMware 共享文件夹挂载:\n\n```bash\nsudo vmhgfs-fuse .host:/ /mnt/hgfs -o allow_other,uid=$(id -u),gid=$(id -g)\n```\n\n---\n\n## 5. 网络受限环境\n\n### 5.1 VS Code Server 离线安装\n\n```bash\n# 有网络的机器上下载\ncommit_id=$(code --version | head -2 | tail -1)\ncurl -L \"https://update.code.visualstudio.com/commit:${commit_id}/server-linux-arm64/stable\" -o vscode-server.tar.gz\n\n# 传输到目标板\nscp vscode-server.tar.gz root@arm-board:~\nssh root@arm-board \"mkdir -p ~/.vscode-server/bin/${commit_id} && tar -xzf ~/vscode-server.tar.gz -C ~/.vscode-server/bin/${commit_id} --strip-components=1\"\n```\n\nURL 架构: `server-linux-x64` (x86) / `server-linux-arm64` (ARM64) / `server-linux-armhf` (ARM32)。\n\n### 5.2 扩展离线安装\n\n从 [marketplace](https://marketplace.visualstudio.com/) 下载 `.vsix`，scp 传输后远程安装:\n\n```bash\nscp clangd-0.1.29.vsix root@arm-board:~/\nssh root@arm-board \"code-server --install-extension ~/clangd-0.1.29.vsix\"\n```\n\n---\n\n## 6. SSH 安全加固\n\n生产环境嵌入式设备 (`/etc/ssh/sshd_config`):\n\n```\nPasswordAuthentication no\nPubkeyAuthentication yes\nAllowUsers developer\nPermitRootLogin prohibit-password\nMaxAuthTries 3\n```\n\n---\n\n## 参考资源\n\n- [VS Code Remote-SSH](https://code.visualstudio.com/docs/remote/ssh) | [clangd](https://clangd.llvm.org/installation) | [GDB Remote Debugging](https://sourceware.org/gdb/current/onlinedocs/gdb.html/Remote-Debugging.html) | [OpenSSH](https://man.openbsd.org/ssh_config)\n",
      "ctime": "1771552506",
      "mtime": "1771552506",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/c_hsm_data_driven_framework.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469587502",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C 语言层次状态机框架: 从过程驱动到数据驱动的重构实践",
      "brief_content": "以 state_machine 框架的重构为案例，展示如何将一个过程驱动的 C 语言状态机改造为数据驱动的层次状态机 (HSM)。涵盖转换表替代 switch-case、LCA 算法消除递归、用户缓冲",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [QPC 框架深度解析: Active Object 模型与层次状态机](../qpc_active_object_hsm/) -- QP/C 的 HSM 双实现策略 (QHsm/QMsm)\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- C++17 模板化 HSM 的现代实现\n> - [行为树 Tick 机制深度解析](../behavior_tree_tick_mechanism/) -- BT 与 HSM 互补的架构实践\n\n状态机是嵌入式系统中最常用的设计模式之一。但随着状态数量增长和层级嵌套加深，传统的 switch-case 实现会变得难以维护。本文以 [state_machine](https://gitee.com/liudegui/state_machine) 框架为例，展示如何将过程驱动的状态机改造为数据驱动的层次状态机 (HSM)。\n\n原始版本来自 [misje/stateMachine](https://github.com/misje/stateMachine)，RT-Thread 社区有一个维护版本。本文基于对两者的重构，重点在于**数据驱动设计**和 **MISRA C:2012 合规**。\n\n## 1. 过程驱动 vs 数据驱动\n\n### 1.1 过程驱动的问题\n\n传统 switch-case 状态机将事件处理逻辑分散在各个 handler 中:\n\n```c\n// 过程驱动: 逻辑分散，修改一个状态需要读懂整个 handler\nvoid state_idle_handler(sm_t *sm, event_t evt) {\n    switch (evt) {\n        case EVT_START:\n            if (can_start()) {          // guard 混在逻辑中\n                do_prepare();           // action 混在逻辑中\n                sm->state = STATE_RUNNING;\n                running_entry(sm);      // 手动调用 entry\n            }\n            break;\n        case EVT_POWER_OFF:\n            idle_exit(sm);              // 手动调用 exit\n            sm->state = STATE_OFF;\n            break;\n        // ... 每个事件一个 case\n    }\n}\n```\n\n问题清单:\n\n| 问题 | 影响 |\n|------|------|\n| 转换逻辑分散在每个 handler 中 | 无法一眼看出完整的状态转换图 |\n| entry/exit 需要手动调用 | 遗漏导致资源泄漏或状态不一致 |\n| guard 条件嵌入 if-else | 复用困难，测试困难 |\n| 新增状态需修改多处 handler | 维护成本随状态数线性增长 |\n| 无层级支持 | 公共事件处理需要每个状态重复实现 |\n\n### 1.2 数据驱动的设计\n\n数据驱动的核心思想: **用数据 (转换表) 描述状态机行为，用通用引擎执行转换逻辑**。\n\n```c\n// 数据驱动: 转换表集中描述所有规则\nconst SM_Transition T_Idle[] = {\n    // 事件          目标状态        守卫           动作          类型\n    {EV_START_TASK, &STATE_Running, can_start_task, NULL,         SM_TRANSITION_EXTERNAL},\n    {EV_POWER_OFF,  &STATE_Off,     NULL,           on_power_off, SM_TRANSITION_EXTERNAL},\n};\n\nstatic const SM_State STATE_Idle = {\n    .parent         = &STATE_On,     // 父状态\n    .entryAction    = entry_Idle,    // 入口动作\n    .exitAction     = NULL,          // 出口动作\n    .transitions    = T_Idle,        // 转换表\n    .numTransitions = 2,\n    .name           = \"Idle\"\n};\n```\n\n开发者只需填写转换表，`SM_Dispatch()` 统一查表执行。entry/exit 动作由引擎自动调用，不会遗漏。\n\n## 2. 框架数据结构\n\n### 2.1 事件\n\n```c\nstruct SM_Event {\n    uint32_t  id;       // 事件标识\n    void     *context;  // 事件附带数据 (可选)\n};\n```\n\n### 2.2 转换规则\n\n```c\ntypedef enum {\n    SM_TRANSITION_EXTERNAL,  // 外部转换: 执行 exit/entry\n    SM_TRANSITION_INTERNAL   // 内部转换: 仅执行 action，不变状态\n} SM_TransitionType;\n\nstruct SM_Transition {\n    uint32_t          eventId;  // 触发事件\n    const SM_State   *target;   // 目标状态 (内部转换时忽略)\n    SM_GuardFn        guard;    // 守卫条件 (NULL = 无条件)\n    SM_ActionFn       action;   // 转换动作 (NULL = 无动作)\n    SM_TransitionType type;     // 转换类型\n};\n```\n\n外部转换与内部转换的区别:\n\n| 转换类型 | exit 动作 | action | entry 动作 | 状态变化 |\n|---------|----------|--------|-----------|---------|\n| EXTERNAL | 执行 | 执行 | 执行 | 变化 |\n| INTERNAL | 不执行 | 执行 | 不执行 | 不变 |\n\n内部转换适合\"在当前状态下执行某个动作但不离开\"的场景，如更新计数器、记录日志。\n\n### 2.3 状态\n\n```c\nstruct SM_State {\n    const SM_State      *parent;         // 父状态 (NULL = 顶层)\n    SM_ActionFn          entryAction;    // 入口动作\n    SM_ActionFn          exitAction;     // 出口动作\n    const SM_Transition *transitions;    // 转换表\n    size_t               numTransitions; // 转换数量\n    const char          *name;           // 调试名称\n};\n```\n\n`parent` 指针构成层级树。子状态未处理的事件会**冒泡**到父状态。\n\n### 2.4 状态机实例\n\n```c\nstruct SM_StateMachine {\n    const SM_State  *currentState;       // 当前活动状态\n    const SM_State  *initialState;       // 初始状态 (用于 Reset)\n    void            *userData;           // 用户数据指针\n    SM_ActionFn      unhandledEventHook; // 未处理事件钩子\n    const SM_State **entryPathBuffer;    // 用户提供的路径缓冲区\n    uint8_t          bufferSize;         // 缓冲区大小\n};\n```\n\n`entryPathBuffer` 由用户提供而非内部 malloc，这是嵌入式友好的关键设计 (见第 4 节)。\n\n## 3. 核心算法: LCA 与事件分发\n\n### 3.1 事件分发: 查表 + 冒泡\n\n`SM_Dispatch()` 的核心逻辑:\n\n```c\nbool SM_Dispatch(SM_StateMachine *sm, const SM_Event *event) {\n    bool is_handled = false;\n    const SM_State *state_iter = sm->currentState;\n\n    // 从当前状态开始，逐级向上查找能处理该事件的状态\n    while ((state_iter != NULL) && (!is_handled)) {\n        for (size_t i = 0; i < state_iter->numTransitions; ++i) {\n            const SM_Transition *t = &state_iter->transitions[i];\n            if (t->eventId == event->id) {\n                // 检查守卫条件\n                bool guard_passed = (t->guard == NULL) || t->guard(sm, event);\n                if (guard_passed) {\n                    if (t->action != NULL) { t->action(sm, event); }\n                    if (t->type == SM_TRANSITION_EXTERNAL) {\n                        perform_transition(sm, t->target, event);\n                    }\n                    is_handled = true;\n                    break;\n                }\n            }\n        }\n        if (!is_handled) {\n            state_iter = state_iter->parent;  // 冒泡到父状态\n        }\n    }\n\n    if (!is_handled && (sm->unhandledEventHook != NULL)) {\n        sm->unhandledEventHook(sm, event);\n    }\n    return is_handled;\n}\n```\n\n事件冒泡机制使得公共事件只需在父状态中处理一次。例如 `EV_POWER_OFF` 定义在 `STATE_On` 的转换表中，其子状态 `Idle` 和 `Running` 无需重复定义。\n\n### 3.2 LCA 算法: O(N) 最低共同祖先\n\n层次状态机的转换需要找到源状态和目标状态的**最低共同祖先 (LCA)**，以确定需要执行哪些 exit/entry 动作。\n\n```c\nstatic const SM_State *find_lca(const SM_State *s1, const SM_State *s2) {\n    if ((s1 == NULL) || (s2 == NULL)) { return NULL; }\n\n    const SM_State *p1 = s1;\n    const SM_State *p2 = s2;\n    uint8_t depth1 = get_state_depth(p1);\n    uint8_t depth2 = get_state_depth(p2);\n\n    // 对齐到相同深度\n    while (depth1 > depth2) { p1 = p1->parent; depth1--; }\n    while (depth2 > depth1) { p2 = p2->parent; depth2--; }\n\n    // 同步上移直到相遇\n    while (p1 != p2) { p1 = p1->parent; p2 = p2->parent; }\n\n    return p1;\n}\n```\n\n这是经典的\"双指针对齐\"LCA 算法，时间复杂度 O(N)，N 为最大层级深度。无递归，栈安全。\n\n### 3.3 转换执行\n\n找到 LCA 后，转换执行分三步:\n\n```c\nstatic void perform_transition(SM_StateMachine *sm,\n                                const SM_State *target,\n                                const SM_Event *event) {\n    const SM_State *source = sm->currentState;\n    const SM_State *lca = find_lca(source, target);\n\n    // Step 1: 从源状态向上执行 exit，直到 LCA\n    const SM_State *exit_iter = source;\n    while ((exit_iter != NULL) && (exit_iter != lca)) {\n        if (exit_iter->exitAction != NULL) {\n            exit_iter->exitAction(sm, event);\n        }\n        exit_iter = exit_iter->parent;\n    }\n\n    // Step 2: 记录从 LCA 到目标状态的 entry 路径 (逆序)\n    uint8_t path_idx = 0;\n    const SM_State *entry_iter = target;\n    while ((entry_iter != NULL) && (entry_iter != lca)) {\n        sm->entryPathBuffer[path_idx++] = entry_iter;\n        entry_iter = entry_iter->parent;\n    }\n\n    // Step 3: 更新当前状态，正序执行 entry\n    sm->currentState = target;\n    for (int8_t i = (int8_t)path_idx - 1; i >= 0; --i) {\n        if (sm->entryPathBuffer[i]->entryAction != NULL) {\n            sm->entryPathBuffer[i]->entryAction(sm, event);\n        }\n    }\n}\n```\n\n以从 `Running` 转换到 `Off` 为例:\n\n```\n状态树:         转换路径:\n    [root]\n    /    \\\n  On      Off     1. exit Running\n  / \\             2. exit On\nIdle Running      3. entry Off\n```\n\nLCA 为 root (NULL)，exit 路径: Running -> On，entry 路径: Off。\n\n## 4. 重构改进点\n\n### 4.1 消除递归\n\n原始版本的 entry 动作通过递归调用实现 (从 LCA 递归到目标状态)。在深层级嵌套时存在栈溢出风险。\n\n重构方案: 用 `entryPathBuffer` 数组记录 entry 路径，然后**迭代**执行:\n\n```c\n// 先记录路径 (逆序): target -> ... -> LCA 的下一级\n// 再反向遍历执行 entry (正序): LCA 的下一级 -> ... -> target\nfor (int8_t i = (int8_t)path_idx - 1; i >= 0; --i) {\n    if (sm->entryPathBuffer[i]->entryAction != NULL) {\n        sm->entryPathBuffer[i]->entryAction(sm, event);\n    }\n}\n```\n\n### 4.2 用户提供缓冲区\n\n`entryPathBuffer` 由用户在栈上分配并传入，而非框架内部 malloc:\n\n```c\n#define MAX_STATE_DEPTH 8\nconst SM_State *path_buffer[MAX_STATE_DEPTH];\n\nSM_Init(&sm, &STATE_Off, path_buffer, MAX_STATE_DEPTH, &app_data, NULL);\n```\n\n优势:\n\n- 零堆分配，适合禁止 malloc 的嵌入式环境\n- 缓冲区大小由用户根据实际层级深度决定\n- `SM_ASSERT(path_idx < sm->bufferSize)` 在运行时检测溢出\n\n### 4.3 外部/内部转换区分\n\n原始版本不区分外部和内部转换。重构后通过 `SM_TransitionType` 显式区分:\n\n```c\n// 外部转换: 退出当前状态，进入目标状态 (即使目标是自己)\n{EV_RESET, &STATE_Idle, NULL, on_reset, SM_TRANSITION_EXTERNAL}\n\n// 内部转换: 仅执行 action，不触发 exit/entry\n{EV_HEARTBEAT, NULL, NULL, update_counter, SM_TRANSITION_INTERNAL}\n```\n\n外部自转换 (`source == target`) 会执行 exit 再 entry，适合需要\"重新初始化当前状态\"的场景。\n\n### 4.4 守卫条件\n\n转换表支持 `guard` 函数指针，返回 `true` 时转换才会执行:\n\n```c\nbool can_start_task(SM_StateMachine *sm, const SM_Event *event) {\n    AppData *data = (AppData *)sm->userData;\n    return data->tasks_completed < 3;\n}\n\nconst SM_Transition T_Idle[] = {\n    {EV_START_TASK, &STATE_Running, can_start_task, NULL, SM_TRANSITION_EXTERNAL},\n};\n```\n\n守卫条件将\"是否可以转换\"的判断从 handler 逻辑中剥离出来，成为独立的、可测试的函数。\n\n### 4.5 MISRA C:2012 合规\n\n- 单一返回点: 所有函数通过局部变量累积结果，在函数末尾统一返回\n- 无递归: entry 路径用迭代实现\n- 显式类型: `uint8_t`, `uint32_t`, `size_t`\n- 断言检查: 入参通过 `SM_ASSERT()` 验证\n- 可配置宏: `SM_ASSERT` 和 `SM_LOG_DEBUG` 可映射到用户平台\n\n## 5. 使用示例\n\n### 5.1 设备电源管理\n\n一个典型的层次状态机: `Off` 和 `On` 为顶层状态，`Idle` 和 `Running` 为 `On` 的子状态。\n\n```mermaid\nstateDiagram-v2\n    [*] --> Off\n    Off --> Idle : EV_POWER_ON\n    state On {\n        [*] --> Idle\n        Idle --> Running : EV_START_TASK [can_start]\n        Running --> Idle : EV_TASK_COMPLETE\n    }\n    On --> Off : EV_POWER_OFF\n```\n\n完整实现:\n\n```c\n#include \"state_machine.h\"\n#include <stdio.h>\n\n// 事件定义\nenum { EV_POWER_ON, EV_START_TASK, EV_TASK_COMPLETE, EV_POWER_OFF };\n\n// 用户数据\ntypedef struct { int tasks_completed; } AppData;\n\n// 状态前向声明\nstatic const SM_State STATE_Off, STATE_On, STATE_Idle, STATE_Running;\n\n// 动作函数\nvoid entry_On(SM_StateMachine *sm, const SM_Event *e)  { printf(\"  Entry -> On\\n\"); }\nvoid exit_On(SM_StateMachine *sm, const SM_Event *e)   { printf(\"  Exit  -> On\\n\"); }\nvoid entry_Idle(SM_StateMachine *sm, const SM_Event *e){ printf(\"    Entry -> Idle\\n\"); }\nvoid entry_Running(SM_StateMachine *sm, const SM_Event *e) {\n    printf(\"    Entry -> Running\\n\");\n}\nvoid exit_Running(SM_StateMachine *sm, const SM_Event *e) {\n    printf(\"    Exit  -> Running\\n\");\n}\nvoid on_power_off(SM_StateMachine *sm, const SM_Event *e) {\n    printf(\"  Action: Shutting down\\n\");\n}\nvoid on_task_done(SM_StateMachine *sm, const SM_Event *e) {\n    AppData *d = (AppData *)sm->userData;\n    d->tasks_completed++;\n    printf(\"  Action: Task done. Total: %d\\n\", d->tasks_completed);\n}\n\n// 守卫函数\nbool can_start_task(SM_StateMachine *sm, const SM_Event *e) {\n    AppData *d = (AppData *)sm->userData;\n    return d->tasks_completed < 3;\n}\n\n// 转换表\nconst SM_Transition T_Off[] = {\n    {EV_POWER_ON, &STATE_Idle, NULL, NULL, SM_TRANSITION_EXTERNAL}\n};\nconst SM_Transition T_On[] = {\n    {EV_POWER_OFF, &STATE_Off, NULL, on_power_off, SM_TRANSITION_EXTERNAL}\n};\nconst SM_Transition T_Idle[] = {\n    {EV_START_TASK, &STATE_Running, can_start_task, NULL, SM_TRANSITION_EXTERNAL}\n};\nconst SM_Transition T_Running[] = {\n    {EV_TASK_COMPLETE, &STATE_Idle, NULL, on_task_done, SM_TRANSITION_EXTERNAL}\n};\n\n// 状态定义\nstatic const SM_State STATE_Off = {\n    NULL, NULL, NULL, T_Off, 1, \"Off\"\n};\nstatic const SM_State STATE_On = {\n    NULL, entry_On, exit_On, T_On, 1, \"On\"\n};\nstatic const SM_State STATE_Idle = {\n    &STATE_On, entry_Idle, NULL, T_Idle, 1, \"Idle\"\n};\nstatic const SM_State STATE_Running = {\n    &STATE_On, entry_Running, exit_Running, T_Running, 1, \"Running\"\n};\n\nint main(void) {\n    SM_StateMachine sm;\n    AppData data = {0};\n    const SM_State *path[8];\n\n    SM_Init(&sm, &STATE_Off, path, 8, &data, NULL);\n    printf(\"State: %s\\n\", SM_GetCurrentStateName(&sm));\n\n    SM_Event ev;\n\n    // Power on -> enters On, then Idle\n    ev = (SM_Event){EV_POWER_ON, NULL};\n    SM_Dispatch(&sm, &ev);\n    printf(\"State: %s, In On? %s\\n\",\n           SM_GetCurrentStateName(&sm),\n           SM_IsInState(&sm, &STATE_On) ? \"Yes\" : \"No\");\n\n    // Start task -> Idle to Running (guard: tasks < 3)\n    ev = (SM_Event){EV_START_TASK, NULL};\n    SM_Dispatch(&sm, &ev);\n    printf(\"State: %s\\n\", SM_GetCurrentStateName(&sm));\n\n    // Task complete -> Running to Idle\n    ev = (SM_Event){EV_TASK_COMPLETE, NULL};\n    SM_Dispatch(&sm, &ev);\n    printf(\"State: %s\\n\", SM_GetCurrentStateName(&sm));\n\n    // Power off -> exits On, enters Off (handled by parent state On)\n    ev = (SM_Event){EV_POWER_OFF, NULL};\n    SM_Dispatch(&sm, &ev);\n    printf(\"State: %s\\n\", SM_GetCurrentStateName(&sm));\n\n    return 0;\n}\n```\n\n输出:\n\n```\nState: Off\n  Entry -> On\n    Entry -> Idle\nState: Idle, In On? Yes\n    Entry -> Running\nState: Running\n    Exit  -> Running\n    Entry -> Idle\nState: Idle\n  Action: Shutting down\n  Exit  -> On\nState: Off\n```\n\n注意第 5 行: `EV_POWER_OFF` 在 `Idle` 的转换表中不存在，但通过冒泡机制由父状态 `On` 处理。退出路径依次执行 `exit_On`，无需在 `Idle` 中重复定义。\n\n### 5.2 与 RT-Thread 集成\n\n在 RTOS 环境中，状态机通常运行在独立线程中，通过消息队列接收事件:\n\n```c\nstatic void sm_thread_entry(void *param) {\n    SM_Init(&sm, &STATE_Off, path_buffer, MAX_STATE_DEPTH, &app_data, NULL);\n\n    while (1) {\n        SM_Event event;\n        rt_err_t ret = rt_mq_recv(sm_mq, &event, sizeof(SM_Event),\n                                   RT_WAITING_FOREVER);\n        if (ret == RT_EOK) {\n            SM_Dispatch(&sm, &event);\n        }\n    }\n}\n\n// 任意线程/ISR 中投递事件\nrt_err_t post_event(uint32_t id, void *ctx) {\n    SM_Event ev = {id, ctx};\n    return rt_mq_send(sm_mq, &ev, sizeof(SM_Event));\n}\n```\n\n消息队列实现了事件生产者和状态机引擎的解耦。ISR 中产生的事件通过 `rt_mq_send()` 投递，状态机线程在安全的上下文中处理。\n\n## 6. 前后对比\n\n| 维度 | 原始版本 (过程驱动) | 重构版本 (数据驱动) |\n|------|-------------------|-------------------|\n| 事件处理 | switch-case 分散在 handler 中 | 转换表集中描述 |\n| entry/exit | 手动调用，容易遗漏 | 引擎自动执行 |\n| guard 条件 | 嵌入 if-else | 独立函数指针 |\n| 转换类型 | 不区分 | 外部/内部显式区分 |\n| LCA 算法 | 递归实现 | 迭代实现，O(N) |\n| 内存分配 | 内部分配 | 用户提供缓冲区，零堆分配 |\n| 代码规范 | 无 | MISRA C:2012 |\n| 未处理事件 | 静默忽略 | unhandledEventHook 回调 |\n\n## 7. 适用场景\n\n- **设备生命周期管理**: 电源状态 (Off/Standby/Active)、初始化序列\n- **通信协议栈**: 连接状态 (Disconnected/Connecting/Connected/Error)\n- **业务流程**: 订单状态、审批流程\n- **需要层级抽象的场合**: 用父状态封装公共行为，子状态只关注差异\n\n不适合:\n\n- 状态极少 (2-3 个) 且无层级需求 -- switch-case 更直接\n- 需要并发状态 (正交区域) -- 本框架不支持\n\n## 8. 项目信息\n\n- 仓库: [Gitee](https://gitee.com/liudegui/state_machine)\n- 原始作者: [misje/stateMachine](https://github.com/misje/stateMachine)\n- RT-Thread 社区版本: [RT-Thread-Mirror/state_machine](https://gitee.com/RT-Thread-Mirror/state_machine)\n- 许可证: MIT\n",
      "ctime": "1771552509",
      "mtime": "1771552509",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/c_oop_nginx_modular_architecture.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038388262",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809641167680962568
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C 语言如何实现面向对象: Nginx 模块化架构源码解读",
      "brief_content": "面向对象编程（OOP）以其强大的封装、继承和多态特性，成为构建复杂系统的关键范式。然而，在研读 Nginx 和 Linux 内核等高性能 C 语言项目源码时，可以观察到一个显著现象：尽管 C 语言原生",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 面向对象编程（OOP）以其强大的封装、继承和多态特性，成为构建复杂系统的关键范式。然而，在研读 Nginx 和 Linux 内核等高性能 C 语言项目源码时，可以观察到一个显著现象：尽管 C 语言原生不支持 OOP，但其设计架构中却深刻体现了面向对象的思想精髓。\n\n## 1. \"对象\"与\"类\"的映射：C++ 与 C 的结构化对比\n\n在 C++ 环境中，`class` 关键字将数据（成员变量）和行为（成员函数）紧密封装。\n\n```cpp\n// C++: \"类\" 将数据和行为封装在一起\nclass ModuleA : public Module {\nprivate:\n    struct Config { int max_conns = 0; };\n    Config config_;\npublic:\n    void parseCommand(...) override { ... }\n    void handleRequest() override { ... }\n};\n```\n\nC 语言中缺乏原生的类定义和访问控制，但通过编程约定能够有效地实现信息封装和抽象：\n\n1. 数据聚合 (Struct): 使用 `struct` 类型完成数据成员的聚合。\n2. 行为绑定 (Function Pointer): 通过全局函数实现操作方法，并将该 `struct` 的指针作为首个参数传入，模拟 C++ 中的 `this` 指针。\n\n```c\n// C: \"对象\" = struct(状态) + 全局函数(方法)\n\ntypedef struct {\n    int max_conns;\n} ModuleAConf;\n\nint set_max_conns(void* conf, char* value) {\n    ModuleAConf* ac = (ModuleAConf*)conf;\n    ac->max_conns = atoi(value);\n    return 0;\n}\n\nint moduleA_handler(void* conf) {\n    ModuleAConf* ac = (ModuleAConf*)conf;\n    printf(\"ModuleA: Handling request, max_conns=%d\\n\", ac->max_conns);\n    return 0;\n}\n```\n\n## 2. 多态机制的手动实现：虚函数表（vtable）的 C 语言化\n\n多态性是 OOP 的核心特征，在 C++ 中依赖于基类中的 `virtual` 关键字和运行时自动查找的虚函数表（vtable）。\n\n```cpp\n// C++: 基类和虚函数\nclass Module {\npublic:\n    virtual ~Module() = default;\n    virtual void handleRequest() = 0;\n};\n\nvoid Server::processRequest() {\n    for (const auto& module : modules_) {\n        module->handleRequest(); // 运行时自动分派\n    }\n}\n```\n\nNginx 采用手动函数分派（Manual Function Dispatch）机制，通过定义一个包含函数指针的结构体，作为模块的统一接口抽象：\n\n```c\n// C: \"接口抽象\" / \"基类\" = 包含函数指针的 struct\ntypedef struct {\n    char* name;\n    void* (*create_conf)(void);\n    int (*init_module)(void* conf);\n    int (*handler)(void* conf);\n} ngx_module_t;\n```\n\n每个具体模块的实现，即是用其自身的函数地址来填充此结构体：\n\n```c\nngx_module_t moduleA = {\n    \"moduleA\",\n    create_moduleA_conf,\n    NULL,\n    moduleA_handler\n};\n\n// 核心引擎通过函数指针实现统一调用\nmoduleA.handler(confA);\nmoduleB.handler(confB);\n```\n\n## 3. 其他面向对象设计借鉴\n\n### 3.1 数据驱动与开闭原则：配置指令的解耦\n\n```c\ntypedef struct {\n    char* name;\n    int (*set)(void* conf, char* value);\n} ngx_command_t;\n\nngx_command_t moduleA_commands[] = {\n    { \"max_conns\", set_max_conns },\n    { NULL, NULL }\n};\n```\n\n核心解析器仅需遍历此数组，找到匹配的指令名称，并调用相应的 `set` 函数指针。新增配置项无需修改核心解析逻辑。\n\n### 3.2 资源生命周期管理：内存池机制\n\nNginx 引入了内存池（`ngx_pool_t`）机制。该机制将与特定上下文（如一个请求或一个连接）相关的所有内存分配集中管理。当上下文生命周期结束时，核心引擎只需销毁整个内存池，而无需逐个 `free` 内存块。\n\n## 4. 继承模拟与请求处理链\n\n### 4.1 模拟继承与多层配置上下文\n\nNginx HTTP 配置的层级结构（Main -> Server -> Location）体现了继承和组合思想。\n\n```c\ntypedef struct {\n    void* (*create_main_conf)(ngx_conf_t *cf);\n    void* (*create_srv_conf)(ngx_conf_t *cf);\n    void* (*create_loc_conf)(ngx_conf_t *cf);\n    char* (*merge_srv_conf)(ngx_conf_t *cf, void *prev, void *conf);\n    char* (*merge_loc_conf)(ngx_conf_t *cf, void *prev, void *conf);\n} ngx_http_module_t;\n```\n\n配置合并函数实现继承行为：\n\n```c\nchar* ngx_example_merge_loc_conf(ngx_conf_t *cf, void *prev, void *conf) {\n    ngx_example_loc_conf_t *parent = prev;\n    ngx_example_loc_conf_t *child = conf;\n\n    ngx_conf_merge_value(child->timeout, parent->timeout, 60000);\n    ngx_conf_merge_str_value(child->root_path, parent->root_path, \"html\");\n\n    return NGX_CONF_OK;\n}\n```\n\n### 4.2 请求处理流水线（责任链模式）\n\nNginx 将 HTTP 请求处理流程划分为一系列有序的阶段（Phase），每个阶段可以注册多个模块处理器。\n\n```c\n#define NGX_HTTP_POST_READ_PHASE        0\n#define NGX_HTTP_SERVER_REWRITE_PHASE   1\n#define NGX_HTTP_CONTENT_PHASE          7\n#define NGX_HTTP_LOG_PHASE             10\n\ntypedef ngx_int_t (*ngx_http_handler_pt)(ngx_http_request_t *r);\n\ntypedef struct {\n    ngx_http_handler_pt handler;\n    ngx_uint_t          next;\n} ngx_http_phase_handler_t;\n```\n\n核心引擎驱动责任链（简化伪代码，实际 Nginx 使用 checker 函数和以 `r->phase_handler` 为索引的扁平 handler 数组）：\n\n```c\nngx_int_t ngx_http_process_request(ngx_http_request_t *r) {\n    ngx_uint_t i;\n    for (i = 0; i < NGX_HTTP_LAST_PHASE; i++) {\n        ngx_http_phase_handler_t *ph = ngx_http_top_filter_handlers[i];\n        while (ph->handler) {\n            ngx_int_t rc = ph->handler(r);\n            if (rc == NGX_OK) {\n                return NGX_OK;  // request handled, stop chain\n            } else if (rc == NGX_DECLINED) {\n                ph++;  // handler declined, try next\n            } else {\n                return rc;  // error or async\n            }\n        }\n    }\n    return NGX_OK;\n}\n```\n\n通过阶段划分和函数指针数组的机制，Nginx 实现了高度解耦的请求处理流水线，完美地符合责任链模式的设计要求。\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/154867716)\n\n---\n",
      "ctime": "1771552513",
      "mtime": "1771552513",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/c_strategy_state_pattern.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357811226",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C 语言设计模式实战: 策略模式与状态模式的本质差异",
      "brief_content": "在没有面向对象语法的 C 语言中，策略模式和状态模式都通过函数指针表 (vtable) 模拟多态，代码结构几乎一致。本文从设计意图出发，用通用示例 (传感器滤波、通信协议状态机) 剖析二者的本质差异，",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "在 C 语言中，策略模式和状态模式的实现代码高度相似 -- 都是\"上下文持有函数指针表\"。这种结构相似性常导致混淆: 既然代码一样，为什么要区分两种模式？\n\n答案在于**谁控制切换、何时切换**。这个设计意图的差异决定了系统的架构走向。\n\n## 1. C 语言中的多态模拟\n\nC 语言没有 class、virtual、继承，但可以通过结构体 + 函数指针精确模拟多态:\n\n```c\n// 接口: 函数指针表 (等价于 C++ vtable)\ntypedef struct {\n    int (*open)(void *ctx);\n    int (*read)(void *ctx, void *buf, size_t len);\n    int (*write)(void *ctx, const void *buf, size_t len);\n    void (*close)(void *ctx);\n} io_ops_t;\n\n// 上下文: 持有接口指针 + 实例数据\ntypedef struct {\n    const io_ops_t *ops;    // 指向当前实现的 vtable\n    void *priv;             // 具体实现的私有数据\n} io_ctx_t;\n\n// 调用方: 通过接口调用，不关心具体实现\nstatic inline int io_read(io_ctx_t *io, void *buf, size_t len) {\n    return io->ops->read(io->priv, buf, len);\n}\n```\n\n这个框架既可以用于策略模式，也可以用于状态模式。区别不在结构，而在语义。\n\n## 2. 策略模式: 关注\"如何做\"\n\n### 2.1 核心特征\n\n- **目的**: 封装一组可互换的算法，让调用方在运行时选择\n- **决策权在外部**: 上下文被动执行指定策略，自身不做选择\n- **算法平行**: 各策略之间无依赖、无先后顺序\n\n### 2.2 示例: 传感器数据滤波\n\n一个传感器模块需要支持多种滤波算法 (均值、中值、卡尔曼)，由上层根据场景选择:\n\n```c\n/* ---------- 策略接口 ---------- */\ntypedef struct {\n    void (*init)(void *state);\n    float (*filter)(void *state, float raw);\n    void (*reset)(void *state);\n} filter_strategy_t;\n\n/* ---------- 上下文 ---------- */\ntypedef struct {\n    const filter_strategy_t *strategy;  // 当前滤波策略\n    void *state;                        // 策略私有状态\n    float last_output;\n} sensor_ctx_t;\n\n/* ---------- 均值滤波实现 ---------- */\n#define MEAN_WINDOW  8\n\ntypedef struct {\n    float buf[MEAN_WINDOW];\n    uint8_t idx;\n    uint8_t count;\n} mean_state_t;\n\nstatic void mean_init(void *s) {\n    mean_state_t *st = (mean_state_t *)s;\n    memset(st, 0, sizeof(*st));\n}\n\nstatic float mean_filter(void *s, float raw) {\n    mean_state_t *st = (mean_state_t *)s;\n    st->buf[st->idx] = raw;\n    st->idx = (st->idx + 1) % MEAN_WINDOW;\n    if (st->count < MEAN_WINDOW) { st->count++; }\n\n    float sum = 0.0f;\n    for (uint8_t i = 0; i < st->count; i++) { sum += st->buf[i]; }\n    return sum / (float)st->count;\n}\n\nstatic void mean_reset(void *s) { mean_init(s); }\n\nstatic const filter_strategy_t g_mean_strategy = {\n    .init   = mean_init,\n    .filter = mean_filter,\n    .reset  = mean_reset,\n};\n\n/* ---------- 中值滤波实现 ---------- */\n#define MEDIAN_WINDOW  5\n\ntypedef struct {\n    float buf[MEDIAN_WINDOW];\n    uint8_t idx;\n    uint8_t count;\n} median_state_t;\n\nstatic void median_init(void *s) {\n    median_state_t *st = (median_state_t *)s;\n    memset(st, 0, sizeof(*st));\n}\n\nstatic float median_filter(void *s, float raw) {\n    median_state_t *st = (median_state_t *)s;\n    st->buf[st->idx] = raw;\n    st->idx = (st->idx + 1) % MEDIAN_WINDOW;\n    if (st->count < MEDIAN_WINDOW) { st->count++; }\n\n    // 排序副本取中值\n    float tmp[MEDIAN_WINDOW];\n    memcpy(tmp, st->buf, sizeof(float) * st->count);\n    for (uint8_t i = 0; i < st->count - 1; i++) {\n        for (uint8_t j = i + 1; j < st->count; j++) {\n            if (tmp[j] < tmp[i]) {\n                float t = tmp[i]; tmp[i] = tmp[j]; tmp[j] = t;\n            }\n        }\n    }\n    return tmp[st->count / 2];\n}\n\nstatic void median_reset(void *s) { median_init(s); }\n\nstatic const filter_strategy_t g_median_strategy = {\n    .init   = median_init,\n    .filter = median_filter,\n    .reset  = median_reset,\n};\n```\n\n使用方式 -- 调用方主动选择策略:\n\n```c\nstatic mean_state_t   s_mean_state;\nstatic median_state_t s_median_state;\n\n// 外部决策: 根据场景选择策略\nvoid sensor_set_filter(sensor_ctx_t *ctx, filter_mode_t mode) {\n    switch (mode) {\n        case FILTER_MEAN:\n            ctx->strategy = &g_mean_strategy;\n            ctx->state    = &s_mean_state;\n            break;\n        case FILTER_MEDIAN:\n            ctx->strategy = &g_median_strategy;\n            ctx->state    = &s_median_state;\n            break;\n    }\n    ctx->strategy->init(ctx->state);\n}\n\n// 使用: 上下文不关心具体算法\nfloat sensor_process(sensor_ctx_t *ctx, float raw) {\n    ctx->last_output = ctx->strategy->filter(ctx->state, raw);\n    return ctx->last_output;\n}\n```\n\n关键点: `sensor_set_filter()` 由外部调用，传感器模块自身不会主动切换策略。决策权完全在调用方。\n\n### 2.3 策略模式类图\n\n```mermaid\nclassDiagram\n    class sensor_ctx_t {\n        +filter_strategy_t_ptr strategy\n        +void_ptr state\n        +process(raw)\n    }\n    class filter_strategy_t {\n        <<interface>>\n        +init(state)\n        +filter(state, raw)\n        +reset(state)\n    }\n    class mean_filter\n    class median_filter\n    class kalman_filter\n\n    sensor_ctx_t --> filter_strategy_t\n    filter_strategy_t <|.. mean_filter\n    filter_strategy_t <|.. median_filter\n    filter_strategy_t <|.. kalman_filter\n```\n\n## 3. 状态模式: 关注\"何时做、做什么\"\n\n### 3.1 核心特征\n\n- **目的**: 将对象行为与内部状态绑定，行为随状态自动切换\n- **决策权在内部**: 状态自身决定何时、向哪个状态转换\n- **状态有序**: 转换路径由状态机管理，不可任意跳转\n\n### 3.2 示例: 通信协议状态机\n\n一个串口通信模块需要管理连接生命周期 (断开 -> 连接中 -> 就绪 -> 错误):\n\n```c\n/* ---------- 事件与状态前向声明 ---------- */\ntypedef enum {\n    EVT_CONNECT,        // 发起连接\n    EVT_ACK_RECEIVED,   // 收到应答\n    EVT_TIMEOUT,        // 超时\n    EVT_DATA_RECEIVED,  // 收到数据\n    EVT_ERROR,          // 错误\n    EVT_DISCONNECT,     // 断开\n    EVT_RESET,          // 重置\n} comm_event_t;\n\ntypedef struct comm_ctx comm_ctx_t;\n\n/* ---------- 状态接口 ---------- */\ntypedef struct {\n    const char *name;\n    void (*on_enter)(comm_ctx_t *ctx);\n    void (*on_event)(comm_ctx_t *ctx, comm_event_t evt);\n    void (*on_exit)(comm_ctx_t *ctx);\n} comm_state_t;\n\n/* ---------- 上下文 ---------- */\nstruct comm_ctx {\n    const comm_state_t *state;    // 当前状态\n    uint8_t retry_count;\n    uint32_t last_activity_ms;\n    uint8_t rx_buf[256];\n    size_t rx_len;\n};\n\n/* ---------- 状态转换 (内部函数) ---------- */\nstatic void comm_transition(comm_ctx_t *ctx, const comm_state_t *new_state) {\n    if (ctx->state->on_exit != NULL) {\n        ctx->state->on_exit(ctx);\n    }\n    ctx->state = new_state;\n    if (ctx->state->on_enter != NULL) {\n        ctx->state->on_enter(ctx);\n    }\n}\n```\n\n每个状态实现自己的事件处理逻辑，并**自主决定**状态转换:\n\n```c\n/* ---------- 前向声明所有状态 ---------- */\nstatic const comm_state_t st_disconnected;\nstatic const comm_state_t st_connecting;\nstatic const comm_state_t st_ready;\nstatic const comm_state_t st_error;\n\n/* ---------- Disconnected 状态 ---------- */\nstatic void disconnected_on_event(comm_ctx_t *ctx, comm_event_t evt) {\n    if (evt == EVT_CONNECT) {\n        ctx->retry_count = 0;\n        comm_transition(ctx, &st_connecting);  // 状态自主决定转换\n    }\n    // 其他事件在此状态下忽略\n}\n\nstatic const comm_state_t st_disconnected = {\n    .name     = \"Disconnected\",\n    .on_enter = NULL,\n    .on_event = disconnected_on_event,\n    .on_exit  = NULL,\n};\n\n/* ---------- Connecting 状态 ---------- */\n#define MAX_RETRIES  3\n\nstatic void connecting_on_enter(comm_ctx_t *ctx) {\n    // 发送连接请求\n    // send_connect_request();\n    ctx->last_activity_ms = get_tick_ms();\n}\n\nstatic void connecting_on_event(comm_ctx_t *ctx, comm_event_t evt) {\n    switch (evt) {\n        case EVT_ACK_RECEIVED:\n            comm_transition(ctx, &st_ready);     // 握手成功\n            break;\n        case EVT_TIMEOUT:\n            if (ctx->retry_count < MAX_RETRIES) {\n                ctx->retry_count++;\n                // send_connect_request();          // 重试\n                ctx->last_activity_ms = get_tick_ms();\n            } else {\n                comm_transition(ctx, &st_error);  // 超过重试次数\n            }\n            break;\n        case EVT_ERROR:\n            comm_transition(ctx, &st_error);\n            break;\n        default:\n            break;\n    }\n}\n\nstatic const comm_state_t st_connecting = {\n    .name     = \"Connecting\",\n    .on_enter = connecting_on_enter,\n    .on_event = connecting_on_event,\n    .on_exit  = NULL,\n};\n\n/* ---------- Ready 状态 ---------- */\nstatic void ready_on_event(comm_ctx_t *ctx, comm_event_t evt) {\n    switch (evt) {\n        case EVT_DATA_RECEIVED:\n            ctx->last_activity_ms = get_tick_ms();\n            // process_data(ctx->rx_buf, ctx->rx_len);\n            break;\n        case EVT_TIMEOUT:\n            comm_transition(ctx, &st_error);\n            break;\n        case EVT_DISCONNECT:\n            comm_transition(ctx, &st_disconnected);\n            break;\n        case EVT_ERROR:\n            comm_transition(ctx, &st_error);\n            break;\n        default:\n            break;\n    }\n}\n\nstatic const comm_state_t st_ready = {\n    .name     = \"Ready\",\n    .on_enter = NULL,\n    .on_event = ready_on_event,\n    .on_exit  = NULL,\n};\n\n/* ---------- Error 状态 ---------- */\nstatic void error_on_event(comm_ctx_t *ctx, comm_event_t evt) {\n    if (evt == EVT_RESET) {\n        ctx->retry_count = 0;\n        comm_transition(ctx, &st_disconnected);\n    }\n    // Error 状态下只响应 RESET\n}\n\nstatic const comm_state_t st_error = {\n    .name     = \"Error\",\n    .on_enter = NULL,\n    .on_event = error_on_event,\n    .on_exit  = NULL,\n};\n```\n\n使用方式 -- 外部只投递事件，不控制状态:\n\n```c\ncomm_ctx_t comm = { .state = &st_disconnected };\n\n// 外部只投递事件，不干预状态转换\nvoid comm_handle_event(comm_ctx_t *ctx, comm_event_t evt) {\n    ctx->state->on_event(ctx, evt);\n}\n\n// 使用\ncomm_handle_event(&comm, EVT_CONNECT);        // Disconnected -> Connecting\ncomm_handle_event(&comm, EVT_ACK_RECEIVED);   // Connecting -> Ready\ncomm_handle_event(&comm, EVT_ERROR);          // Ready -> Error\ncomm_handle_event(&comm, EVT_RESET);          // Error -> Disconnected\n```\n\n关键点: 外部调用 `comm_handle_event()` 只投递事件，状态转换逻辑完全封装在各状态的 `on_event` 中。外部无法直接设置状态。\n\n### 3.3 状态图\n\n```mermaid\nstateDiagram-v2\n    [*] --> Disconnected\n    Disconnected --> Connecting : EVT_CONNECT\n    Connecting --> Ready : EVT_ACK_RECEIVED\n    Connecting --> Connecting : EVT_TIMEOUT (retry < MAX)\n    Connecting --> Error : EVT_TIMEOUT (retry >= MAX)\n    Connecting --> Error : EVT_ERROR\n    Ready --> Error : EVT_TIMEOUT / EVT_ERROR\n    Ready --> Disconnected : EVT_DISCONNECT\n    Error --> Disconnected : EVT_RESET\n```\n\n## 4. 本质差异对比\n\n代码结构相似，但设计意图截然不同:\n\n| 维度 | 策略模式 | 状态模式 |\n|------|----------|----------|\n| 核心问题 | 用哪个算法？ | 当前处于什么阶段？ |\n| 决策权 | **外部** (调用方选择) | **内部** (状态自主转换) |\n| 切换方式 | `ctx->strategy = &new_strategy` | `transition(ctx, &new_state)` |\n| 切换约束 | 任意时刻、任意方向 | 受状态机规则约束 |\n| 切换触发 | 调用方显式调用 | 事件驱动，自动发生 |\n| 各实现间关系 | 平行、互不感知 | 有序、相互引用 |\n| 典型场景 | 算法选择、后端切换 | 协议状态机、设备生命周期 |\n\n用一句话总结:\n\n> 策略模式是**调用方告诉上下文\"用这个\"**；状态模式是**上下文自己决定\"现在该做什么\"**。\n\n## 5. 协作: 在同一系统中组合使用\n\n实际系统中，策略模式和状态模式经常协作。以一个日志系统为例:\n\n- **策略模式**: 日志输出后端可切换 (串口、文件、网络)\n- **状态模式**: 网络后端内部管理连接状态 (断开、连接中、已连接)\n\n```c\n/* ===== 策略层: 日志后端选择 ===== */\ntypedef struct {\n    int (*init)(void *priv);\n    int (*write_log)(void *priv, const char *msg, size_t len);\n    void (*flush)(void *priv);\n} log_backend_t;\n\ntypedef struct {\n    const log_backend_t *backend;\n    void *priv;\n} logger_t;\n\n// 策略切换: 外部决策\nvoid logger_set_backend(logger_t *log, const log_backend_t *be, void *priv) {\n    if (log->backend != NULL && log->backend->flush != NULL) {\n        log->backend->flush(log->priv);\n    }\n    log->backend = be;\n    log->priv    = priv;\n    if (be->init != NULL) { be->init(priv); }\n}\n\n/* ===== 状态层: 网络后端内部状态管理 ===== */\ntypedef enum {\n    NET_ST_DISCONNECTED,\n    NET_ST_CONNECTING,\n    NET_ST_CONNECTED,\n} net_log_state_t;\n\ntypedef struct {\n    net_log_state_t state;\n    int sock_fd;\n    uint8_t cache[1024];  // 断线时缓存\n    size_t cache_len;\n} net_log_ctx_t;\n\nstatic int net_write_log(void *priv, const char *msg, size_t len) {\n    net_log_ctx_t *ctx = (net_log_ctx_t *)priv;\n    switch (ctx->state) {\n        case NET_ST_CONNECTED:\n            // 直接发送\n            return send(ctx->sock_fd, msg, len, 0);\n        case NET_ST_DISCONNECTED:\n            // 缓存 + 触发重连 (状态模式: 内部决策)\n            if (ctx->cache_len + len <= sizeof(ctx->cache)) {\n                memcpy(ctx->cache + ctx->cache_len, msg, len);\n                ctx->cache_len += len;\n            }\n            ctx->state = NET_ST_CONNECTING;  // 自动转换\n            // start_reconnect(ctx);\n            return (int)len;\n        case NET_ST_CONNECTING:\n            // 缓存，等待连接完成\n            if (ctx->cache_len + len <= sizeof(ctx->cache)) {\n                memcpy(ctx->cache + ctx->cache_len, msg, len);\n                ctx->cache_len += len;\n            }\n            return (int)len;\n    }\n    return -1;\n}\n\nstatic const log_backend_t g_net_backend = {\n    .init      = net_log_init,\n    .write_log = net_write_log,\n    .flush     = net_log_flush,\n};\n```\n\n层次关系:\n\n```\n调用方 --[策略选择]--> logger_t --[函数指针]--> log_backend_t\n                                                    |\n                                    串口后端 (无状态)  |  网络后端 (有状态)\n                                                    |\n                                            net_log_ctx_t\n                                            [状态机: 断开/连接中/已连接]\n```\n\n- 上层用**策略模式**在串口、文件、网络后端之间切换 (外部决策)\n- 网络后端内部用**状态模式**管理连接生命周期 (内部自治)\n- 两种模式各司其职，互不干扰\n\n## 6. 实现要点\n\n### 6.1 函数指针表用 const 修饰\n\n```c\n// vtable 放在 .rodata 段，防止意外修改\nstatic const filter_strategy_t g_mean_strategy = { ... };\nstatic const comm_state_t st_disconnected = { ... };\n```\n\n所有函数指针表都应声明为 `const`，让编译器将其放入只读段。嵌入式系统中这意味着放入 Flash，不占 RAM。\n\n### 6.2 上下文指针而非全局变量\n\n```c\n// 正确: 通过上下文指针传递\nstatic void connecting_on_event(comm_ctx_t *ctx, comm_event_t evt) { ... }\n\n// 错误: 全局变量\n// static comm_ctx_t g_comm;  // 线程不安全，不可重入\n```\n\n每个函数都通过参数接收上下文指针，不依赖全局变量。这使得同一套代码可以管理多个实例 (如多路传感器、多路通信)。\n\n### 6.3 状态转换封装\n\n```c\n// 状态转换统一通过 transition 函数\nstatic void comm_transition(comm_ctx_t *ctx, const comm_state_t *new_state) {\n    if (ctx->state->on_exit != NULL)  { ctx->state->on_exit(ctx); }\n    ctx->state = new_state;\n    if (ctx->state->on_enter != NULL) { ctx->state->on_enter(ctx); }\n}\n```\n\n不要在状态处理函数中直接赋值 `ctx->state = &st_xxx`。统一通过 `transition()` 函数，保证 `on_exit` / `on_enter` 回调被正确执行。\n\n### 6.4 NULL 函数指针检查\n\n```c\n// 允许部分回调为 NULL，调用前检查\nif (ctx->state->on_enter != NULL) {\n    ctx->state->on_enter(ctx);\n}\n```\n\n不是所有状态都需要 `on_enter` / `on_exit`。允许 NULL 可以减少空函数的编写。\n\n## 7. 判断选择\n\n遇到\"上下文 + 函数指针\"结构时，问自己:\n\n1. **谁决定切换？** 外部调用方 -> 策略模式；内部自动 -> 状态模式\n2. **切换有顺序约束吗？** 无约束 -> 策略模式；有固定路径 -> 状态模式\n3. **各实现之间知道彼此吗？** 互不感知 -> 策略模式；相互引用 -> 状态模式\n\n```\n需要运行时切换行为？\n    ├── 是: 切换由谁控制？\n    │       ├── 外部调用方 → 策略模式\n    │       └── 内部自动   → 状态模式\n    └── 否: 不需要这两种模式\n```\n\n两种模式并非互斥。如本文第 5 节所示，一个系统可以同时使用策略模式 (选择后端) 和状态模式 (管理后端内部生命周期)，各自解决不同层次的问题。\n",
      "ctime": "1771552516",
      "mtime": "1771552516",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/compile_time_dispatch_optimization.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267177510",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式系统中的编译期分发: 用模板消除虚函数开销",
      "brief_content": "结合 MISRA C++ 规范和 newosp 工程实践，系统阐述如何利用 C++17 模板技术实现编译期分发，在保持代码灵活性的同时消除虚函数的性能损耗。实测显示编译期分发相比回调模式有 15 倍性",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 在嵌入式系统开发中，虚函数带来的运行时开销和 MISRA C++ 标准的约束使得传统的面向对象设计模式面临挑战。本文结合 MISRA C++ 规范和 [newosp](https://github.com/DeguiLiu/newosp) 项目的工程实践，系统阐述如何利用 C++17 模板技术实现编译期分发，在保持代码灵活性的同时消除虚函数的性能损耗。实测显示，编译期分发相比回调模式有 15 倍性能提升，相比虚函数分发开销降低 95% 以上。\n\n## 1. 虚函数在嵌入式系统中的挑战\n\n### 1.1 MISRA C++ 标准的约束\n\nMISRA C++ 标准对嵌入式系统中虚函数的使用做出严格规定：\n\n- **Rule 5-0-1**: 禁止使用 `dynamic_cast`、`reinterpret_cast` 等不安全类型转换\n- **Rule 10-3-3**: 虚函数在派生类中的重写必须明确标注 `override`\n- **Rule 12-1-1**: 避免使用虚基类，虚继承会增加内存布局复杂度\n\n### 1.2 虚函数的性能开销\n\n```\n运行时开销：\n  - vtable 查找：每次虚函数调用需要间接跳转（2-3 个内存访问）\n  - 缓存不友好：虚函数指针分散在不同对象中，破坏数据局部性\n  - 无法内联：编译器无法对虚函数调用进行内联优化\n\n内存开销：\n  - vtable 指针：每个对象增加 8 字节（64 位平台）\n  - RTTI 信息：启用 typeid/dynamic_cast 时增加类型元数据\n\n嵌入式典型场景：\n  - ARM Cortex-A9 @ 1GHz，虚函数调用 ~10ns\n  - 100 万次/秒消息分发，虚函数额外开销 ~10ms\n  - 实时系统 P99 延迟增加 50-100%\n```\n\n### 1.3 传统设计模式的困境\n\n以工厂模式为例，传统实现依赖虚函数：\n\n```cpp\n// 传统工厂模式：依赖虚函数\nclass Product {\n public:\n  virtual void operation() = 0;  // 虚函数：运行时分发\n  virtual ~Product() = default;\n};\n\nclass ConcreteProductA : public Product {\n public:\n  void operation() override { /* ... */ }\n};\n\nclass Factory {\n public:\n  virtual std::unique_ptr<Product> create() = 0;  // 虚工厂方法\n};\n```\n\n问题：\n- 每次 `operation()` 调用需要 vtable 查找\n- `create()` 返回的是基类指针，无法内联\n- MISRA C++ 要求避免虚析构函数（Rule 12-1-4）\n\n## 2. 编译期分发技术\n\n### 2.1 CRTP 模式：静态多态\n\nCRTP（Curiously Recurring Template Pattern）是编译期多态的基础：\n\n```cpp\ntemplate <typename Derived>\nclass Base {\n public:\n  void interface() {\n    // 编译期决议：static_cast 到 Derived\n    static_cast<Derived*>(this)->implementation();\n  }\n};\n\nclass ConcreteA : public Base<ConcreteA> {\n public:\n  void implementation() {\n    std::cout << \"ConcreteA implementation\\n\";\n  }\n};\n\nclass ConcreteB : public Base<ConcreteB> {\n public:\n  void implementation() {\n    std::cout << \"ConcreteB implementation\\n\";\n  }\n};\n\n// 使用示例\ntemplate <typename T>\nvoid process(Base<T>& obj) {\n  obj.interface();  // 编译期内联，零开销\n}\n```\n\n优势：\n- **编译期决议**：`static_cast` 在编译时确定目标类型，无运行时查表\n- **内联优化**：编译器可将 `implementation()` 内联到 `interface()` 中\n- **类型安全**：错误的类型转换在编译期被捕获\n\n### 2.2 模板参数化：消除间接调用\n\n[newosp](https://github.com/DeguiLiu/newosp) 项目的 `AsyncBus` 是模板参数化的典型应用：\n\n```cpp\n// AsyncBus 模板参数化：编译期配置\ntemplate <typename PayloadVariant,\n          uint32_t QueueDepth = 256,\n          uint32_t BatchSize = 16>\nclass AsyncBus {\n public:\n  // 发布消息：编译期确定 variant 类型\n  template <typename T>\n  bool Publish(uint32_t topic, const T& data, Priority prio) {\n    PayloadVariant payload = data;  // 编译期类型检查\n    return ring_buffer_.TryPush(Envelope{topic, prio, payload});\n  }\n\n  // 订阅消息：编译期绑定回调类型\n  template <typename Fn>\n  SubscriptionId Subscribe(uint32_t topic, Fn&& callback) {\n    // FixedFunction<Sig, Size> 替代 std::function\n    FixedFunction<void(const PayloadVariant&, const MessageHeader&), 64> fn(\n        std::forward<Fn>(callback));\n    return callback_table_.Add(topic, std::move(fn));\n  }\n\n private:\n  // MPSC 无锁队列：编译期固定容量\n  SpscRingBuffer<Envelope, QueueDepth> ring_buffer_;\n  // 回调表：编译期类型擦除\n  CallbackTable<PayloadVariant, BatchSize> callback_table_;\n};\n```\n\n关键技术：\n- **模板参数化配置**：`QueueDepth`/`BatchSize` 在编译期确定，避免运行时动态分配\n- **`PayloadVariant` 类型安全**：只有 variant 中包含的类型才能发布，编译期类型检查\n- **`FixedFunction` SBO**：栈上分配回调对象，避免 `std::function` 的堆分配\n\n### 2.3 std::variant + std::visit：类型安全的编译期分发\n\nC++17 引入的 `std::variant` 和 `std::visit` 提供了类型安全的编译期分发机制：\n\n```cpp\n// 定义消息类型\nstruct SensorData { float temperature; };\nstruct MotorCommand { int32_t speed; };\nstruct SystemStatus { uint8_t code; };\n\nusing MessageVariant = std::variant<SensorData, MotorCommand, SystemStatus>;\n\n// 访问者：处理不同类型消息\nstruct MessageHandler {\n  void operator()(const SensorData& msg) {\n    std::cout << \"Temperature: \" << msg.temperature << \"\\n\";\n  }\n  void operator()(const MotorCommand& msg) {\n    std::cout << \"Speed: \" << msg.speed << \"\\n\";\n  }\n  void operator()(const SystemStatus& msg) {\n    std::cout << \"Status: \" << static_cast<int>(msg.code) << \"\\n\";\n  }\n};\n\n// 处理消息：编译期生成分发表\nvoid processMessage(const MessageVariant& msg) {\n  std::visit(MessageHandler{}, msg);  // 编译期展开为 switch\n}\n```\n\n汇编验证（GCC 12.2 -O3）：\n```asm\n; std::visit 生成的代码等价于：\nmovl    (%rdi), %eax        ; 读取 variant index\ncmpl    $1, %eax\nje      .L_MotorCommand\ncmpl    $2, %eax\nje      .L_SystemStatus\n; fall through to SensorData\n```\n\n性能对比（x86_64 -O3，100 万次调用）：\n| 分发方式 | 延迟 (ns) | 吞吐量 (Mops/s) | 代码大小 |\n|---------|----------|----------------|---------|\n| 虚函数  | 8.5      | 117.6          | 152 B   |\n| `std::function` | 5.2 | 192.3      | 184 B   |\n| `std::visit` | 2.1  | 476.2          | 96 B    |\n\n### 2.4 名称隐藏：Instance 无 virtual 的优雅实现\n\n[newosp](https://github.com/DeguiLiu/newosp) 的 `Application/Instance` 模型通过名称隐藏（name hiding）替代虚函数：\n\n```cpp\n// 基类：无 virtual，通过公开包装方法委托给 HSM\nclass InstanceBase {\n public:\n  // 公开包装方法：委托给 HSM 状态机\n  void BeginMessage(uint16_t msg_type) {\n    hsm_.HandleEvent(EventBeginMsg{msg_type});\n  }\n\n  void EndMessage() {\n    hsm_.HandleEvent(EventEndMsg{});\n  }\n\n protected:\n  StateMachine<InstanceLifecycle, 16> hsm_;  // HSM 驱动生命周期\n};\n\n// 派生类：通过名称隐藏实现多态\nclass MyInstance : public InstanceBase {\n public:\n  // 名称隐藏：OnMessage 不是 override，而是静态绑定\n  void OnMessage(const SensorData& msg) {\n    // 编译期绑定：Application 模板参数确定调用此方法\n    std::cout << \"Processing sensor data: \" << msg.temperature << \"\\n\";\n  }\n\n  void OnMessage(const MotorCommand& msg) {\n    std::cout << \"Executing motor command: \" << msg.speed << \"\\n\";\n  }\n};\n\n// Application 模板：编译期绑定 Instance 类型\ntemplate <typename InstanceImpl, uint32_t MaxInstances>\nclass Application {\n public:\n  void RouteMessage(uint32_t iid, const MessageVariant& msg) {\n    InstanceImpl* inst = pool_.Get(GetInsId(iid));\n    if (inst) {\n      inst->BeginMessage(msg.index());\n      std::visit([inst](const auto& m) { inst->OnMessage(m); }, msg);\n      inst->EndMessage();\n    }\n  }\n\n private:\n  MemPool<InstanceImpl, MaxInstances> pool_;  // 零堆分配实例池\n};\n```\n\n关键优势：\n- **无 virtual 开销**：`OnMessage` 不是虚函数，`Application` 模板参数在编译期确定 `InstanceImpl` 类型\n- **HSM 状态机**：`BeginMessage`/`EndMessage` 委托给 HSM 处理状态转换，无需虚函数多态\n- **编译期内联**：`std::visit` 将 `OnMessage` 调用内联到 `RouteMessage` 中\n\nC++ 标准依据：\n- **CWG 1873**：`friend` + `static_cast<Base*>(derived)` 访问 `protected` 成员在 C++ 中不合法\n- **解决方案**：用公开包装方法（`BeginMessage`/`EndMessage`）替代 `friend` 声明\n\n## 3. newosp 项目的实践案例\n\n### 3.1 StaticNode：编译期绑定 Handler\n\n`StaticNode` 是 [newosp](https://github.com/DeguiLiu/newosp) 中编译期分发的极致优化：\n\n```cpp\n// Handler 协议：通过 operator() 重载处理不同消息类型\nstruct MyHandler {\n  void operator()(const SensorData& msg, const MessageHeader& header) {\n    std::cout << \"Sensor: \" << msg.temperature << \"\\n\";\n  }\n\n  void operator()(const MotorCommand& msg, const MessageHeader& header) {\n    std::cout << \"Motor: \" << msg.speed << \"\\n\";\n  }\n\n  // catch-all：忽略不关心的消息类型\n  template <typename T>\n  void operator()(const T&, const MessageHeader&) {\n    // 编译器可优化为零开销（dead code elimination）\n  }\n};\n\n// StaticNode：编译期绑定 Handler 类型\ntemplate <typename PayloadVariant, typename Handler>\nclass StaticNode {\n public:\n  StaticNode(const char* name, uint32_t node_id, Handler handler, AsyncBus<PayloadVariant>* bus)\n      : handler_(std::move(handler)), bus_(bus), node_id_(node_id) {}\n\n  // ProcessBatchWith：直接分发，绕过回调表\n  template <typename Visitor>\n  uint32_t ProcessBatchWith(Visitor&& visitor) {\n    return bus_->ProcessBatchWith(node_id_, std::forward<Visitor>(visitor));\n  }\n\n private:\n  Handler handler_;  // 编译期确定类型，无类型擦除\n  AsyncBus<PayloadVariant>* bus_;\n  uint32_t node_id_;\n};\n\n// 使用示例\nStaticNode<MessageVariant, MyHandler> node(\"sensor\", 1, MyHandler{}, &bus);\n\n// 消息循环：编译期内联 handler 调用\nwhile (running) {\n  node.ProcessBatchWith([&node](const auto& payload, const MessageHeader& header) {\n    std::visit([&node, &header](const auto& msg) {\n      node.handler_(msg, header);  // 编译期决议，可内联\n    }, payload);\n  });\n}\n```\n\n性能对比（x86_64 -O3，64B 消息）：\n| 分发模式 | 延迟 (ns) | 吞吐量 (Mops/s) | 开销消除 |\n|---------|----------|----------------|---------|\n| 虚函数  | 42       | 23.8           | 基准    |\n| Node (回调表) | 29  | 34.5           | -31%    |\n| StaticNode (直接分发) | 2 | 500.0       | -95%    |\n\n### 3.2 FixedFunction：栈上 SBO 替代 std::function\n\n`FixedFunction` 通过 SBO（Small Buffer Optimization）避免堆分配：\n\n```cpp\ntemplate <typename Signature, uint32_t Size = 64>\nclass FixedFunction;\n\ntemplate <typename R, typename... Args, uint32_t Size>\nclass FixedFunction<R(Args...), Size> {\n public:\n  template <typename Fn>\n  FixedFunction(Fn&& fn) {\n    static_assert(sizeof(Fn) <= Size, \"Functor too large\");\n    new (buffer_) Fn(std::forward<Fn>(fn));  // placement new\n    invoker_ = [](void* ptr, Args... args) -> R {\n      return (*static_cast<Fn*>(ptr))(std::forward<Args>(args)...);\n    };\n  }\n\n  R operator()(Args... args) const {\n    return invoker_(const_cast<void*>(static_cast<const void*>(buffer_)), std::forward<Args>(args)...);\n  }\n\n private:\n  alignas(alignof(std::max_align_t)) uint8_t buffer_[Size];\n  R (*invoker_)(void*, Args...);\n};\n```\n\n内存布局对比：\n```\nstd::function<void(int)>:\n  - 控制块指针（堆分配）：8 字节\n  - vtable 指针：8 字节\n  - 总开销：16 字节 + 动态分配\n\nFixedFunction<void(int), 64>:\n  - 栈上缓冲区：64 字节\n  - invoker 函数指针：8 字节\n  - 总开销：72 字节（栈上，零堆分配）\n```\n\n### 3.3 if constexpr：编译期分支消除\n\n`if constexpr` 用于编译期根据条件选择不同代码路径：\n\n```cpp\n// FaultCollector：根据回调返回类型编译期选择逻辑\ntemplate <typename Fn>\nvoid ForEachRecent(Fn&& callback) const {\n  std::unique_lock<std::mutex> lock(mutex_);\n\n  for (uint32_t i = 0; i < fault_count_; ++i) {\n    const auto& entry = faults_[(fault_head_ + i) % MaxFaults];\n\n    if constexpr (std::is_same_v<decltype(callback(entry)), bool>) {\n      // 回调返回 bool：支持 early-stop\n      if (!callback(entry)) {\n        break;\n      }\n    } else {\n      // 回调返回 void：遍历所有故障\n      callback(entry);\n    }\n  }\n}\n\n// 使用示例\nfault_collector.ForEachRecent([](const FaultEntry& entry) -> bool {\n  std::cout << \"Fault: \" << entry.code << \"\\n\";\n  return entry.priority != Priority::kCritical;  // early-stop 条件\n});\n```\n\n编译器生成的代码（GCC 12.2 -O3）：\n```asm\n; if constexpr 编译期展开，运行时无分支\n; bool 版本：\ncall    _ZN7Fn4call17h...   ; callback(entry)\ntestb   %al, %al           ; 检查返回值\nje      .L_early_stop      ; 提前退出\n\n; void 版本：\ncall    _ZN7Fn4call17h...   ; callback(entry)\n; 无检查，直接继续\n```\n\n## 4. 性能对比与分析\n\n### 4.1 基准测试设置\n\n测试环境：\n```\n硬件：ARM Cortex-A53 @ 1.2GHz (4 核)\n内存：2GB DDR3\n编译器：GCC 11.2, -O3 -march=native\n场景：100 万次消息分发，64B 消息负载\n```\n\n### 4.2 延迟对比\n\n| 方法 | P50 (ns) | P99 (ns) | P99.9 (ns) | 说明 |\n|------|----------|----------|------------|------|\n| 虚函数 | 42 | 157 | 428 | 基准 |\n| `std::function` | 35 | 142 | 391 | -17% |\n| FixedFunction | 29 | 118 | 312 | -31% |\n| std::visit | 18 | 85 | 201 | -57% |\n| StaticNode | 2 | 12 | 45 | **-95%** |\n\n### 4.3 吞吐量对比\n\n```\n虚函数分发：        23.8 Mops/s\nstd::function 回调： 28.6 Mops/s  (+20%)\nFixedFunction 回调： 34.5 Mops/s  (+45%)\nstd::visit 分发：    55.6 Mops/s  (+133%)\nStaticNode 直接分发：500.0 Mops/s (+2000%)\n```\n\n### 4.4 内存占用对比\n\n| 方法 | 对象大小 | 代码大小 | 堆分配 |\n|------|----------|----------|--------|\n| 虚函数 | 16 B (vtable ptr) | 152 B | 0 |\n| std::function | 32 B | 184 B | 每回调 1 次 |\n| FixedFunction | 72 B | 128 B | 0 |\n| StaticNode | 88 B | 96 B | 0 |\n\n### 4.5 性能提升来源\n\n编译期分发性能优势的根源：\n\n1. **消除间接调用**\n   - 虚函数：`load vtable ptr → load func ptr → call` (3 次内存访问)\n   - 编译期分发：`call` (直接跳转)\n\n2. **内联优化**\n   ```cpp\n   // 虚函数：无法内联\n   virtual void process(int x) { data_ += x; }\n\n   // 编译期分发：完全内联\n   template <typename Derived>\n   void process(int x) {\n     static_cast<Derived*>(this)->processImpl(x);  // 内联为：data_ += x;\n   }\n   ```\n\n3. **缓存友好**\n   - 虚函数：vtable 指针分散，破坏缓存局部性\n   - 编译期分发：代码和数据连续，缓存命中率高\n\n4. **编译器优化**\n   - 虚函数：编译器无法跨越虚函数调用边界优化\n   - 编译期分发：编译器可应用全局优化（常量传播、死代码消除）\n\n## 5. 工程实践建议\n\n### 5.1 何时使用编译期分发\n\n适用场景：\n- **性能关键路径**：消息分发、事件处理、数据转换\n- **嵌入式系统**：资源受限、实时性要求高\n- **类型固定**：消息类型在编译期已知\n- **MISRA C++ 合规**：需要避免虚函数和 RTTI\n\n不适用场景：\n- **插件系统**：需要运行时加载未知类型\n- **ABI 稳定性**：动态库接口需要跨版本兼容\n- **反射需求**：需要运行时类型信息和动态类型转换\n\n### 5.2 迁移策略\n\n从虚函数迁移到编译期分发的步骤：\n\n1. **识别热点**：profiling 找出虚函数调用热点\n2. **类型封闭**：确保消息类型在编译期已知（`std::variant`）\n3. **重构接口**：CRTP 模板化基类\n4. **渐进替换**：先替换热点，保留冷路径虚函数\n5. **验证性能**：benchmark 确认性能提升\n\n### 5.3 调试与可维护性\n\n编译期分发的权衡：\n\n优势：\n- 编译期错误检测：类型不匹配在编译期捕获\n- 零运行时开销：无 vtable/RTTI 数据\n\n劣势：\n- 编译时间增加：模板实例化开销\n- 错误信息冗长：模板错误堆栈深\n- 二进制膨胀：每个类型生成独立代码\n\n缓解措施：\n- **extern template**：显式实例化减少编译单元\n- **type traits**：`static_assert` 提前检查类型约束\n- **概念（C++20）**：`concept` 简化模板约束表达\n\n## 6. 总结\n\n编译期分发技术通过 CRTP、模板参数化、`std::variant` 和 `if constexpr` 等机制，在嵌入式系统中消除了虚函数的运行时开销。[newosp](https://github.com/DeguiLiu/newosp) 项目的工程实践验证了这些技术的有效性：\n\n- **性能提升**：延迟降低 95%，吞吐量提升 20 倍\n- **内存优化**：零堆分配，栈上 SBO 替代 `std::function`\n- **标准合规**：符合 MISRA C++ 规范，兼容 `-fno-exceptions -fno-rtti`\n- **可维护性**：类型安全，编译期错误检测\n\n对于追求极致性能的嵌入式系统，编译期分发不仅是一种优化技术，更是一种架构思想：**将运行时决策前移到编译期，让编译器成为你的性能优化伙伴**。\n\n## 参考资料\n\n1. [newosp](https://github.com/DeguiLiu/newosp) - C++17 嵌入式基础设施库\n2. MISRA C++:2008 Guidelines for the use of the C++ language in critical systems\n3. C++17 标准：ISO/IEC 14882:2017\n4. \"Curiously Recurring Template Pattern\" - James O. Coplien (1995)\n5. \"Modern C++ Design\" - Andrei Alexandrescu (2001)\n\n---\n\n**关于作者**：本文基于 [newosp](https://github.com/DeguiLiu/newosp) 项目的工程实践总结，newosp 是一个面向 ARM-Linux 嵌入式平台的 C++17 纯头文件基础设施库，已通过 1100+ 测试用例和 ASan/TSan/UBSan 验证。\n",
      "ctime": "1771552519",
      "mtime": "1771552519",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/cpp17_what_c_cannot_do.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853651978",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C11 做不到的事: 10 项 C++17 语言级不可替代能力",
      "brief_content": "筛选标准: 只保留 C11 在语言层面无法实现的能力。从类型安全、编译期计算、内存安全、类型分发四个维度，逐项对比 C++17 与 C11 的语言级差异，附完整代码对比。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 筛选标准: 只保留 C11 在**语言层面无法实现**的能力。\n> 条件编译、`_Alignas`、`_Static_assert(常量表达式)`、`atomic_signal_fence`、栈上固定数组等 C11 同样能做到的内容不在讨论范围。\n\n> 姊妹篇: [newosp 源码中的 C++17 实践]({{< ref \"cpp17_claims_in_newosp\" >}}) -- 这些语言能力在工业嵌入式库中的具体落地位置与工程决策。\n\n---\n\n## 一、类型安全 -- 编译器拒绝类型混用\n\n### 1. 编译期类型成员校验\n\nC 的 `void*` 不携带类型信息，编译器无法验证传入类型是否属于合法集合。\n\n```cpp\n// C++: 编译期递归，将类型 T 映射为 variant 中的索引，不存在则编译失败\ntemplate <typename T, typename... Types>\nstruct VariantIndex<T, std::variant<Types...>> {\n  static constexpr size_t value =\n      detail::VariantIndexImpl<T, 0, std::variant<Types...>>::value;\n  static_assert(value != static_cast<size_t>(-1),\n                \"Type not found in PayloadVariant\");\n};\n\n// 订阅不在 variant 中的类型 -> 编译失败\nbus.Subscribe<GpsData>(handler);  // GpsData 不在 variant 中 -> 编译错误\n```\n\n```c\n// C: tag 写错不产生编译错误\nsubscribe(bus, GPS_TAG, handler);  // GPS_TAG 写错 -> 把 SensorData 按 GpsData 解释\n                                    // 编译器无任何警告\n```\n\nC11 的 `_Static_assert` 只能检查整型常量表达式，无法检查\"某类型是否在类型列表中\"。\n\n### 2. 强类型别名\n\nC 的 `typedef uint32_t TimerId` 和 `typedef uint32_t NodeId` 是同一类型，编译器不阻止互相赋值。\n\n```cpp\n// C++: NewType 创建真正不同的类型\ntemplate <typename T, typename Tag>\nclass NewType final {\n public:\n  constexpr explicit NewType(T val) noexcept : val_(val) {}\n  constexpr T value() const noexcept { return val_; }\n private:\n  T val_;\n};\n\nusing TimerId   = NewType<uint32_t, struct TimerIdTag>;\nusing SessionId = NewType<uint32_t, struct SessionIdTag>;\n\nTimerId tid{1};\nSessionId sid = tid;  // 编译失败: 不同类型\n```\n\n```c\n// C: typedef 不阻止混用\ntypedef uint32_t TimerId;\ntypedef uint32_t SessionId;\n\nTimerId tid = 1;\nSessionId sid = tid;  // 编译通过，运行时传错 ID\n```\n\n### 3. enum class -- 枚举值不泄漏、不隐式转整型\n\n```cpp\n// C++: 作用域枚举\nenum class Priority : uint8_t { kLow, kMedium, kHigh };\nint x = Priority::kLow;       // 编译失败: 不能隐式转 int\nif (Priority::kLow == 0) {}   // 编译失败: 不能与 int 比较\n```\n\n```c\n// C: 枚举值泄漏到全局\nenum Priority { LOW, MEDIUM, HIGH };\nenum LogLevel { LOW, HIGH };  // 编译错误: LOW/HIGH 重定义\nint x = LOW;                  // 编译通过，LOW 就是 int 0\n```\n\n### 4. not_null -- 空指针解引用在构造期拦截\n\n```cpp\n// C++: 类型系统标注\"不可能为空\"\nvoid Process(not_null<Sensor*> sensor) {\n  sensor->Read();  // 调用者保证非空，函数内无需检查\n}\nProcess(nullptr);  // 编译期或构造期断言失败\n```\n\n```c\n// C: 指针永远可能为空\nvoid process(Sensor* sensor) {\n  if (!sensor) return;  // 每个函数都要防御性检查\n  sensor->read();       // 忘了检查 -> SIGSEGV\n}\n```\n\n---\n\n## 二、编译期计算 -- 将运行时工作移至编译期\n\n### 5. constexpr 函数 -- 保证编译期求值\n\nC 的 `const` 不是编译期常量合同，`#define` 宏无法写循环或条件逻辑。\n\n```cpp\n// C++: 编译器保证在编译期求值\nconstexpr uint32_t Fnv1a32(const char* str) noexcept {\n  uint32_t hash = 2166136261u;\n  while (*str) {\n    hash ^= static_cast<uint32_t>(*str++);\n    hash *= 16777619u;\n  }\n  return hash;\n}\n\nconstexpr auto kTopicHash = Fnv1a32(\"sensor/imu\");  // 编译结果: 立即数\n```\n\nC 可以用宏做简单常量折叠 (`#define MAKE_IID(a,b) ((a)<<16|(b))`)，但无法在宏中写循环来实现哈希函数。\n\n### 6. if constexpr -- 基于类型属性的编译期分支消除\n\nC 的 `#ifdef` 只能基于宏开关，无法检测类型属性。C 的运行时 `if` 在函数未内联时无法消除死分支。\n\n**(a) 按 trivially copyable 选择拷贝策略:**\n\n```cpp\nif constexpr (std::is_trivially_copyable_v<T>) {\n  std::memcpy(&buffer[offset], src, count * sizeof(T));\n} else {\n  for (size_t i = 0; i < count; ++i) {\n    buffer[(offset + i) & mask] = src[i];\n  }\n}\n// 编译后只保留命中的分支，另一条完全不存在于二进制中\n```\n\n**(b) 按回调返回类型选择控制流:**\n\n```cpp\nif constexpr (std::is_same_v<decltype(fn(entry)), bool>) {\n  if (!fn(entry)) { break; }  // 返回 bool -> 可提前终止\n} else {\n  fn(entry);                   // 返回 void -> 无条件执行\n}\n```\n\n**(c) 编译期递归展开多后端分派:**\n\n```cpp\ntemplate <typename First, typename... Rest>\nauto DispatchFile(const char* path, ConfigFormat format) {\n  if (First::kFormat == format)\n    return ConfigParser<First>::ParseFile(*this, path);\n  if constexpr (sizeof...(Rest) > 0)\n    return DispatchFile<Rest...>(path, format);\n  return error(ConfigError::kFormatNotSupported);\n}\n// 未启用的后端不生成任何代码\n```\n\nC 没有类型 trait 系统，无法在编译期查询类型属性并据此选择代码路径。\n\n### 7. 模板实例化 -- 参数化专用代码生成\n\nC 的 `void* + size_t` 传参让编译器丢失常量信息。模板将参数编码为类型的一部分，编译器可据此生成专用指令。\n\n```cpp\ntemplate <typename T, size_t BufferSize>\nclass SpscRingbuffer {\n  static_assert((BufferSize & (BufferSize - 1)) == 0, \"Must be power of 2\");\n  static constexpr size_t kMask = BufferSize - 1;\n  // index & kMask -> 单条 AND 立即数指令\n};\n\n// 不同实例化 -> 不同类型 -> 各自生成最优代码\nSpscRingbuffer<SensorData, 256> sensor_rb;   // 版本 A\nSpscRingbuffer<MotorCmd, 64>    motor_rb;    // 版本 B\n```\n\nC 的通用函数接收 `void*`，`index % depth` 变成运行时除法。\n\n同一机制还可做**编译期字面量长度检查**:\n\n```cpp\ntemplate <uint32_t Capacity>\nclass FixedString {\n  template <uint32_t N, typename = std::enable_if_t<(N <= Capacity + 1)>>\n  FixedString(const char (&str)[N]) noexcept : size_(N - 1) {\n    static_assert(N - 1 <= Capacity, \"String literal exceeds capacity\");\n    std::memcpy(buf_, str, N);\n  }\n};\n\nFixedString<8> name(\"too_long_string\");  // 编译失败\n```\n\nC 无法从 `const char*` 推导字面量长度并做静态断言。`strncpy` 静默截断。\n\n---\n\n## 三、内存安全 -- 编译器管理资源生命周期\n\n### 8. RAII -- 编译器自动在每条退出路径插入清理代码\n\n标准 C 没有析构函数。GCC 的 `__attribute__((cleanup))` 是非标准扩展。\n\n```cpp\n// C++: 编译器在每条退出路径自动插入析构\nauto fd = ::socket(AF_INET, SOCK_STREAM, 0);\nScopeGuard guard([fd]{ ::close(fd); });\n\nif (::connect(fd, ...) < 0) return unexpected(kConnectFailed); // 自动 close\nif (::setsockopt(...) < 0) return unexpected(kOptionFailed);   // 自动 close\nguard.release();\nreturn TcpSocket(fd);  // 成功路径，所有权转移\n```\n\n```c\n// C: 每条路径手动 close，漏一个就泄漏\nint fd = socket(AF_INET, SOCK_STREAM, 0);\nif (connect(fd, ...) < 0) { close(fd); return -1; }\nif (setsockopt(...) < 0) { return -1; }  // 忘了 close -> fd 泄漏\nreturn fd;                                // 编译器不警告\n```\n\nRAII 还保证析构顺序，可用于锁外释放资源避免死锁:\n\n```cpp\nbool Unsubscribe(const Handle& handle) noexcept {\n    Callback old;                   // 最后析构\n    {\n      std::unique_lock lock(mtx_);  // 先析构 -> 先释放锁\n      old = std::move(slot.callback);\n    }\n    // old 在锁释放后才析构，避免析构函数内部再次获取锁\n    return static_cast<bool>(old);\n}\n```\n\n### 9. Move 语义与拷贝控制\n\nC 没有语言级所有权转移，也无法禁止结构体赋值。\n\n**Move 语义** -- 零拷贝所有权转移:\n\n```cpp\nauto socket = TcpSocket::Connect(\"host\", 8080);\nauto socket2 = std::move(socket);  // 所有权转移，源对象进入已知空状态\nsocket.Send(data);  // 静态分析工具警告 use-after-move\n```\n\n```c\nint fd = connect_to(\"host\");\nint fd2 = fd;           // 复制了 fd，两处都能 close\nclose(fd);              // 关闭后 fd2 变成悬空句柄\nwrite(fd2, data, len);  // 写入已关闭的 fd -> 未定义行为\n```\n\n**拷贝删除** -- 禁止危险的复制:\n\n```cpp\nBus(const Bus&) = delete;\nBus& operator=(const Bus&) = delete;\n// C: struct Bus b2 = b1; 编译通过，两份指向同一资源\n```\n\n**expected 错误处理** -- 编译器强制检查:\n\n```cpp\nauto result = pool.CreateChecked(args...);\nauto ptr = result.value();  // 未检查 has_value() -> Debug 断言失败\n```\n\n```c\nvoid* ptr = pool_alloc(&pool);     // 返回 NULL 表示失败\nmemcpy(ptr, data, size);           // ptr == NULL -> SIGSEGV，编译器不警告\n```\n\n---\n\n## 四、类型分发 -- 编译器穷举检查\n\n### 10. variant + visit 穷举式分发与 Fold Expression\n\nC 的 `switch (msg->tag)` 缺少 `case` 只产生 `-Wswitch` 警告，且对 `void*` 载荷无效。\n\n```cpp\n// C++: 缺少任何一个 variant 类型的处理 -> 编译失败\ntemplate <class... Ts>\nstruct overloaded : Ts... { using Ts::operator()...; };\ntemplate <class... Ts>\noverloaded(Ts...) -> overloaded<Ts...>;\n\nstd::visit(overloaded{\n    [](const SensorData& d) { process(d); },\n    [](const MotorCmd& c)   { execute(c); },\n    // 缺 SystemStatus -> 编译错误，不是警告\n}, payload);\n```\n\n```c\n// C: 缺少 case -> 运行时静默丢消息\nswitch (msg->tag) {\n    case SENSOR: handle_sensor(msg->data); break;\n    case MOTOR:  handle_motor(msg->data);  break;\n    // 忘了 STATUS -> 消息丢失，可能运行数天才发现\n}\n```\n\nFold Expression 为 variant 中每个类型自动展开操作:\n\n```cpp\ntemplate <typename... Types>\nvoid SubscribeAll(std::variant<Types...>*) noexcept {\n  (MaybeSubscribe<Types>(), ...);  // 为每个类型展开一次调用\n}\n// C: 需要手动枚举或 X-Macro 生成\n```\n\n新增消息类型时，C++ 在所有未更新的 `visit` 处报编译错误，强制补全。C 的 `-Wswitch` 只是警告，经常被忽略。\n\n---\n\n## 总结\n\n| # | C++17 能力 | C11 的局限 |\n|---|-----------|-----------|\n| 1 | 编译期类型成员校验 | `void*` 无类型信息，`_Static_assert` 无法检查类型列表 |\n| 2 | 强类型别名 (NewType) | `typedef` 是别名非新类型 |\n| 3 | enum class | `enum` 隐式转 `int`，枚举值泄漏到全局 |\n| 4 | not_null 空指针拦截 | 指针永远可能为空，每处需防御性检查 |\n| 5 | constexpr 保证编译期求值 | `const` 非编译期合同，宏无法写循环 |\n| 6 | if constexpr 分支消除 | 无 type trait，无编译期分支选择 |\n| 7 | 模板参数化专用代码 | `void* + size_t` 丢失常量和类型信息 |\n| 8 | RAII 自动资源清理 | 无析构函数，`goto cleanup` 编译器不强制 |\n| 9 | Move / `= delete` / expected | 无所有权转移，无法禁止拷贝，错误码被忽略 |\n| 10 | variant + visit 穷举分发 | `switch` 缺 `case` 仅警告，`void*` 无法分发 |\n\n**本质**: C++17 让编译器掌握更多信息 -- 模板给类型和常量，`constexpr` 给求值合同，RAII 给生命周期，`variant` 给完整类型列表，`NewType` 给语义区分。信息越多，编译器能做的检查和优化就越多。C 的 `void*`、宏、手动 cleanup 在隐藏信息，编译器看到的只是指针和整数。\n",
      "ctime": "1771552523",
      "mtime": "1771552523",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/cpp_design_patterns_embedded.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857470514",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 C++17 设计模式实战: 零虚函数、零堆分配的编译期技术",
      "brief_content": "传统设计模式依赖虚函数和动态分配，在嵌入式系统中代价过高。本文基于 newosp 库的真实代码，展示 8 种编译期设计模式的实现：类型擦除替代 std::function、ScopeGuard 替代虚",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [MISRA C++设计模式改进：模板编程替代虚函数](https://blog.csdn.net/stallion5632/article/details/143805125)\n>\n> 参考实现: [newosp](https://github.com/DeguiLiu/newosp) v0.2.0 -- 工业嵌入式 C++17 Header-Only 基础设施库\n\n## 1. 为什么嵌入式需要重新审视设计模式\n\n经典设计模式（GoF）的实现通常依赖三个 C++ 特性：**虚函数**、**动态内存分配**、**异常处理**。这三者在嵌入式系统中都有显著的代价：\n\n| 特性 | 代价 | MISRA C++ 约束 |\n|------|------|----------------|\n| 虚函数 | vtable 间接跳转，阻止内联优化，需要 RTTI 支持 `dynamic_cast` | Rule 5-0-1: 限制不安全类型转换 |\n| `std::function` | 堆分配（大 callable），不可预测的拷贝开销 | 热路径禁止动态分配 |\n| `std::string` / `std::vector` | 堆分配，分配失败无法恢复（`-fno-exceptions`） | 内存碎片化风险 |\n| 异常 | 栈展开的代码体积和延迟不可控 | 许多嵌入式工具链默认关闭 |\n\nC++17 提供了足够的编译期工具来替代这些运行时机制：`if constexpr`、折叠表达式、`std::variant` + `std::visit`、结构化绑定、`constexpr` 函数等。\n\n本文基于 [newosp](https://github.com/DeguiLiu/newosp) 库中的真实代码，展示在 `-fno-exceptions -fno-rtti` 约束下如何实现零虚函数、零堆分配的设计模式。这些不是教科书示例，而是经过 979 个测试用例和 ASan/UBSan/TSan 验证的产品级实现。\n\n## 2. 类型擦除：FixedFunction 替代 std::function\n\n### 2.1 问题\n\n`std::function` 在 callable 对象超过内部 SBO 缓冲区时会触发堆分配。在嵌入式热路径（消息总线回调、定时器回调）中，这是不可接受的。\n\n### 2.2 newosp 的解决方案\n\n`FixedFunction<Sig, BufferSize>` 通过编译期 `static_assert` 强制所有 callable 必须放入固定大小的栈缓冲区，彻底消除堆分配的可能性：\n\n```cpp\ntemplate <typename Ret, typename... Args, size_t BufferSize>\nclass FixedFunction<Ret(Args...), BufferSize> final {\n public:\n  FixedFunction() noexcept = default;\n\n  // 支持 nullptr 赋值清除回调\n  FixedFunction(std::nullptr_t) noexcept {}\n\n  template <typename F, typename = typename std::enable_if<\n      !std::is_same<typename std::decay<F>::type, FixedFunction>::value &&\n      !std::is_same<typename std::decay<F>::type, std::nullptr_t>::value>::type>\n  FixedFunction(F&& f) noexcept {\n    using Decay = typename std::decay<F>::type;\n    // 编译期检查：callable 必须放得下\n    static_assert(sizeof(Decay) <= BufferSize,\n                  \"Callable too large for FixedFunction buffer\");\n    static_assert(alignof(Decay) <= alignof(Storage),\n                  \"Callable alignment exceeds buffer alignment\");\n    // placement-new 就地构造\n    ::new (&storage_) Decay(static_cast<F&&>(f));\n    // 类型擦除：无状态 lambda 作为函数指针\n    invoker_ = [](const Storage& s, Args... args) -> Ret {\n      return (*reinterpret_cast<const Decay*>(&s))(static_cast<Args&&>(args)...);\n    };\n    destroyer_ = [](Storage& s) {\n      reinterpret_cast<Decay*>(&s)->~Decay();\n    };\n  }\n\n  // const-qualified operator() -- 与 std::function 的关键区别\n  Ret operator()(Args... args) const {\n    OSP_ASSERT(invoker_);\n    return invoker_(storage_, static_cast<Args&&>(args)...);\n  }\n\n  explicit operator bool() const noexcept { return invoker_ != nullptr; }\n\n private:\n  using Storage = typename std::aligned_storage<BufferSize, alignof(void*)>::type;\n  using Invoker = Ret (*)(const Storage&, Args...);\n  using Destroyer = void (*)(Storage&);\n\n  Storage storage_{};\n  Invoker invoker_ = nullptr;\n  Destroyer destroyer_ = nullptr;\n};\n```\n\n### 2.3 设计要点\n\n**类型擦除的核心**：`invoker_` 和 `destroyer_` 是普通函数指针（非虚函数），由无状态 lambda 在构造时生成。编译器会将这些 lambda 内联为直接的函数指针，没有 vtable 开销。\n\n**const-qualified `operator()`**：`std::function::operator()` 是 non-const 的，这在 const 上下文中无法使用。`FixedFunction` 的 `operator()` 标记为 `const`，使其可以在 const 引用和 const 成员函数中调用。\n\n**`nullptr_t` 支持**：可以通过 `callback = nullptr` 清除回调，语义与原生指针一致。\n\n**编译期安全**：如果 callable 体积超过 `BufferSize`（默认 16 字节），编译直接失败。不存在\"静默退化到堆分配\"的行为。\n\n### 2.4 对比\n\n| 特性 | `std::function` | `FixedFunction` |\n|------|----------------|-----------------|\n| 堆分配 | 可能（大 callable） | 不可能（static_assert） |\n| `operator()` const | 否 | 是 |\n| `nullptr` 赋值 | 是 | 是 |\n| 异常安全 | 需要 | 不需要（noexcept） |\n| 拷贝 | 可拷贝（可能堆分配） | 仅移动 |\n| 大小 | 实现依赖（通常 32-48 B） | 用户控制（默认 16 B + 16 B 元数据） |\n\n## 3. RAII 清理：ScopeGuard 替代虚析构\n\n### 3.1 问题\n\n传统 RAII 清理通常需要定义一个带虚析构函数的基类，或者手动在每个返回点添加清理代码。\n\n### 3.2 newosp 的 ScopeGuard\n\n利用 FixedFunction 实现零虚函数的 RAII 清理守卫：\n\n```cpp\nclass ScopeGuard final {\n public:\n  explicit ScopeGuard(FixedFunction<void()> cleanup) noexcept\n      : cleanup_(static_cast<FixedFunction<void()>&&>(cleanup)),\n        active_(true) {}\n\n  ~ScopeGuard() {\n    if (active_ && cleanup_) {\n      cleanup_();\n    }\n  }\n\n  void release() noexcept { active_ = false; }\n\n  ScopeGuard(const ScopeGuard&) = delete;\n  ScopeGuard& operator=(const ScopeGuard&) = delete;\n\n  ScopeGuard(ScopeGuard&& other) noexcept\n      : cleanup_(static_cast<FixedFunction<void()>&&>(other.cleanup_)),\n        active_(other.active_) {\n    other.active_ = false;\n  }\n\n private:\n  FixedFunction<void()> cleanup_;\n  bool active_;\n};\n\n// 便捷宏：作用域退出时自动执行清理\n#define OSP_SCOPE_EXIT(...)                                             \\\n  ::osp::ScopeGuard OSP_CONCAT(_scope_guard_, __LINE__) {              \\\n    ::osp::FixedFunction<void()> { [&]() { __VA_ARGS__; } }           \\\n  }\n```\n\n使用示例：\n\n```cpp\nvoid ProcessFile() {\n  FILE* f = fopen(\"data.bin\", \"rb\");\n  if (!f) return;\n  OSP_SCOPE_EXIT(fclose(f));  // 无论如何退出，都会关闭文件\n\n  int fd = open(\"/dev/ttyS0\", O_RDWR);\n  if (fd < 0) return;         // fclose(f) 仍会执行\n  OSP_SCOPE_EXIT(close(fd));\n\n  // ... 业务逻辑 ...\n}  // 析构顺序: close(fd) -> fclose(f) (LIFO)\n```\n\n### 3.3 设计要点\n\n- **零虚函数**：清理逻辑通过 FixedFunction 捕获，析构函数直接调用，无 vtable 查表\n- **`release()` 机制**：在成功路径上调用 `release()` 取消清理，实现\"仅在失败时清理\"的语义\n- **`__LINE__` 宏**：每行生成唯一变量名，支持同一作用域内多个 ScopeGuard\n\n## 4. 编译期分发：if constexpr 替代运行时分支\n\n### 4.1 问题\n\n在泛型容器（环形缓冲区、容器 push/pop）中，trivially copyable 类型可以用 `memcpy` 高效拷贝，而非 trivially copyable 类型必须逐元素 move。传统做法是运行时 `if` 判断或模板特化，前者有分支代价，后者代码膨胀。\n\n### 4.2 newosp 的 SpscRingbuffer 中的 if constexpr\n\n```cpp\ntemplate <typename T, size_t BufferSize = 16, bool FakeTSO = false>\nclass SpscRingbuffer {\n  static constexpr bool kTriviallyCopyable =\n      std::is_trivially_copyable<T>::value;\n\n  bool Pop(T& data) noexcept {\n    const IndexT cur_tail = tail_.value.load(std::memory_order_relaxed);\n    const IndexT cur_head = head_.value.load(AcquireOrder());\n    if (cur_tail == cur_head) return false;\n\n    // 编译期选择：POD 用直接赋值，非 POD 用 move\n    if constexpr (kTriviallyCopyable) {\n      data = data_buff_[cur_tail & kMask];\n    } else {\n      data = std::move(data_buff_[cur_tail & kMask]);\n    }\n\n    tail_.value.store(cur_tail + 1, ReleaseOrder());\n    return true;\n  }\n\n  size_t PushBatch(const T* buf, size_t count) noexcept {\n    // ...\n    if constexpr (kTriviallyCopyable) {\n      // 批量 memcpy：处理环形缓冲区的回绕\n      const size_t first_part = std::min(to_write, BufferSize - head_offset);\n      std::memcpy(&data_buff_[head_offset], buf + written,\n                   first_part * sizeof(T));\n      if (to_write > first_part) {\n        std::memcpy(&data_buff_[0], buf + written + first_part,\n                     (to_write - first_part) * sizeof(T));\n      }\n    } else {\n      // 逐元素拷贝\n      for (size_t i = 0; i < to_write; ++i) {\n        data_buff_[(head_offset + i) & kMask] = buf[written + i];\n      }\n    }\n    // ...\n  }\n\n  // 内存序也通过编译期选择\n  static constexpr std::memory_order AcquireOrder() noexcept {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_acquire;\n  }\n};\n```\n\n### 4.3 与传统模板特化的对比\n\n```cpp\n// 传统做法：需要两个特化版本\ntemplate <typename T, bool Trivial>\nstruct CopyHelper;\n\ntemplate <typename T>\nstruct CopyHelper<T, true> {\n  static void copy(T* dst, const T* src, size_t n) {\n    std::memcpy(dst, src, n * sizeof(T));\n  }\n};\n\ntemplate <typename T>\nstruct CopyHelper<T, false> {\n  static void copy(T* dst, const T* src, size_t n) {\n    for (size_t i = 0; i < n; ++i) dst[i] = src[i];\n  }\n};\n\n// if constexpr 做法：一个函数体，编译器裁剪不可达分支\n// 代码更紧凑，逻辑更清晰，无需辅助类\n```\n\n`if constexpr` 的优势：未选中的分支在编译期被完全丢弃（不参与编译），即使其中引用了不存在的成员函数也不会报错。这使得一个函数模板可以同时处理多种类型约束。\n\n## 5. Tag Dispatch：构造行为的编译期选择\n\n### 5.1 问题\n\n`FixedString` 需要支持两种构造语义：编译期字面量（必须完整放入缓冲区）和运行时字符串（可以截断）。这两种行为不能用同一个构造函数参数签名区分。\n\n### 5.2 newosp 的 Tag 类型\n\n```cpp\n// 空标签类型 -- 仅用于重载决议\nstruct TruncateToCapacity_t {};\nconstexpr TruncateToCapacity_t TruncateToCapacity{};\n\ntemplate <uint32_t Capacity>\nclass FixedString {\n public:\n  // 构造方式 1: 编译期字面量 -- 超长直接编译失败\n  template <uint32_t N>\n  FixedString(const char (&str)[N]) noexcept : size_(N - 1U) {\n    static_assert(N - 1U <= Capacity,\n                  \"String literal exceeds FixedString capacity\");\n    (void)std::memcpy(buf_, str, N);\n  }\n\n  // 构造方式 2: 运行时字符串 -- Tag 标记允许截断\n  FixedString(TruncateToCapacity_t, const char* str) noexcept : size_(0U) {\n    if (str != nullptr) {\n      uint32_t i = 0U;\n      while ((i < Capacity) && (str[i] != '\\0')) {\n        buf_[i] = str[i];\n        ++i;\n      }\n      size_ = i;\n    }\n    buf_[size_] = '\\0';\n  }\n};\n\n// 使用\nFixedString<16> a(\"hello\");                          // 编译期检查\nFixedString<8> b(TruncateToCapacity, runtime_str);   // 允许截断\n// FixedString<4> c(\"hello\");                        // 编译错误！\n```\n\n### 5.3 设计要点\n\nTag Dispatch 的核心是**用类型区分语义，而非用值区分语义**。`TruncateToCapacity_t` 是一个空结构体，不占运行时空间，仅参与重载决议。这比布尔参数 `bool truncate = false` 更安全：布尔参数容易传错，而 Tag 类型在调用点必须显式写出，意图一目了然。\n\n## 6. 强类型包装：NewType 防止 ID 混用\n\n### 6.1 问题\n\n嵌入式系统中大量使用 `uint32_t` 作为各种 ID（定时器 ID、会话 ID、节点 ID）。裸 `uint32_t` 之间可以随意赋值，编译器无法检查语义错误。\n\n### 6.2 newosp 的 NewType\n\n```cpp\ntemplate <typename T, typename Tag>\nclass NewType final {\n public:\n  constexpr explicit NewType(T val) noexcept : val_(val) {}\n  constexpr T value() const noexcept { return val_; }\n\n  constexpr bool operator==(NewType rhs) const noexcept {\n    return val_ == rhs.val_;\n  }\n  constexpr bool operator!=(NewType rhs) const noexcept {\n    return val_ != rhs.val_;\n  }\n\n private:\n  T val_;\n};\n\n// 定义语义不同的 ID 类型\nstruct TimerTaskIdTag {};\nstruct SessionIdTag {};\n\nusing TimerTaskId = NewType<uint32_t, TimerTaskIdTag>;\nusing SessionId   = NewType<uint32_t, SessionIdTag>;\n\nvoid CancelTimer(TimerTaskId id);\nvoid CloseSession(SessionId id);\n\n// 使用\nTimerTaskId tid(42);\nSessionId   sid(42);\n\nCancelTimer(tid);   // OK\n// CancelTimer(sid); // 编译错误！SessionId != TimerTaskId\n// CancelTimer(42);  // 编译错误！explicit 构造\n```\n\n### 6.3 零运行时代价\n\n`NewType<uint32_t, Tag>` 在内存布局和指令生成上与裸 `uint32_t` 完全等价。Tag 类型是空结构体，不占用任何空间。编译器优化后，`NewType` 的所有操作都内联为直接的整数操作。\n\n类型安全的代价完全在编译期支付，运行时零开销。\n\n## 7. 错误处理：expected 替代异常\n\n### 7.1 问题\n\n关闭异常（`-fno-exceptions`）后，传统的错误处理退化为返回错误码。但错误码缺少类型安全：调用者可以忽略返回值，也可以用错误的类型解释返回值。\n\n### 7.2 newosp 的 expected<V, E>\n\n```cpp\ntemplate <typename V, typename E>\nclass expected final {\n public:\n  // 工厂方法：明确表达意图\n  static expected success(const V& val) noexcept {\n    expected e;\n    e.has_value_ = true;\n    ::new (&e.storage_) V(val);  // placement-new，零堆分配\n    return e;\n  }\n\n  static expected error(E err) noexcept {\n    expected e;\n    e.has_value_ = false;\n    e.err_ = err;\n    return e;\n  }\n\n  bool has_value() const noexcept { return has_value_; }\n\n  V& value() & noexcept {\n    OSP_ASSERT(has_value_);\n    return *reinterpret_cast<V*>(&storage_);\n  }\n\n  E get_error() const noexcept {\n    OSP_ASSERT(!has_value_);\n    return err_;\n  }\n\n private:\n  typename std::aligned_storage<sizeof(V), alignof(V)>::type storage_;\n  E err_;\n  bool has_value_ = false;\n};\n\n// void 特化：仅表达成功/失败，无值\ntemplate <typename E>\nclass expected<void, E> final { /* ... */ };\n```\n\n函数式链式调用：\n\n```cpp\n// and_then: 成功时继续处理，失败时短路\ntemplate <typename V, typename E, typename F>\nauto and_then(const expected<V, E>& result, F&& fn)\n    -> decltype(fn(result.value())) {\n  if (result.has_value()) {\n    return fn(result.value());\n  }\n  return decltype(fn(result.value()))::error(result.get_error());\n}\n\n// 使用\nauto result = ParseConfig(path);\nand_then(result, [](const Config& cfg) {\n  return ValidateConfig(cfg);\n});\n```\n\n## 8. 观察者 / Pub-Sub：零堆分配的消息总线\n\n### 8.1 传统观察者的问题\n\n原文中的观察者模式使用 `std::function<void(int)>` + `std::map` + `std::vector`，三个容器都可能触发堆分配。\n\n### 8.2 newosp 的 Bus/Node 实现\n\nnewosp 的消息总线用 `FixedFunction` 替代 `std::function`，用固定大小数组替代 `std::map` + `std::vector`，用 CAS 原子操作实现无锁 MPSC：\n\n```cpp\ntemplate <typename PayloadVariant,\n          uint32_t QueueDepth = 256,\n          uint32_t BatchSize = 16>\nclass AsyncBus {\n  // 回调表：固定大小，FixedFunction 替代 std::function\n  struct SubscriptionSlot {\n    FixedFunction<void(const MessageEnvelope<PayloadVariant>&)> callback;\n    std::atomic<bool> active{false};\n  };\n\n  std::array<SubscriptionSlot, kMaxSubscriptions> subscriptions_;\n\n  // CAS 无锁发布（MPSC: 多生产者单消费者）\n  bool PublishInternal(PayloadVariant&& payload, uint32_t sender_id,\n                       uint64_t timestamp_us, MessagePriority priority,\n                       uint32_t topic_hash) noexcept {\n    uint32_t prod_pos;\n    RingBufferNode* target;\n\n    do {\n      prod_pos = producer_pos_.load(std::memory_order_relaxed);\n      target = &ring_buffer_[prod_pos & kBufferMask];\n\n      uint32_t seq = target->sequence.load(std::memory_order_acquire);\n      if (seq != prod_pos) return false;  // 满了\n    } while (!producer_pos_.compare_exchange_weak(\n        prod_pos, prod_pos + 1,\n        std::memory_order_acq_rel, std::memory_order_relaxed));\n\n    // 写入消息并发布\n    target->envelope.payload = std::move(payload);\n    target->sequence.store(prod_pos + 1, std::memory_order_release);\n    return true;\n  }\n};\n\n// Node 通过 RAII 管理订阅生命周期\ntemplate <typename PayloadVariant>\nclass Node {\n  SubscriptionHandle handles_[OSP_MAX_NODE_SUBSCRIPTIONS];\n  uint32_t handle_count_ = 0;\n\n  ~Node() noexcept { Stop(); }  // 析构时自动取消所有订阅\n};\n```\n\n### 8.3 与原文观察者模式的对比\n\n| 维度 | 原文 Events<std::function> | newosp AsyncBus |\n|------|---------------------------|-----------------|\n| 回调存储 | `std::map<uint32_t, std::vector<std::function>>` | `std::array<FixedFunction, N>` |\n| 堆分配 | 3 层（map + vector + function） | 零 |\n| 线程安全 | 无 | CAS 无锁 MPSC |\n| 订阅管理 | 手动 `removeObserver(key)` | RAII（Node 析构自动取消） |\n| Topic 路由 | 无 | FNV-1a 32-bit hash |\n\n## 9. Visitor 模式：std::visit 直接分发\n\n### 9.1 问题\n\n当消息总线使用 `std::variant` 存储多种消息类型时，需要根据实际类型分发到对应的处理函数。传统做法是虚函数 + 双分派，或者 `dynamic_cast` 链。\n\n### 9.2 newosp 的 ProcessBatchWith\n\n```cpp\n// 直接分发模式：std::visit 将 Handler 内联到分发点\ntemplate <typename Visitor>\nuint32_t ProcessBatchWith(Visitor&& visitor) noexcept {\n  uint32_t processed = 0;\n\n  while (processed < kBatchSize) {\n    auto& node = ring_buffer_[cons_pos & kBufferMask];\n\n    // std::visit 编译期生成跳转表，无虚函数\n    std::visit([&visitor, &hdr](const auto& data) {\n      visitor(data, hdr);\n    }, node.envelope.payload);\n\n    ++processed;\n  }\n\n  return processed;\n}\n\n// Handler 示例：函数对象，每种类型一个 operator()\nstruct MyHandler {\n  void operator()(const SensorData& data, const MessageHeader& hdr) {\n    // 处理传感器数据\n  }\n  void operator()(const CommandMsg& cmd, const MessageHeader& hdr) {\n    // 处理控制命令\n  }\n};\n```\n\n`std::visit` 在编译期为 `std::variant` 的每种 alternative 生成一个跳转表入口。与虚函数调用相比，跳转表的优势是：编译器可以看到所有分支的完整代码，因此可以进行内联优化。\n\n## 10. CRTP + 折叠表达式：StaticNode 编译期 Handler 绑定\n\n### 10.1 问题\n\n动态回调表（`std::vector<std::function>`）需要运行时查找和间接调用。对于性能敏感的消息处理路径，这个间接层是可以消除的。\n\n### 10.2 newosp 的 StaticNode\n\n```cpp\ntemplate <typename PayloadVariant, typename Handler>\nclass StaticNode {\n  Handler handler_;  // Handler 作为模板参数，编译器可完全内联\n\n  // 折叠表达式：编译期为 variant 的每个类型注册订阅\n  template <size_t... Is>\n  bool SubscribeAll(std::index_sequence<Is...>) noexcept {\n    return (SubscribeOne<Is>() && ...);  // 短路求值\n  }\n\n  template <size_t I>\n  bool SubscribeOne() noexcept {\n    using T = std::variant_alternative_t<I, PayloadVariant>;\n\n    Handler* handler_ptr = &handler_;\n    SubscriptionHandle handle =\n        bus_ptr_->template Subscribe<T>(\n            [handler_ptr](const EnvelopeType& env) noexcept {\n              const T* data = std::get_if<T>(&env.payload);\n              if (OSP_LIKELY(data != nullptr)) {\n                (*handler_ptr)(*data, env.header);  // 编译器可内联\n              }\n            });\n    return handle.IsValid();\n  }\n\n  // 双模式分发\n  uint32_t SpinOnce() noexcept {\n    if (started_) {\n      return bus_ptr_->ProcessBatch();       // 回调表模式\n    }\n    return bus_ptr_->ProcessBatchWith(handler_);  // 直接分发模式\n  }\n};\n```\n\n### 10.3 设计要点\n\n**Handler 模板参数化**：`Handler` 不是基类指针，而是模板参数。编译器在实例化 `StaticNode<PayloadVariant, MyHandler>` 时，可以看到 `MyHandler::operator()` 的完整定义，因此可以内联到消息处理的热路径中。\n\n**`std::index_sequence` + 折叠表达式**：`SubscribeAll` 在编译期展开为 N 次 `SubscribeOne<0>() && SubscribeOne<1>() && ...`，N 是 `PayloadVariant` 中的类型数量。这是编译期循环的标准技术。\n\n**双模式分发**：`SpinOnce()` 根据是否调用过 `Start()` 选择分发路径。直接分发模式（`ProcessBatchWith`）跳过回调表，让 `std::visit` 直接将事件分发给 Handler，最大化内联机会。\n\n## 11. 策略模式：编译期内存序选择\n\n### 11.1 问题\n\n无锁数据结构在不同硬件平台上需要不同的内存序。x86 的 TSO 模型保证了 store-load 顺序，ARM 则需要显式的 acquire/release 屏障。单核 MCU 甚至可以用 relaxed + signal_fence 替代硬件屏障。\n\n### 11.2 newosp 的编译期策略\n\n```cpp\ntemplate <typename T, size_t BufferSize, bool FakeTSO = false>\nclass SpscRingbuffer {\n  // 策略：内存序通过 constexpr 函数在编译期确定\n  static constexpr std::memory_order AcquireOrder() noexcept {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_acquire;\n  }\n\n  static constexpr std::memory_order ReleaseOrder() noexcept {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_release;\n  }\n};\n\n// x86/ARM Linux: 正常内存序\nusing NormalQueue = SpscRingbuffer<Msg, 256, false>;\n\n// 单核 MCU: relaxed + signal_fence，省掉硬件 DMB\nusing McuQueue = SpscRingbuffer<Msg, 256, true>;\n```\n\n同样的策略模式也用于平台相关的 CPU 让步指令：\n\n```cpp\nstatic void CpuRelax() noexcept {\n#if defined(__x86_64__) || defined(__i386__)\n  __builtin_ia32_pause();\n#elif defined(__aarch64__) || defined(__arm__)\n  asm volatile(\"yield\" ::: \"memory\");\n#else\n  std::this_thread::yield();\n#endif\n}\n```\n\n## 12. 总结：模式选择速查表\n\n| 传统模式 | 传统实现 | newosp 替代 | 核心技术 |\n|----------|---------|------------|---------|\n| 回调/委托 | `std::function` + 堆分配 | `FixedFunction` | 类型擦除 + SBO + placement-new |\n| RAII 清理 | 虚析构基类 | `ScopeGuard` | FixedFunction + `__LINE__` 宏 |\n| 泛型容器操作 | 模板特化 / 运行时 if | `if constexpr` | 编译期分支裁剪 |\n| 构造重载 | 布尔参数 / 枚举 | Tag Dispatch | 空结构体类型参与重载决议 |\n| ID 类型安全 | `typedef` / `using`（无保护） | `NewType<T, Tag>` | 空 Tag 类型区分语义 |\n| 错误处理 | 异常 / 错误码 | `expected<V, E>` | 判别联合 + 工厂方法 |\n| 观察者 | `std::map<std::vector<std::function>>` | `AsyncBus` | CAS 无锁 + FixedFunction |\n| 分发 | 虚函数 / `dynamic_cast` | `std::visit` | 编译期跳转表 |\n| Handler 绑定 | 回调表 + 间接调用 | `StaticNode<Handler>` | CRTP + 折叠表达式 + 内联 |\n| 策略选择 | 虚函数 / 继承 | `constexpr` 模板参数 | 编译期策略确定 |\n\n这些模式的共同特征：\n\n1. **零虚函数**：所有分发在编译期确定或通过函数指针完成\n2. **零堆分配**：`FixedFunction`、`FixedString`、`FixedVector`、`expected` 全部栈分配\n3. **`-fno-exceptions -fno-rtti` 兼容**：不依赖异常和运行时类型信息\n4. **编译期安全**：`static_assert` 在编译时捕获尺寸/对齐/类型错误\n5. **可测试**：979 个 Catch2 测试用例 + ASan/UBSan/TSan 全绿\n\n参考实现: [newosp](https://github.com/DeguiLiu/newosp) -- MIT 协议开源，header-only，可直接在嵌入式项目中使用。\n",
      "ctime": "1771552526",
      "mtime": "1771552526",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/pimpl_modern_cpp_embedded.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853668362",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "PIMPL 的三种现代实现: 从堆分配到栈内联",
      "brief_content": "PIMPL 是 C++ 中最经典的编译隔离手段，但教科书只展示了 unique_ptr 一种实现。本文对比三种 C++14 兼容的 PIMPL 实现 -- Heap PIMPL、Fast PIMPL ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 适用标准: C++14 及以上 | 原始案例: [C++ PIMPL 机制](https://blog.csdn.net/stallion5632/article/details/125603112)\n\n---\n\n## 1. PIMPL 解决什么问题\n\n一个头文件的私有成员变更，导致所有包含它的编译单元重新编译:\n\n```cpp\n// sensor.h -- v1\nclass Sensor {\npublic:\n    float Read();\nprivate:\n    int fd_;           // 文件描述符\n    float calibration_; // 校准系数\n};\n```\n\n`Sensor` 的 `sizeof` 编码在每个 `#include \"sensor.h\"` 的编译单元中。新增一个私有成员:\n\n```cpp\n// sensor.h -- v2: 新增 filter_buffer_\nclass Sensor {\n    // ...\nprivate:\n    int fd_;\n    float calibration_;\n    float filter_buffer_[16];  // 新增: 滑动窗口滤波\n};\n```\n\n`sizeof(Sensor)` 从 8 字节变为 72 字节。所有依赖 `sensor.h` 的 `.cpp` 必须重编，即使它们只调用 `Read()` 而从未接触私有成员。\n\nPIMPL 的核心思路: 将私有成员移到一个前向声明的类中，头文件只暴露一个指针，`sizeof` 永远不变。\n\n下面对比三种实现方式。\n\n---\n\n## 2. 方式一: Heap PIMPL (std::unique_ptr)\n\n最经典的实现，也是原文介绍的方式。\n\n### 2.1 头文件\n\n```cpp\n// sensor.h\n#ifndef SENSOR_H_\n#define SENSOR_H_\n#include <memory>\n\nclass Sensor {\npublic:\n    Sensor();\n    ~Sensor();\n\n    // 支持移动，禁止拷贝\n    Sensor(Sensor&&) noexcept;\n    Sensor& operator=(Sensor&&) noexcept;\n\n    float Read();\n\nprivate:\n    struct Impl;\n    std::unique_ptr<Impl> impl_;\n};\n#endif\n```\n\n### 2.2 实现文件\n\n```cpp\n// sensor.cpp\n#include \"sensor.h\"\n\nstruct Sensor::Impl {\n    int fd_ = -1;\n    float calibration_ = 1.0f;\n    float filter_buffer_[16] = {};\n\n    float DoRead() {\n        // 实际读取 + 滤波逻辑\n        return 0.0f;\n    }\n};\n\nSensor::Sensor() : impl_(new Impl()) {}\nSensor::~Sensor() = default;\nSensor::Sensor(Sensor&&) noexcept = default;\nSensor& Sensor::operator=(Sensor&&) noexcept = default;\n\nfloat Sensor::Read() { return impl_->DoRead(); }\n```\n\n### 2.3 关键细节\n\n**析构函数必须在 .cpp 中定义**。`unique_ptr<Impl>` 的析构需要 `Impl` 的完整定义。如果在头文件中使用编译器生成的默认析构，会因 `Impl` 不完整而编译失败:\n\n```\nerror: invalid application of 'sizeof' to incomplete type 'Sensor::Impl'\n```\n\n这也是为什么必须显式声明 `~Sensor()` 并在 `.cpp` 中 `= default`。移动构造/赋值同理。\n\n**拷贝语义需要手动实现**。如果需要拷贝，必须在 `.cpp` 中深拷贝 `Impl`:\n\n```cpp\nSensor::Sensor(const Sensor& other)\n    : impl_(other.impl_ ? new Impl(*other.impl_) : nullptr) {}\n```\n\n### 2.4 成本分析\n\n| 维度 | 成本 |\n|------|------|\n| 构造 | 一次 `operator new` (~50-200ns，取决于分配器) |\n| 每次调用 | 一次指针解引用 (~1-5ns，取决于缓存命中) |\n| 内存 | 对象本身 8B (指针) + 堆上 Impl 大小 + 分配器元数据 (~16-32B) |\n| 缓存 | Sensor 和 Impl 在不同内存位置，首次访问必然 cache miss |\n\n对于生命周期长、调用频率低的对象 (如设备驱动、配置管理器)，这些成本可以忽略。但对于高频创建销毁的小对象，堆分配成为瓶颈。\n\n---\n\n## 3. 方式二: Fast PIMPL (栈内联存储)\n\n核心思想: 在对象内部预留一块对齐的原始存储，用 placement new 在其中构造 `Impl`，避免堆分配。\n\n### 3.1 头文件\n\n```cpp\n// sensor.h\n#ifndef SENSOR_H_\n#define SENSOR_H_\n#include <cstddef>\n#include <cstdint>\n#include <new>\n#include <type_traits>\n\nclass Sensor {\npublic:\n    Sensor();\n    ~Sensor();\n\n    Sensor(const Sensor&) = delete;\n    Sensor& operator=(const Sensor&) = delete;\n\n    float Read();\n\nprivate:\n    struct Impl;\n\n    // 预留存储: 大小和对齐必须 >= Impl 的实际值\n    // 这两个常量是 Fast PIMPL 的\"契约\"\n    static constexpr std::size_t kImplSize  = 80;\n    static constexpr std::size_t kImplAlign = 8;\n\n    typename std::aligned_storage<kImplSize, kImplAlign>::type storage_;\n\n    Impl* Self() noexcept {\n        return static_cast<Impl*>(static_cast<void*>(&storage_));\n    }\n    const Impl* Self() const noexcept {\n        return static_cast<const Impl*>(static_cast<const void*>(&storage_));\n    }\n};\n#endif\n```\n\n### 3.2 实现文件\n\n```cpp\n// sensor.cpp\n#include \"sensor.h\"\n#include <cassert>\n\nstruct Sensor::Impl {\n    int fd_ = -1;\n    float calibration_ = 1.0f;\n    float filter_buffer_[16] = {};\n\n    float DoRead() { return 0.0f; }\n};\n\n// 编译期校验: 预留空间必须足够\nstatic_assert(sizeof(Sensor::Impl) <= Sensor::kImplSize,\n              \"kImplSize too small for Impl\");\nstatic_assert(alignof(Sensor::Impl) <= Sensor::kImplAlign,\n              \"kImplAlign too small for Impl\");\n\nSensor::Sensor() {\n    new (&storage_) Impl();  // placement new，零堆分配\n}\n\nSensor::~Sensor() {\n    Self()->~Impl();  // 显式析构\n}\n\nfloat Sensor::Read() { return Self()->DoRead(); }\n```\n\n### 3.3 关键细节\n\n**kImplSize 的维护问题**。这是 Fast PIMPL 最大的实践痛点。`Impl` 的大小变化时，必须同步更新头文件中的 `kImplSize`。如果忘记更新，`static_assert` 会在编译 `.cpp` 时报错，但不会在其他编译单元报错 -- 这正是编译防火墙的意义。\n\n**确定 kImplSize 的方法**:\n\n```cpp\n// 在 sensor.cpp 中临时添加，编译一次获取实际大小\n#pragma message(\"sizeof(Impl) = \" + std::to_string(sizeof(Impl)))\n```\n\n或者更实用的做法 -- 预留一个合理的上界并加注释:\n\n```cpp\n// sizeof(Impl) 当前 = 72, 预留 80 应对未来扩展\nstatic constexpr std::size_t kImplSize = 80;\n```\n\n**移动语义需要手动实现**。不能使用 `= default`，因为编译器不知道 `storage_` 中存放的是什么:\n\n```cpp\nSensor::Sensor(Sensor&& other) noexcept {\n    new (&storage_) Impl(std::move(*other.Self()));\n}\n```\n\n### 3.4 成本分析\n\n| 维度 | 成本 |\n|------|------|\n| 构造 | placement new，无系统调用 (~5-10ns) |\n| 每次调用 | 与直接成员访问相同 (Impl 在对象内部，同一 cache line) |\n| 内存 | 对象本身包含 Impl 存储，无额外分配器元数据 |\n| 缓存 | Sensor 和 Impl 连续存储，cache 友好 |\n\n**代价**: 头文件中暴露了 `kImplSize`，这是一个\"弱耦合\" -- 大小变化需要更新头文件，但不会暴露 `Impl` 的内部结构。实际项目中，`Impl` 大小稳定后很少变动，这个代价可以接受。\n\n### 3.5 与 Heap PIMPL 的编译隔离对比\n\n| 场景 | Heap PIMPL | Fast PIMPL |\n|------|-----------|------------|\n| Impl 新增成员 (大小不变) | 仅重编 .cpp | 仅重编 .cpp |\n| Impl 新增成员 (大小超限) | 仅重编 .cpp | 需更新 kImplSize，触发全量重编 |\n| Impl 方法签名变更 | 仅重编 .cpp | 仅重编 .cpp |\n| 公共接口变更 | 全量重编 | 全量重编 |\n\nFast PIMPL 在大小稳定时提供与 Heap PIMPL 相同的编译隔离，同时消除堆分配。\n\n---\n\n## 4. 方式三: 函数指针表 PIMPL (C 风格 Opaque + C++ 封装)\n\n这种方式借鉴 C 语言的 opaque pointer 模式和 Linux 内核的 `file_operations` 结构体，用函数指针表替代虚函数，实现零 RTTI 开销的运行时多态。\n\n### 4.1 头文件\n\n```cpp\n// sensor.h\n#ifndef SENSOR_H_\n#define SENSOR_H_\n#include <cstdint>\n\nclass Sensor {\npublic:\n    // 操作表: 类似 Linux file_operations\n    struct Ops {\n        float (*read)(void* ctx);\n        void  (*destroy)(void* ctx);\n    };\n\n    // 从外部注入实现 (工厂函数创建)\n    Sensor(void* ctx, const Ops* ops) noexcept\n        : ctx_(ctx), ops_(ops) {}\n\n    ~Sensor() {\n        if (ops_ && ops_->destroy) ops_->destroy(ctx_);\n    }\n\n    // 禁止拷贝，允许移动\n    Sensor(const Sensor&) = delete;\n    Sensor& operator=(const Sensor&) = delete;\n\n    Sensor(Sensor&& other) noexcept\n        : ctx_(other.ctx_), ops_(other.ops_) {\n        other.ctx_ = nullptr;\n        other.ops_ = nullptr;\n    }\n\n    Sensor& operator=(Sensor&& other) noexcept {\n        if (this != &other) {\n            if (ops_ && ops_->destroy) ops_->destroy(ctx_);\n            ctx_ = other.ctx_;\n            ops_ = other.ops_;\n            other.ctx_ = nullptr;\n            other.ops_ = nullptr;\n        }\n        return *this;\n    }\n\n    float Read() { return ops_->read(ctx_); }\n\n    // 工厂函数: 创建具体实现\n    static Sensor CreateAdc(int channel);\n    static Sensor CreateI2c(uint8_t addr);\n\nprivate:\n    void* ctx_;        // opaque 上下文指针\n    const Ops* ops_;   // 操作表 (静态生命周期)\n};\n#endif\n```\n\n### 4.2 实现文件\n\n```cpp\n// sensor_adc.cpp\n#include \"sensor.h\"\n\nnamespace {\n\nstruct AdcContext {\n    int channel;\n    float calibration;\n    float buffer[16];\n};\n\nfloat AdcRead(void* ctx) {\n    auto* adc = static_cast<AdcContext*>(ctx);\n    // ADC 读取 + 滤波\n    return adc->calibration * 3.3f;\n}\n\nvoid AdcDestroy(void* ctx) {\n    delete static_cast<AdcContext*>(ctx);\n}\n\nconst Sensor::Ops kAdcOps = {AdcRead, AdcDestroy};\n\n}  // namespace\n\nSensor Sensor::CreateAdc(int channel) {\n    auto* ctx = new AdcContext{channel, 1.0f, {}};\n    return Sensor(ctx, &kAdcOps);\n}\n```\n\n```cpp\n// sensor_i2c.cpp\n#include \"sensor.h\"\n\nnamespace {\n\nstruct I2cContext {\n    uint8_t addr;\n    int fd;\n};\n\nfloat I2cRead(void* ctx) {\n    auto* i2c = static_cast<I2cContext*>(ctx);\n    // I2C 读取\n    return 0.0f;\n}\n\nvoid I2cDestroy(void* ctx) {\n    delete static_cast<I2cContext*>(ctx);\n}\n\nconst Sensor::Ops kI2cOps = {I2cRead, I2cDestroy};\n\n}  // namespace\n\nSensor Sensor::CreateI2c(uint8_t addr) {\n    auto* ctx = new I2cContext{addr, -1};\n    return Sensor(ctx, &kI2cOps);\n}\n```\n\n### 4.3 关键细节\n\n**操作表是 `const` 静态对象**。`kAdcOps` 和 `kI2cOps` 在 `.rodata` 段，不占堆内存，不需要析构。每个 `Sensor` 实例只存储两个指针 (16B)。\n\n**支持运行时多态，无需虚函数**。不同的工厂函数返回不同的操作表，调用 `Read()` 时通过函数指针分发。与虚函数的区别:\n\n| 维度 | 虚函数 | 函数指针表 |\n|------|--------|-----------|\n| RTTI 依赖 | 需要 (`-fno-rtti` 下受限) | 不需要 |\n| 内存布局 | 对象头部隐含 vptr | 显式 `ops_` 成员 |\n| 间接调用成本 | 一次间接跳转 | 一次间接跳转 (相同) |\n| 新增操作 | 修改基类虚函数表 (ABI 破坏) | 扩展 Ops 结构体 (可向后兼容) |\n| 编译隔离 | 需要包含基类头文件 | 只需前向声明 Ops |\n\n**ABI 稳定性**。在 `Ops` 末尾新增函数指针不会破坏已有的二进制兼容性，这是 C 语言 API 设计的经典技巧 (Linux 内核、SQLite、OpenSSL 均采用此模式)。\n\n### 4.4 成本分析\n\n| 维度 | 成本 |\n|------|------|\n| 构造 | 一次 `new` (与 Heap PIMPL 相同) |\n| 每次调用 | 一次函数指针间接调用 (~2-5ns) |\n| 内存 | 对象 16B (两个指针) + 堆上 Context |\n| 编译隔离 | 完全隔离: Context 定义在 .cpp 的匿名命名空间中 |\n| 多态 | 支持运行时多态，无 RTTI |\n\n**也可以结合 Fast PIMPL 消除堆分配**: 将 `void* ctx_` 替换为内联存储，但会失去运行时多态能力 (因为不同实现的 Context 大小不同)。\n\n---\n\n## 5. 三种方式对比\n\n### 5.1 量化对比\n\n| 维度 | Heap PIMPL | Fast PIMPL | 函数指针表 |\n|------|-----------|------------|-----------|\n| C++ 标准 | C++11 | C++11 | C++11 |\n| 堆分配 | 每次构造 1 次 | 零 | 每次构造 1 次 |\n| sizeof(外壳) | 8B (指针) | kImplSize | 16B (两个指针) |\n| 调用开销 | 指针解引用 | 直接访问 | 函数指针跳转 |\n| 缓存友好 | 差 (两次内存访问) | 好 (连续存储) | 差 (两次内存访问) |\n| 编译隔离 | 完全 | 大小变化时破坏 | 完全 |\n| 运行时多态 | 不支持 | 不支持 | 支持 |\n| ABI 稳定性 | 好 | 大小变化时破坏 | 最好 (可扩展 Ops) |\n| 实现复杂度 | 低 | 中 | 中 |\n\n### 5.2 选型决策\n\n```\n需要运行时多态 (同一接口多种实现)?\n├── 是 → 函数指针表 PIMPL\n│        (替代虚函数，兼容 -fno-rtti)\n└── 否 → 对象是否高频创建/销毁?\n         ├── 是 → Fast PIMPL\n         │        (零堆分配，cache 友好)\n         └── 否 → Heap PIMPL\n                  (最简单，编译隔离最彻底)\n```\n\n### 5.3 实际项目中的选择参考\n\n| 场景 | 推荐方式 | 理由 |\n|------|---------|------|\n| 设备驱动 (生命周期 = 进程) | Heap PIMPL | 构造一次，简单优先 |\n| 消息信封 (每秒百万级创建) | Fast PIMPL | 堆分配是瓶颈 |\n| 传感器抽象 (ADC/I2C/SPI) | 函数指针表 | 需要运行时选择后端 |\n| 配置解析器 | Heap PIMPL | 启动时构造一次 |\n| 网络连接对象 (连接池) | Fast PIMPL | 频繁创建/回收 |\n| 插件系统 / 动态库接口 | 函数指针表 | ABI 稳定性最重要 |\n\n---\n\n## 6. 补充: 常见陷阱\n\n### 6.1 Heap PIMPL 忘记在 .cpp 定义析构函数\n\n```cpp\n// sensor.h\nclass Sensor {\n    struct Impl;\n    std::unique_ptr<Impl> impl_;\npublic:\n    Sensor();\n    // 忘记声明 ~Sensor() → 编译器在头文件中生成默认析构\n    // → unique_ptr<Impl>::~unique_ptr() 需要 sizeof(Impl)\n    // → 编译错误: incomplete type\n};\n```\n\n修复: 在头文件中声明 `~Sensor();`，在 `.cpp` 中 `= default`。\n\n### 6.2 Fast PIMPL 的 kImplSize 过小\n\n`static_assert` 只在编译 `.cpp` 时触发。如果只改了 `Impl` 但没重编 `.cpp` (增量构建缓存)，可能出现运行时内存越界。\n\n防御措施: CI 中始终 clean build，或在 CMake 中将 `kImplSize` 的校验作为独立编译单元。\n\n### 6.3 函数指针表的 void* 类型安全\n\n`void*` 丢失了类型信息。错误的 `static_cast` 会导致未定义行为且难以调试。\n\n防御措施: 在 Debug 模式下给 Context 加一个 magic number 校验:\n\n```cpp\nstruct AdcContext {\n    static constexpr uint32_t kMagic = 0xADC00001;\n    uint32_t magic = kMagic;\n    // ...\n};\n\nfloat AdcRead(void* ctx) {\n    auto* adc = static_cast<AdcContext*>(ctx);\n    assert(adc->magic == AdcContext::kMagic);\n    // ...\n}\n```\n\n---\n\n## 7. 总结\n\nPIMPL 不只有 `unique_ptr` 一种写法。三种实现各有适用场景:\n\n- **Heap PIMPL**: 最简单，编译隔离最彻底，适合低频长生命周期对象\n- **Fast PIMPL**: 零堆分配，cache 友好，适合高频创建的值语义对象\n- **函数指针表**: 支持运行时多态且 ABI 稳定，适合替代虚函数的场景\n\n三种方式均兼容 C++14，不依赖异常和 RTTI，可直接用于 `-fno-exceptions -fno-rtti` 的嵌入式环境。\n\n选型的核心判据只有两个: **是否需要运行时多态**和**是否在热路径上频繁构造**。其他情况下，Heap PIMPL 的简单性就是最大的优势。\n\n---\n\n**测试环境**: Linux 6.8.0, GCC 13.3.0 / Clang 18, C++14 模式\n",
      "ctime": "1771552529",
      "mtime": "1771552529",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "pattern/smart_pointer_pitfalls_embedded.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267193894",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 C++ 智能指针的五个陷阱与零堆分配替代方案",
      "brief_content": "std::shared_ptr 和 std::weak_ptr 在桌面开发中是安全的默认选择，但在嵌入式实时系统中会引入原子引用计数开销、堆碎片化、不确定延迟和竞态条件等问题。本文从一个 weak_p",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 基础设施库: [newosp](https://github.com/DeguiLiu/newosp) v0.4.0 (1114 tests, ASan/TSan/UBSan clean)\n>\n> 目标平台: ARM-Linux (Cortex-A53/A72/A7) | C++17, Header-only\n>\n> 原始案例: [C++ 智能指针失效分析](https://blog.csdn.net/stallion5632/article/details/140479753)\n\n---\n\n## 1. 引子: 一个 weak_ptr 竞态 Bug\n\n以下是一个典型的生产者-消费者事件队列，队列中存储 `std::weak_ptr` 以避免循环引用:\n\n```cpp\nclass EventQueue {\n  std::queue<std::pair<Event, std::weak_ptr<void>>> events_;\n  std::mutex mtx_;\n\n  void consume_events(std::function<void(Event, std::shared_ptr<void>)> callback) {\n    std::unique_lock<std::mutex> lck(mtx_);\n    while (true) {\n      cv_.wait(lck, [this] { return !events_.empty() || stop_; });\n\n      auto event_item = events_.front();\n      events_.pop();\n      lck.unlock();  // 释放锁以允许其他线程推送事件\n\n      // BUG: weak_ptr::lock() 在无锁保护下执行\n      // 此时其他线程可能已销毁最后一个 shared_ptr\n      callback(event_item.first, event_item.second.lock());\n\n      lck.lock();\n    }\n  }\n};\n```\n\n问题出在 `lck.unlock()` 和 `event_item.second.lock()` 之间: 释放互斥锁后，生产者线程中持有的 `std::shared_ptr` 可能已经析构，`weak_ptr::lock()` 返回空指针，导致回调函数访问无效数据。\n\n原作者给出的修复方案是在持锁期间调用 `lock()`:\n\n```cpp\n// 修复: 在持锁时提升 weak_ptr\nif (const auto& shared = event_item.second.lock()) {\n    callback(event_item.first, shared);\n}\n```\n\n这个修复是正确的，但它暴露了一个更深层的架构问题: **在嵌入式事件系统中使用 `shared_ptr` / `weak_ptr` 本身就是错误的设计选择**。\n\n---\n\n## 2. 五个根本陷阱\n\n### 陷阱 1: 原子引用计数的隐性开销\n\n`std::shared_ptr` 的引用计数使用 `std::atomic<long>` 实现。每次拷贝、赋值、析构都触发原子操作:\n\n```cpp\n// libstdc++ 简化实现\nclass _Sp_counted_base {\n  _Atomic_word _M_use_count;   // 强引用计数\n  _Atomic_word _M_weak_count;  // 弱引用计数\n\n  void _M_add_ref_copy() {\n    __gnu_cxx::__atomic_add_dispatch(&_M_use_count, 1);  // 原子加\n  }\n\n  void _M_release() {\n    if (__gnu_cxx::__exchange_and_add_dispatch(&_M_use_count, -1) == 1) {\n      _M_dispose();     // 销毁管理对象\n      if (__gnu_cxx::__exchange_and_add_dispatch(&_M_weak_count, -1) == 1) {\n        _M_destroy();   // 销毁控制块\n      }\n    }\n  }\n};\n```\n\n在 ARM Cortex-A53 上，每次 `__atomic_add` 编译为 `ldaxr` + `stlxr` + 重试循环 (LL/SC)。在多核竞争下，单次原子操作耗时从 ~5 ns 膨胀到 ~50 ns。\n\n**根因**: `shared_ptr` 的设计目标是通用场景的安全性，它必须支持任意线程在任意时刻拷贝和销毁。这种灵活性的代价是每次操作都要经过原子读-改-写 (RMW) 路径，即使在单线程使用场景下也无法消除。\n\n> 关于 ARM 平台原子操作的硬件实现，参见 Preshing 的 [An Introduction to Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)，其中详细解释了 Load-Link/Store-Conditional (LL/SC) 机制和 CAS 循环。\n\n**实际影响**: 在 100 Hz 帧率的激光雷达 Pipeline 中，假设每帧经过 6 个 stage，每个 stage 拷贝一次 `shared_ptr` (入队) + 析构一次 (出队) = 12 次原子操作/帧。100 Hz x 12 = 1200 次/秒，看似不多。但如果 stage 内部将 `shared_ptr` 传递给子函数或临时存储，拷贝次数会迅速膨胀到数万次/秒。在多核竞争下，LL/SC 重试会产生不可预测的延迟尖峰。\n\n### 陷阱 2: 控制块的堆分配与碎片化\n\n每个 `shared_ptr` 管理的对象都有一个控制块 (control block)，存储引用计数和删除器:\n\n```cpp\n// std::make_shared 合并分配 (一次 malloc)\nauto p = std::make_shared<Event>();  // sizeof(控制块) + sizeof(Event), 一次 malloc\n\n// std::shared_ptr<T>(new T) 分离分配 (两次 malloc)\nauto p = std::shared_ptr<Event>(new Event());  // Event 一次 + 控制块一次\n```\n\n即使使用 `make_shared` 合并分配，仍然是一次 `malloc` 调用。在嵌入式系统中，`malloc` 的问题不是速度，而是**碎片化**:\n\n```\n初始堆:  [████████████████████████████████] 64 KB free\n\n分配释放 10000 次后:\n         [██░░██░██░░░██░██░░██░░░██░██░░]\n          ^ 碎片      ^ 碎片      ^ 碎片\n\n此时 malloc(4096) 可能失败，即使总空闲 > 4096\n```\n\n**根因**: 通用堆分配器 (glibc malloc / dlmalloc) 为了支持任意大小的分配请求，使用 bin/arena/chunk 结构。频繁的小块分配-释放会产生外部碎片。嵌入式系统的 RAM 通常在 64 KB ~ 512 MB 之间，碎片化会直接导致内存耗尽。\n\n### 陷阱 3: weak_ptr 竞态窗口\n\n引子中的 bug 是 `weak_ptr` 的固有设计问题。`weak_ptr::lock()` 的语义是: \"如果管理对象还存在，返回一个 `shared_ptr`; 否则返回空\"。这个操作本身是线程安全的 (原子地检查并增加引用计数)，但它的结果与程序逻辑之间存在 TOCTOU (Time-of-Check to Time-of-Use) 窗口:\n\n```\n线程 A (消费者)              线程 B (生产者/所有者)\n─────────────               ──────────────────\nlck.unlock()\n                             shared_ptr 离开作用域\n                             引用计数 → 0\n                             ~Event() 析构\nweak.lock() → nullptr!\ncallback(nullptr)  → UB\n```\n\n**根因**: `weak_ptr` 的设计假设是 \"观察者不拥有对象\"。但在事件队列中，消费者需要在处理期间拥有数据的所有权。用 `weak_ptr` 传递所有权是语义错误 -- 它是观察工具，不是传输机制。\n\n> 关于 TOCTOU 竞态和内存可见性问题，Preshing 在 [Memory Barriers Are Like Source Control Operations](https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/) 中用源码管理系统类比解释了多线程内存交互中的可见性延迟。\n\n### 陷阱 4: std::function 的堆逃逸\n\n上面的事件队列使用 `std::function<void(Event, std::shared_ptr<void>)>` 作为回调类型。`std::function` 内部也有类似 `shared_ptr` 的问题:\n\n```cpp\n// libstdc++ 简化实现\nclass function<R(Args...)> {\n  union _Any_data {\n    void* _M_access;\n    char _M_pod_data[sizeof(void*) * 3];  // SBO: 24 bytes (x86-64)\n  };\n\n  _Any_data _M_functor;\n  _Manager_type _M_manager;  // 虚函数表指针 (类型擦除)\n\n  // 如果 callable 大于 24 字节 → 堆分配\n  template<typename Fn>\n  void _M_init_functor(_Any_data& __f, Fn&& __fn) {\n    if constexpr (sizeof(Fn) <= sizeof(_Any_data)) {\n      ::new (&__f._M_pod_data) Fn(std::forward<Fn>(__fn));  // SBO\n    } else {\n      __f._M_access = new Fn(std::forward<Fn>(__fn));  // 堆分配!\n    }\n  }\n};\n```\n\n关键问题:\n\n1. **SBO 阈值不可控**: libstdc++ 的 SBO 通常为 24 字节 (3 个指针)，捕获 3 个以上变量的 lambda 就会堆逃逸，且没有编译期警告\n2. **虚函数调用**: 类型擦除通过 `_M_manager` 虚表指针实现，每次调用多一次间接跳转\n3. **拷贝开销**: `std::function` 可拷贝，每次拷贝可能触发堆分配 (复制被擦除的 callable)\n\n**根因**: `std::function` 的设计目标是 \"存储任意可调用对象\"。这种通用性需要运行时多态 (虚函数/类型擦除) 和动态内存 (大 callable 堆分配)。嵌入式系统需要的是编译期已知大小、不分配内存的回调容器。\n\n### 陷阱 5: 异常路径的不确定性\n\n`shared_ptr` 和 `std::function` 在异常开启时会增加额外的清理路径:\n\n```cpp\n// shared_ptr 析构时如果 use_count == 1，调用删除器\n// 如果删除器抛出异常 → std::terminate\n~shared_ptr() noexcept {\n  if (_M_pi && _M_pi->_M_release()) {\n    // 调用 deleter\n  }\n}\n```\n\n在 `-fno-exceptions` 编译模式下 (嵌入式常见)，`shared_ptr` 仍然工作，但错误处理变成了 `std::terminate` 或未定义行为。而且 RTTI (运行时类型信息) 通常也被禁用 (`-fno-rtti`)，这使得 `std::function` 的类型擦除机制可能出现问题。\n\n**根因**: C++ 标准库的智能指针和函数对象设计于桌面/服务器环境，假设异常和 RTTI 可用。嵌入式编译选项 (`-fno-exceptions -fno-rtti`) 切断了这些假设，迫使开发者在标准库的 \"安全\" API 和嵌入式的编译约束之间进行权衡。\n\n---\n\n## 3. newosp 的替代方案\n\nnewosp 是为 ARM-Linux 嵌入式平台设计的 C++17 header-only 基础设施库。它遵循一个核心原则:\n\n> **栈优先分配，热路径禁止堆分配。** -- newosp 设计文档\n\n| 原则 | 说明 |\n|------|------|\n| 栈优先分配 | 固定容量容器，热路径禁止堆分配 |\n| 无锁或最小锁 | MPSC 无锁总线，SPSC 无锁队列，SharedMutex 读写分离 |\n| 编译期分发 | 模板特化、标签分发、`if constexpr` 替代虚函数 |\n| 类型安全 | `expected<V,E>` 错误处理，`NewType<T,Tag>` 强类型，`std::variant` 消息路由 |\n| 嵌入式友好 | 兼容 `-fno-exceptions -fno-rtti`，固定宽度整数，缓存行对齐 |\n\n以下是 newosp 对五个陷阱的逐一替代方案。\n\n### 3.1 ObjectPool: 替代 shared_ptr + new\n\n**陷阱 1 + 2 的解决方案**: 用 O(1) 固定块池替代 `shared_ptr` + 堆分配。\n\n```cpp\n// newosp: ObjectPool -- 编译期固定大小，O(1) 分配，零碎片\ntemplate <typename T, uint32_t MaxObjects>\nclass ObjectPool {\n  FixedPool<sizeof(T), MaxObjects> pool_;   // 内嵌存储，无 malloc\n  bool alive_[MaxObjects] = {};             // 存活位图\n\n public:\n  // O(1) 分配: 从 free list 头部取块 + placement new\n  template <typename... Args>\n  T* Create(Args&&... args) {\n    void* mem = pool_.Allocate();           // 跟随 free_head 指针，无搜索\n    if (!mem) return nullptr;\n    return ::new (mem) T(std::forward<Args>(args)...);\n  }\n\n  // O(1) 释放: 析构 + 归还 free list\n  void Destroy(T* obj) {\n    obj->~T();                              // 显式析构\n    pool_.Free(obj);                        // 归还到 free list 头部\n  }\n\n  // 安全版本: 返回 expected 而非裸指针\n  template <typename... Args>\n  expected<T*, MemPoolError> CreateChecked(Args&&... args);\n};\n```\n\nFixedPool 的内部结构:\n\n```\n┌────────────────────────────────────────────┐\n│ FixedPool<256, 64>  (内嵌 16 KB 存储)       │\n│                                            │\n│ free_head_ → [0] → [1] → [2] → ... → [63] │\n│              ↑                              │\n│              block_size = max(256, align)   │\n│                                            │\n│ Allocate(): head=0, free_head_=1, return &[0]│\n│ Free([0]):  [0].next=free_head_, free_head_=0│\n└────────────────────────────────────────────┘\n```\n\n**对比**:\n\n| 操作 | shared_ptr + new | ObjectPool |\n|------|-----------------|------------|\n| 分配 | malloc (不确定延迟) | O(1) free list pop |\n| 释放 | atomic decrement + free | O(1) free list push |\n| 碎片化 | 随运行时间增长 | **零** (等块大小) |\n| 并发开销 | 原子引用计数 (LL/SC 竞争) | mutex (冷路径) 或无锁 (热路径) |\n| 内存预算 | 不可预测 | **编译期确定** (sizeof(T) x MaxObjects) |\n| 失败模式 | bad_alloc 异常 / OOM kill | `CreateChecked()` 返回 `expected` |\n\n**事件队列重写** -- 替代引子中的 `shared_ptr<void>` 方案:\n\n```cpp\nstruct Event { uint32_t id; /* ... */ };\n\n// 固定池: 预分配 256 个 Event，零堆分配\nosp::ObjectPool<Event, 256> event_pool;\n\n// SPSC 环形缓冲: 传递池索引，不传递指针/智能指针\nstruct EventHandle {\n  uint16_t pool_index;\n  uint32_t event_id;\n};\nosp::SpscRingbuffer<EventHandle, 256> event_queue;\n\n// 生产者: 分配 + 入队\nvoid producer() {\n  auto result = event_pool.CreateChecked(42);\n  if (result.has_value()) {\n    Event* evt = result.value();\n    uint16_t idx = /* pool index */;\n    event_queue.Push(EventHandle{idx, evt->id});\n  }\n}\n\n// 消费者: 出队 + 处理 + 释放\nvoid consumer() {\n  if (auto* handle = event_queue.Peek()) {\n    Event& evt = pool_ref(handle->pool_index);\n    process(evt);                      // 直接访问，无 lock() 竞态\n    event_queue.Discard();\n    event_pool.Destroy(&evt);          // 确定性释放\n  }\n}\n```\n\n**关键区别**: 没有 `weak_ptr::lock()` 竞态窗口。Handle 持有的池索引在 Destroy 之前始终有效，而 Destroy 只由最后一个消费者显式调用。所有权语义清晰: 生产者 Create，消费者 Destroy，SPSC 保证顺序。\n\n### 3.2 FixedFunction: 替代 std::function\n\n**陷阱 4 的解决方案**: 编译期固定大小的可调用对象容器。\n\n```cpp\n// newosp: FixedFunction -- SBO 永不逃逸到堆\ntemplate <typename Ret, typename... Args, size_t BufferSize>\nclass FixedFunction<Ret(Args...), BufferSize> final {\n  using Storage = typename std::aligned_storage<BufferSize, alignof(void*)>::type;\n  using Invoker = Ret (*)(const Storage&, Args...);\n  using Destroyer = void (*)(Storage&);\n\n  Storage storage_{};             // 内联存储 (栈上)\n  Invoker invoker_ = nullptr;     // 调用器 (函数指针，非虚函数)\n  Destroyer destroyer_ = nullptr; // 析构器 (函数指针)\n\n public:\n  template <typename F>\n  FixedFunction(F&& f) noexcept {\n    using Decay = typename std::decay<F>::type;\n    // 编译期断言: 超大 callable 直接报错，不会静默堆分配\n    static_assert(sizeof(Decay) <= BufferSize,\n                  \"Callable too large for FixedFunction buffer\");\n    ::new (&storage_) Decay(static_cast<F&&>(f));  // placement new\n    invoker_ = [](const Storage& s, Args... args) -> Ret {\n      return (*reinterpret_cast<const Decay*>(&s))(static_cast<Args&&>(args)...);\n    };\n  }\n};\n```\n\n**对比**:\n\n| 特性 | std::function | FixedFunction |\n|------|--------------|---------------|\n| SBO 大小 | ~24B (实现定义，不可配置) | **模板参数** (默认 16B，Bus 用 32B) |\n| 超大 callable | 静默堆分配 | **static_assert 编译报错** |\n| 调用方式 | 虚函数表 (_M_manager) | **函数指针** (直接跳转) |\n| 拷贝 | 深拷贝 (可能堆分配) | **move-only** |\n| -fno-exceptions | 部分支持 | **完全兼容** |\n| -fno-rtti | 可能出问题 | **完全兼容** |\n\n**在 AsyncBus 中的使用**:\n\n```cpp\n// newosp AsyncBus: 回调使用 FixedFunction<void(const Envelope&), 32>\nstatic constexpr size_t kCallbackBufSize = 4 * sizeof(void*);  // 32B\nusing CallbackType = FixedFunction<void(const EnvelopeType&), kCallbackBufSize>;\n\n// 订阅时，lambda 直接 placement new 到 32B 栈缓冲中\n// 捕获 1-2 个指针 (16B) 完全在 SBO 内\nbus.Subscribe<SensorData>([this](const auto& envelope) {\n  process(std::get<SensorData>(envelope.payload));\n});\n```\n\n如果 lambda 捕获超过 32 字节，编译器会在 `Subscribe` 调用处报 `static_assert` 错误，而不是在运行时静默分配堆内存。\n\n### 3.3 ScopeGuard: 替代 unique_ptr 的自定义删除器\n\n**陷阱 5 的解决方案**: 轻量级 RAII 清理器。\n\n使用 `unique_ptr` 管理非指针资源 (文件描述符、锁、硬件寄存器) 需要自定义删除器，语法笨拙且有虚调用开销:\n\n```cpp\n// 传统方案: unique_ptr + 自定义删除器\nstruct FdDeleter { void operator()(int* fd) { close(*fd); delete fd; } };\nstd::unique_ptr<int, FdDeleter> fd(new int(open(\"/dev/spi0\", O_RDWR)));\n// 问题: 1) 必须堆分配 int 2) 删除器类型侵入模板参数\n```\n\nnewosp 的 `ScopeGuard` 使用 `FixedFunction` 存储清理逻辑:\n\n```cpp\n// newosp: ScopeGuard -- 零堆分配 RAII\nclass ScopeGuard final {\n  FixedFunction<void()> cleanup_;   // 16B SBO\n  bool active_;\n\n public:\n  explicit ScopeGuard(FixedFunction<void()> cleanup) noexcept\n      : cleanup_(static_cast<FixedFunction<void()>&&>(cleanup)),\n        active_(true) {}\n\n  ~ScopeGuard() {\n    if (active_ && cleanup_) {\n      cleanup_();\n    }\n  }\n\n  void release() noexcept { active_ = false; }  // 取消清理\n};\n\n// 便捷宏\n#define OSP_SCOPE_EXIT(...)                                              \\\n  ::osp::ScopeGuard _scope_guard_ {                                     \\\n    ::osp::FixedFunction<void()> { [&]() { __VA_ARGS__; } }            \\\n  }\n```\n\n使用示例:\n\n```cpp\n// 文件描述符管理: 零堆分配\nint fd = open(\"/dev/spi0\", O_RDWR);\nOSP_SCOPE_EXIT(close(fd));\n\n// 硬件寄存器恢复\nuint32_t old_cfg = read_reg(GPIO_CFG);\nwrite_reg(GPIO_CFG, new_cfg);\nOSP_SCOPE_EXIT(write_reg(GPIO_CFG, old_cfg));\n\n// 可选释放: 成功时不清理\nauto guard = osp::ScopeGuard(FixedFunction<void()>{[&] { rollback(); }});\nif (commit_success) {\n  guard.release();  // 成功，不回滚\n}\n```\n\n**对比 unique_ptr**:\n\n| 特性 | unique_ptr + Deleter | ScopeGuard |\n|------|---------------------|------------|\n| 管理对象 | 指针类型 (T*) | **任意操作** (lambda) |\n| 删除器 | 侵入模板参数 | **lambda capture** |\n| 堆分配 | Deleter 可能堆分配 | **零** (FixedFunction SBO) |\n| 灵活性 | 只能管理指针 | fd / reg / lock / rollback |\n\n### 3.4 expected: 替代异常\n\n**陷阱 5 的解决方案**: 值类型的错误传播。\n\n```cpp\n// newosp: expected<V, E> -- 内联存储，零堆分配\ntemplate <typename V, typename E>\nclass expected final {\n  typename std::aligned_storage<sizeof(V), alignof(V)>::type storage_;\n  E err_;\n  bool has_value_;\n\n public:\n  static expected success(V&& val) noexcept;\n  static expected error(E err) noexcept;\n\n  bool has_value() const noexcept;\n  V& value() noexcept;\n  E get_error() const noexcept;\n};\n```\n\n使用模式:\n\n```cpp\n// 传统方案: 异常\ntry {\n  auto* buf = allocate_buffer(4096);\n  process(buf);\n} catch (const std::bad_alloc& e) {\n  handle_oom();\n}\n\n// newosp: expected -- 编译期强制错误处理\nauto result = pool.CreateChecked(frame_id, data);\nif (!result.has_value()) {\n  // 编译期可见的错误路径\n  log_error(result.get_error());  // MemPoolError::kPoolExhausted\n  return;\n}\nprocess(result.value());\n```\n\n**优势**:\n\n- 兼容 `-fno-exceptions`: 错误处理完全在类型系统中\n- 零分配: 成功值和错误码都内联存储\n- 调用者无法忽略错误: 必须检查 `has_value()` 才能访问 `value()`\n\n### 3.5 函数指针 + context: 替代虚基类\n\n在事件队列的回调场景中，传统方案通常使用虚基类:\n\n```cpp\n// 传统方案: 虚基类 + unique_ptr\nclass IEventHandler {\n public:\n  virtual ~IEventHandler() = default;\n  virtual void OnEvent(const Event& e) = 0;\n};\n\nclass ConcreteHandler : public IEventHandler {\n  void OnEvent(const Event& e) override { /* ... */ }\n};\n\nqueue.SetHandler(std::make_unique<ConcreteHandler>());  // 堆分配\n```\n\nnewosp 使用函数指针 + context 替代:\n\n```cpp\n// newosp: 函数指针 + void* context\nusing EventCallback = void (*)(const Event& e, void* ctx);\n\nstruct EventHandler {\n  EventCallback fn = nullptr;\n  void* ctx = nullptr;\n\n  void Invoke(const Event& e) const noexcept {\n    if (fn) fn(e, ctx);\n  }\n};\n\n// 使用\nvoid on_sensor_data(const Event& e, void* ctx) {\n  auto* pipeline = static_cast<Pipeline*>(ctx);\n  pipeline->process(e);\n}\n\nhandler.fn = on_sensor_data;\nhandler.ctx = &pipeline;\n```\n\n| 特性 | 虚基类 + unique_ptr | 函数指针 + context |\n|------|-------------------|-------------------|\n| 堆分配 | make_unique 分配 | **零** |\n| 调用开销 | vtable 间接跳转 (~5 ns) | **直接调用** (~1 ns) |\n| 类型 | 多态 (RTTI 依赖) | **trivial** (可 memcpy) |\n| constexpr | 不可能 | **可以** |\n| -fno-rtti | vtable 受影响 | **完全兼容** |\n\n---\n\n## 4. AsyncBus: 一个完整的替代案例\n\n将引子中的事件队列用 newosp 组件完全重写:\n\n```cpp\n#include \"osp/bus.hpp\"\n#include \"osp/node.hpp\"\n#include \"osp/platform.hpp\"\n\n// 1. 类型安全的事件定义 (替代 void*)\nstruct SensorEvent   { uint32_t id; float value; };\nstruct ControlEvent  { uint32_t id; uint8_t cmd; };\n\nusing Payload = std::variant<SensorEvent, ControlEvent>;\nusing Bus = osp::AsyncBus<Payload>;\n\n// 2. 节点: 编译期绑定 Handler (替代 std::function 回调)\nstruct SensorHandler {\n  void operator()(const SensorEvent& e, const osp::MessageHeader& hdr) {\n    // 编译期分发，可内联\n    process_sensor(e.id, e.value);\n  }\n  void operator()(const ControlEvent& e, const osp::MessageHeader& hdr) {\n    apply_control(e.cmd);\n  }\n};\n\nosp::StaticNode<Payload, SensorHandler> node(\n    \"sensor\", 1, SensorHandler{});\n\n// 3. 发布: variant 类型安全 (替代 weak_ptr<void>)\nauto& bus = Bus::Instance();\nbus.Publish(SensorEvent{42, 3.14f}, /*sender_id=*/1);\n// 编译期检查: Publish(UnknownType{}) → 编译错误\n\n// 4. 消费: ProcessBatchWith 直接分发 (替代 function + lock + weak_ptr::lock)\nSensorHandler handler;\nbus.ProcessBatchWith(handler);\n// 无 mutex, 无 weak_ptr 竞态, 无堆分配\n```\n\n**对比引子中的方案**:\n\n| 维度 | 原始方案 (CSDN) | newosp 方案 |\n|------|----------------|------------|\n| 事件传递 | `weak_ptr<void>` + lock() | `std::variant` 值语义 |\n| 类型安全 | `void*` 强转 | 编译期 variant 检查 |\n| 回调存储 | `std::function` (可能堆分配) | FixedFunction SBO (32B, 编译期断言) |\n| 同步 | mutex + condition_variable | lock-free MPSC CAS |\n| 竞态风险 | weak_ptr::lock() TOCTOU | **无** (值拷贝，无引用悬挂) |\n| 异常依赖 | bad_alloc / terminate | expected + -fno-exceptions |\n| 堆分配 | shared_ptr 控制块 + function callable | **零** |\n\n---\n\n## 5. 嵌入式场景的智能指针使用建议\n\n完全避免智能指针不现实，以下是嵌入式 C++ 中的实用决策矩阵:\n\n### 5.1 何时可以用 unique_ptr\n\n- 初始化阶段 (非热路径) 的一次性资源分配\n- 所有权语义明确的单一持有者场景\n- 对象生命周期与作用域完全一致\n\n```cpp\n// 可接受: 启动时分配，生命周期 = 进程\nauto config = std::make_unique<SystemConfig>();\nconfig->Load(\"/etc/sensor.ini\");\n// config 在整个进程生命周期内有效\n```\n\n### 5.2 何时禁止用 shared_ptr\n\n- 实时热路径 (每帧/每消息都经过的代码)\n- 多线程高频传递 (原子引用计数竞争)\n- 内存受限系统 (控制块碎片化)\n- 事件队列 (用值传递或 Handle 替代)\n\n### 5.3 替代方案决策树\n\n```\n需要管理资源生命周期?\n├── 单一所有者?\n│   ├── 热路径? → ObjectPool + Handle 传递\n│   └── 冷路径? → unique_ptr 或 ScopeGuard\n├── 多消费者共享?\n│   ├── 编译期已知消费者数量? → ObjectPool + 引用位图\n│   └── 运行时动态? → shared_ptr (仅限冷路径)\n└── 临时清理?\n    └── ScopeGuard / OSP_SCOPE_EXIT\n```\n\n### 5.4 嵌入式内存管理的四个原则\n\n1. **编译期确定内存预算**: 所有容器容量、池大小、缓冲区长度在编译期通过模板参数固定。运行时 `malloc` 失败不是 \"异常\"，而是设计缺陷。\n\n2. **所有权语义在类型中表达**: 用 `ObjectPool::Create()` / `Destroy()` 显式标注所有权转移，而非隐式的引用计数增减。代码审查时能直接看到 \"谁分配，谁释放\"。\n\n3. **零堆分配热路径**: 消息传递、回调调用、状态转换等每帧都执行的代码路径中，不允许出现 `malloc` / `new` / `shared_ptr` 拷贝。\n\n4. **失败路径编译期可见**: 用 `expected<V, E>` 替代异常。调用者必须处理 `MemPoolError::kPoolExhausted` 等错误，编译器强制检查。\n\n---\n\n## 6. 总结\n\n| 陷阱 | 根因 | newosp 替代 |\n|------|------|------------|\n| 原子引用计数 | shared_ptr 为通用多线程设计 | ObjectPool O(1) 固定块 |\n| 堆碎片化 | malloc 支持任意大小分配 | 编译期固定容量，内嵌存储 |\n| weak_ptr 竞态 | 观察者语义误用为传输 | 值传递 / Handle + SPSC |\n| std::function 堆逃逸 | SBO 阈值不可控 | FixedFunction static_assert |\n| 异常路径不确定 | 标准库假设异常可用 | expected + -fno-exceptions |\n\n智能指针在桌面 C++ 中是合理的默认选择，但在嵌入式实时系统中，它们引入的不确定性 (原子竞争、堆碎片、TOCTOU) 恰好违反了实时系统最核心的约束: **确定性**。newosp 通过编译期固定内存预算、placement new 管理对象生命周期、函数指针替代虚分发，在保持 C++17 类型安全的同时消除了这些不确定性。\n\n---\n\n## 参考\n\n- [newosp GitHub](https://github.com/DeguiLiu/newosp) -- C++17 header-only 嵌入式基础设施库\n- [newosp 设计文档](https://github.com/DeguiLiu/newosp/blob/main/docs/design_zh.md) -- 完整架构设计\n- [C++ 智能指针失效分析](https://blog.csdn.net/stallion5632/article/details/140479753) -- weak_ptr 竞态案例\n- [An Introduction to Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/) -- Lock-free 编程入门 (Jeff Preshing)\n- [Memory Barriers Are Like Source Control Operations](https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/) -- 内存屏障与多核可见性 (Jeff Preshing)\n- [Double-Checked Locking is Fixed in C++11](https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/) -- C++11 内存模型与 DCLP (Jeff Preshing)\n- [Memory Ordering at Compile Time](https://preshing.com/20120625/memory-ordering-at-compile-time/) -- 编译器重排序与屏障 (Jeff Preshing)\n- [C++ and the Perils of Double-Checked Locking](http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf) -- Scott Meyers & Andrei Alexandrescu\n- [Is Parallel Programming Hard, And, If So, What Can You Do About It?](https://kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html) -- Paul McKenney\n",
      "ctime": "1771552532",
      "mtime": "1771552532",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/arm_linux_lock_contention_benchmark.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853684746",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "ARM-Linux 锁竞争性能实测: Spinlock/Mutex/ConcurrentQueue 对比",
      "brief_content": "本文通过严格的基准测试方法，对比多线程高竞争场景下三种同步策略的性能表现：自旋锁 (atomic_flag)、互斥锁 (std::mutex) 和无锁队列 (moodycamel::Concurren",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 本文通过严格的基准测试方法，对比多线程高竞争场景下三种同步策略的性能表现：自旋锁 (atomic_flag)、互斥锁 (std::mutex) 和无锁队列 (moodycamel::ConcurrentQueue)。\n>\n> 相关文章:\n> - [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/) -- 生产环境的锁竞争定位方法\n> - [嵌入式系统死锁防御: 从有序锁到无锁架构](../deadlock_prevention/) -- 从架构层面消除锁问题\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- 无锁数据结构的理论基础\n> - [多线程死锁与优先级反转实战](../deadlock_priority_inversion_practice/) -- 锁使用不当的典型问题\n>\n> 完整测试代码: [lock-contention-benchmark](https://gitee.com/liudegui/lock-contention-benchmark)\n\n## 1. 背景\n\n多线程数据共享是嵌入式系统的核心问题。常见的同步策略有三类：\n\n| 策略 | 机制 | 适用场景 |\n|------|------|----------|\n| Spinlock | atomic_flag TAS + pause/yield | 短临界区、线程数 <= 核心数 |\n| Mutex | OS futex (Linux) | 长临界区、线程数 > 核心数 |\n| Lock-free Queue | CAS 原子操作 | MPMC 生产者-消费者模型 |\n\n一个常见的误区是将 `std::atomic_flag` 自旋锁称为\"无锁\"。自旋锁本质上仍然是锁 -- 它通过忙等待 (busy-wait) 获取互斥访问权，只是不经过 OS 调度器。真正的 lock-free 数据结构（如 ConcurrentQueue）保证至少一个线程能在有限步内完成操作，不存在互斥等待。\n\n## 2. 旧测试的问题\n\n此前的测试代码存在多个方法论缺陷，导致结果不可信：\n\n| 问题 | 影响 |\n|------|------|\n| Push/Pop 数量不匹配 | 30 线程各 push 10K = 300K 条；30 线程各 pop 333 = 9,990 条。Pop 仅消费 3.3%，Pop 时间完全失真 |\n| CMake 变量名错误 | 检查 `COMPILER_SUPPORTS_CXX14` 但 if 判断 `COMPILER_SUPPORTS_CXX11`，C++ 标准未生效 |\n| Debug 构建 (-O0) | 基准测试在无优化模式下运行，结果无参考价值 |\n| 无 warmup | 第一个测试承受 CPU cache 冷启动惩罚 |\n| 单次运行 | 无法评估方差，结果不可重复 |\n| 无线程同步起跑 | 线程创建有先后，不是同时开始竞争 |\n| Spinlock 无 pause 指令 | 自旋循环浪费 CPU 流水线资源 |\n| std::list 容器 | 每次 push 触发堆分配，测的是\"锁 + 分配器\"混合开销 |\n| try_dequeue 返回值未检查 | ConcurrentQueue 可能空转 |\n| 编译器可能优化掉结果 | dequeue 的值未使用，编译器可能消除整个循环 |\n\n## 3. 改进后的测试方法\n\n### 3.1 测试参数\n\n```\nThreads:         8\nItems/thread:    50,000\nTotal items:     400,000 (push 和 pop 数量严格相等)\nWarmup rounds:   2 (结果丢弃)\nMeasured rounds: 5 (报告 min/median/max)\nSmallItem:       80 bytes (int32_t[20])\nLargeItem:       4096 bytes (int32_t[1024])\n```\n\n### 3.2 关键改进\n\n**线程同步起跑**: 使用原子 Barrier，所有线程就绪后同时开始竞争：\n\n```cpp\nclass Barrier {\n public:\n    explicit Barrier(int32_t count) : threshold_(count), count_(count), gen_(0) {}\n\n    void wait() {\n        uint32_t my_gen = gen_.load(std::memory_order_relaxed);\n        if (--count_ == 0) {\n            count_ = threshold_;\n            gen_.fetch_add(1, std::memory_order_release);\n        } else {\n            while (gen_.load(std::memory_order_acquire) == my_gen) {\n                spin_pause();\n            }\n        }\n    }\n};\n```\n\n**Spinlock 加 pause 提示**: 减少自旋时的流水线浪费：\n\n```cpp\ninline void spin_pause() {\n#if defined(__x86_64__) || defined(_M_X64) || defined(__i386__) || defined(_M_IX86)\n    __builtin_ia32_pause();\n#elif defined(__aarch64__) || defined(__arm__)\n    asm volatile(\"yield\" ::: \"memory\");\n#endif\n}\n```\n\n**编译器屏障**: 防止编译器优化掉 dequeue 结果：\n\n```cpp\ntemplate <typename T>\ninline void do_not_optimize(const T& val) {\n    asm volatile(\"\" : : \"r,m\"(val) : \"memory\");\n}\n```\n\n**容器统一为 std::deque**: 隔离锁竞争成本，避免 `std::list` 的逐元素堆分配干扰。\n\n**ConcurrentQueue 使用 ProducerToken/ConsumerToken**: 利用 per-thread token 获得最佳吞吐。\n\n## 4. 测试结果\n\n### 4.1 测试环境\n\n```\nCPU:      AMD Ryzen 7 5800H (8 cores / 16 threads) @ 3.2GHz\nRAM:      32GB DDR4\nOS:       Ubuntu 24.04, Linux 6.8.0-79-generic x86_64\nCompiler: GCC 13.3.0, -O2 -DNDEBUG\n```\n\n### 4.2 SmallItem (80 bytes)\n\n| 同步策略 | Push min | Push median | Push max | Pop min | Pop median | Pop max |\n|----------|----------|-------------|----------|---------|------------|---------|\n| Spinlock + deque | 136.85 ms | 144.45 ms | 150.62 ms | 114.25 ms | 123.02 ms | 128.10 ms |\n| Mutex + deque | 154.14 ms | 178.89 ms | 186.68 ms | 198.58 ms | 211.40 ms | 215.61 ms |\n| ConcurrentQueue | 2.78 ms | 2.98 ms | 3.33 ms | 4.08 ms | 4.25 ms | 5.07 ms |\n\n吞吐量换算 (基于 median, 400K items):\n\n| 同步策略 | Push ops/s | Pop ops/s |\n|----------|-----------|-----------|\n| Spinlock + deque | 2.77M | 3.25M |\n| Mutex + deque | 2.24M | 1.89M |\n| ConcurrentQueue | **134.2M** | **94.1M** |\n\n### 4.3 LargeItem (4096 bytes)\n\n| 同步策略 | Push min | Push median | Push max | Pop min | Pop median | Pop max |\n|----------|----------|-------------|----------|---------|------------|---------|\n| Spinlock + deque | 1.584 s | 1.631 s | 1.659 s | 261.05 ms | 268.85 ms | 286.62 ms |\n| Mutex + deque | 2.591 s | 2.693 s | 2.713 s | 461.52 ms | 477.66 ms | 587.43 ms |\n| ConcurrentQueue | 267.54 ms | 283.93 ms | 288.31 ms | 47.03 ms | 48.53 ms | 54.17 ms |\n\n吞吐量换算 (基于 median, 400K items):\n\n| 同步策略 | Push ops/s | Pop ops/s |\n|----------|-----------|-----------|\n| Spinlock + deque | 245K | 1.49M |\n| Mutex + deque | 149K | 837K |\n| ConcurrentQueue | **1.41M** | **8.24M** |\n\n## 5. 分析\n\n### 5.1 ConcurrentQueue 为何全面碾压\n\nConcurrentQueue 在所有场景下都领先 1-2 个数量级，原因：\n\n1. **无互斥等待**: CAS 操作失败后立即重试，不存在线程阻塞或自旋等待\n2. **预分配内存块**: 内部使用 block-based 分配，避免每次 enqueue 的堆分配\n3. **Per-thread token**: ProducerToken 让每个生产者写入独立的 block，消除 false sharing\n4. **批量内存管理**: 内部以 block 为单位分配/回收，摊薄分配器开销\n\n### 5.2 Spinlock vs Mutex\n\n在本测试条件下 (8 线程 / 8 核心)，spinlock 全面优于 mutex：\n\n| 场景 | Spinlock 优势 |\n|------|--------------|\n| SmallItem Push | 快 ~19% |\n| SmallItem Pop | 快 ~42% |\n| LargeItem Push | 快 ~39% |\n| LargeItem Pop | 快 ~44% |\n\n原因分析：\n- **临界区短**: push/pop 操作本身很快（memcpy + 指针调整），锁持有时间短\n- **线程数 = 核心数**: 每个线程独占一个核心，自旋不会抢占其他线程的 CPU 时间\n- **Mutex 的 futex 开销**: 在高竞争下，mutex 频繁进入内核态 (futex wait/wake)，上下文切换成本显著\n\n### 5.3 Spinlock 的适用边界\n\nSpinlock 并非总是更优。以下场景应优先选择 mutex：\n\n| 场景 | 原因 |\n|------|------|\n| 线程数 >> 核心数 | 自旋线程占用 CPU，阻止持锁线程运行，导致 lock convoy |\n| 临界区包含 I/O | 持锁时间不可预测，自旋浪费大量 CPU 周期 |\n| 优先级反转风险 | mutex 支持优先级继承协议 (PI)，spinlock 不支持 |\n| 需要公平性 | spinlock 无 FIFO 保证，可能导致线程饥饿 |\n\n### 5.4 数据大小的影响\n\n对比 SmallItem (80B) 和 LargeItem (4096B) 的 push median：\n\n| 同步策略 | 80B -> 4096B | 放大倍数 |\n|----------|-------------|---------|\n| Spinlock | 144 ms -> 1631 ms | 11.3x |\n| Mutex | 179 ms -> 2693 ms | 15.0x |\n| ConcurrentQueue | 2.98 ms -> 284 ms | 95.3x |\n\n数据变大 51 倍，但耗时增长远超线性。原因是大数据 memcpy 增加了临界区持有时间，加剧了锁竞争。ConcurrentQueue 的放大倍数最高，因为它的基线极低 (2.98 ms)，大数据场景下 memcpy 成为主要瓶颈而非同步开销。\n\n## 6. 结论与建议\n\n| 场景 | 推荐方案 |\n|------|---------|\n| MPMC 生产者-消费者队列 | ConcurrentQueue (性能领先 1-2 个数量级) |\n| 短临界区、线程数 <= 核心数 | Spinlock (比 mutex 快 20-40%) |\n| 长临界区、线程数 > 核心数、需要公平性 | std::mutex |\n| RTOS 环境、有优先级反转风险 | mutex + 优先级继承 |\n\n对于嵌入式 ARM-Linux 平台，如果业务模型是多线程数据交换，ConcurrentQueue 是首选。如果需要保护共享状态（非队列场景），在核心数充足时优先考虑 spinlock。\n\n## 7. 参考\n\n- [moodycamel::ConcurrentQueue](https://github.com/cameron314/concurrentqueue)\n- [C++ atomic_flag](https://en.cppreference.com/w/cpp/atomic/atomic_flag)\n- [std::mutex](https://en.cppreference.com/w/cpp/thread/mutex)\n- [Futex overview (Linux man page)](https://man7.org/linux/man-pages/man7/futex.7.html)\n",
      "ctime": "1771552535",
      "mtime": "1771552535",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/arm_linux_network_optimization.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038404646",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "ARM-Linux 网络性能优化实战: 从中断到零拷贝的全链路调优",
      "brief_content": "面向 ARM-Linux 嵌入式系统的网络性能优化系统指南。从数据包接收全链路出发，覆盖 CPU 频率管理、中断亲和性与分流（RSS/RPS/RFS）、NAPI 轮询、Ring Buffer 调优、协",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [嵌入式Linux的网络吞吐量优化](https://blog.csdn.net/stallion5632/article/details/143636884)\n>\n> 参考:\n> - [Linux Network Performance Ultimate Guide](https://ntk148v.github.io/posts/linux-network-performance-ultimate-guide/)\n> - [Monitoring and Tuning the Linux Networking Stack](https://blog.packagecloud.io/monitoring-tuning-linux-networking-stack-receiving-data/)\n> - [Linux Kernel: Scaling in the Networking Stack](https://docs.kernel.org/networking/scaling.html)\n> - [ARM: Optimize Network Interrupt Handling on Arm Servers](https://learn.arm.com/learning-paths/servers-and-cloud-computing/irq-tuning-guide/patterns/)\n> - [Red Hat: Network Performance Tuning Guide](https://access.redhat.com/sites/default/files/attachments/20150325_network_performance_tuning.pdf)\n\n## 1. 数据包接收全链路概览\n\n优化网络性能的前提是理解数据包从网卡到应用层的完整路径。以下是 Linux 接收侧（RX）的关键阶段：\n\n```\nNIC Hardware\n    |\n    | DMA write to Ring Buffer (pre-allocated sk_buff)\n    |\n    v\nHardIRQ (driver ISR)\n    |\n    | napi_schedule() -- 触发 SoftIRQ\n    |\n    v\nSoftIRQ (NET_RX_SOFTIRQ)\n    |\n    | NAPI poll: driver->poll() 批量收包\n    | GRO 聚合\n    |\n    v\nnetif_receive_skb()\n    |\n    | RPS/RFS 分发到目标 CPU\n    |\n    v\nProtocol Stack (IP -> UDP/TCP)\n    |\n    | Socket Buffer (sk->sk_receive_queue)\n    |\n    v\nApplication (recvmsg / read)\n```\n\n每个阶段都可能成为瓶颈。优化的核心原则是：**减少每个阶段的 CPU 开销，减少数据拷贝次数，减少跨 CPU 缓存失效**。\n\n## 2. CPU 频率管理\n\nARM 处理器普遍支持动态电压频率调节（DVFS）。默认的 `ondemand` 或 `schedutil` 调速器在网络 I/O 密集场景下存在问题：**网络中断和协议处理属于 I/O 密集型负载，但 CPU 利用率指标可能不高，导致调速器不升频**。\n\n### 2.1 问题表现\n\n`ondemand` 调速器仅观察 CPU 负载（`%busy`），不考虑 I/O 等待。网络收包主要在 SoftIRQ 上下文执行，CPU 利用率统计可能不准确。结果：CPU 运行在低频率下处理网络包，吞吐量受限。\n\n在 ARM Cortex-A 系列上，这个问题尤为突出，因为 ARM SoC 的频率范围通常很宽（如 408 MHz ~ 1.8 GHz），低频与高频之间的性能差距达 4x 以上。\n\n### 2.2 优化方案\n\n```bash\n# 查看当前调速器\ncat /sys/devices/system/cpu/cpu0/cpufreq/scaling_governor\n\n# 设置为 performance 模式（锁定最高频率）\necho performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n\n# 永久生效（systemd 系统）\n# 在 /etc/rc.local 或 udev 规则中设置\n```\n\n### 2.3 ARM 特有说明\n\n现代 ARM 处理器（Cortex-A7/A53/A72）具备良好的时钟门控（clock gating）机制。实测表明：\n\n- **空闲功耗差异极小**：Cortex-A7 在 408 MHz 和 1008 MHz 空闲时功耗几乎相同\n- **\"Race to idle\" 策略有效**：高频快速完成任务后进入 WFI（Wait For Interrupt）低功耗状态，总能耗可能更低\n\n因此，**对于非电池供电的嵌入式设备，`performance` 调速器是网络密集场景的推荐选项**。\n\n**副作用**：电池供电设备需要评估功耗影响。可折中使用 `ondemand` 并设置 `io_is_busy=1`：\n\n```bash\necho 1 > /sys/devices/system/cpu/cpufreq/ondemand/io_is_busy\n```\n\n## 3. 中断优化\n\n网络中断是整个接收路径的起点。默认配置下，中断处理效率低下是 ARM-Linux 网络性能的首要瓶颈。\n\n### 3.1 中断合并（Interrupt Coalescing）\n\n默认情况下，每个数据包触发一次硬中断。在高流量场景下，每秒数十万次中断会耗尽 CPU 资源。\n\n```bash\n# 查看当前合并参数\nethtool -c eth0\n\n# 设置合并参数：每 50us 或每 64 个帧触发一次中断\nethtool -C eth0 rx-usecs 50 rx-frames 64\n\n# 启用自适应合并（驱动自动调整）\nethtool -C eth0 adaptive-rx on\n```\n\n**吞吐量 vs 延迟权衡**：\n\n| 参数 | 高吞吐量场景 | 低延迟场景 |\n|------|------------|-----------|\n| `rx-usecs` | 50-100 | 0-10 |\n| `rx-frames` | 64-256 | 1-16 |\n| `adaptive-rx` | on | off |\n\n**ARM 注意事项**：ARM SoC 上的以太网控制器（如 Marvell mvneta、Allwinner EMAC）通常只有一个 RX 队列，中断合并对这类设备尤为重要。关闭自适应模式（AIC）在某些场景下反而能提供更稳定的性能。\n\n### 3.2 中断亲和性（IRQ Affinity）\n\n将网络中断绑定到特定 CPU 核心，避免在多核之间随机迁移导致的缓存失效。\n\n```bash\n# 查看网卡中断号\ngrep eth0 /proc/interrupts\n\n# 假设中断号为 42，绑定到 CPU 1（bitmask: 0x2）\necho 2 > /proc/irq/42/smp_affinity\n\n# 或使用 CPU 列表格式\necho 1 > /proc/irq/42/smp_affinity_list\n```\n\n**原则**：\n\n1. 网络中断和处理该网络数据的应用线程应绑定到同一个 CPU 或同一 NUMA 节点\n2. 不同网卡的中断应分散到不同 CPU\n3. 禁用 `irqbalance` 守护进程（它会动态迁移中断，在网络密集场景下反而有害）\n\n```bash\nsystemctl stop irqbalance\nsystemctl disable irqbalance\n```\n\n### 3.3 RSS、RPS 与 RFS\n\n当 NIC 只有单队列（ARM 嵌入式常见），所有包的中断由同一个 CPU 处理，协议栈处理也在同一个 CPU，其他核心空闲。这时需要 **RPS**（Receive Packet Steering）将协议处理分散到多核。\n\n```\n              硬件单队列\n                 |\n           HardIRQ (CPU 0)\n                 |\n           NAPI poll (CPU 0)\n                 |\n          ┌──────┼──────┐\n          v      v      v\n        CPU 1  CPU 2  CPU 3     <-- RPS 按流哈希分发\n          |      |      |\n       Protocol Stack 并行处理\n```\n\n```bash\n# 启用 RPS：将 RX 队列 0 的处理分散到 CPU 0-3（bitmask: 0xf）\necho f > /sys/class/net/eth0/queues/rx-0/rps_cpus\n\n# 设置 RPS 流表大小（建议 32768）\necho 32768 > /proc/sys/net/core/rps_sock_flow_entries\necho 2048 > /sys/class/net/eth0/queues/rx-0/rps_flow_cnt\n```\n\n**RFS**（Receive Flow Steering）在 RPS 基础上更进一步：将包导向**正在消费该流数据的应用所在 CPU**，提升数据缓存命中率。RPS 和 RFS 通常配合使用。\n\n**RSS**（Receive Side Scaling）是硬件多队列方案，如果 NIC 支持，优先使用 RSS：\n\n```bash\n# 查看队列数\nethtool -l eth0\n\n# 设置 RX 队列数（匹配 CPU 核心数）\nethtool -L eth0 combined 4\n```\n\n| 方案 | 实现层 | 前提条件 | ARM 可用性 |\n|------|--------|----------|-----------|\n| RSS | 硬件 | NIC 支持多队列 + MSI-X | 高端 SoC（如 i.MX8） |\n| RPS | 软件 | 内核 CONFIG_RPS | 所有 ARM Linux |\n| RFS | 软件 | RPS + 应用使用 connect() | 所有 ARM Linux |\n\n## 4. NAPI 轮询与 SoftIRQ 调优\n\nNAPI（New API）是 Linux 网络栈的核心优化机制：收到第一个包时触发硬中断，随后切换到轮询模式批量收包，避免高频中断风暴。\n\n### 4.1 NAPI Budget 调优\n\n```bash\n# 每次 SoftIRQ 处理的最大包数（默认 300）\nsysctl -w net.core.netdev_budget=600\n\n# SoftIRQ 处理超时（微秒，默认 2000）\nsysctl -w net.core.netdev_budget_usecs=4000\n\n# 单个 NAPI poll 的 weight（驱动层参数，通常默认 64）\n# 需要在驱动代码中修改，或通过驱动模块参数设置\n```\n\n**ARM 注意事项**：ARM 处理器的单核性能通常低于 x86，SoftIRQ 处理速度较慢。适当增大 `netdev_budget` 可以让每次轮询处理更多包，但不能过大，否则会饿死其他 SoftIRQ（如定时器）。建议从 300 开始逐步增加到 600-1200 进行测试。\n\n### 4.2 Busy Polling（低延迟模式）\n\nBusy Polling 让应用线程在 `recvmsg()` 等待数据时直接轮询 NIC 的 NAPI 队列，绕过 SoftIRQ 调度延迟。\n\n```bash\n# 全局启用（单位：微秒）\nsysctl -w net.core.busy_read=50\nsysctl -w net.core.busy_poll=50\n```\n\n或在代码中按 socket 启用：\n\n```c\nint val = 50;  /* 微秒 */\nsetsockopt(fd, SOL_SOCKET, SO_BUSY_POLL, &val, sizeof(val));\n```\n\n**性能数据**（参考 Cloudflare 和 FIX Protocol 基准）：\n\n| 指标 | 无 Busy Poll | 有 Busy Poll |\n|------|------------|-------------|\n| 平均延迟 | 47.5 us | 16.4 us |\n| 最大延迟 | 166 us | 131 us |\n\n约 **3x 平均延迟改善**。\n\n**副作用**：CPU 核心在等待数据期间持续占用（忙等待），功耗显著增加。适用于延迟敏感型应用（如工业控制 UDP 响应），不适用于电池供电场景。\n\n**ARM 嵌入式实测**：在 DE0-Nano-SoC（ARM Cortex-A9）上，基础 Linux UDP 延迟为 0.5 ms，通过 Busy Polling + CPU 绑定可降至 0.1 ms 以内。\n\n## 5. Ring Buffer 与 Backlog 调优\n\n### 5.1 NIC Ring Buffer\n\nRing Buffer 是 NIC 与内核之间的 DMA 缓冲区，存储待处理的数据包描述符。Ring Buffer 满时，新到达的包会被丢弃。\n\n```bash\n# 查看当前 Ring Buffer 大小和最大值\nethtool -g eth0\n\n# 增大 Ring Buffer（如果硬件允许）\nethtool -G eth0 rx 4096 tx 4096\n```\n\n**诊断丢包**：\n\n```bash\n# 查看 NIC 统计中的丢包\nethtool -S eth0 | grep -i drop\nethtool -S eth0 | grep -i discard\n\n# 查看系统级统计\ncat /proc/net/softnet_stat\n# 第一列: 处理包数 第二列: 丢包数 第三列: time_squeeze（budget 用尽次数）\n```\n\n**权衡**：大 Ring Buffer 增加吞吐量但也增加最大延迟（更多包在队列中等待）。低延迟场景应使用较小的 Ring Buffer 配合更频繁的中断。\n\n### 5.2 Backlog 队列\n\nBacklog 队列位于 Ring Buffer 之后、协议栈之前，是 RPS 分发的目标缓冲区。\n\n```bash\n# 增大 backlog 队列（默认 1000）\nsysctl -w net.core.netdev_max_backlog=25000\n```\n\n**何时增大**：当 `/proc/net/softnet_stat` 第二列非零时，说明 backlog 满导致丢包，应增大。\n\n## 6. 协议栈 sysctl 参数调优\n\n### 6.1 Socket Buffer\n\n```bash\n# UDP/TCP 接收缓冲区最大值\nsysctl -w net.core.rmem_max=16777216    # 16 MB\nsysctl -w net.core.wmem_max=16777216    # 16 MB\n\n# UDP 接收缓冲区默认值\nsysctl -w net.core.rmem_default=1048576  # 1 MB\n\n# TCP 缓冲区自动调优（min, default, max）\nsysctl -w net.ipv4.tcp_rmem=\"4096 1048576 16777216\"\nsysctl -w net.ipv4.tcp_wmem=\"4096 1048576 16777216\"\n```\n\n**ARM 注意事项**：嵌入式设备 RAM 有限（通常 256 MB - 2 GB），不应盲目套用服务器级参数。建议：\n\n| 设备 RAM | rmem_max 建议值 | 说明 |\n|----------|----------------|------|\n| 256 MB | 2 MB | 保守设置 |\n| 512 MB | 4-8 MB | 平衡 |\n| 1 GB+ | 16 MB | 高吞吐量 |\n\n### 6.2 TCP 拥塞控制\n\n```bash\n# 查看可用算法\nsysctl net.ipv4.tcp_available_congestion_control\n\n# BBR 拥塞控制（Linux 4.9+，部分场景提升 2-25x）\nsysctl -w net.ipv4.tcp_congestion_control=bbr\nsysctl -w net.core.default_qdisc=fq\n```\n\nBBR 由 Google 开发，在高延迟和有丢包的链路上表现优异。但在 ARM 嵌入式的局域网场景（低延迟、低丢包），默认的 `cubic` 通常已经足够。\n\n### 6.3 其他关键参数\n\n```bash\n# TCP 窗口缩放（高带宽必须开启）\nsysctl -w net.ipv4.tcp_window_scaling=1\n\n# TCP 连接复用\nsysctl -w net.ipv4.tcp_tw_reuse=1\n\n# 禁用不需要的协议（减少协议栈开销）\nsysctl -w net.ipv6.conf.all.disable_ipv6=1\n\n# 增大连接跟踪表（如果使用 conntrack/NAT）\nsysctl -w net.netfilter.nf_conntrack_max=131072\n# 或者完全禁用 conntrack（不需要 NAT/状态防火墙时）\n# modprobe -r nf_conntrack\n```\n\n## 7. 硬件卸载功能\n\n现代 NIC 可以将部分协议处理卸载到硬件，释放 CPU 资源。\n\n### 7.1 查看和管理卸载\n\n```bash\n# 查看所有卸载特性\nethtool -k eth0\n\n# 常用卸载开关\nethtool -K eth0 rx-checksumming on     # 接收校验和卸载\nethtool -K eth0 tx-checksumming on     # 发送校验和卸载\nethtool -K eth0 gro on                 # Generic Receive Offload\nethtool -K eth0 tso on                 # TCP Segmentation Offload\nethtool -K eth0 sg on                  # Scatter-Gather\n```\n\n### 7.2 各卸载特性说明\n\n| 特性 | 作用 | ARM 可用性 |\n|------|------|-----------|\n| **Checksum Offload** | NIC 硬件计算 IP/TCP/UDP 校验和 | 多数 ARM NIC 支持 |\n| **GRO** (Generic Receive Offload) | 将多个小包在软件层合并为大包再上送协议栈 | 所有 Linux（软件实现） |\n| **LRO** (Large Receive Offload) | 硬件层合并，但可能违反 RFC | 部分高端 NIC |\n| **TSO** (TCP Segmentation Offload) | NIC 硬件做 TCP 分段 | 部分 ARM NIC |\n| **GSO** (Generic Segmentation Offload) | 软件层推迟分段到最后一刻 | 所有 Linux |\n| **Scatter-Gather** | 非连续内存直接发送，减少拷贝 | 多数 ARM NIC |\n\n**GRO 是 ARM 嵌入式最有价值的卸载**：它是纯软件实现，不依赖硬件支持，通过合并 TCP/UDP 数据包减少协议栈处理次数。\n\n**排错提示**：如果遇到网络性能异常，尝试关闭所有卸载作为基线测试，然后逐个开启定位问题：\n\n```bash\nethtool -K eth0 gro off tso off sg off rx off tx off\n```\n\n## 8. DMA 与零拷贝\n\n### 8.1 DMA 基础\n\nNIC 通过 DMA 直接将数据写入内核内存，绕过 CPU。DMA 性能取决于：\n\n- **缓冲区分配策略**：`dma_alloc_coherent`（一致性映射，无需手动同步）vs `dma_map_single`（流式映射，需显式同步）\n- **缓冲区对齐**：ARM 要求 DMA 缓冲区按 `ARCH_DMA_MINALIGN`（通常为 cache line 大小）对齐\n- **Cache 一致性**：ARM 非一致性 DMA 需要显式 `dma_sync_single_for_cpu/device` 调用\n\n### 8.2 ARM 特有的 DMA 注意事项\n\n```\nCPU Cache          Main Memory         NIC DMA\n    |                  |                   |\n    |<-- cache line -->|                   |\n    |                  |<-- DMA write -----|\n    |                  |                   |\n    |--- 需要 invalidate cache 才能看到 DMA 数据 ---|\n```\n\nARM 的 DMA 一致性问题：\n\n1. NIC DMA 写入主存后，CPU Cache 可能仍持有旧数据\n2. 需要在 DMA 完成后调用 `dma_sync_single_for_cpu()` 使 Cache 失效\n3. `dma_alloc_coherent` 分配的内存默认映射为 uncacheable，避免一致性问题但降低 CPU 访问速度\n\n**优化建议**：对于高频访问的 DMA 缓冲区（如网络接收），使用流式 DMA 映射 + 显式同步，比 coherent mapping 性能更好。\n\n### 8.3 零拷贝技术\n\n传统数据路径需要多次拷贝：\n\n```\nNIC -> DMA -> Kernel Buffer -> copy_to_user -> App Buffer\n         (1)                      (2)\n```\n\n零拷贝技术减少或消除第 (2) 次拷贝：\n\n| 技术 | 原理 | 适用场景 |\n|------|------|----------|\n| `mmap` | 内核缓冲区直接映射到用户空间 | 自定义驱动 |\n| `sendfile` | 内核内直接从文件到 socket，不经过用户空间 | 文件传输 |\n| `MSG_ZEROCOPY` | 发送时不拷贝用户数据 | 大包发送 |\n| AF_XDP | 用户空间直接访问 NIC ring buffer | 高性能收发 |\n\n**ARM `mmap` 注意事项**：Linux 在 ARM/ARM64 上默认将 DMA mmap 映射为 non-cacheable（避免 Cache 别名问题）。如需 cacheable 映射（性能更好但需要手动同步），可使用 `u-dma-buf` 驱动的 `quirk-mmap` 选项。\n\n## 9. XDP 快速数据路径\n\nXDP（eXpress Data Path）在数据包到达协议栈**之前**，在驱动 NAPI poll 循环内执行 eBPF 程序处理数据包。\n\n```\n传统路径:  NIC -> DMA -> Ring Buffer -> sk_buff 分配 -> 协议栈\nXDP 路径:  NIC -> DMA -> Ring Buffer -> XDP 程序 -> [DROP/TX/REDIRECT/PASS]\n                                          ^\n                                     无 sk_buff 分配\n```\n\n### 9.1 XDP 模式\n\n| 模式 | 执行位置 | 性能 | 要求 |\n|------|----------|------|------|\n| Native XDP | 驱动 NAPI poll 内 | 最高 | 驱动支持 |\n| Generic XDP | `napi_gro_receive` 之后 | 较低 | 所有 NIC |\n\n### 9.2 ARM 上的 Native XDP\n\n多个 ARM SoC 的以太网驱动已支持 Native XDP：\n\n- **Marvell mvneta**（Armada 38x/37x）：`mvneta_run_xdp()` 在 sk_buff 分配前执行\n- **FreeScale/NXP DPAA2**：i.MX8 系列\n- **TI CPSW**：AM335x/AM57x\n\n```bash\n# 加载 XDP 程序（示例：丢弃所有 UDP 端口 9999 的包）\nip link set dev eth0 xdp obj xdp_filter.o sec xdp\n\n# 查看 XDP 状态\nip link show eth0\n```\n\nXDP 适合的 ARM 嵌入式场景：\n\n- **DDoS 过滤**：在驱动层丢弃攻击流量，不消耗协议栈资源\n- **数据包转发**：XDP_TX 直接从 NIC 重新发出，绕过整个协议栈\n- **流量采样**：XDP_REDIRECT 到 AF_XDP socket 的零拷贝接收\n\n**副作用**：需要内核编译支持 eBPF 和 XDP；Generic XDP 的性能优势有限。\n\n## 10. 实时调度与内存锁定\n\n对于延迟敏感的网络应用（工业控制、机器人、激光雷达），还需要从调度器层面保证确定性。\n\n### 10.1 SCHED_FIFO + CPU 绑定\n\n```bash\n# 将网络处理进程设为 FIFO 实时调度，优先级 80\nchrt -f 80 ./my_udp_server\n\n# 绑定到 CPU 2\ntaskset -c 2 chrt -f 80 ./my_udp_server\n```\n\n在代码中：\n\n```c\n#include <sched.h>\n#include <sys/mman.h>\n\n/* 锁定所有内存，防止缺页中断 */\nmlockall(MCL_CURRENT | MCL_FUTURE);\n\n/* 设置 SCHED_FIFO 优先级 80 */\nstruct sched_param param;\nparam.sched_priority = 80;\nsched_setscheduler(0, SCHED_FIFO, &param);\n\n/* 绑定到 CPU 2 */\ncpu_set_t cpuset;\nCPU_ZERO(&cpuset);\nCPU_SET(2, &cpuset);\nsched_setaffinity(0, sizeof(cpuset), &cpuset);\n```\n\n### 10.2 PREEMPT_RT 内核\n\nLinux 6.12 起，PREEMPT_RT 已合入主线内核，支持 ARM64 和 RISC-V。\n\nPREEMPT_RT 的关键改进：\n\n- 将 spinlock 替换为可抢占的 mutex\n- 所有中断处理线程化（可被 SCHED_FIFO 任务抢占）\n- 最坏调度延迟从标准内核的数毫秒降至 **100 us 以下**\n\n```bash\n# 检查内核是否支持 PREEMPT_RT\nuname -a  # 应包含 PREEMPT_RT 或 PREEMPT RT\ncat /sys/kernel/realtime  # 输出 1 表示 RT 内核\n```\n\n**ARM PREEMPT_RT 延迟实测**（cyclictest，SCHED_FIFO 优先级 80）：\n\n| 内核 | 无负载 (max) | 重负载 (max) |\n|------|-------------|-------------|\n| 标准内核 | 50 us | 717 us |\n| PREEMPT_RT | 32 us | 279 us |\n\n### 10.3 RT 内核调优要点\n\n```bash\n# 禁用调试选项（严重影响延迟）\n# 内核编译时确保关闭：\n# CONFIG_DEBUG_LOCKDEP=n\n# CONFIG_DEBUG_PREEMPT=n\n# CONFIG_DEBUG_OBJECTS=n\n# CONFIG_SLUB_DEBUG=n\n\n# 隔离 CPU 核心（不运行普通任务）\n# 内核启动参数：\n# isolcpus=2,3 nohz_full=2,3 rcu_nocbs=2,3\n```\n\n## 11. 内存管理优化\n\n### 11.1 禁用 Swap\n\nSwap 导致的缺页中断会引入不可预测的延迟（毫秒级），在实时网络系统中不可接受。\n\n```bash\n# 立即禁用\nswapoff -a\n\n# 永久禁用：编辑 /etc/fstab 注释 swap 行\n\n# 或者设置 swappiness=0（尽量不用但不完全禁止）\nsysctl -w vm.swappiness=0\necho \"vm.swappiness = 0\" >> /etc/sysctl.conf\n```\n\n| 方案 | 行为 | 适用场景 |\n|------|------|----------|\n| `swapoff -a` | 完全禁用 swap | RAM 充足的嵌入式系统 |\n| `swappiness=0` | 极力避免但不禁止 | RAM 紧张但需要兜底 |\n\n### 11.2 内存锁定\n\n使用 `mlockall()` 防止实时进程的内存被换出或触发缺页：\n\n```c\n/* 在 main() 起始处调用 */\nif (mlockall(MCL_CURRENT | MCL_FUTURE) != 0) {\n    perror(\"mlockall failed\");\n}\n```\n\n## 12. 应用层优化\n\n### 12.1 Socket 选项\n\n```c\n/* 增大接收缓冲区 */\nint rcvbuf = 4 * 1024 * 1024;  /* 4 MB */\nsetsockopt(fd, SOL_SOCKET, SO_RCVBUF, &rcvbuf, sizeof(rcvbuf));\n\n/* 启用时间戳（减少系统调用获取时间的开销） */\nint ts = 1;\nsetsockopt(fd, SOL_SOCKET, SO_TIMESTAMPNS, &ts, sizeof(ts));\n\n/* UDP: 使用 connect() 建立绑定（启用 RFS，减少路由查找） */\nconnect(fd, (struct sockaddr*)&dest, sizeof(dest));\n```\n\n### 12.2 批量收发\n\n```c\n/* recvmmsg: 一次系统调用接收多个包 */\nstruct mmsghdr msgs[BATCH_SIZE];\n/* ... 初始化 msgs ... */\nint count = recvmmsg(fd, msgs, BATCH_SIZE, MSG_WAITFORONE, NULL);\n\n/* sendmmsg: 一次系统调用发送多个包 */\nint sent = sendmmsg(fd, msgs, count, 0);\n```\n\n`recvmmsg`/`sendmmsg` 减少系统调用次数，在 ARM 上效果明显（ARM 的系统调用开销高于 x86）。\n\n### 12.3 GRO 与 UDP\n\nLinux 内核支持 UDP GRO（Generic Receive Offload for UDP），将多个相同流的 UDP 包合并为一个大包上送应用层：\n\n```c\n/* 启用 UDP GRO */\nint val = 1;\nsetsockopt(fd, IPPROTO_UDP, UDP_GRO, &val, sizeof(val));\n```\n\n配合 GRO，应用层一次 `recvmsg` 可以收到合并后的大包，减少系统调用次数和协议栈处理开销。\n\n## 13. 诊断方法论\n\n优化前必须先定位瓶颈。以下工具和方法论按诊断顺序排列：\n\n### 13.1 快速检查清单\n\n```bash\n# 1. 查看 NIC 丢包\nethtool -S eth0 | grep -iE \"drop|error|discard|miss\"\n\n# 2. 查看 SoftIRQ 统计\ncat /proc/net/softnet_stat\n# 每行对应一个 CPU，格式: [processed] [dropped] [time_squeeze]\n\n# 3. 查看 socket 缓冲区溢出\ncat /proc/net/snmp | grep Udp\n# UdpInErrors, RcvbufErrors, SndbufErrors\n\n# 4. 查看中断分布\ncat /proc/interrupts | grep eth\n\n# 5. 查看 CPU 使用率（关注 softirq 比例）\nmpstat -P ALL 1\n\n# 6. 查看网络流量\nsar -n DEV 1\n```\n\n### 13.2 瓶颈定位矩阵\n\n| 现象 | 可能原因 | 对应优化 |\n|------|----------|----------|\n| `ethtool -S` 显示 rx_dropped | Ring Buffer 满 | 增大 Ring Buffer / 增大 NAPI budget |\n| `softnet_stat` 第 2 列非零 | Backlog 满 | 增大 `netdev_max_backlog` |\n| `softnet_stat` 第 3 列非零 | SoftIRQ budget 耗尽 | 增大 `netdev_budget` |\n| `/proc/net/snmp` RcvbufErrors | Socket 缓冲区满 | 增大 `rmem_max` / 应用层加速处理 |\n| 中断集中在单个 CPU | 无 RPS / RSS 配置 | 启用 RPS 或 RSS |\n| `mpstat` 显示 `%soft` 高 | 协议栈处理瓶颈 | GRO / Busy Poll / XDP |\n| CPU 频率低于最高值 | 调速器未升频 | 设置 `performance` 调速器 |\n\n## 14. 完整优化配置模板\n\n以下是一个面向 ARM-Linux 嵌入式高吞吐量 UDP 场景的系统配置模板：\n\n```bash\n#!/bin/bash\n# ARM-Linux Network Performance Tuning Script\n# Target: High-throughput UDP on embedded systems\n\nIFACE=\"eth0\"\n\n# --- CPU Frequency ---\necho performance | tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor\n\n# --- IRQ Affinity ---\nsystemctl stop irqbalance 2>/dev/null\n# 假设 eth0 中断号通过 grep 获取\nIRQ=$(grep ${IFACE} /proc/interrupts | awk '{print $1}' | tr -d ':' | head -1)\necho 1 > /proc/irq/${IRQ}/smp_affinity_list\n\n# --- RPS (单队列 NIC 分散到多核) ---\necho f > /sys/class/net/${IFACE}/queues/rx-0/rps_cpus\necho 32768 > /proc/sys/net/core/rps_sock_flow_entries\necho 4096 > /sys/class/net/${IFACE}/queues/rx-0/rps_flow_cnt\n\n# --- Ring Buffer ---\nethtool -G ${IFACE} rx 4096 tx 4096 2>/dev/null\n\n# --- Interrupt Coalescing ---\nethtool -C ${IFACE} adaptive-rx on 2>/dev/null\n\n# --- Offloads ---\nethtool -K ${IFACE} gro on 2>/dev/null\nethtool -K ${IFACE} rx-checksumming on tx-checksumming on 2>/dev/null\n\n# --- Kernel Parameters ---\nsysctl -w net.core.rmem_max=8388608\nsysctl -w net.core.wmem_max=8388608\nsysctl -w net.core.rmem_default=1048576\nsysctl -w net.core.netdev_max_backlog=25000\nsysctl -w net.core.netdev_budget=600\nsysctl -w net.core.netdev_budget_usecs=4000\nsysctl -w net.ipv4.tcp_window_scaling=1\nsysctl -w vm.swappiness=0\n\n# --- (可选) Busy Polling ---\n# sysctl -w net.core.busy_read=50\n# sysctl -w net.core.busy_poll=50\n\necho \"Network tuning applied for ${IFACE}\"\n```\n\n## 15. 总结\n\nARM-Linux 网络性能优化是一个多维度的工程问题，需要从硬件、驱动、内核、协议栈和应用层协同调优。\n\n**高收益优化**（建议优先实施）：\n\n1. CPU 调速器设为 `performance`（ARM 嵌入式设备几乎无副作用）\n2. 中断亲和性 + 禁用 irqbalance（消除缓存失效）\n3. RPS 多核分流（单队列 ARM NIC 的必需项）\n4. Socket 缓冲区和 Backlog 调优（按设备 RAM 比例设置）\n5. GRO 开启（纯软件实现，零成本）\n\n**中等收益优化**（按需评估）：\n\n6. Ring Buffer 增大 + 中断合并调优\n7. NAPI budget 增大\n8. 禁用 Swap / `swappiness=0`\n9. `recvmmsg`/`sendmmsg` 批量收发\n\n**高级优化**（延迟敏感场景）：\n\n10. Busy Polling（3x 延迟改善，但增加 CPU 功耗）\n11. SCHED_FIFO + mlockall + CPU 隔离\n12. PREEMPT_RT 内核\n13. XDP 快速数据路径\n\n**核心原则**：永远先诊断再优化。使用 `ethtool -S`、`/proc/net/softnet_stat`、`mpstat` 定位实际瓶颈，然后针对性地应用上述优化。盲目套用参数可能适得其反。\n",
      "ctime": "1771552539",
      "mtime": "1771552539",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/armv8_crc32_hardware_vs_neon_benchmark.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853701130",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "ARMv8 CRC 性能实测: 硬件指令快 8 倍, NEON 反而更慢",
      "brief_content": "对比两组实验: ARMv8 CRC32 硬件指令 (crc32cx) vs 软件查表法，以及 NEON SIMD vs 简单 C 循环的字节累加校验和。结果表明 CRC32 硬件指令比查表快 8 倍以",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 本文比较了两组实验: (1) 使用 NEON (Advanced SIMD) 指令和简单 C 循环实现字节累加 CRC 校验和; (2) 使用 ARMv8 CRC32 扩展指令 (`crc32cx`) 和软件查表法实现 CRC32。结果表明，CRC32 硬件指令比软件查表快 8 倍以上，而 NEON 手写的字节累加 CRC 在 -O2 下反而比编译器自动优化的标量代码慢。\n\n## 1. 实验方法\n\n### 1.1 NEON (Advanced SIMD) 尝试加速字节累加 CRC 校验和 vs 简单 C 循环\n\n```c\n#include <arm_neon.h>\n#include <stdbool.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <time.h>\n\n#define DATA_SIZE 1024 * 1024  // 1MB\n\n// BUG: vaddq_u8 是 8-bit 无符号加法，每个 lane 在超过 255 后会回绕 (wrap around)。\n// 对于 1MB 数据，每个 lane 累加值远超 255，结果与 crc_Simple 的 int 累加不一致。\n// 正确做法应使用 vaddw_u8 / vpaddlq_u8 将 8-bit 扩展到 16-bit 或 32-bit 再累加。\nbool crc_NEON(uint8_t* data, uint32_t len) {\n    int sum = 0;\n    uint32_t i = 1;\n    uint8x16_t v_sum = vdupq_n_u8(0);\n\n    for (; i + 16 <= len; i += 16) {\n        uint8x16_t v_data = vld1q_u8(data + i);\n        v_sum = vaddq_u8(v_sum, v_data);\n    }\n\n    uint8_t temp[16];\n    vst1q_u8(temp, v_sum);\n    for (int j = 0; j < 16; j++) { sum += temp[j]; }\n    for (; i < len; i++) { sum += data[i]; }\n\n    // 注意: data[len] 访问看似越界，但此处的约定是 data 数组实际分配了 len+1 字节，\n    // data[len] 存放的是校验字节。调用方需确保分配足够空间。\n    return ((uint8_t)((0x100 - (sum & 0xff)) & 0xff) == data[len]);\n}\n\nbool crc_Simple(uint8_t* data, uint32_t len) {\n    int sum = 0;\n    for (uint32_t i = 1; i < len; i++) { sum += data[i]; }\n    // 同上，data[len] 是校验字节，调用方需确保 data 分配了 len+1 字节。\n    return ((uint8_t)((0x100 - (sum & 0xff)) & 0xff) == data[len]);\n}\n```\n\nARM64 开发板测试结果:\n\n```\n# -O0 (未优化)\nNEON crc耗时: 1562.000000 微秒\n简单crc耗时: 11247.000000 微秒\n\n# -O2 (优化后)\nNEON crc耗时: 815.000000 微秒\n简单crc耗时: 5.000000 微秒\n```\n\n### 1.2 ARMv8 CRC32 硬件扩展指令 vs 软件查表法 CRC32\n\n```c\n// 注意: 此函数使用的是 ARMv8 CRC32 扩展指令 (crc32cx/crc32cw/crc32ch/crc32cb)，\n// 这些是标量整数流水线指令，不是 NEON (Advanced SIMD) 指令。\n// 需要 -march=armv8-a+crc 编译选项。\n//\n// 严格别名警告: 将 uint8_t* 强制转换为 uint64_t*/uint32_t*/uint16_t* 违反了\n// C/C++ 严格别名规则 (strict aliasing)，在 -O2 下可能导致未定义行为。\n// 生产代码应使用 memcpy 或 __attribute__((may_alias)) 类型来安全地读取数据。\nuint32_t crc32_do_HW(const void *const in_buf, uint32_t crc,\n                       const uint64_t in_buf_len) {\n    int64_t bytes = in_buf_len;\n    const uint8_t *data = (const uint8_t *)(in_buf);\n    while (bytes >= sizeof(uint64_t)) {\n        __asm__(\"crc32cx %w[c], %w[c], %x[v]\"\n                : [c] \"+r\"(crc)\n                : [v] \"r\"(*((uint64_t *)data)));\n        data += sizeof(uint64_t);\n        bytes -= sizeof(uint64_t);\n    }\n    if (bytes & sizeof(uint32_t)) {\n        __asm__(\"crc32cw %w[c], %w[c], %w[v]\"\n                : [c] \"+r\"(crc)\n                : [v] \"r\"(*((uint32_t *)data)));\n        data += sizeof(uint32_t);\n        bytes -= sizeof(uint32_t);\n    }\n    if (bytes & sizeof(uint16_t)) {\n        __asm__(\"crc32ch %w[c], %w[c], %w[v]\"\n                : [c] \"+r\"(crc)\n                : [v] \"r\"(*((uint16_t *)data)));\n        data += sizeof(uint16_t);\n        bytes -= sizeof(uint16_t);\n    }\n    if (bytes & sizeof(uint8_t)) {\n        __asm__(\"crc32cb %w[c], %w[c], %w[v]\"\n                : [c] \"+r\"(crc)\n                : [v] \"r\"(*((uint8_t *)data)));\n    }\n    return crc;\n}\n```\n\nARM64 开发板测试结果:\n\n```\n# -O2 优化\nHW CRC32耗时: 700.000000 微秒\nsimple CRC32耗时: 4796.000000 微秒\n\n# -O0 未优化\nHW CRC32耗时: 1265.000000 微秒\nsimple CRC32耗时: 13898.000000 微秒\n```\n\n## 2. 加速原理\n\n本文涉及两种完全不同的指令集，需要区分:\n\n**ARMv8 CRC32 扩展指令 (标量整数流水线)**\n\n`crc32cx`/`crc32cw`/`crc32ch`/`crc32cb` 是 ARMv8-A 架构的 CRC32 扩展指令，属于标量整数流水线，与 NEON (Advanced SIMD) 无关。这些指令在硬件中直接实现 CRC32C (Castagnoli) 多项式运算:\n\n- `crc32cx`: 一条指令处理 8 字节 (64-bit)\n- `crc32cw`: 一条指令处理 4 字节 (32-bit)\n- `crc32ch`: 一条指令处理 2 字节 (16-bit)\n- `crc32cb`: 一条指令处理 1 字节 (8-bit)\n\n相比之下，软件查表法 (如 Sarwate 算法) 每次迭代通常处理 1-4 字节，且每次需要查表 + 异或操作。硬件指令将整个 GF(2) 多项式除法在单周期内完成，因此获得 8 倍以上的加速。\n\n**NEON (Advanced SIMD)**\n\n实验 1.1 中的 `crc_NEON` 使用了 NEON 的 `vld1q_u8`/`vaddq_u8` 等 128-bit SIMD 指令来并行累加字节，这才是真正的 NEON 指令。但这只是简单的字节求和校验，不是 CRC32 算法。\n\n## 3. 性能分析\n\n**实验 1.2: ARMv8 CRC32 硬件指令 vs 软件查表法**\n\nCRC32 硬件指令 (`crc32cx`) 每条指令在单周期内处理 8 字节数据，将 GF(2) 多项式除法完全卸载到硬件。软件查表法每次迭代处理 1-4 字节，且需要内存访问 (查表) + 异或运算。硬件指令的加速是本质性的——算法复杂度不变，但每步的执行开销从多条指令降到单条指令。这解释了 8 倍以上的性能差距。\n\n**实验 1.1: NEON 手写 CRC 校验和 vs 编译器优化的标量代码**\n\n-O0 下 NEON 版本快 7 倍，符合预期: NEON 一次加载 16 字节并行累加，而标量代码逐字节处理。\n\n-O2 下标量代码反而快 160 倍 (815μs vs 5μs)，原因是:\n\n1. `crc_Simple` 的字节累加循环模式极其规整，编译器在 -O2 下会自动向量化 (auto-vectorization)，生成与手写 NEON 等价甚至更优的 SIMD 代码\n2. 编译器自动向量化还能结合循环展开、指令调度等优化，整体效果优于手写 intrinsics\n3. 手写 NEON intrinsics 被编译器视为不透明操作，阻止了进一步的优化 (如循环展开、寄存器分配优化)\n4. 此外 `crc_NEON` 存在 `vaddq_u8` 的 8-bit 溢出 bug (见代码注释)，虽然不影响性能，但会导致结果错误\n\n## 4. 结论\n\n- ARMv8 CRC32 硬件扩展指令 (`crc32cx`) 可以显著加速 CRC32 计算 (8 倍以上)，这些是标量整数指令，不是 NEON\n- 对于简单的字节累加 CRC 校验和，编译器 -O2 自动向量化后的代码反而比手写 NEON intrinsics 更快\n- 手写 SIMD 代码需要注意数据类型宽度 (如 `vaddq_u8` 的 8-bit 溢出) 和严格别名规则\n- 编译器优化能力不可忽视，简单规整的循环应优先让编译器自动向量化，仅在编译器无法优化的复杂算法中才考虑手写 intrinsics\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/140112767)\n\n---\n",
      "ctime": "1771552542",
      "mtime": "1771552542",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/cpp11_threadsafe_pubsub_bus.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469603886",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++11 线程安全消息总线: 从零实现 Pub/Sub 模型",
      "brief_content": "消息总线（Message Bus）作为一种重要的通信模式，被应用于解耦系统中的组件，实现异步通信和事件驱动架构。本文介绍如何使用 C++11 实现一个基于 mutex 保护的消息总线。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 消息总线（Message Bus）作为一种重要的通信模式，被应用于解耦系统中的组件，实现异步通信和事件驱动架构。本文介绍如何使用 C++11 实现一个基于 mutex 保护的消息总线。\n>\n> 完整代码: [message_bus](https://gitee.com/liudegui/message_bus)\n\n## 1. 设计方案\n\n### 1.1 核心数据结构\n\n```cpp\n#include <functional>\n#include <cstdint>\n#include <map>\n#include <vector>\n#include <list>\n#include <mutex>\n#include <string>\n\ntypedef std::function<void(const std::string& param1, int param2)> Callback_t;\ntypedef std::function<void()> TimeOutCallback_t;\n\nenum class CallbackType_t {\n    ALWAYS = 0,\n    ONCE\n};\n\nstruct CallbackItem_t {\n    Callback_t callback = nullptr;\n    TimeOutCallback_t timeOutCallback = nullptr;\n    uint32_t timeoutInterval = 1000;    // milliseconds\n    uint64_t timeoutStamp = 0;          // milliseconds (与 timeoutInterval 统一单位)\n    std::vector<int> msgNumVec;\n    CallbackType_t callbackType = CallbackType_t::ALWAYS;\n};\n```\n\n> 注: 原始版本中 `timeoutInterval` 单位为 ms，`timeoutStamp` 单位为 us，容易引发换算 bug。此处统一为 ms。\n\n### 1.2 MessageBus 类\n\n```cpp\nclass MessageBus {\npublic:\n    // C++11 保证局部静态变量初始化是线程安全的 (Magic Statics)\n    static MessageBus& instance() {\n        static MessageBus ins;\n        return ins;\n    }\n\n    void publish(int msg, const std::string& param1, int param2 = 0);\n    void timeOutCheck();\n    bool subscribe(const CallbackItem_t& item);\n    void reset();\n    void stop();\n    void start();\n\nprivate:\n    MessageBus() = default;\n    MessageBus(const MessageBus&) = delete;\n    MessageBus& operator=(const MessageBus&) = delete;\n\n    std::mutex mutex_;\n    // 内部使用 mutex_ 保护订阅表的读写\n};\n```\n\n> 注: `publish` 和 `subscribe` 的参数改为 `const&` 传递，避免不必要的 `std::string` 和 `CallbackItem_t` 拷贝。\n\n### 1.3 核心特性\n\n- 单例模式，全局唯一消息总线实例（C++11 Magic Statics 保证线程安全初始化）\n- 支持一次性 (ONCE) 和持久 (ALWAYS) 两种订阅模式\n- 内置超时检测机制\n- 线程安全（`std::mutex` 保护订阅表读写）\n\n> 注: `publish` 内部持有 `std::mutex`，属于阻塞式互斥。对于需要真正无锁发布的场景，请参考 [mccc-bus](https://gitee.com/liudegui/mccc-bus) 的 Lock-free MPSC 实现。\n\n## 2. 优缺点分析\n\n优点：\n- 解耦发布者和订阅者\n- 支持超时回调机制\n- 接口简洁，易于集成\n\n缺点：\n- 使用 `std::function` 和 `std::map`，存在堆分配\n- `publish` 持有 mutex，高频发布场景下存在锁竞争\n- 全局单例模式，不适合多总线场景\n- 缺少优先级和背压控制\n\n（完整实现请参阅代码仓库）\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/125514223)\n> 代码仓库: [Gitee](https://gitee.com/liudegui/message_bus)\n",
      "ctime": "1771552545",
      "mtime": "1771552545",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/cpp14_message_bus_optimization.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267210278",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++14 消息总线的工程优化与性能瓶颈分析",
      "brief_content": "基于 C++14 实现一个带超时管理的线程安全消息总线，解决回调内重入死锁、线程安全订阅管理等工程问题。通过压力测试暴露 mutex + std::function + std::map 方案在多线程",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [C++编程：实现一个简单的消息总线](https://blog.csdn.net/stallion5632/article/details/143785271)\n>\n> 完整代码: [message_bus](https://gitee.com/liudegui/message_bus) (optimze 分支)\n>\n> 前篇: [用 C++11 从零实现一个线程安全消息总线](../cpp11_message_bus/)\n\n## 1. 背景: 从 C++11 版本到优化版本\n\n在 [前篇](../cpp11_message_bus/) 中，我们用 C++11 实现了一个基于 mutex 保护的消息总线。该版本功能可用，但存在几个工程缺陷：\n\n- **回调内重入死锁**: `publishMessage()` 持锁调用回调，回调内再次 `publishMessage()` 会死锁\n- **回调参数固定**: `std::string` 参数不适合二进制协议数据\n- **超时管理粗糙**: `timeoutInterval` 和 `timeoutStamp` 单位不一致 (ms vs us)，容易引发换算 bug\n- **线程创建不干净**: 定时器线程 detach 后无法保证干净关闭\n\n本文基于 [message_bus](https://gitee.com/liudegui/message_bus) 仓库的 optimze 分支代码，逐一解决上述问题，并通过压力测试暴露 mutex + `std::function` 方案的性能天花板。\n\n## 2. 架构设计\n\n### 2.1 系统组成\n\n```mermaid\nclassDiagram\n    class MessageBus {\n        -mutex_ : std::mutex\n        -callbackMap_ : map~int, vector~SubscriptionItemPtr~~\n        -timeoutCallbackList_ : vector~SubscriptionItemPtr~\n        -taskScheduler_ : PeriodicTaskScheduler\n        +instance() MessageBus&\n        +publishMessage(messageId, content, additionalData)\n        +subscribeToMessage(item) bool\n        +checkAndHandleTimeouts()\n        +clearAllSubscriptions()\n        +start() / stop()\n    }\n\n    class PeriodicTaskScheduler {\n        -running_ : atomic~bool~\n        -thread_ : std::thread\n        -cv_ : condition_variable\n        +startTask(intervalMs, task)\n        +stop()\n        +isStopped() bool\n    }\n\n    class SubscriptionItem {\n        +messageCallback : MessageCallback\n        +timeoutCallback : TimeoutCallback\n        +timeoutIntervalMilliseconds : int32\n        +timeoutTimestampMicroseconds : int64\n        +subscribedMessageIds : vector~int32~\n        +subscriptionType : SubscriptionType\n    }\n\n    MessageBus \"1\" --> \"1\" PeriodicTaskScheduler : owns\n    MessageBus \"1\" --> \"*\" SubscriptionItem : manages via shared_ptr\n```\n\n### 2.2 核心设计决策\n\n| 决策 | C++11 版本 | 优化版本 | 改进点 |\n|------|-----------|---------|--------|\n| 锁策略 | 持锁调用回调 | 锁内收集，锁外调用 | 消除重入死锁 |\n| 回调参数 | `std::string` | `std::vector<uint8_t>` | 支持二进制协议 |\n| 订阅管理 | 裸指针 | `std::shared_ptr` | 生命周期安全 |\n| 定时器线程 | `std::thread` detach | joinable + `condition_variable` | 干净关闭 |\n| 锁粒度 | 双 mutex (死锁风险) | 单 mutex | 消除锁序风险 |\n\n## 3. 核心实现\n\n### 3.1 数据结构\n\n```cpp\nusing MessageCallback = std::function<void(\n    const std::vector<std::uint8_t>& messageContent,\n    std::int32_t additionalData)>;\nusing TimeoutCallback = std::function<void()>;\n\nenum class SubscriptionType { ALWAYS_SUBSCRIBE = 0, ONCE_SUBSCRIBE };\n\nstruct SubscriptionItem {\n    MessageCallback messageCallback = nullptr;\n    TimeoutCallback timeoutCallback = nullptr;\n    std::int32_t timeoutIntervalMilliseconds = 1000;\n    std::int64_t timeoutTimestampMicroseconds = 0;\n    std::vector<std::int32_t> subscribedMessageIds;\n    SubscriptionType subscriptionType = SubscriptionType::ALWAYS_SUBSCRIBE;\n};\n```\n\n相比 C++11 版本的关键改进：\n\n- 回调参数改为 `std::vector<uint8_t>`，适合传输二进制帧、protobuf 序列化数据等\n- `timeoutTimestampMicroseconds` 统一为微秒，由框架内部计算，避免用户换算错误\n\n### 3.2 锁外回调: 解决重入死锁\n\n这是优化版本最重要的改动。C++11 版本在持锁状态下直接调用回调，如果回调内再次 `publishMessage()`，同一线程会尝试重复加锁 (`std::mutex` 不可重入)，导致死锁。\n\n解决方案：**锁内收集，锁外执行**。\n\n```cpp\nvoid MessageBus::publishMessage(std::int32_t messageId,\n                                const std::vector<std::uint8_t>& messageContent,\n                                std::int32_t additionalData) {\n    // 锁外执行的回调集合\n    std::vector<MessageCallback> pendingCallbacks;\n\n    {\n        std::lock_guard<std::mutex> lk(mutex_);\n\n        // 1. 移除该 messageId 对应的超时条目\n        timeoutCallbackList_.erase(\n            std::remove_if(timeoutCallbackList_.begin(),\n                           timeoutCallbackList_.end(),\n                           [messageId](const SubscriptionItemPtr& item) {\n                               auto& ids = item->subscribedMessageIds;\n                               return std::find(ids.begin(), ids.end(),\n                                                messageId) != ids.end();\n                           }),\n            timeoutCallbackList_.end());\n\n        // 2. 收集匹配的回调\n        auto it = callbackMap_.find(messageId);\n        if (it == callbackMap_.end()) return;\n\n        std::vector<SubscriptionItemPtr> onceItems;\n        for (auto& item : it->second) {\n            if (item->messageCallback) {\n                pendingCallbacks.push_back(item->messageCallback);\n            }\n            if (item->subscriptionType == SubscriptionType::ONCE_SUBSCRIBE) {\n                onceItems.push_back(item);\n            }\n        }\n\n        // 3. 移除 ONCE 订阅\n        for (auto& item : onceItems) {\n            removeFromCallbackMap(item);\n        }\n    }\n    // mutex_ 已释放\n\n    // 4. 锁外逐一调用回调 -- 回调内可安全地再次 publishMessage\n    for (auto& cb : pendingCallbacks) {\n        cb(messageContent, additionalData);\n    }\n}\n```\n\n这个模式的关键点：\n\n- **步骤 1-3** 在 `std::lock_guard` 保护下操作共享数据\n- **步骤 4** 在锁释放后执行回调，回调内可以安全调用 `publishMessage()` 或 `subscribeToMessage()`\n- `pendingCallbacks` 是栈上局部变量，持有 `std::function` 的拷贝\n\n### 3.3 单 mutex 消除锁序风险\n\nC++11 版本使用两把锁 (`callbackMapMutex_` 和 `timeoutCallbackListMutex_`)，需要通过 `std::lock()` 保证加锁顺序一致，否则不同线程以不同顺序加锁会死锁。\n\n优化版本合并为单一 `mutex_`，同时保护 `callbackMap_` 和 `timeoutCallbackList_`：\n\n```cpp\nclass MessageBus {\nprivate:\n    // 单一 mutex 保护所有共享数据\n    std::mutex mutex_;\n    CallbackMap callbackMap_;\n    std::vector<SubscriptionItemPtr> timeoutCallbackList_;\n    PeriodicTaskScheduler taskScheduler_;\n};\n```\n\n单 mutex 的代价是粒度较粗，但对于当前的使用场景（发布频率 < 1M/s），避免死锁比细粒度锁更重要。\n\n### 3.4 定时器: joinable 线程 + condition_variable\n\nC++11 版本的定时器线程使用 `std::thread::detach()`，存在两个问题：\n\n1. 进程退出时 detached 线程可能访问已销毁的资源\n2. 无法确认线程是否已停止\n\n优化版本使用 joinable 线程 + `condition_variable` 实现优雅关闭：\n\n```cpp\nclass PeriodicTaskScheduler {\npublic:\n    void startTask(std::int32_t intervalMs, std::function<void()> task) {\n        if (running_.load(std::memory_order_relaxed)) return;\n        running_.store(true, std::memory_order_relaxed);\n\n        thread_ = std::thread([this, intervalMs, task = std::move(task)]() {\n#ifdef __linux__\n            pthread_setname_np(pthread_self(), \"MsgBusTimer\");\n#endif\n            while (running_.load(std::memory_order_relaxed)) {\n                std::unique_lock<std::mutex> lk(mutex_);\n                // wait_for 返回 true 表示被通知停止\n                if (cv_.wait_for(lk, std::chrono::milliseconds(intervalMs),\n                                 [this] { return !running_.load(); })) {\n                    break;\n                }\n                lk.unlock();\n                task();\n            }\n        });\n    }\n\n    void stop() {\n        bool expected = true;\n        if (!running_.compare_exchange_strong(expected, false)) return;\n        cv_.notify_one();\n        if (thread_.joinable()) {\n            thread_.join();  // 等待线程完成\n        }\n    }\n\nprivate:\n    std::atomic<bool> running_{false};\n    std::mutex mutex_;\n    std::condition_variable cv_;\n    std::thread thread_;\n};\n```\n\n`condition_variable::wait_for` 兼顾两个需求：定时唤醒执行任务，以及被 `stop()` 立即唤醒退出。比 `std::this_thread::sleep_for` + 轮询标志位更高效。\n\n### 3.5 `shared_ptr` 管理订阅生命周期\n\n```cpp\nusing SubscriptionItemPtr = std::shared_ptr<SubscriptionItem>;\n\nbool MessageBus::subscribeToMessage(const SubscriptionItem& item) {\n    auto itemPtr = std::make_shared<SubscriptionItem>(item);\n    std::lock_guard<std::mutex> lk(mutex_);\n    for (std::int32_t messageId : itemPtr->subscribedMessageIds) {\n        callbackMap_[messageId].push_back(itemPtr);\n    }\n    if (itemPtr->timeoutCallback) {\n        registerTimeoutCallback(itemPtr);\n    }\n    return true;\n}\n```\n\n同一个 `SubscriptionItem` 可能同时存在于 `callbackMap_` 和 `timeoutCallbackList_` 中。使用 `shared_ptr` 保证：\n\n- 从超时列表移除后，如果回调表仍持有引用，对象不会被销毁\n- 反之亦然\n- 两处引用都移除后，对象自动释放\n\n### 3.6 时序流程\n\n```mermaid\nsequenceDiagram\n    participant Producer as 生产者线程\n    participant Bus as MessageBus\n    participant CB as 回调函数\n    participant Timer as PeriodicTaskScheduler\n\n    Note over Bus: 启动\n    Bus->>Timer: startTask(100ms, checkAndHandleTimeouts)\n\n    Producer->>Bus: publishMessage(id, content)\n    activate Bus\n    Note over Bus: lock(mutex_)\n    Bus->>Bus: 移除该 id 的超时条目\n    Bus->>Bus: 收集匹配回调到 pendingCallbacks\n    Bus->>Bus: 移除 ONCE 订阅\n    Note over Bus: unlock(mutex_)\n    Bus->>CB: 逐一调用回调 (锁外)\n    CB->>Bus: 回调内可安全调用 publishMessage\n    deactivate Bus\n\n    Timer->>Bus: checkAndHandleTimeouts()\n    activate Bus\n    Note over Bus: lock(mutex_)\n    Bus->>Bus: 收集超时回调到 expiredCallbacks\n    Note over Bus: unlock(mutex_)\n    Bus->>CB: 调用超时回调 (锁外)\n    deactivate Bus\n```\n\n## 4. 测试与性能\n\n### 4.1 功能测试\n\n测试程序覆盖 5 个场景：\n\n| 测试 | 验证内容 |\n|------|---------|\n| 单线程压力测试 | 10 万消息发布吞吐量 |\n| 多线程压力测试 | 8 线程并发发布 |\n| 超时回调测试 | 0.5s 超时触发验证 |\n| 一次性订阅测试 | ONCE 订阅只触发一次 |\n| 重入发布测试 | 回调内 publish 不死锁 |\n\n重入测试是关键的正确性验证：\n\n```cpp\n// 订阅消息 4，回调内发布消息 5\nSubscriptionItem item4;\nitem4.messageCallback = [&bus](const std::vector<std::uint8_t>& content,\n                               std::int32_t) {\n    g_callbackCount.fetch_add(1, std::memory_order_relaxed);\n    bus.publishMessage(5, content, 0);  // 回调内再次 publish\n};\nitem4.subscribedMessageIds.push_back(4);\nbus.subscribeToMessage(item4);\n\n// 订阅消息 5\nSubscriptionItem item5;\nitem5.messageCallback = [](const std::vector<std::uint8_t>&, std::int32_t) {\n    g_callbackCount.fetch_add(1, std::memory_order_relaxed);\n};\nitem5.subscribedMessageIds.push_back(5);\nbus.subscribeToMessage(item5);\n\nbus.publishMessage(4, testMsg, 0);\n// 预期: g_callbackCount == 2 (msg4 回调 + msg5 回调)\n```\n\nC++11 版本此测试会死锁，优化版本通过锁外回调机制正确完成链式发布。\n\n### 4.2 性能测试结果\n\n测试环境: Ubuntu 24.04, Intel Xeon, GCC 13.3, `-O2`\n\n```\n=== Single Thread Test ===\n  Published 100000 messages in 0.179179 s (0.558 M/s)\n  Callbacks invoked: 100000\n\n=== Multi Thread Test ===\n  8 threads x 10000 = 80000 messages in 0.224865 s (0.356 M/s)\n  Callbacks invoked: 80000\n\n=== High Frequency Test ===\n  Published 100000 messages in 0.170551 s (0.586 M/s)\n```\n\n| 测试 | 消息数 | 线程数 | 耗时 | 吞吐量 |\n|------|:------:|:------:|:----:|:------:|\n| 单线程 | 100,000 | 1 | 0.179 s | **0.56 M/s** |\n| 多线程 | 80,000 | 8 | 0.225 s | **0.36 M/s** |\n| 高频 | 100,000 | 1 | 0.171 s | **0.59 M/s** |\n\n## 5. 性能瓶颈分析\n\n### 5.1 锁竞争: 多线程吞吐量低于单线程\n\n多线程 (8 线程) 吞吐量 0.36 M/s，**比单线程 0.56 M/s 还低 36%**。这不是测试误差，而是 mutex 竞争的直接后果：\n\n```\n单线程: 无竞争，每次 lock/unlock 约 20 ns (缓存命中)\n多线程: 竞争状态下，mutex 的 futex 系统调用 + 上下文切换\n        每次 lock 可能需要 200-2000 ns (取决于竞争强度)\n```\n\n`std::mutex` 在高竞争下的问题不仅是\"慢\"，更是**不可预测**。在 SCHED_OTHER 调度下，持锁线程可能被抢占，其他生产者被迫等待不确定时长。对于实时系统，这种延迟抖动是不可接受的。\n\n### 5.2 std::function 的堆分配\n\n每个 `SubscriptionItem` 包含两个 `std::function`。当 callable 对象超过 `std::function` 内部 SBO 缓冲区 (通常 16-32 字节) 时，会触发堆分配。\n\n更严重的是 `publishMessage` 中的回调收集：\n\n```cpp\nstd::vector<MessageCallback> pendingCallbacks;  // 栈上 vector\n// ...\npendingCallbacks.push_back(item->messageCallback);  // 拷贝 std::function\n```\n\n每次 `publishMessage` 都可能触发：\n1. `std::vector` 扩容的堆分配\n2. `std::function` 拷贝时的堆分配 (如果 callable 超过 SBO)\n\n### 5.3 std::map 的 O(log N) 查找\n\n```cpp\nCallbackMap callbackMap_;  // std::map<int32_t, vector<shared_ptr>>\n// ...\nauto callbackIt = callbackMap_.find(messageId);  // O(log N) 红黑树查找\n```\n\n`std::map` 是红黑树实现，每次查找 O(log N)，且节点分散在堆上，缓存不友好。对于消息总线这种高频查找场景，哈希表 (`std::unordered_map`) 的 O(1) 平均查找更合适。但两者都有堆分配问题。\n\n### 5.4 shared_ptr 的原子引用计数\n\n```cpp\nusing SubscriptionItemPtr = std::shared_ptr<SubscriptionItem>;\n```\n\n`shared_ptr` 的引用计数操作是原子的 (`fetch_add`/`fetch_sub`)。在高频路径上，拷贝和销毁 `shared_ptr` 的原子操作会造成缓存行竞争 (cache line bouncing)。\n\n### 5.5 超时检查的 O(N) 遍历\n\n```cpp\nvoid MessageBus::checkAndHandleTimeouts() {\n    // 每 100ms 遍历全部超时列表\n    for (auto it = timeoutCallbackList_.begin();\n         it != timeoutCallbackList_.end();) {\n        if ((*it)->timeoutTimestampMicroseconds <= currentTime) {\n            // ... 超时处理\n        }\n    }\n}\n```\n\n定时器每 100ms 遍历全部超时订阅。当订阅数量增长到 1000+ 时，每次遍历的代价不可忽视。时间轮 (timing wheel) 或最小堆 (min-heap) 可以将复杂度降到 O(1) 或 O(log N)。\n\n### 5.6 瓶颈总结\n\n| 瓶颈 | 影响 | 量化 |\n|------|------|------|\n| `std::mutex` 竞争 | 多线程吞吐量下降，延迟不可预测 | 8 线程比单线程低 36% |\n| `std::function` 堆分配 | 热路径上的 malloc/free | 每次 publish 可能 2 次堆分配 |\n| `std::map` 查找 | O(log N) + 缓存不友好 | 红黑树节点分散堆上 |\n| `shared_ptr` 原子计数 | 缓存行竞争 | 每次拷贝/销毁 1 次 atomic |\n| 全量超时遍历 | O(N) 定时开销 | 100ms 间隔 x N 订阅 |\n| 全局单例 | 不适合多总线隔离 | 无法独立配置 |\n\n## 6. 与 Lock-free 方案的对比\n\n上述瓶颈在嵌入式实时系统中会被放大。以激光雷达点云处理为例：传感器数据以 10 kHz 频率产生，电机控制回路要求微秒级响应，mutex 的不确定延迟是不可接受的。\n\n[MCCC (Message-Centric Component Communication)](https://gitee.com/liudegui/mccc-bus) 消息总线针对这些问题逐一设计了替代方案：\n\n| 维度 | 本文方案 (mutex) | MCCC (Lock-free) |\n|------|:----------------:|:----------------:|\n| 同步机制 | `std::mutex` | CAS 原子操作 (MPSC) |\n| 回调存储 | `std::function` (可能堆分配) | `FixedFunction` (栈上 SBO, 编译期 static_assert) |\n| 消息路由 | `std::map<int, vector>` | 编译期 `std::variant` 类型索引 |\n| 订阅管理 | `shared_ptr` + 动态 vector | 固定大小 `std::array` + 原子标志 |\n| 内存分配 | 多处堆分配 | **零堆分配** (Envelope 内嵌 Ring Buffer) |\n| 优先级 | 无 | 三级准入控制 (HIGH 99% / MEDIUM 80% / LOW 60%) |\n| 多线程吞吐 | 0.36 M/s (8 线程) | **20.6 M/s** (FULL) / **31.1 M/s** (BARE) |\n\n**关键差距: 多线程场景下 MCCC 吞吐量是本文方案的 57 倍 (BARE) 到 86 倍 (BARE)。**\n\n更详细的对比数据和 6 个开源方案的横向评测，请参阅 [C++ 消息总线性能实测: 6 个开源方案的吞吐量、延迟与嵌入式适配性对比](../MCCC_Competitive_Analysis/)。\n\n## 7. 从 mutex 方案迁移到 MCCC\n\n### 7.1 概念映射\n\n| 本文方案 | MCCC 等价概念 |\n|---------|-------------|\n| `SubscriptionItem` | `MessageEnvelope<PayloadVariant>` |\n| `MessageCallback` | `FixedFunction<void(const Envelope&)>` |\n| `callbackMap_[messageId]` | `AsyncBus::Subscribe<T>(callback)` (编译期类型路由) |\n| `publishMessage(id, data)` | `bus.Publish(SensorData{...})` (类型安全) |\n| 整数 messageId | `std::variant` alternative 类型 (编译期索引) |\n\n### 7.2 迁移示例\n\n**本文方案:**\n\n```cpp\n// 定义回调\nvoid onSensor(const std::vector<uint8_t>& content, int32_t data) {\n    // 需要手动反序列化 content\n    float temp;\n    memcpy(&temp, content.data(), sizeof(float));\n}\n\n// 订阅\nSubscriptionItem item;\nitem.messageCallback = onSensor;\nitem.subscribedMessageIds.push_back(MSG_SENSOR);\nbus.subscribeToMessage(item);\n\n// 发布\nfloat temp = 25.5f;\nstd::vector<uint8_t> payload(sizeof(float));\nmemcpy(payload.data(), &temp, sizeof(float));\nbus.publishMessage(MSG_SENSOR, payload);\n```\n\n**MCCC 方案:**\n\n```cpp\n// 消息类型直接用结构体，无需序列化\nstruct SensorData { float temp; };\nstruct MotorCmd   { int speed; };\nusing Payload = std::variant<SensorData, MotorCmd>;\nusing Bus = mccc::AsyncBus<Payload>;\n\nBus bus;\n\n// 订阅: 编译期类型路由，拼写错误直接编译失败\nbus.Subscribe<SensorData>([](const auto& env) {\n    float temp = std::get<SensorData>(env.payload).temp;  // 类型安全\n});\n\n// 发布: 直接传结构体，零序列化开销\nbus.Publish(SensorData{25.5f});\n```\n\n### 7.3 MCCC 深入学习路径\n\n| 主题 | 文章 |\n|------|------|\n| 设计决策与架构 | [Lock-free MPSC 消息总线的设计与实现](../MCCC_Design/) |\n| 性能对比评测 | [6 个开源方案的吞吐量、延迟与嵌入式适配性对比](../MCCC_Competitive_Analysis/) |\n| C++17 语言特性 | [mccc-bus 源码中的 C++17 实践](../mccc_bus_cpp17_practice/) |\n| API 参考文档 | [MCCC 消息总线 API 全参考](../mccc_bus_api_reference/) |\n| 实战重构案例 | [用 MCCC 无锁消息总线替代 mutex + priority_queue](/posts/blog/mccc_message_passing/) |\n\n## 8. 总结\n\n本文实现的消息总线在工程层面做了几项实质性改进：\n\n1. **锁外回调** -- 彻底解决了重入死锁问题\n2. **单 mutex** -- 消除了锁序不一致导致的死锁风险\n3. **joinable 线程** -- 保证了干净关闭\n4. **二进制载荷** -- `vector<uint8_t>` 替代 `string`，适合协议数据\n\n这些改进使其成为一个**正确的**消息总线实现。但性能测试表明，mutex + `std::function` + `std::map` 的组合在多线程高频场景下存在根本性瓶颈：\n\n- 单线程吞吐量约 0.56 M/s\n- 多线程 (8 线程) 吞吐量反而降至 0.36 M/s\n- 热路径存在多处堆分配\n- 延迟不可预测\n\n对于嵌入式实时系统，这些数字意味着该方案只适用于低频控制指令 (< 10 kHz) 的场景。高频数据流 (传感器、点云、视频帧) 需要 Lock-free 方案。\n\n[MCCC 消息总线](https://gitee.com/liudegui/mccc-bus) 通过 CAS 无锁 MPSC、Envelope 内嵌零堆分配、编译期类型路由等技术，将多线程吞吐量提升到 20-31 M/s (本文方案的 57-86 倍)，同时保持 MISRA C++ 合规和 `-fno-exceptions -fno-rtti` 兼容。\n\n> 代码仓库: [message_bus](https://gitee.com/liudegui/message_bus) | [mccc-bus](https://gitee.com/liudegui/mccc-bus)\n",
      "ctime": "1771552548",
      "mtime": "1771552548",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/cpp17_binary_size_vs_c.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038421030",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++17 vs C 二进制体积: 嵌入式场景的实测与分析",
      "brief_content": "基于 GCC 13 / x86-64 实测数据，面向 ARM-Linux 工业嵌入式开发者",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/158074852)\n\n> 基于 GCC 13 / x86-64 实测数据，面向 ARM-Linux 工业嵌入式开发者\n\n---\n\n## 核心结论\n\n\"C 语言生成的二进制更小\"在禁用 RTTI 和异常的工业嵌入式场景下不成立。\n实测表明，等价功能的 C 和 C++17 代码在 `-fno-exceptions -fno-rtti -Os` 下，\n.text 段差异在 1-4% 以内，C++ 在某些场景下反而更小。\n\n---\n\n## 一、原文观点逐条验证\n\n### 观点 1：\"RTTI 和异常是 C++ 体积膨胀的罪魁祸首\"\n\n**正确。** 这两个特性是 C++ 二进制体积超出 C 的主要原因：\n\n| 特性 | 体积开销来源 | 典型开销 |\n|------|------------|---------|\n| RTTI | 每个多态类生成 `typeinfo` 结构和名称字符串 | 每类 ~50-200 字节 |\n| 异常 | 展开表 (`.eh_frame`)、着陆区 (`.gcc_except_table`) | .eh_frame 可占 .text 的 10-30% |\n\n工业嵌入式项目通常开启 `-fno-exceptions -fno-rtti`，此时这些开销归零。\n[newosp](https://github.com/DeguiLiu/newosp) 用 `expected<V,E>` 替代异常，用模板/CRTP 替代虚函数，从设计上规避了这两项开销。\n\n### 观点 2：\"if constexpr 做物理剪枝，C++ 可能更小\"\n\n**正确，且有实测数据支撑。**\n\n用 GCC `-O2 -fno-inline` 编译（禁止内联以观察函数体本身），对比处理函数的汇编：\n\n**C++ `if constexpr` -- `process<int>()` 仅 6 条指令，无分支：**\n\n```asm\nprocess<int>(int):\n    mov    %edi,%edx              ; 参数直接传递\n    lea    0xe87(%rip),%rsi       ; \"integer: %d\\n\"\n    xor    %eax,%eax\n    jmp    __printf_chk@plt       ; 尾调用\n```\n\nfloat 分支**完全不存在**：无 `test/jne` 跳转，无 `movsd` 浮点加载，\n无 `\"float: %f\\n\"` 字符串引用。\n\n**C runtime `if` -- `process()` 有 14 条指令，包含条件分支：**\n\n```asm\nprocess:\n    test   %edi,%edi              ; if (t == TYPE_INT)\n    jne    .L_float               ; 条件跳转\n    mov    (%rsi),%edx            ; integer 分支\n    lea    ...,%rsi               ; \"integer: %d\\n\"\n    jmp    __printf_chk@plt\n.L_float:\n    movsd  (%rsi),%xmm0          ; float 分支 (死代码)\n    lea    ...,%rsi               ; \"float: %f\\n\"\n    jmp    __printf_chk@plt\n```\n\n即使 `main()` 只调用 `process(TYPE_INT, &x)`，float 分支的代码和字符串常量\n**仍然存在于二进制中**。\n\n| 对比项 | `if constexpr` | C runtime `if` |\n|--------|---------------|----------------|\n| .text 段 | 1421 字节 | 1525 字节 (+7.3%) |\n| 死分支消除 | 语言标准保证 | 依赖优化器，不保证 |\n| .rodata 字符串 | 仅保留使用的 | 死分支的字符串也保留 |\n\n关键区别：`if constexpr` 的分支消除发生在**模板实例化阶段**，早于任何优化 pass。\nC 的运行时 `if` 依赖优化器的常量传播，在函数未被内联时（动态库导出、函数指针调用）\n优化器**无法消除死分支**。\n\n### 观点 3：\"内联让 C++ 更小\"\n\n**部分正确，需要区分场景。**\n\n内联的体积效应是双向的：\n\n| 场景 | 体积效应 | 原因 |\n|------|---------|------|\n| 极小函数 (getter/setter, < 5 条指令) | **减小** | 消除 call/ret 序列 (通常 5-10 字节) |\n| 中等函数 (10-50 条指令) | **增大** | 函数体在每个调用点复制 |\n| 大函数 | 编译器通常不内联 | `-Os` 下尤其保守 |\n\n原文说\"内联后的代码往往比函数调用更精简\"过于绝对。准确的说法是：\n\n- C 的 `void*` + 函数指针**阻止**编译器内联，编译器被迫生成间接调用\n- C++ 模板让编译器**有机会**内联，但是否内联取决于优化级别和函数大小\n- `-Os` 下编译器对内联非常保守，优先控制体积\n\n### 观点 4：\"空基类优化 (EBCO) 让 C++ 不浪费空间\"\n\n**结论正确，但 C 的对比描述有误。**\n\n原文说\"C 语言中一个空的 struct 至少占 1 字节\"，实测 GCC C 模式下：\n\n```\nC:   sizeof(struct Empty) = 0    (GCC 扩展，ISO C 未定义)\nC++: sizeof(Empty)        = 1    (标准要求，保证唯一地址)\n```\n\n**C 的空结构体 sizeof 为 0（GCC 扩展），不是 1。**\n但 sizeof 为 0 会导致 `Empty arr[10]` 所有元素地址相同，引发其他问题。\n\nC++ 的 EBCO 价值在于：\n\n| 组合方式 | sizeof | 说明 |\n|---------|--------|------|\n| `struct A { Empty e; int x; }` | 8 | 成员: 1 字节 + 3 padding + 4 int |\n| `struct B : Empty { int x; }` | 4 | EBCO: 基类零开销 |\n\n嵌入式 C++ 中策略类、tag 类、空 allocator 应该用**继承**而非**成员组合**，\n通过 EBCO 实现零开销。C++20 的 `[[no_unique_address]]` 可让成员也享受此优化。\n\n### 观点 5：\"模板膨胀可以控制\"\n\n**正确。** 但原文遗漏了最重要的控制手段：\n\n| 手段 | 说明 |\n|------|------|\n| `-ffunction-sections -Wl,--gc-sections` | 链接器移除未引用的函数段 |\n| `-Os` | 编译器优先控制体积 |\n| LTO (`-flto`) | 跨编译单元合并重复实例化 |\n| 类型无关代码下沉 | 模板中与 T 无关的逻辑提取到非模板基类 |\n| 显式实例化 (`extern template`) | 控制实例化位置，避免重复 |\n\n实测 `-ffunction-sections -Wl,--gc-sections` 对两种语言都只移除了约 4 字节，\n说明紧凑的代码本身就没有多少死代码可清除。此选项在大型项目中效果更明显。\n\n---\n\n## 二、实测数据：等价功能的消息总线\n\n### 测试代码\n\nC 版本：`void*` + `enum MsgType` + 函数指针 dispatch，手动类型转换。\nC++ 版本：`std::variant` + 模板 subscribe + `std::visit` dispatch，编译期类型安全。\n\n两者功能等价：注册两种消息类型的订阅，发布并处理消息。\n\n### 编译配置\n\n```\nC:   gcc -Os -s -fno-asynchronous-unwind-tables\nC++: g++ -Os -s -fno-exceptions -fno-rtti -fno-asynchronous-unwind-tables -std=c++17\n```\n\n### 实测结果\n\n| 配置 | C .text | C++ .text | 差值 | 文件大小 |\n|------|---------|-----------|------|---------|\n| `-O2` | 2177 B | 2085 B | **C++ 小 92 字节 (-4.2%)** | 相同 |\n| `-Os` | 2036 B | 2062 B | C++ 大 26 字节 (+1.3%) | 相同 |\n| `-Os + gc-sections` | 2032 B | 2058 B | C++ 大 26 字节 (+1.3%) | 相同 |\n\n- .data 和 .bss 段两者完全相同 (600-608 / 288-320 字节)\n- ELF 文件总大小完全相同 (14464-14472 字节)\n- strip 后大小完全相同\n\n### 数据解读\n\n1. **`-O2` 下 C++ 反而更小**：编译器对模板代码做了更激进的优化，\n   C 版本的 `publish()` 需要循环匹配 + 函数指针间接调用，\n   C++ 的 `std::visit` 被优化器展开为更紧凑的跳转表。\n\n2. **`-Os` 下差异仅 26 字节**：`-Os` 抑制了内联，`std::variant` 的\n   visitation 机制多出约 26 字节分发逻辑。在实际项目中（几十 KB .text），\n   这个差异可忽略。\n\n3. **gc-sections 效果有限**：两种实现都很紧凑，几乎无死代码可移除。\n\n---\n\n## 三、C++ 体积更小的真实场景\n\n### 3.1 多配置系统\n\nC 的通用函数包含所有配置的运行时分支：\n\n```c\n// C: 所有分支都编译进二进制\nvoid parse(int format, const char* path) {\n    if (format == FMT_INI)  { /* INI 解析 ~200 行 */ }\n    if (format == FMT_JSON) { /* JSON 解析 ~300 行 */ }\n    if (format == FMT_YAML) { /* YAML 解析 ~250 行 */ }\n}\n// 即使项目只用 INI，JSON 和 YAML 的代码仍在二进制中\n```\n\nC++ 的 `if constexpr` 只保留启用的后端：\n\n```cpp\n// C++: 编译期确定，未启用的后端不生成任何代码\ntemplate <typename... Backends>\nvoid parse(const char* path) {\n    if constexpr (has<IniBackend>())  { /* INI 解析 */ }\n    if constexpr (has<JsonBackend>()) { /* JSON 解析 */ }  // 未启用 -> 不存在\n}\n```\n\n### 3.2 静态多态 vs 虚函数表\n\n```cpp\n// C 函数指针表: 每个\"接口\"一个函数指针数组\nstruct Transport {\n    int (*send)(void* ctx, const void* data, uint32_t size);\n    int (*recv)(void* ctx, void* buf, uint32_t size);\n    void (*close)(void* ctx);\n};\n// 每个实例: 3 个指针 = 24 字节 (64 位平台)\n// 每次调用: 间接跳转，不可内联\n```\n\n```cpp\n// C++ CRTP: 零额外存储，编译期解析\ntemplate <typename Derived>\nstruct Transport {\n    void Send(const void* data, uint32_t size) {\n        static_cast<Derived*>(this)->DoSend(data, size);  // 内联\n    }\n};\n// 每个实例: 0 字节额外开销\n// 每次调用: 直接调用或内联\n```\n\nCRTP 消除了函数指针表的 24 字节/实例存储，以及间接调用的 call 序列。\n当实例数量多时（如 64 个连接各持有一个 Transport），差异显著。\n\n### 3.3 constexpr 查表 vs 运行时初始化\n\n```c\n// C: 运行时初始化 CRC 表 -> 表存在 .data 段 (可写) 或运行时计算\nstatic uint16_t crc_table[256];\nvoid init_crc_table() { /* 运行时计算 256 个值 */ }\n// init_crc_table 函数本身也占 .text 空间\n```\n\n```cpp\n// C++: constexpr 编译期计算 -> 表直接放入 .rodata 段 (只读)\nstatic constexpr auto crc_table = [] {\n    std::array<uint16_t, 256> t{};\n    for (uint32_t i = 0; i < 256; ++i) { /* 编译期计算 */ }\n    return t;\n}();\n// 无 init 函数，无运行时计算，表在 Flash 中只读\n```\n\nconstexpr 消除了初始化函数的 .text 开销和 .data 段的可写拷贝。\n对 Flash 受限的 MCU，.rodata（XIP 直接执行）比 .data（需要拷贝到 RAM）更节省。\n\n---\n\n## 四、C++ 体积更大的真实场景\n\n公平起见，列出 C++ 确实会增大体积的情况：\n\n| 场景 | 原因 | 体积影响 |\n|------|------|---------|\n| 标准库容器 (`std::vector`, `std::map`) | 模板实例化 + 异常处理代码 | 数 KB |\n| `std::iostream` | 拖入整套 IO 子系统 | +100-200 KB |\n| 大量不同类型的模板实例化 | 每个类型生成独立代码 | 线性增长 |\n| 虚函数 + RTTI | typeinfo 结构和展开表 | 每类 ~50-200 字节 |\n| 未禁用异常 | .eh_frame 展开表 | .text 的 10-30% |\n\n工业嵌入式的应对策略：\n\n1. 禁用 `-fno-exceptions -fno-rtti` -- 消除运行时类型信息和展开表\n2. 避免标准库容器 -- 用 `FixedVector<T,N>` 等固定容量容器替代\n3. 不使用 iostream -- 用 `printf` 或自定义日志\n4. 控制模板实例化数量 -- 类型无关代码下沉到非模板基类\n5. 开启 `-Os -flto -ffunction-sections -Wl,--gc-sections`\n\n---\n\n## 五、嵌入式关键编译选项\n\n### 必选项\n\n```makefile\n# 消除 C++ 运行时开销\nCXXFLAGS += -fno-exceptions -fno-rtti\n\n# 体积优化\nCXXFLAGS += -Os\n\n# 链接器移除未引用段\nCXXFLAGS += -ffunction-sections -fdata-sections\nLDFLAGS  += -Wl,--gc-sections\n\n# 移除展开表 (无异常时不需要)\nCXXFLAGS += -fno-asynchronous-unwind-tables -fno-unwind-tables\n```\n\n### 可选项\n\n```makefile\n# 全程序优化 (跨编译单元合并重复实例化)\nCXXFLAGS += -flto\nLDFLAGS  += -flto\n\n# 合并相同内容的段 (如相同的模板实例化)\nLDFLAGS  += -Wl,--icf=safe\n\n# 移除符号表 (最终发布)\nLDFLAGS  += -s\n# 或发布后 strip\n# arm-none-eabi-strip -s firmware.elf\n```\n\n### 体积审查工具\n\n```bash\n# 查看各段大小\nsize firmware.elf\n\n# 按符号大小排序，找出最大的函数\nnm --size-sort -r firmware.elf | head -20\n\n# 查看模板实例化产生的符号\nnm firmware.elf | c++filt | grep \"AsyncBus\" | sort -k2\n\n# 对比两次构建的体积变化\nbloaty new.elf -- old.elf\n```\n\n## 六、总结\n\n1. **开启 `-fno-exceptions -fno-rtti`** -- 这是 C++ 体积与 C 持平的前提条件。\n   不开启就不要比较。\n\n2. **`-Os` 而非 `-O2`** -- `-O2` 下 C++ 内联更激进，可能反而更小，\n   但也可能因过度内联膨胀。`-Os` 让编译器主动控制体积。\n\n3. **.text 段差异在 1-4% 以内** -- 等价功能的 C/C++ 代码，在禁用 RTTI/异常后，\n   体积差异可忽略。选择语言时不应以体积为主要考量。\n\n4. **C++ 的体积优势在大型系统中更明显** -- `if constexpr` 剪枝、CRTP 消除 vtable、\n   constexpr 查表等技术，在功能复杂的系统中累积的体积节省超过模板实例化的开销。\n\n5. **真正影响体积的是设计决策，不是语言** -- 是否使用 iostream、是否引入标准库容器、\n   是否控制模板实例化数量，这些设计选择的影响远大于 C vs C++ 的语言差异。\n",
      "ctime": "1771552551",
      "mtime": "1771552551",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/cpp_performance_memory_branch_compiler.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857486898",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C/C++ 性能优化实战: 内存布局、分支预测与编译器调优",
      "brief_content": "系统级性能优化不是微调指令，而是在编译器、数据布局、并发架构三个层面做出正确选择。本文从编译器内建函数、编译期多态替代虚函数、零堆分配热路径、缓存友好布局、无锁并发、Active Object 去锁化",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 1. 优化三定律\n\n### 度量、定位、验证\n\n性能优化的第一条铁律: **不要猜**。\n\n- **度量** (Measure): 用 perf、DWT 周期计数器、Google Benchmark 建立基线数据\n- **定位** (Locate): 用火焰图或 profiler 找到真正的热点，而不是\"感觉慢\"的地方\n- **验证** (Verify): 每次改动后重新跑基准，确认改进是真实且稳定的\n\n违反这条定律的后果可能是\"优化\"反而让性能变差。一个典型案例: 在 ARMv8 上用 NEON SIMD 优化 CRC32，获得了 8 倍加速; 但用同样的思路优化简单字节累加校验和，性能反而下降 20% — SIMD 的寄存器加载/存储开销超过了并行计算的收益。\n\n> 详细的 CRC/NEON 对比实验数据参见 [ARMv8 CRC 性能实测: 硬件指令快 8 倍, NEON 反而更慢](/tech-notes/posts/blog/neon_crc32_analysis/)\n\n### 零拷贝思维\n\n现代处理器的计算速度与内存访问速度差距超过 100 倍。数据移动的成本往往高于计算本身:\n\n| 操作 | 延迟 (cycles) |\n|------|-------------|\n| L1 Cache 命中 | 3-5 |\n| L2 Cache 命中 | 10-20 |\n| L3 Cache 命中 | 30-50 |\n| 主存访问 | 100-300 |\n| 分支预测失败 | 10-20 |\n| 虚函数调用 | 10-30 (含 cache miss) |\n\n优化的核心不是让 CPU 算得更快，而是**减少数据搬运和间接跳转**:\n\n- 传指针，不传对象\n- DMA 搬运，不用 CPU 拷贝\n- 缓存行对齐，减少 miss\n- 编译期绑定，消除虚函数跳转\n\n### 优化优先级\n\n架构决定上限，算法决定下限，微优化只影响常数因子:\n\n1. **算法复杂度** — O(n) → O(log n) 的改进远超任何微优化\n2. **架构设计** — 零拷贝、无锁、核绑定等系统级决策\n3. **数据布局** — 缓存友好的内存组织\n4. **编译器提示** — 分支预测、预取、强制内联\n5. **指令级优化** — SIMD、汇编 (投入大收益不确定)\n\n### 跨平台开发模型: 主机优化，目标部署\n\n在 MCU 上调试和性能分析工具极其有限。一个高效的实践是**将核心算法封装为平台无关的 C/C++ 模块**:\n\n1. 通过回调函数或 HAL 层抽象硬件操作 (SPI/UART/DMA)\n2. 在 Linux 上用 perf、Valgrind、gdb 进行性能分析和调试\n3. 优化验证通过后，移植到 RT-Thread/FreeRTOS 工程，只需实现硬件接口\n\n这种\"主机开发 + 目标部署\"的模式显著提升了开发效率，也让本文介绍的 perf 火焰图等 Linux 工具在 MCU 项目中发挥作用。\n\n---\n\n## 2. 编译器内建优化\n\n### 强制内联\n\n热点函数的内联化是最基础的优化手段。编译器通常会自主决定是否内联，但在嵌入式和实时系统中，关键路径上的短小函数需要**保证**内联:\n\n```cpp\n// GCC/Clang: __attribute__((always_inline))\n// MSVC: __forceinline\n// 跨平台宏:\n#if defined(_MSC_VER)\n  #define FORCE_INLINE __forceinline\n#else\n  #define FORCE_INLINE inline __attribute__((always_inline))\n#endif\n\nFORCE_INLINE uint32_t FastHash(uint32_t key) {\n    key = ((key >> 16) ^ key) * 0x45d9f3b;\n    key = ((key >> 16) ^ key) * 0x45d9f3b;\n    key = (key >> 16) ^ key;\n    return key;\n}\n```\n\n内联消除了函数调用的固定开销 (参数压栈/出栈、返回地址保存、栈帧创建)，更重要的是让编译器能跨函数边界做常量传播和死代码消除。\n\n**注意**: 过度内联会导致代码膨胀 (code bloat)，增加指令缓存压力。只对**热路径上的短小函数**使用强制内联。\n\n### 分支预测提示: `__builtin_expect`\n\nCPU 流水线依赖分支预测。当预测失败时，需要清空流水线重新执行，代价是 10-20 个周期。`__builtin_expect` 告诉编译器哪条分支更可能执行，让编译器把热路径放在直通路径上:\n\n```cpp\n#define likely(x)   __builtin_expect(!!(x), 1)\n#define unlikely(x) __builtin_expect(!!(x), 0)\n\nint ProcessPacket(const uint8_t* packet, size_t len) {\n    // 正常情况下校验通过 — 编译器优化直通路径\n    if (likely(ValidateChecksum(packet, len))) {\n        return HandleValidPacket(packet, len);\n    }\n    // 异常路径放在分支末尾，减少指令缓存污染\n    return HandleError(packet, len);\n}\n```\n\n编译器会将 likely 分支生成为无跳转的直通代码，unlikely 分支放在函数末尾:\n\n```asm\n; likely 路径: 直通，无跳转\n    bl  ValidateChecksum\n    cbz r0, .Lerror       ; 只在失败时跳转\n    bl  HandleValidPacket ; 热路径直通\n    bx  lr\n\n.Lerror:                  ; 冷路径放在末尾\n    bl  HandleError\n    bx  lr\n```\n\n**适用场景**: 分支概率明显不均衡的情况 (90/10 或更极端)。如果两条分支概率接近 50/50，使用 `__builtin_expect` 没有意义。\n\n### 缓存预取: `__builtin_prefetch`\n\n当访问模式可预测但数据不在缓存中时，可以提前发出预取指令，让数据在实际使用前就进入缓存:\n\n```cpp\nvoid ProcessLargeArray(int* data, size_t count) {\n    const size_t kPrefetchDistance = 16;  // 根据 cache line 大小调整\n\n    for (size_t i = 0; i < count; ++i) {\n        if (i + kPrefetchDistance < count) {\n            __builtin_prefetch(&data[i + kPrefetchDistance], 0, 3);\n            // 参数: 地址, 0=只读/1=写, 0-3=局部性级别\n        }\n        data[i] = Compute(data[i]);\n    }\n}\n\n// 链表遍历: 预取下一个节点\nvoid TraverseList(Node* head) {\n    for (Node* cur = head; cur != nullptr; cur = cur->next) {\n        if (cur->next) {\n            __builtin_prefetch(cur->next, 0, 1);\n            // 局部性 1: 链表节点通常只访问一次\n        }\n        Process(cur);\n    }\n}\n```\n\nnewosp 的消息总线在批处理消费循环中使用了预取:\n\n```cpp\n// newosp bus.hpp: 批处理循环中预取下一个 ring buffer 节点\nfor (uint32_t i = 0; i < batch_count; ++i) {\n    if (i + 1 < kBatchSize) {\n        __builtin_prefetch(\n            &ring_buffer_[(cons_pos + 1) & kBufferMask], 0, 1);\n    }\n    // 处理当前消息...\n}\n```\n\n### MCU 平台适用性\n\n| MCU 类型 | `__builtin_expect` | `__builtin_prefetch` | 实际收益 |\n|----------|-------------------|---------------------|----------|\n| Cortex-M0/M3 | 编译支持 | 硬件无缓存，NOP | 分支优化有限，预取无效 |\n| Cortex-M4/M7 | 编译支持 | M7 有 D-Cache | M7 两者均有收益 |\n| Cortex-A7/A9/A53 | 支持 | 多级缓存 | 两者均有显著收益 |\n\n在没有 D-Cache 的 MCU 上，`__builtin_prefetch` 会被编译器生成为 NOP，不会造成错误，但也没有任何收益。\n\n---\n\n## 3. 编译期多态: 模板替代虚函数\n\n### 为什么要避免虚函数\n\n在嵌入式和实时系统中，虚函数有三个代价:\n\n1. **vtable 间接跳转**: 每次虚函数调用需要先读 vtable 指针，再读函数地址，两次内存访问。如果 vtable 不在缓存中，代价可达 100+ 周期\n2. **无法内联**: 编译器在编译期不知道虚函数的实际目标，无法进行内联优化\n3. **RTTI 内存**: 启用 RTTI 后每个多态类型增加类型信息，在 MCU 上不可接受\n\nMISRA C++ 2008 对虚函数和 RTTI 有严格限制 (Rule 5-0-1, Rule 5-0-2)。在 `-fno-rtti -fno-exceptions` 编译模式下，需要编译期替代方案。\n\n### CRTP: 编译期多态\n\nCuriously Recurring Template Pattern (CRTP) 是虚函数的零开销替代:\n\n```cpp\ntemplate <typename Derived>\nclass SensorAdapter {\npublic:\n    void ReadData() {\n        // 编译期绑定: 编译器知道 Derived 的具体类型\n        static_cast<Derived*>(this)->ReadDataImpl();\n    }\n};\n\nclass LidarAdapter : public SensorAdapter<LidarAdapter> {\npublic:\n    void ReadDataImpl() {\n        // 编译器可以内联这个调用\n        ReadLidarWithDMA();\n    }\n};\n\nclass CameraAdapter : public SensorAdapter<CameraAdapter> {\npublic:\n    void ReadDataImpl() {\n        ReadCameraWithAlignment();\n    }\n};\n\n// 使用: 编译期确定类型，零间接调用\ntemplate <typename Adapter>\nvoid ProcessSensor(Adapter& adapter) {\n    adapter.ReadData();  // 直接调用，可内联\n}\n```\n\n### 模板参数化策略选择\n\nnewosp 的 `StaticNode` 展示了编译期 Handler 绑定的实际应用。通过模板参数传入 Handler 类型，编译器可以将整条消息分发路径内联:\n\n```cpp\n// 编译期订阅所有消息类型 — 使用 fold expression\ntemplate <size_t... Is>\nbool SubscribeAll(std::index_sequence<Is...>) noexcept {\n    return (SubscribeOne<Is>() && ...);\n}\n\n// 每个类型的订阅: lambda 捕获 handler 指针，直接调用\ntemplate <size_t I>\nbool SubscribeOne() noexcept {\n    using T = std::variant_alternative_t<I, PayloadVariant>;\n    Handler* handler_ptr = &handler_;\n\n    bus_ptr_->template Subscribe<T>(\n        [handler_ptr](const EnvelopeType& env) noexcept {\n            const T* data = std::get_if<T>(&env.payload);\n            if (data != nullptr) {\n                (*handler_ptr)(*data, env.header);  // 直接调用，可内联\n            }\n        });\n}\n```\n\n对比虚函数方案:\n\n| 维度 | 虚函数 | CRTP / 模板 |\n|------|--------|------------|\n| 绑定时机 | 运行时 | 编译时 |\n| 内联 | 不可能 | 编译器可内联 |\n| 内存 | vtable 指针 (8B/对象) | 零额外内存 |\n| 适用性 | 运行时多态 (插件系统) | 编译期已知类型集合 |\n\n**权衡**: CRTP 只适用于类型在编译期已知的场景。如果需要运行时动态加载 (如插件系统)，虚函数仍然是正确选择。\n\n### C 语言等价方案: 函数指针表\n\nC 语言没有模板，但可以用 `const` 函数指针表实现相同的编译期绑定:\n\n```c\n// 声明操作接口\ntypedef struct {\n    int (*encode)(void* ctx, const uint8_t* data, size_t len);\n    int (*decode)(void* ctx, uint8_t* data, size_t len);\n    void* ctx;\n} codec_ops_t;\n\n// 编译期初始化，函数地址在编译期确定\nstatic const codec_ops_t crc16_codec = {\n    .encode = crc16_encode,\n    .decode = crc16_decode,\n    .ctx    = NULL,\n};\n```\n\n优点: 无堆分配、指针直跳 (无 vtable 二次查找)、编译器可内联。这也是 Linux 内核中 `file_operations`、`i2c_algorithm` 等子系统的标准做法。\n\n### 设计模式的性能代价\n\nGoF 设计模式为解耦而生，但在热路径上会引入可观的运行时开销:\n\n| 类别 | 典型模式 | 主要开销 |\n|------|---------|---------|\n| 对象创建 | Singleton / Factory / Builder | 原子操作、堆分配 |\n| 方法转发 | Decorator / Proxy | 层层包装 + 间接跳转 |\n| 运行时多态 | Strategy / State / Visitor | vtable 查找，阻止内联 |\n| 链式结构 | Observer / Chain / Composite | 列表遍历、缓存抖动 |\n\nC++17 提供了零开销替代方案:\n\n| 模式 | 传统损耗 | C++17 替代 |\n|------|---------|-----------|\n| Singleton | DCLP 锁竞争 + 堆分配 | `static T inst;` (魔法静态，编译器保证线程安全) |\n| Strategy / State | vtable 查找 | `std::variant` + `std::visit` (编译期分支) |\n| Factory | 字符串映射 + 堆分配 | `std::make_unique<T>(args...)` (模板工厂) |\n| Observer | 虚函数回调链 | `FixedFunction` + 环形缓冲批处理 |\n\n**原则**: 热循环内禁止堆分配和虚调用。启动、初始化等冷路径可以保留面向对象层次; 中断和紧循环必须用编译期确定的调用。\n\n---\n\n## 4. 零堆分配热路径\n\n### 问题: 热路径上的堆分配\n\n在消息总线、事件处理等每秒执行数百万次的热路径上，堆分配是严重的性能瓶颈:\n\n- `malloc/free` 涉及全局锁或 thread-local cache 管理\n- 堆碎片导致分配器性能退化\n- 堆分配的地址不可预测，破坏缓存局部性\n- 在 RTOS 和安全关键系统中，堆分配可能导致不确定的延迟\n\n### FixedFunction: 栈上类型擦除\n\n`std::function` 的问题在于它内部可能进行堆分配 (当 callable 超过 SBO 阈值时)。newosp 的 `FixedFunction` 使用固定大小的栈缓冲区 (Small Buffer Optimization):\n\n```cpp\ntemplate <typename Signature, size_t BufferSize = 4 * sizeof(void*)>\nclass FixedFunction;\n\ntemplate <typename Ret, typename... Args, size_t BufferSize>\nclass FixedFunction<Ret(Args...), BufferSize> {\n    using Storage = typename std::aligned_storage<BufferSize,\n                                                   alignof(void*)>::type;\n    using Invoker = Ret (*)(const Storage&, Args...);\n    using Destroyer = void (*)(Storage&);\n\n    Storage storage_{};       // 栈上缓冲区 (默认 32 字节)\n    Invoker invoker_ = nullptr;\n    Destroyer destroyer_ = nullptr;\n\npublic:\n    template <typename F>\n    FixedFunction(F&& f) noexcept {\n        using Decay = typename std::decay<F>::type;\n        // 编译期检查: callable 是否放得下\n        static_assert(sizeof(Decay) <= BufferSize,\n                      \"Callable too large for FixedFunction buffer\");\n        // Placement new: 直接在栈缓冲区上构造\n        ::new (&storage_) Decay(static_cast<F&&>(f));\n        invoker_ = [](const Storage& s, Args... args) -> Ret {\n            return (*reinterpret_cast<const Decay*>(&s))(\n                static_cast<Args&&>(args)...);\n        };\n    }\n};\n```\n\n32 字节的默认缓冲区足以容纳大多数 lambda (1-2 个捕获变量)。如果 callable 太大，`static_assert` 在编译期报错而不是默默回退到堆分配。\n\n### 栈容器: FixedString 和 FixedVector\n\n同样的思路也适用于容器。`std::string` 和 `std::vector` 的堆分配在嵌入式系统中不可接受:\n\n```cpp\n// 固定容量栈字符串\ntemplate <size_t Capacity>\nclass FixedString {\n    char data_[Capacity + 1]{};\n    uint32_t size_ = 0;\npublic:\n    // 编译期容量检查\n    void Append(const char* str, size_t len) {\n        size_t to_copy = std::min(len, Capacity - size_);\n        std::memcpy(data_ + size_, str, to_copy);\n        size_ += static_cast<uint32_t>(to_copy);\n        data_[size_] = '\\0';\n    }\n};\n\n// 固定容量栈数组\ntemplate <typename T, size_t Capacity>\nclass FixedVector {\n    alignas(T) uint8_t storage_[sizeof(T) * Capacity];\n    uint32_t size_ = 0;\npublic:\n    template <typename... Args>\n    void EmplaceBack(Args&&... args) {\n        OSP_ASSERT(size_ < Capacity);\n        ::new (Data() + size_) T(std::forward<Args>(args)...);\n        ++size_;\n    }\n};\n```\n\n### O(1) 内存池\n\n当确实需要动态分配时，使用预分配的内存池替代 `malloc`:\n\n```cpp\ntemplate <typename T, size_t MaxBlocks>\nclass FixedPool {\n    // 嵌入式空闲链表: 释放的块中存储下一个空闲块的索引\n    alignas(std::max_align_t) uint8_t storage_[sizeof(T) * MaxBlocks];\n    uint32_t free_head_ = 0;\n\npublic:\n    FixedPool() {\n        // 初始化空闲链表: block[0]->block[1]->...->block[N-1]->INVALID\n        for (uint32_t i = 0; i < MaxBlocks - 1; ++i) {\n            StoreIndex(i, i + 1);\n        }\n        StoreIndex(MaxBlocks - 1, kInvalidIndex);\n    }\n\n    // O(1) 分配: 弹出链表头\n    void* Allocate() {\n        if (free_head_ == kInvalidIndex) return nullptr;\n        uint32_t idx = free_head_;\n        free_head_ = LoadIndex(idx);\n        return BlockPtr(idx);\n    }\n\n    // O(1) 释放: 压入链表头\n    void Deallocate(void* ptr) {\n        uint32_t idx = BlockIndex(ptr);\n        StoreIndex(idx, free_head_);\n        free_head_ = idx;\n    }\n};\n```\n\nQPC 框架中的事件内存池 (`QF_poolInit/Q_NEW/QF_gc`) 采用相同的设计，保证所有事件的分配和回收都是 O(1) 恒定时间。\n\n---\n\n## 5. 缓存友好的数据布局\n\n### AoS vs SoA vs AoSoA\n\n数据在内存中的组织方式直接决定缓存效率:\n\n**Array of Structs (AoS)** — 面向对象的自然布局:\n\n```cpp\nstruct Particle {\n    float x, y, z;        // 位置\n    float vx, vy, vz;     // 速度\n    float mass;            // 质量\n    uint32_t type;         // 类型\n};\nstd::array<Particle, 10000> particles;\n```\n\n当算法只需要位置 (x, y, z) 时，每次加载一个缓存行 (64B)，只有 12B 有用，其余 20B 是速度/质量/类型的无用数据。缓存带宽利用率仅 37%。\n\n**Struct of Arrays (SoA)** — 数据并行友好:\n\n```cpp\nstruct ParticleSystem {\n    std::array<float, 10000> x, y, z;    // 位置连续存储\n    std::array<float, 10000> vx, vy, vz; // 速度连续存储\n    std::array<float, 10000> mass;\n    std::array<uint32_t, 10000> type;\n};\n```\n\n只处理位置时，x/y/z 数组连续存储，每个缓存行的数据全部有用。适合 SIMD 向量化 (一次加载 4 个 float)。\n\n**AoSoA** — 分块混合布局:\n\n```cpp\nstruct ParticleBlock {\n    // 每块 16 个粒子，块内 SoA\n    float x[16], y[16], z[16];\n    float vx[16], vy[16], vz[16];\n};\n// 块间连续存储\nstd::array<ParticleBlock, 625> blocks;  // 625 * 16 = 10000\n```\n\nAoSoA 既保持了 SoA 的向量化友好性，又限制了块大小以适应缓存行。适合 GPU/CPU 混合计算。\n\n| 布局 | 缓存利用率 | 向量化 | 随机访问 | 适用场景 |\n|------|-----------|--------|---------|---------|\n| AoS | 低 (部分字段浪费) | 差 | 好 | OOP 设计 |\n| SoA | 高 (顺序访问) | 好 | 差 | 数值密集计算 |\n| AoSoA | 高 (块内顺序) | 好 | 中 | GPU/SIMD 混合 |\n\n### 伪共享与缓存行对齐\n\n当两个线程分别写入同一缓存行的不同变量时，硬件缓存一致性协议 (MESI) 会导致缓存行在核间反复失效和传递，即**伪共享** (False Sharing):\n\n```cpp\n// 错误: producer_pos_ 和 consumer_pos_ 可能在同一缓存行\nstruct BadQueue {\n    std::atomic<uint32_t> producer_pos_;  // 线程A写\n    std::atomic<uint32_t> consumer_pos_;  // 线程B写\n    // 如果两者在同一 64B 缓存行内，每次写操作都会使对方的缓存失效\n};\n```\n\n解决方案: 用 `alignas(64)` 确保不同线程写的变量在不同缓存行:\n\n```cpp\n// newosp bus.hpp: 生产者和消费者位置分别对齐到独立缓存行\nstruct GoodQueue {\n    alignas(64) std::atomic<uint32_t> producer_pos_;\n    std::atomic<uint32_t> cached_consumer_pos_;  // 生产者侧缓存\n\n    alignas(64) std::atomic<uint32_t> consumer_pos_;\n    // 消费者位置在独立的缓存行，与生产者互不干扰\n};\n```\n\nnewosp 的 SPSC Ring Buffer 同样对 head/tail 索引做了缓存行对齐:\n\n```cpp\nstruct alignas(kCacheLineSize) PaddedIndex {\n    std::atomic<IndexT> value{0};\n};\nPaddedIndex head_;    // 生产者写\nPaddedIndex tail_;    // 消费者写\nalignas(kCacheLineSize) std::array<T, BufferSize> data_buff_{};\n```\n\n### 结构体成员重排\n\n编译器按声明顺序布局结构体成员 (C/C++ 标准要求)。不合理的声明顺序会导致大量 padding:\n\n```cpp\n// 差: 24 字节 (含 7 字节 padding)\nstruct BadLayout {\n    uint8_t  type;     // 1B + 3B padding\n    uint32_t id;       // 4B\n    uint8_t  flags;    // 1B + 7B padding\n    uint64_t timestamp;// 8B\n};\n\n// 好: 16 字节 (含 2 字节 padding)\nstruct GoodLayout {\n    uint64_t timestamp;// 8B\n    uint32_t id;       // 4B\n    uint8_t  type;     // 1B\n    uint8_t  flags;    // 1B + 2B padding\n};\n```\n\n原则: 按成员大小降序排列，大的放前面。用 `static_assert(sizeof(T) == expected)` 确认布局。\n\n---\n\n## 6. 无锁并发\n\n### SPSC Wait-Free Ring Buffer\n\n单生产者单消费者 (SPSC) 场景是最简单的无锁结构。由于只有一个写者和一个读者，不需要 CAS 操作，只需要正确的内存序:\n\n```cpp\ntemplate <typename T, size_t Size, bool FakeTSO = false>\nclass SpscRingBuffer {\n    static constexpr size_t kMask = Size - 1;  // Size 必须是 2 的幂\n\n    // 编译期选择: trivially copyable 类型用 memcpy 批量拷贝\n    static constexpr bool kTriviallyCopyable =\n        std::is_trivially_copyable<T>::value;\n\n    PaddedIndex head_;  // 生产者写\n    PaddedIndex tail_;  // 消费者写\n    alignas(kCacheLineSize) std::array<T, Size> data_{};\n\n    // 内存序选择: 单核 MCU 用 relaxed + signal fence\n    static constexpr auto AcquireOrder() noexcept {\n        return FakeTSO ? std::memory_order_relaxed\n                       : std::memory_order_acquire;\n    }\n    static constexpr auto ReleaseOrder() noexcept {\n        return FakeTSO ? std::memory_order_relaxed\n                       : std::memory_order_release;\n    }\n};\n```\n\n两个关键优化:\n\n1. **`if constexpr` 双路径**: 对于 trivially copyable 类型 (如 `int`、`float`、POD 结构体)，使用 `memcpy` 批量拷贝而不是逐元素赋值。这让编译器生成 SIMD 或 REP MOVSB 指令:\n\n```cpp\nif constexpr (kTriviallyCopyable) {\n    size_t first_part = std::min(to_write, Size - head_offset);\n    std::memcpy(&data_[head_offset], buf, first_part * sizeof(T));\n    if (to_write > first_part) {\n        std::memcpy(&data_[0], buf + first_part,\n                    (to_write - first_part) * sizeof(T));\n    }\n} else {\n    for (size_t i = 0; i < to_write; ++i) {\n        data_[(head_offset + i) & kMask] = buf[i];\n    }\n}\n```\n\n2. **FakeTSO 模式**: 在单核 MCU 上 (Cortex-M0/M3/M4)，不存在多核缓存一致性问题。将 acquire/release 降级为 relaxed + `atomic_signal_fence` (只阻止编译器重排，不发出 DMB 硬件指令)，消除内存屏障开销。\n\n### MPSC Lock-Free Ring Buffer\n\n多生产者单消费者 (MPSC) 场景需要 CAS 来解决生产者间的竞争:\n\n```cpp\nbool TryEnqueue(const T& item) {\n    uint32_t pos = producer_pos_.load(std::memory_order_relaxed);\n    for (;;) {\n        auto& slot = ring_buffer_[pos & kBufferMask];\n        uint32_t seq = slot.sequence.load(std::memory_order_acquire);\n\n        int32_t diff = static_cast<int32_t>(seq) -\n                       static_cast<int32_t>(pos);\n\n        if (diff == 0) {\n            // 槽位可用，尝试 CAS 占位\n            if (producer_pos_.compare_exchange_weak(\n                    pos, pos + 1, std::memory_order_relaxed)) {\n                slot.data = item;\n                slot.sequence.store(pos + 1, std::memory_order_release);\n                return true;\n            }\n        } else if (diff < 0) {\n            return false;  // 队列满\n        } else {\n            pos = producer_pos_.load(std::memory_order_relaxed);\n        }\n    }\n}\n```\n\n每个槽位有独立的 sequence 原子变量，用于实现无锁的生产者-消费者同步。消费者通过检查 sequence 判断数据是否就绪。\n\n### 自适应退避: Spin → Yield → Sleep\n\n纯自旋等待 (busy-wait) 浪费 CPU 和电力; 直接 sleep 延迟太高。newosp 的 `AdaptiveBackoff` 实现了三阶段自适应策略:\n\n```cpp\nvoid Wait() noexcept {\n    if (spin_count_ < kSpinLimit) {\n        // 阶段 1: CPU Relax 自旋 (指数增长: 1, 2, 4, 8...64 次)\n        const uint32_t iters = 1U << spin_count_;\n        for (uint32_t i = 0U; i < iters; ++i) {\n            CpuRelax();  // x86: PAUSE; ARM: YIELD\n        }\n        ++spin_count_;\n    } else if (spin_count_ < kSpinLimit + kYieldLimit) {\n        // 阶段 2: 让出 CPU (微秒级)\n        std::this_thread::yield();\n        ++spin_count_;\n    } else {\n        // 阶段 3: 睡眠 (毫秒级，仅在持续空闲时)\n        std::this_thread::sleep_for(std::chrono::microseconds(50));\n    }\n}\n\nstatic void CpuRelax() noexcept {\n#if defined(__x86_64__) || defined(__i386__)\n    __builtin_ia32_pause();      // PAUSE: 降频省电 + 通知超线程\n#elif defined(__aarch64__) || defined(__arm__)\n    asm volatile(\"yield\" ::: \"memory\");  // YIELD: 提示核心让出执行\n#else\n    std::this_thread::yield();\n#endif\n}\n```\n\n这个策略在短暂等待时保持低延迟 (纳秒级自旋)，长时间空闲时节省功耗 (毫秒级睡眠)。\n\n### 批处理: 减少原子操作频率\n\n逐条消息更新原子变量的开销很高。newosp 的做法是**在循环内不更新共享状态，循环结束后一次性提交**:\n\n```cpp\n// 消费者批处理: 一次处理多条消息，最后一次性更新 consumer_pos_\nuint32_t ProcessBatch() {\n    uint32_t cons_pos = consumer_pos_.load(std::memory_order_relaxed);\n    uint32_t processed = 0;\n\n    for (uint32_t i = 0; i < kBatchSize; ++i) {\n        auto& slot = ring_buffer_[cons_pos & kBufferMask];\n        uint32_t seq = slot.sequence.load(std::memory_order_acquire);\n        if (seq != cons_pos + 1) break;  // 无更多数据\n\n        // 处理消息...\n        slot.sequence.store(cons_pos + kQueueDepth,\n                            std::memory_order_release);\n        ++cons_pos;\n        ++processed;\n    }\n\n    // 一次性更新共享的消费者位置\n    if (processed > 0) {\n        consumer_pos_.store(cons_pos, std::memory_order_release);\n    }\n    return processed;\n}\n```\n\n批处理将 N 次原子 store 减少为 1 次，吞吐量提升显著。\n\n---\n\n### 线程局部存储 (TLS): 消除共享计数器的锁\n\n频繁更新的全局统计变量 (计数器、时间戳) 如果用 mutex 保护，每次更新都有锁竞争。TLS 为每个线程维护私有副本，彻底消除锁:\n\n```cpp\n// Linux: __thread 关键字\n__thread uint32_t local_counter = 0;\n\nvoid OnEvent() {\n    local_counter++;  // 无锁，线程私有\n}\n\n// 定期聚合 (低频操作)\nuint32_t AggregateCounters();  // 遍历所有线程的 TLS，累加\n```\n\n在 RT-Thread 中，利用线程控制块的 `user_data` 字段:\n\n```c\ntypedef struct {\n    uint32_t event_count;\n    uint32_t error_count;\n    char     temp_buf[64];\n} thread_local_data_t;\n\nvoid thread_init_tls(void) {\n    thread_local_data_t* tls = rt_malloc(sizeof(thread_local_data_t));\n    rt_memset(tls, 0, sizeof(*tls));\n    rt_thread_self()->user_data = (rt_ubase_t)tls;\n}\n\nstatic inline thread_local_data_t* get_tls(void) {\n    return (thread_local_data_t*)rt_thread_self()->user_data;\n}\n\nvoid on_sensor_event(void) {\n    get_tls()->event_count++;  // O(1)，无竞争\n}\n```\n\n**适用场景**: 读写频繁、偶尔需要聚合的统计数据。不适合需要线程间实时共享的数据。\n\n---\n\n## 7. 架构级优化\n\n### 7.1 锁优化: 从度量到消除\n\n优化锁的正确步骤是\"度量 → 缩小 → 替代\":\n\n**第一步: 定位热锁**。用 perf lock / DWT 埋点找到争用最激烈的锁。不要凭感觉猜。\n\n**第二步: 最小化临界区**。持锁时间越短越好。锁内只做 O(1) 操作 (指针交换、标志位修改)，耗时操作 (内存分配、I/O) 移到锁外:\n\n```cpp\n// 错误: 锁内执行耗时操作\nlock.lock();\nauto data = PrepareData();    // 耗时计算，应在锁外\nshared_queue.push(data);\nlock.unlock();\n\n// 正确: 临界区最小化\nauto data = PrepareData();    // 锁外完成\nlock.lock();\nshared_queue.push(data);      // 仅保护必要操作\nlock.unlock();\n```\n\n**第三步: 自适应自旋**。对持锁时间极短的场景，用自旋锁避免上下文切换。但纯自旋浪费 CPU — 参见上文 AdaptiveBackoff 三阶段策略。\n\n**第四步: 无锁替代**。争用极其激烈的核心路径上，用 SPSC/MPSC Ring Buffer 替代锁。\n\n### 7.2 事件驱动 Active Object: 消灭共享状态\n\n传统多线程编程的核心问题是**共享状态 + 锁**。Active Object 模式从架构上消除这个问题:\n\n- 每个 Active Object (AO) 拥有私有事件队列和私有线程\n- AO 之间只通过事件通信，没有共享变量\n- 事件处理遵循 Run-to-Completion (RTC) 语义: 处理完一个事件再取下一个\n\n```\n┌─────────────┐     事件      ┌─────────────┐\n│  生产者线程  │ ──────────→ │  事件队列    │\n│  (多个)      │              │  (MPSC)      │\n└─────────────┘              └──────┬───────┘\n                                    │\n                              ┌─────▼───────┐\n                              │  AO 线程     │\n                              │  (单消费者)  │\n                              │  状态机处理  │\n                              └─────────────┘\n```\n\n这个架构天然无锁:\n\n| 维度 | 传统锁方案 | Active Object |\n|------|-----------|---------------|\n| 并发控制 | mutex/condition_variable | 事件队列 (无锁) |\n| 数据竞争 | 需要仔细分析每个共享变量 | 不存在 (无共享状态) |\n| 死锁风险 | 多锁交叉可能死锁 | 不可能 (单线程处理) |\n| 调试难度 | 竞态条件难以复现 | 事件序列可回放 |\n\nQPC 框架 (Quantum Platform in C) 是 Active Object 模式的经典实现。它的事件系统使用恒定时间内存池，事件只携带指针和长度，大数据通过强转访问:\n\n```cpp\ntypedef struct QEvt {\n    uint16_t sig;       // 事件信号\n    uint8_t  poolId;    // 内存池 ID (O(1) 分配)\n    uint8_t  refCtr;    // 引用计数 (发布/订阅)\n} QEvt;\n\n// 零拷贝事件投递: 只传指针\nvoid QActive_post(QActive* const me, QEvt const* const e) {\n    me->eQueue[me->tail] = e;  // O(1) 入队\n    me->tail = (me->tail + 1) % QUEUE_SIZE;\n    os_signal(me->thread);     // 唤醒 AO 线程\n}\n```\n\n### 7.3 状态机消除锁竞争\n\n一个常见的嵌入式反模式: 多个线程共享一个硬件资源 (如 UART)，用 mutex 保护:\n\n```cpp\n// 反模式: 持锁忙等\nclass TraditionalUART {\n    pthread_mutex_t mutex_;\npublic:\n    void Send(const char* data, size_t len) {\n        pthread_mutex_lock(&mutex_);    // 获取锁\n        for (size_t i = 0; i < len; ++i) {\n            uart_write_byte(data[i]);\n            while (!uart_tx_empty()) {  // 忙等，期间持锁!\n                usleep(1);\n            }\n        }\n        pthread_mutex_unlock(&mutex_);  // 释放锁\n    }\n};\n// 问题: 忙等期间持锁，其他线程全部阻塞\n```\n\n用\"消息队列 + 单线程状态机\"替代:\n\n```cpp\n// 业务线程: 只做消息发送，立即返回\nint SendAsync(const char* data, size_t len) {\n    TxMessage msg = {EV_TX, data, len};\n    return mq_send(queue_, &msg, sizeof(msg), 0);  // O(1)\n}\n\n// UART 管理线程: 单线程顺序执行，无锁\nvoid UartThread() {\n    UartStateMachine sm;\n    TxMessage msg;\n    while (mq_receive(queue_, &msg, sizeof(msg), nullptr) > 0) {\n        sm.HandleEvent(msg);  // 状态机处理，无竞争\n    }\n}\n\n// 状态机: Idle ↔ Transmitting\nclass UartStateMachine {\n    enum State { IDLE, TRANSMITTING } state_ = IDLE;\n    const char* tx_buf_ = nullptr;\n    size_t tx_pos_ = 0, tx_len_ = 0;\n\npublic:\n    void HandleEvent(const TxMessage& msg) {\n        switch (state_) {\n            case IDLE:\n                if (msg.event == EV_TX) {\n                    tx_buf_ = msg.data;\n                    tx_pos_ = 0;\n                    tx_len_ = msg.length;\n                    state_ = TRANSMITTING;\n                    StartTransmit();\n                }\n                break;\n            case TRANSMITTING:\n                if (msg.event == EV_TX_DONE) {\n                    if (++tx_pos_ < tx_len_) {\n                        StartTransmit();\n                    } else {\n                        state_ = IDLE;\n                    }\n                }\n                break;\n        }\n    }\n};\n```\n\n业务线程只做 O(1) 的消息入队; 所有硬件操作集中在一个线程，无竞争、无锁、无忙等持锁。\n\n进一步优化: 用硬件发送完成中断替代忙等。ISR 向消息队列投递 `EV_TX_DONE` 事件，UART 管理线程在 `mq_receive` 上阻塞等待，真正的零 CPU 占用:\n\n```cpp\n// 中断服务程序: 发送完成时投递事件\nvoid UART_TxComplete_ISR(void) {\n    TxMessage msg = {EV_TX_DONE, nullptr, 0};\n    mq_send(queue_, &msg, sizeof(msg), 0);\n}\n```\n\n### 7.4 行为树驱动并行启动\n\n传统嵌入式系统的启动是串行的: 逐个模块初始化，等一个完成再启动下一个。当模块数增加时，启动时间线性增长:\n\n```cpp\n// 传统串行启动\nvoid SystemInit() {\n    irsc_init();     // 200ms\n    isp_init();      // 150ms\n    video_init();    // 300ms\n    network_init();  // 100ms\n    // 总计: 750ms，且 CPU 峰值持续\n}\n```\n\n用行为树 (Behavior Tree) 替代串行初始化:\n\n- **Parallel 节点**: 并行启动无依赖关系的模块\n- **Sequence 节点**: 串行执行有依赖关系的阶段\n- **Decorator 节点**: 条件控制 (延迟加载、CPU 负载门控)\n\n```\nSystemBoot (Sequence)\n├── CriticalInit (Parallel)    ← 关键模块并行启动\n│   ├── IRSC Init\n│   └── BasicIO Init\n├── NormalInit (Parallel)      ← 普通模块并行 + 延迟加载\n│   ├── [LazyDecorator] ISP Init\n│   ├── [LazyDecorator] Video Init\n│   └── Network Init\n└── ServiceInit (Sequence)     ← 验证 + 服务启动\n    ├── SystemCheck\n    └── MainService Start\n```\n\nParallel 节点实现关键: CPU 负载门控。限制同时初始化的模块数，避免 CPU 峰值:\n\n```cpp\nbt_status_t bt_parallel_tick(bt_node_t* self, void* bb) {\n    startup_blackboard_t* board = (startup_blackboard_t*)bb;\n    uint32_t active = 0;\n\n    for (size_t i = 0; i < self->child_count; ++i) {\n        // CPU 负载控制: 达到并发上限时跳过新初始化\n        if (board->cpu_usage > 80.0f &&\n            active >= board->max_concurrent_inits) {\n            continue;\n        }\n\n        bt_status_t status = self->children[i]->tick(\n            self->children[i], bb);\n\n        if (status == BT_RUNNING) ++active;\n        if (status == BT_FAILURE) return BT_FAILURE;\n    }\n    return (active > 0) ? BT_RUNNING : BT_SUCCESS;\n}\n```\n\n延迟加载装饰器: 模块只在前置条件满足且 CPU 负载低时才初始化:\n\n```cpp\nbt_status_t bt_lazy_decorator(bt_node_t* self, void* bb) {\n    bt_lazy_data_t* data = (bt_lazy_data_t*)self->user_data;\n\n    if (!data->initialized && data->should_init(bb)) {\n        bt_status_t status = self->children[0]->tick(\n            self->children[0], bb);\n        if (status == BT_SUCCESS) {\n            data->initialized = true;\n        }\n        return status;\n    }\n    return data->initialized ? BT_SUCCESS : BT_RUNNING;\n}\n\n// 条件示例: ISP 在 IRSC 初始化完成且 CPU 负载低于 50% 时启动\nbool isp_should_init(void* bb) {\n    startup_blackboard_t* board = (startup_blackboard_t*)bb;\n    return board->modules_initialized >= 1 &&\n           board->cpu_usage < 50.0f;\n}\n```\n\n### 7.5 异构 SoC 分层流水线\n\n在 Zynq-7000 等 FPGA+ARM 异构 SoC 上，任务应按计算复杂度分级:\n\n| 任务等级 | 典型操作 | 执行单元 |\n|----------|---------|---------|\n| 轻量 | 坐标转换、阈值滤波 | CPU + NEON SIMD |\n| 中等 | 滑窗滤波、畸变补偿 | FPGA 局部加速 |\n| 重度 | 最近邻搜索、ICP 对齐 | FPGA 全并行 |\n\n数据流: CPU (核 0) 接收数据 → 分级 → 轻量任务在 CPU (核 1) 处理 → 中重度任务通过 AXI-DMA 交给 FPGA → DMA 返回结果 → CPU (核 1) 封装输出。\n\n```mermaid\ngraph LR\n    A[传感器数据] --> B(Core 0: I/O接收)\n    B --> C{复杂度分级}\n    C -->|轻量| D[Core 1: SIMD处理]\n    C -->|中/重| E[AXI-DMA → FPGA]\n    E --> F[FPGA 并行计算]\n    F --> G[DMA → Core 1]\n    D --> H[输出]\n    G --> H\n```\n\n核心原则:\n\n- **核 0 专职 I/O**: 数据接收、DMA 配置、中断处理\n- **核 1 专职计算**: 算法处理、协议栈、结果封装\n- **CPU 亲和性绑定**: 避免任务在核间迁移导致的缓存抖动\n\n> 详细的 Zynq-7000 架构设计参见 [Zynq-7000 激光雷达点云处理: FPGA + 双核 ARM 的架构设计](/tech-notes/posts/architecture/zynq7000_lidar_feasibility/)\n\n---\n\n## 8. 实时调度优化\n\n### CPU 亲和性与内存锁定\n\n在 Linux 实时系统中，三项配置决定了延迟的确定性:\n\n**1. CPU 亲和性绑定** — 消除缓存迁移:\n\n```cpp\nvoid BindToCpu(int cpu_id) {\n    cpu_set_t cpuset;\n    CPU_ZERO(&cpuset);\n    CPU_SET(cpu_id, &cpuset);\n    pthread_setaffinity_np(pthread_self(), sizeof(cpuset), &cpuset);\n}\n```\n\n线程在核间迁移时，L1/L2 缓存全部失效。绑定后可减少 20-40% 的缓存 miss。\n\n**2. 内存锁定** — 消除页错误:\n\n```cpp\nmlockall(MCL_CURRENT | MCL_FUTURE);\n// MCL_CURRENT: 锁定当前已映射的页\n// MCL_FUTURE:  锁定未来新映射的页\n```\n\n实时线程被页错误中断会导致毫秒级的不确定延迟。`mlockall` 把所有虚拟内存页锁定在物理内存中。\n\n**3. 实时调度策略** — 保证优先级:\n\n```cpp\nstruct sched_param param;\nparam.sched_priority = 80;  // 1-99, 越高优先级越高\npthread_setschedparam(pthread_self(), SCHED_FIFO, &param);\n```\n\n`SCHED_FIFO` 保证: 高优先级线程一旦就绪就能抢占低优先级线程运行。\n\nnewosp 的 `RealtimeExecutor` 将这三项封装为声明式配置:\n\n```cpp\nRealtimeConfig config;\nconfig.sched_policy = SCHED_FIFO;\nconfig.sched_priority = 80;\nconfig.lock_memory = true;\nconfig.cpu_affinity = 1;     // 绑定到核 1\nconfig.stack_size = 65536;   // 预分配 64KB 栈\n\nRealtimeExecutor executor(config);\nexecutor.Start([](){ /* 实时任务 */ });\n```\n\n### 精确唤醒: clock_nanosleep\n\n`std::this_thread::sleep_for` 在 Linux 上默认精度约 1-4ms。对于需要亚毫秒精度的实时任务，使用 `clock_nanosleep` 配合 `CLOCK_MONOTONIC` 和绝对时间:\n\n```cpp\n// 基于 CLOCK_MONOTONIC 的绝对时间唤醒\nstruct timespec ts;\nuint64_t target_ns = current_ns + period_ns;\nts.tv_sec  = target_ns / 1000000000ULL;\nts.tv_nsec = target_ns % 1000000000ULL;\nclock_nanosleep(CLOCK_MONOTONIC, TIMER_ABSTIME, &ts, nullptr);\n```\n\n`TIMER_ABSTIME` 避免了相对时间的累积误差 — 即使某次处理耗时超出预期，下一次唤醒时间仍然准确。\n\n---\n\n## 9. 向量化与硬件加速\n\n### SIMD 并非万能\n\nSIMD (单指令多数据) 理论上可以提供 4-16 倍的并行加速，但实际收益高度依赖算法特性:\n\n| 条件 | SIMD 效果 |\n|------|----------|\n| 数据无依赖，可并行处理 | 有效 |\n| 计算密集，计算量 > 搬运量 | 有效 |\n| 数据量小，搬运开销 > 计算 | 可能负优化 |\n| 存在数据依赖链 | 无法并行 |\n| 分支密集 | 向量化困难 |\n\n**实测案例**: ARM NEON 优化 CRC32 获得 8 倍加速 (适合并行)，但同样手法优化简单字节累加校验和反而下降 20% (加载/存储开销大于并行收益)。\n\n> 完整实验数据参见 [ARMv8 CRC 性能实测](/tech-notes/posts/blog/neon_crc32_analysis/)\n\n### DMA 零拷贝\n\n高吞吐 I/O 场景的正确做法不是优化 `memcpy`，而是用 DMA 消除 CPU 拷贝:\n\n- **DMA + 双缓冲**: 外设通过 DMA 写入缓冲区 A，CPU 处理缓冲区 B，完成后交换\n- **Scatter-Gather DMA**: 支持非连续内存区域的零拷贝传输\n- **中断/轮询混合**: 低流量用中断 (低 CPU 占用)，高流量切换到批量轮询 (低延迟):\n\n```cpp\nvoid AdaptivePolling() {\n    if (traffic_rate < kLowThreshold) {\n        EnableRxInterrupt();        // 低流量: 中断模式\n    } else {\n        DisableRxInterrupt();       // 高流量: 轮询模式\n        while (HasPendingPackets()) {\n            ProcessBatch();          // 批量处理\n        }\n    }\n}\n```\n\n---\n\n## 10. 性能度量方法论\n\n### MCU: DWT 周期计数\n\nCortex-M3/M4/M7 内置 DWT (Data Watchpoint and Trace) 周期计数器，精度为 1 个 CPU 周期:\n\n```cpp\n// 启用 DWT\nCoreDebug->DEMCR |= CoreDebug_DEMCR_TRCENA_Msk;\nDWT->CTRL |= DWT_CTRL_CYCCNTENA_Msk;\n\n// 测量\nDWT->CYCCNT = 0;\nuint32_t start = DWT->CYCCNT;\n\n/* 被测代码 */\n\nuint32_t cycles = DWT->CYCCNT - start;\nfloat ns = (float)cycles / (SystemCoreClock / 1e9f);\n```\n\n### Linux: perf 火焰图\n\n```bash\n# 采样 + 调用栈\nperf record -F 10000 -g ./your_program\n\n# 生成火焰图\nperf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg\n```\n\n火焰图的横轴是采样占比 (不是时间轴)，纵轴是调用栈深度。最宽的\"平台\"就是最热的函数。\n\n### Google Benchmark\n\n```cpp\n#include <benchmark/benchmark.h>\n\nstatic void BM_ProcessMessage(benchmark::State& state) {\n    AsyncBus bus;\n    for (auto _ : state) {\n        bus.TryEnqueue(msg);\n    }\n    state.SetItemsProcessed(state.iterations());\n}\nBENCHMARK(BM_ProcessMessage)->Range(1, 1 << 20);\n```\n\n**基准测试原则**:\n\n1. 预热: 丢弃前几次结果，避免冷缓存影响\n2. 多次采样: 取中位数而非平均值 (排除异常值)\n3. 每次只改一个变量: 隔离优化效果\n4. 不同数据规模: 确认优化在各种场景下都有效\n\n---\n\n## 11. 常用性能工具\n\n| 工具类别 | Linux | 嵌入式 (MCU) | 跨平台 |\n|---------|-------|-------------|-------|\n| 分析器 | perf, Valgrind | DWT, ETM, ITM | Intel VTune, Tracy |\n| 内存 | Memcheck, Heaptrack | 静态分析 (Coverity) | ASan/MSan |\n| 基准 | - | DWT 周期计数 | Google Benchmark |\n| 可视化 | Flame Graph | Segger SystemView | Chrome Tracing |\n\n---\n\n## 12. 常见问题\n\n**Q: `likely/unlikely` 总是有用吗?**\n不一定。现代 CPU 的分支预测器已经很准。只在分支概率极不均衡 (>90%) 且 profiler 确认是热点时使用。\n\n**Q: CAS 原子操作会不会比加锁还慢?**\n高冲突场景下 CAS 可能因反复重试而退化。此时应退回自旋 + 退避或直接用 mutex。\n\n**Q: `std::function` 会导致堆分配吗?**\n捕获体积 <= SBO 阈值 (通常 2-3 个指针大小) 时在栈上; 超过则堆分配。newosp 的 `FixedFunction<Ret(Args...), 32>` 通过 `static_assert` 在编译期强制要求栈分配。\n\n**Q: 模板元编程会导致代码膨胀吗?**\n会。需要通过按需实例化、LTO (Link-Time Optimization) 和合理的接口设计来控制。\n\n**Q: 零拷贝一定更快吗?**\n仅当数据块较大且跨进程/硬件搬运成本显著时才有优势。小消息反而可能因对齐与缓存失效变慢。\n\n**Q: 必须手写 SIMD 才能榨干性能吗?**\n90% 场景下自动向量化即可。只有编译器因别名或分支失败时再考虑 Intrinsic。用 `-fopt-info-vec` (GCC) 或 `-Rpass=loop-vectorize` (Clang) 查看向量化结果。\n\n---\n\n## 13. 总结\n\n系统级性能优化是一个分层问题。从投入产出比的角度:\n\n| 层次 | 技术 | 典型收益 | 投入 |\n|------|------|---------|------|\n| 架构 | Active Object 去锁化、核绑定 | 3-10x | 高 (需重构) |\n| 数据布局 | AoS→SoA、缓存行对齐 | 2-5x | 中 |\n| 内存管理 | 零堆分配、内存池 | 1.5-3x | 中 |\n| 并发 | 无锁队列、批处理 | 2-5x | 中高 |\n| 编译器 | 内联、分支预测、预取 | 1.1-1.5x | 低 |\n| SIMD | 向量化 | 0.8-8x (不确定) | 高 |\n\n几条经验:\n\n1. **架构先行**: \"分层分级 + 零拷贝 + 核绑定\"带来的收益远超微优化\n2. **实测驱动**: 不量化就不优化，不验证就不上线\n3. **零堆热路径**: 每秒执行百万次的路径上，杜绝 malloc/new\n4. **消灭共享**: 事件驱动 + 私有状态 > mutex + 共享变量\n5. **批处理**: 循环内累积，循环外提交，减少原子操作和系统调用频率\n",
      "ctime": "1771552555",
      "mtime": "1771552555",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/cpp_singleton_thread_safety_dclp.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357827610",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++ 单例模式的线程安全实现: 从 DCLP 的历史缺陷到 C++11 的修复",
      "brief_content": "双重检查锁定 (DCLP) 是 C++ 并发编程中最臭名昭著的模式之一。2004 年 Scott Meyers 和 Andrei Alexandrescu 论证了它在 C++03 中不可移植地安全实现",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [内存屏障的硬件原理: 从 Store Buffer 到 ARM DMB/DSB/ISB](../memory_barrier_hardware/) -- DCLP 失败的硬件根因 (Store Buffer 导致的写入重排)\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- acquire/release 内存序的完整理论\n>\n> 原文链接: [C++单例的安全实现，double-check(双重检查锁定)的安全实现方法](https://blog.csdn.net/stallion5632/article/details/126218126)\n>\n> 核心参考: [Double-Checked Locking is Fixed In C++11](https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/) (Jeff Preshing)\n>\n> 经典论文: [C++ and the Perils of Double-Checked Locking](http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf) (Scott Meyers & Andrei Alexandrescu, DDJ 2004)\n\n## 1. 单例模式概述\n\n单例模式 (Singleton) 确保一个类在整个进程生命周期中只有一个实例，并提供全局访问点。它是最简单也是最容易实现错误的设计模式之一。\n\n一个正确的单例需要满足：\n\n- **唯一性**: 构造函数私有，禁止拷贝和赋值\n- **全局访问**: 通过静态方法获取实例\n- **线程安全**: 多线程同时首次访问时，不会创建多个实例\n- **初始化安全**: 实例完全构造完成后，其他线程才能使用\n\n前三项容易理解，第四项是 DCLP 问题的根源。\n\n## 2. DCLP 的历史: 一个\"正确\"了 20 年的错误\n\n### 2.1 朴素加锁方案\n\n最直接的线程安全单例：\n\n```cpp\n// 正确，但每次访问都加锁\nSingleton* Singleton::getInstance() {\n    std::lock_guard<std::mutex> lock(m_mutex);\n    if (m_instance == nullptr) {\n        m_instance = new Singleton;\n    }\n    return m_instance;\n}\n```\n\n这是正确的，但一旦单例创建完成，后续每次访问仍然需要获取锁。在高频访问场景下，锁竞争成为性能瓶颈。\n\n### 2.2 朴素 DCLP: 看起来对，实际上是未定义行为\n\n为了避免每次都加锁，DCLP 在加锁前先检查一次指针：\n\n```cpp\n// 错误！C++11 之前无法安全实现\nSingleton* Singleton::getInstance() {\n    if (m_instance == nullptr) {        // 第一次检查 (无锁)\n        std::lock_guard<std::mutex> lock(m_mutex);\n        if (m_instance == nullptr) {    // 第二次检查 (有锁)\n            m_instance = new Singleton;\n        }\n    }\n    return m_instance;\n}\n```\n\n直觉上这很合理：第一次检查避免了不必要的加锁，第二次检查防止了重复创建。但这段代码在 C++11 之前是**未定义行为**，即使在 C++11 中，如果 `m_instance` 是裸指针 (`Singleton*`)，它仍然是未定义行为。\n\n### 2.3 为什么 DCLP 是错的\n\n2004 年，Scott Meyers 和 Andrei Alexandrescu 在 DDJ 发表了 *\"C++ and the Perils of Double-Checked Locking\"*，论证了 DCLP 的根本缺陷。问题有两层：\n\n**第一层: 指令重排序**\n\n`m_instance = new Singleton` 在抽象层面是三个操作：\n\n1. 分配内存 (`operator new`)\n2. 在分配的内存上构造 `Singleton` 对象\n3. 将内存地址赋值给 `m_instance`\n\n编译器和 CPU 可以将步骤 2 和 3 重排序为 3 → 2 (在 ARM 弱序架构上，Store Buffer 的异步刷新机制使这种重排序成为现实，详见 [内存屏障的硬件原理](../memory_barrier_hardware/))。此时另一个线程在第一次检查中看到 `m_instance != nullptr`，直接返回一个**尚未完成构造**的对象。\n\n**第二层: 缺少 synchronizes-with 关系**\n\n即使没有重排序，第一个线程在锁内写入 `m_instance` 和 `Singleton` 的成员变量，第二个线程在**锁外**读取 `m_instance`。锁只保护持有锁的线程之间的可见性。第二个线程跳过了锁，因此无法保证它能看到第一个线程的所有写入。\n\n用 C++ 标准的术语：第一次无锁读取与被保护的写入之间构成**数据竞争** (data race)，属于未定义行为。\n\n> 2000 年，一群 Java 开发者联合发表了声明 *\"Double-Checked Locking Is Broken\"*。Java 直到 2004 年 (Java 5) 引入新的内存模型和 `volatile` 语义才修复了这个问题。C++ 要到 2011 年才跟上。\n\n## 3. C++11 的三种修复方案\n\n### 3.1 方案一: Magic Statics (推荐)\n\nC++11 标准 [stmt.dcl] p4 保证：\n\n> \"If control enters the declaration concurrently while the variable is being initialized, the concurrent execution shall wait for completion of the initialization.\"\n\n即局部静态变量的初始化是线程安全的，编译器负责生成必要的同步代码。\n\n```cpp\nclass Singleton {\npublic:\n    static Singleton& getInstance() {\n        static Singleton instance;  // C++11 保证线程安全初始化\n        return instance;\n    }\n\n    Singleton(const Singleton&) = delete;\n    Singleton& operator=(const Singleton&) = delete;\n\nprivate:\n    Singleton() = default;\n    ~Singleton() = default;\n};\n```\n\n**编译器实现细节**: GCC 和 Clang 内部使用 guard 变量 + `__cxa_guard_acquire`/`__cxa_guard_release` 实现，本质上就是编译器替你写了正确的 DCLP。在 ARM 上，GCC 甚至利用数据依赖省略了 acquire fence (`dmb` 指令)，生成的代码比手写 DCLP 更高效。\n\n**优点:**\n- 代码最简洁\n- 编译器保证正确性\n- 返回引用而非指针，无需动态分配\n- 生成的机器码通常最优\n\n**注意事项:**\n- MSVC 2015 之前不支持 Magic Statics (MSVC 2013 和更早版本不符合 C++11 该条款)\n- 静态局部变量按照构造的**逆序**销毁，如果另一个静态对象的析构函数访问该单例，可能触发 use-after-destroy\n\n### 3.2 方案二: acquire/release 原子操作\n\n当需要手动控制 (例如动态分配、延迟创建、或避免销毁顺序问题) 时，使用 `std::atomic` + acquire/release 语义：\n\n```cpp\nclass Singleton {\npublic:\n    static Singleton* getInstance() {\n        // acquire load: 保证后续读取能看到 release store 之前的所有写入\n        Singleton* tmp = m_instance.load(std::memory_order_acquire);\n        if (tmp == nullptr) {\n            std::lock_guard<std::mutex> lock(m_mutex);\n            // 锁内可以用 relaxed: mutex 本身提供了同步\n            tmp = m_instance.load(std::memory_order_relaxed);\n            if (tmp == nullptr) {\n                tmp = new Singleton;\n                // release store: 保证 Singleton 构造完成后才对外可见\n                m_instance.store(tmp, std::memory_order_release);\n            }\n        }\n        return tmp;\n    }\n\n    Singleton(const Singleton&) = delete;\n    Singleton& operator=(const Singleton&) = delete;\n\nprivate:\n    Singleton() = default;\n\n    static std::atomic<Singleton*> m_instance;\n    static std::mutex m_mutex;\n};\n\nstd::atomic<Singleton*> Singleton::m_instance{nullptr};\nstd::mutex Singleton::m_mutex;\n```\n\n**内存序解释:**\n\n| 操作 | 内存序 | 原因 |\n|------|--------|------|\n| 第一次 load | `memory_order_acquire` | 与创建线程的 release store 构成 synchronizes-with 关系，保证看到完整构造的对象 |\n| 锁内 load | `memory_order_relaxed` | `std::mutex` 的 lock/unlock 已提供足够的同步保证，无需额外内存序 |\n| store | `memory_order_release` | 保证 `new Singleton` 的所有写操作 (内存分配 + 构造函数) 在 store 之前完成 |\n\n**为什么 `memory_order_relaxed` 不能用于第一次 load:**\n\n```\n线程 A (创建):                    线程 B (使用):\n  tmp = new Singleton;              tmp = m_instance.load(relaxed);  // 可能看到非空指针\n  // Singleton 成员写入              if (tmp != nullptr)\n  m_instance.store(tmp, release);     tmp->member;  // 但成员可能还未构造！\n```\n\nrelaxed load 不提供 acquire 语义，线程 B 看到指针非空时，不保证能看到 Singleton 构造函数中的写入。在 ARM、PowerPC 等弱序架构上，这个 bug 会真实发生。x86 的 TSO 模型碰巧掩盖了这个问题，但依赖特定硬件行为不是可移植的做法。\n\n### 3.3 方案三: 顺序一致性 (默认)\n\n省略 `memory_order` 参数，`std::atomic` 默认使用 `memory_order_seq_cst`：\n\n```cpp\nstatic Singleton* getInstance() {\n    Singleton* tmp = m_instance.load();  // 默认 seq_cst\n    if (tmp == nullptr) {\n        std::lock_guard<std::mutex> lock(m_mutex);\n        tmp = m_instance.load();         // 默认 seq_cst\n        if (tmp == nullptr) {\n            tmp = new Singleton;\n            m_instance.store(tmp);       // 默认 seq_cst\n        }\n    }\n    return tmp;\n}\n```\n\n这是正确的，但 `seq_cst` 的代价比 acquire/release 更高：\n\n| 架构 | acquire/release | seq_cst |\n|------|:---------------:|:-------:|\n| x86/x64 | load: `mov`; store: `mov` | load: `mov`; store: `xchg` (full barrier) |\n| ARMv7 | load: `ldr + dmb`; store: `dmb + str` | load: `dmb + ldr + dmb`; store: `dmb + str + dmb` |\n| ARMv8 | load: `ldar`; store: `stlr` | load: `ldar`; store: `stlr` (ARMv8 的 `stlr` 已是 seq_cst) |\n\n> 参考 Herb Sutter 的演讲 *\"atomic<> Weapons\" Part 2* (00:44:25 - 00:49:16)，详细分析了 seq_cst 在弱序 CPU 上生成的低效代码。\n\n对于单例这个场景，`seq_cst` 的额外开销不重要（store 操作只在首次创建时执行一次），但理解 acquire/release 对于其他 lock-free 编程场景至关重要。\n\n## 4. 常见错误分析\n\n### 4.1 错误一: 裸指针 DCLP\n\n```cpp\n// 错误: m_instance 不是 atomic，数据竞争 = 未定义行为\nstatic Singleton* m_instance;\n\nSingleton* getInstance() {\n    if (m_instance == nullptr) {        // 无锁读取裸指针 = data race\n        std::lock_guard<std::mutex> lock(m_mutex);\n        if (m_instance == nullptr) {\n            m_instance = new Singleton;\n        }\n    }\n    return m_instance;\n}\n```\n\n即使在 x86 上\"看起来\"能工作（因为 TSO 模型碰巧保证了对齐指针读写的原子性），这仍然是未定义行为。编译器可以假设不存在数据竞争，并据此进行优化（例如将 `m_instance` 缓存到寄存器中，导致永远看不到其他线程的写入）。\n\n### 4.2 错误二: atomic + relaxed 全用\n\n```cpp\n// 错误: relaxed load 不保证看到构造函数的写入\nSingleton* tmp = m_instance.load(std::memory_order_relaxed);\nif (tmp != nullptr) {\n    return tmp;  // tmp 指向的对象可能尚未完成构造！\n}\n```\n\n`memory_order_relaxed` 只保证原子性（不会读到半写的指针值），但不保证可见性。一个线程可能看到非空指针，却看不到 Singleton 构造函数中对成员变量的赋值。\n\n### 4.3 错误三: volatile 替代 atomic\n\n```cpp\n// 错误: C++ 的 volatile 与 Java 的 volatile 语义完全不同\nstatic volatile Singleton* m_instance;\n```\n\nC++ 的 `volatile` 只防止编译器优化掉对该变量的读写，不提供任何多线程同步保证。它是为 memory-mapped I/O 设计的，不是线程同步原语。Java 5+ 的 `volatile` 具有 acquire/release 语义，但 C++ 的 `volatile` 没有。\n\n### 4.4 错误四: 忽略销毁顺序\n\n```cpp\n// 潜在问题: Logger 析构时 Config 可能已销毁\nclass Config {\npublic:\n    static Config& getInstance() { static Config c; return c; }\n};\n\nclass Logger {\npublic:\n    static Logger& getInstance() { static Logger l; return l; }\n    ~Logger() {\n        Config::getInstance().get(\"log_level\");  // 危险！\n    }\n};\n```\n\n静态局部变量按构造的逆序销毁。如果 `Config` 先于 `Logger` 构造，它会后于 `Logger` 销毁，此时 Logger 析构函数中访问 Config 是安全的。但如果构造顺序相反，就会触发 use-after-destroy。\n\nNifty Counter 惯用法或 `std::call_once` + 动态分配 (永不删除) 可以规避此问题，但都增加了复杂度。\n\n## 5. 嵌入式系统中的单例\n\n### 5.1 MISRA C++ 视角\n\nMISRA C++ 对单例模式的几个相关规则：\n\n| 规则 | 约束 | 对单例的影响 |\n|------|------|-------------|\n| Rule 18-4-1 | 不应使用动态堆内存分配 | 禁止 `new Singleton`，只能用 Magic Statics (栈/BSS 分配) |\n| Rule 0-1-1 | 所有代码应可达 | 析构函数如果不可达 (单例永不销毁)，需文档化偏差 |\n| Rule 3-4-1 | 对象应在最窄作用域声明 | 全局单例与此规则冲突，需文档化 |\n\n在严格 MISRA 合规的嵌入式项目中，Magic Statics 方案是唯一可接受的实现，因为它避免了动态分配。\n\n### 5.2 `-fno-exceptions` 下的行为\n\n嵌入式常用 `-fno-exceptions` 编译。此时 Magic Statics 的行为：\n\n- GCC/Clang: `__cxa_guard_acquire` 失败时调用 `__cxa_guard_abort`，不抛异常。如果构造函数中的代码本身不依赖异常，整个初始化流程是 exception-free 的\n- 构造函数中不能使用 `try/catch`，需要用返回值或断言处理错误\n\n### 5.3 单核 MCU 的简化\n\n在没有操作系统的单核 MCU 上，不存在真正的多线程（只有主循环和中断）。此时单例退化为全局变量：\n\n```cpp\n// 单核裸机: 不需要任何同步机制\nclass Peripheral {\npublic:\n    static Peripheral& getInstance() {\n        static Peripheral instance;  // 在 main() 之前或首次调用时初始化\n        return instance;\n    }\nprivate:\n    Peripheral() { /* 初始化硬件寄存器 */ }\n};\n```\n\n如果 ISR 也需要访问单例，只需保证在启用中断之前完成单例初始化即可。\n\n### 5.4 何时不用单例\n\n单例模式在嵌入式系统中被过度使用。以下场景有更好的替代：\n\n| 场景 | 问题 | 替代方案 |\n|------|------|---------|\n| 多个模块共享配置 | 全局状态隐藏了依赖关系 | 依赖注入: 构造时传入配置引用 |\n| 硬件外设抽象 | 如果需要支持多个同类外设？ | 模板参数化: `Uart<1>`, `Uart<2>` |\n| 日志系统 | 测试时难以 mock | 接口注入: 构造时传入日志实例 |\n| 消息总线 | 不同子系统需要独立的总线 | 实例化多个 Bus 对象 |\n\n## 6. 完整测试代码\n\n```cpp\n#include <atomic>\n#include <cassert>\n#include <iostream>\n#include <mutex>\n#include <thread>\n#include <vector>\n\n// ==================== 方案一: Magic Statics ====================\nclass SingletonA {\npublic:\n    static SingletonA& getInstance() {\n        static SingletonA instance;\n        return instance;\n    }\n    int getValue() const { return value_; }\n\n    SingletonA(const SingletonA&) = delete;\n    SingletonA& operator=(const SingletonA&) = delete;\n\nprivate:\n    SingletonA() : value_(42) {}\n    int value_;\n};\n\n// ==================== 方案二: Acquire/Release DCLP ====================\nclass SingletonB {\npublic:\n    static SingletonB* getInstance() {\n        SingletonB* tmp = instance_.load(std::memory_order_acquire);\n        if (tmp == nullptr) {\n            std::lock_guard<std::mutex> lock(mutex_);\n            tmp = instance_.load(std::memory_order_relaxed);\n            if (tmp == nullptr) {\n                tmp = new SingletonB;\n                instance_.store(tmp, std::memory_order_release);\n            }\n        }\n        return tmp;\n    }\n\n    int getValue() const { return value_; }\n\n    SingletonB(const SingletonB&) = delete;\n    SingletonB& operator=(const SingletonB&) = delete;\n\nprivate:\n    SingletonB() : value_(42) {}\n    int value_;\n\n    static std::atomic<SingletonB*> instance_;\n    static std::mutex mutex_;\n};\n\nstd::atomic<SingletonB*> SingletonB::instance_{nullptr};\nstd::mutex SingletonB::mutex_;\n\n// ==================== 测试 ====================\nstatic std::atomic<int> g_count{0};\n\ntemplate <typename GetInstance>\nvoid concurrencyTest(const char* name, GetInstance getInst) {\n    g_count.store(0);\n    constexpr int kThreads = 16;\n    constexpr int kIterations = 100000;\n\n    std::vector<std::thread> threads;\n    threads.reserve(kThreads);\n\n    for (int i = 0; i < kThreads; ++i) {\n        threads.emplace_back([&getInst]() {\n            for (int j = 0; j < kIterations; ++j) {\n                auto* inst = getInst();\n                if (inst->getValue() == 42) {\n                    g_count.fetch_add(1, std::memory_order_relaxed);\n                }\n            }\n        });\n    }\n\n    for (auto& t : threads) {\n        t.join();\n    }\n\n    int expected = kThreads * kIterations;\n    std::cout << name << \": \" << g_count.load() << \"/\" << expected;\n    if (g_count.load() == expected) {\n        std::cout << \" PASS\" << std::endl;\n    } else {\n        std::cout << \" FAIL\" << std::endl;\n    }\n}\n\nint main() {\n    std::cout << \"=== Singleton Thread Safety Test ===\" << std::endl;\n\n    concurrencyTest(\"Magic Statics\",\n        []() { return &SingletonA::getInstance(); });\n\n    concurrencyTest(\"Acquire/Release DCLP\",\n        []() { return SingletonB::getInstance(); });\n\n    // 验证唯一性\n    assert(&SingletonA::getInstance() == &SingletonA::getInstance());\n    assert(SingletonB::getInstance() == SingletonB::getInstance());\n    std::cout << \"Uniqueness: PASS\" << std::endl;\n\n    return 0;\n}\n```\n\n## 7. 方案对比与推荐\n\n| 维度 | Magic Statics | acquire/release DCLP | seq_cst DCLP |\n|------|:-------------:|:--------------------:|:------------:|\n| 正确性 | 编译器保证 | 需要正确使用内存序 | 编译器保证 (默认最强序) |\n| 代码量 | 3 行 | 15+ 行 | 12+ 行 |\n| 动态分配 | 无 (BSS/栈) | 是 (`new`) | 是 (`new`) |\n| 内存泄漏 | 无 | 需手动管理 | 需手动管理 |\n| 销毁控制 | 自动 (逆序) | 手动控制 | 手动控制 |\n| MISRA 合规 | 合规 | 违反 Rule 18-4-1 | 违反 Rule 18-4-1 |\n| ARM 性能 | 最优 (编译器可利用数据依赖) | 接近最优 | 多余的 DMB 指令 |\n| 编译器要求 | C++11 完整支持 | C++11 `<atomic>` | C++11 `<atomic>` |\n\n**推荐:**\n\n1. **默认选择 Magic Statics** -- 简洁、正确、零动态分配、MISRA 合规\n2. **需要控制销毁顺序时**用 acquire/release DCLP -- 理解内存序是前提\n3. **不确定时用 seq_cst** -- 性能代价在单例场景中可忽略，正确性更重要\n4. **考虑是否真的需要单例** -- 依赖注入通常是更好的设计\n\n## 参考文献\n\n1. Scott Meyers & Andrei Alexandrescu, [*C++ and the Perils of Double-Checked Locking*](http://www.aristeia.com/Papers/DDJ_Jul_Aug_2004_revised.pdf), DDJ, 2004\n2. Jeff Preshing, [*Double-Checked Locking is Fixed In C++11*](https://preshing.com/20130930/double-checked-locking-is-fixed-in-cpp11/), 2013\n3. StackOverflow, [*Is implementation of double-checked singleton thread-safe?*](https://stackoverflow.com/questions/43292897/is-implementation-of-double-checked-singleton-thread-safe)\n4. Herb Sutter, [*atomic<> Weapons*](https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/), 2013\n5. ISO/IEC 14882:2011 (C++11), [stmt.dcl] p4 -- 静态局部变量并发初始化保证\n6. [*Double-Checked Locking Is Broken*](https://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html), Bill Pugh et al., 2000\n",
      "ctime": "1771552558",
      "mtime": "1771552558",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/deadlock_priority_inversion_practice.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267226662",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "多线程死锁与优先级反转实战: 从问题复现到工程解决方案",
      "brief_content": "死锁与优先级反转的实战指南。通过 6 个可编译运行的 C++ 示例，复现经典 AB-BA 死锁、回调重入死锁、自死锁、优先级反转等场景，逐一给出工程修复方案（全局锁序、std::scoped_lock",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 本文是**实战篇**，通过可编译运行的代码示例复现死锁与优先级反转，并给出修复方案。\n>\n> **姊妹篇**: [嵌入式系统死锁防御: 从有序锁到无锁架构的工程实践](../deadlock_prevention/) -- 侧重 newosp 框架的架构级防御策略（无锁 MPSC 总线、SPSC 队列、Collect-Release-Execute 模式、LIFO 有序关停等），读者可先阅读本文理解问题场景，再阅读姊妹篇学习系统级解决方案。\n>\n> 相关文章:\n> - [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/) -- 生产环境的锁竞争量化定位\n> - [锁竞争基准测试](../lock_contention_benchmark/) -- Spinlock vs Mutex vs 无锁队列性能对比\n>\n> 参考:\n> - 原文: [C++ 线程优先级反转](https://blog.csdn.net/stallion5632/article/details/143610920)\n> - 原文: [C++ 嵌套锁与编译优化导致的死锁问题](https://blog.csdn.net/stallion5632/article/details/143633084)\n> - [Mars Pathfinder Priority Inversion](https://www.cs.cornell.edu/courses/cs614/1999sp/papers/pathfinder.html)\n> - [Valgrind Helgrind](https://valgrind.org/docs/manual/hg-manual.html)\n> - [ThreadSanitizer](https://clang.llvm.org/docs/ThreadSanitizer.html)\n\n---\n\n## 两篇文章的关系\n\n| 维度 | 本文（实战篇） | 姊妹篇（架构篇） |\n|------|---------------|-----------------|\n| 侧重 | **复现问题 + 逐个修复** | **架构级根除** |\n| 代码风格 | 独立可编译示例 | newosp 框架源码 |\n| 读者画像 | 遇到死锁 bug 需要定位修复 | 设计新系统需要防御策略 |\n| 覆盖范围 | AB-BA 死锁、重入死锁、自死锁、优先级反转 | 无锁 MPSC/SPSC、自旋锁退避、Collect-Release-Execute、LIFO 关停 |\n\n建议阅读顺序: **本文（理解问题） -> 姊妹篇（系统方案）**。\n\n---\n\n## 1. 经典死锁: AB-BA 锁序违反\n\n### 1.1 问题复现\n\n这是最经典的死锁模式: 两个线程以相反顺序获取两把锁。\n\n```cpp\n// deadlock_abba.cpp\n// g++ -std=c++17 -pthread -o deadlock_abba deadlock_abba.cpp\n#include <iostream>\n#include <mutex>\n#include <thread>\n#include <chrono>\n\nstd::mutex mutex_a;\nstd::mutex mutex_b;\n\nvoid thread1() {\n    std::lock_guard<std::mutex> lock_a(mutex_a);       // 先锁 A\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    std::lock_guard<std::mutex> lock_b(mutex_b);       // 再锁 B\n    std::cout << \"Thread 1 acquired both locks\\n\";\n}\n\nvoid thread2() {\n    std::lock_guard<std::mutex> lock_b(mutex_b);       // 先锁 B\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    std::lock_guard<std::mutex> lock_a(mutex_a);       // 再锁 A -- 死锁!\n    std::cout << \"Thread 2 acquired both locks\\n\";\n}\n\nint main() {\n    std::thread t1(thread1);\n    std::thread t2(thread2);\n    t1.join();\n    t2.join();\n    return 0;\n}\n```\n\n运行结果: **程序挂起，永不退出**。\n\n```\n$ ./deadlock_abba\n(挂起，无输出)\n```\n\n时序分析:\n\n```mermaid\ngantt\n    title AB-BA 死锁时序 (错误的锁获取顺序)\n    dateFormat X\n    axisFormat %s\n\n    section Thread 1\n    lock(mutex_a) 成功          :done, t1a, 0, 1\n    模拟工作                     :done, t1w, 1, 2\n    lock(mutex_b) 阻塞...       :crit, t1b, 2, 5\n\n    section Thread 2\n    lock(mutex_b) 成功          :done, t2b, 0, 1\n    模拟工作                     :done, t2w, 1, 2\n    lock(mutex_a) 阻塞...       :crit, t2a, 2, 5\n```\n\n> Thread 1 持有 A 等待 B，Thread 2 持有 B 等待 A -- 循环等待，死锁。\n\n### 1.2 修复方案一: 统一锁序\n\n最简单直接的修复: **所有线程以相同顺序获取锁**。\n\n```cpp\nvoid thread1_fixed() {\n    std::lock_guard<std::mutex> lock_a(mutex_a);       // 先 A\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    std::lock_guard<std::mutex> lock_b(mutex_b);       // 后 B\n    std::cout << \"Thread 1 acquired both locks\\n\";\n}\n\nvoid thread2_fixed() {\n    std::lock_guard<std::mutex> lock_a(mutex_a);       // 先 A（与 thread1 一致）\n    std::this_thread::sleep_for(std::chrono::milliseconds(10));\n    std::lock_guard<std::mutex> lock_b(mutex_b);       // 后 B\n    std::cout << \"Thread 2 acquired both locks\\n\";\n}\n```\n\n```mermaid\ngantt\n    title 统一锁序后 (正确的锁获取顺序)\n    dateFormat X\n    axisFormat %s\n\n    section Thread 1\n    lock(mutex_a) 成功          :done, t1a, 0, 1\n    模拟工作                     :done, t1w, 1, 2\n    lock(mutex_b) 成功          :done, t1b, 2, 3\n    完成                         :done, t1d, 3, 4\n\n    section Thread 2\n    lock(mutex_a) 等待...       :active, t2a, 0, 4\n    lock(mutex_a) 成功          :done, t2a2, 4, 5\n    lock(mutex_b) 成功          :done, t2b, 5, 6\n    完成                         :done, t2d, 6, 7\n```\n\n> 两个线程按相同顺序 (A -> B) 获取锁，Thread 2 排队等待 Thread 1 释放 A 后再继续，不会死锁。\n\n**局限**: 当系统中有数十把锁时，维护全局锁序变得困难。新增一把锁需要确定它在全局序中的位置，并更新所有调用点。姊妹篇中介绍的 `OrderedLock_t` + `lock_multiple()` 方案通过编号自动排序解决了这个问题。\n\n### 1.3 修复方案二: std::scoped_lock (C++17)\n\nC++17 提供了 `std::scoped_lock`，它内部使用死锁避免算法（类似 `std::lock`）同时获取多把锁:\n\n```cpp\nvoid thread1_scoped() {\n    std::scoped_lock lock(mutex_a, mutex_b);  // 原子地获取两把锁\n    std::cout << \"Thread 1 acquired both locks\\n\";\n}\n\nvoid thread2_scoped() {\n    std::scoped_lock lock(mutex_a, mutex_b);  // 同样的调用，顺序无关\n    std::cout << \"Thread 2 acquired both locks\\n\";\n}\n```\n\n`std::scoped_lock` 的内部实现使用 try-and-back-off 算法:\n\n1. 尝试锁定第一把锁\n2. 尝试 `try_lock` 第二把锁\n3. 如果失败，释放第一把锁，从第二把锁开始重新尝试\n\n这保证不会出现「持有一把锁等待另一把」的情况，从根本上打破了循环等待条件。\n\n**嵌入式注意**: `std::scoped_lock` 适用于 Linux 用户空间。RTOS 环境（FreeRTOS、RT-Thread）无 C++ 标准库，需使用姊妹篇中的 `lock_multiple()` C 实现。\n\n### 1.4 修复方案三: try_lock + 回退\n\n适用于不能同时获取所有锁的场景（例如锁在不同阶段才确定）:\n\n```cpp\nvoid thread2_trylock() {\n    while (true) {\n        std::unique_lock<std::mutex> lock_b(mutex_b);\n        if (mutex_a.try_lock()) {\n            // 成功获取两把锁\n            std::lock_guard<std::mutex> lock_a(mutex_a, std::adopt_lock);\n            std::cout << \"Thread 2 acquired both locks\\n\";\n            return;\n        }\n        // try_lock 失败: 释放 mutex_b，退避后重试\n        lock_b.unlock();\n        std::this_thread::sleep_for(std::chrono::microseconds(100));\n    }\n}\n```\n\n**关键**: `try_lock` 失败时**必须释放已持有的锁**，否则会活锁。退避时间加随机抖动可以避免两个线程同步重试。\n\n---\n\n## 2. 回调重入死锁\n\n### 2.1 问题复现\n\n这是嵌入式系统中最常见但最隐蔽的死锁: 在持有锁的情况下调用回调函数，而回调函数内部又尝试获取同一把锁。\n\n```mermaid\nsequenceDiagram\n    participant main\n    participant NotifyAll\n    participant Callback\n    participant Count\n\n    main->>NotifyAll: 调用 NotifyAll()\n    NotifyAll->>NotifyAll: lock(mutex_) 成功\n    NotifyAll->>Callback: 执行回调 cb()\n    Callback->>Count: 调用 Count()\n    Count->>Count: lock(mutex_) 阻塞!\n    Note over NotifyAll,Count: 死锁: mutex_ 已被 NotifyAll 持有,<br/>Count 永远无法获取\n```\n\n```cpp\n// deadlock_reentrant.cpp\n// g++ -std=c++17 -pthread -o deadlock_reentrant deadlock_reentrant.cpp\n#include <iostream>\n#include <mutex>\n#include <functional>\n#include <vector>\n\nclass EventManager {\npublic:\n    void Register(std::function<void()> callback) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        callbacks_.push_back(callback);\n    }\n\n    void NotifyAll() {\n        std::lock_guard<std::mutex> lock(mutex_);      // 持有锁\n        for (auto& cb : callbacks_) {\n            cb();                                       // 回调内可能再次获取锁!\n        }\n    }\n\n    size_t Count() {\n        std::lock_guard<std::mutex> lock(mutex_);       // 尝试获取同一把锁\n        return callbacks_.size();\n    }\n\nprivate:\n    std::mutex mutex_;\n    std::vector<std::function<void()>> callbacks_;\n};\n\nint main() {\n    EventManager mgr;\n\n    // 注册一个回调，回调内部调用 Count()\n    mgr.Register([&mgr]() {\n        std::cout << \"Callback: count = \" << mgr.Count() << \"\\n\";  // 死锁!\n    });\n\n    mgr.NotifyAll();  // 触发死锁\n    return 0;\n}\n```\n\n调用栈:\n\n```\nmain()\n  -> NotifyAll()\n    -> lock(mutex_)        // 第一次加锁，成功\n    -> cb()\n      -> Count()\n        -> lock(mutex_)    // 第二次加锁，死锁! (std::mutex 不可重入)\n```\n\n### 2.2 错误修复: 使用 recursive_mutex\n\n```cpp\nstd::recursive_mutex mutex_;  // 允许同一线程多次加锁\n```\n\n这在技术上能避免死锁，但**不推荐**。`recursive_mutex` 掩盖了架构问题: 回调在锁内执行意味着回调可以看到中间状态的数据结构，容易引发更难调试的逻辑错误。\n\n此外，`recursive_mutex` 的性能开销高于普通 `mutex`（需要记录持有线程 ID 和递归计数）。\n\n### 2.3 正确修复: Collect-Release-Execute\n\n```mermaid\nsequenceDiagram\n    participant main\n    participant NotifyAll\n    participant Callback\n    participant Count\n\n    main->>NotifyAll: 调用 NotifyAll()\n    rect rgb(200,230,200)\n        Note over NotifyAll: Phase 1: Collect\n        NotifyAll->>NotifyAll: lock(mutex_) 成功\n        NotifyAll->>NotifyAll: 拷贝回调列表到 local\n        NotifyAll->>NotifyAll: unlock(mutex_) (RAII)\n    end\n    rect rgb(200,210,240)\n        Note over NotifyAll: Phase 3: Execute (锁外)\n        NotifyAll->>Callback: 执行回调 cb()\n        Callback->>Count: 调用 Count()\n        Count->>Count: lock(mutex_) 成功!\n        Count-->>Callback: 返回 count\n    end\n```\n\n将通知逻辑拆分为三个阶段: 在锁内**收集**回调列表，**释放**锁后再**执行**回调:\n\n```cpp\nclass EventManagerFixed {\npublic:\n    void Register(std::function<void()> callback) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        callbacks_.push_back(callback);\n    }\n\n    void NotifyAll() {\n        // Phase 1: Collect -- 在锁内拷贝回调列表\n        std::vector<std::function<void()>> local_callbacks;\n        {\n            std::lock_guard<std::mutex> lock(mutex_);\n            local_callbacks = callbacks_;\n        }\n        // Phase 2: Release -- 锁已自动释放 (RAII)\n\n        // Phase 3: Execute -- 在锁外执行回调\n        for (auto& cb : local_callbacks) {\n            cb();  // 回调内可以安全调用 Count()、Register() 等任意方法\n        }\n    }\n\n    size_t Count() {\n        std::lock_guard<std::mutex> lock(mutex_);\n        return callbacks_.size();\n    }\n\nprivate:\n    std::mutex mutex_;\n    std::vector<std::function<void()>> callbacks_;\n};\n```\n\n**代价**: 额外的回调列表拷贝。对于嵌入式系统，可以使用栈上固定数组替代 `std::vector` 避免堆分配（参见姊妹篇中 newosp Watchdog 的 `PendingCallback timeout_pending[MaxThreads]` 实现）。\n\n---\n\n## 3. 自死锁: 同一线程重复加锁\n\n### 3.1 问题复现\n\n```mermaid\nsequenceDiagram\n    participant main\n    participant outer\n    participant inner\n\n    main->>outer: 调用 outer()\n    outer->>outer: lock(mtx) 成功\n    outer->>inner: 调用 inner()\n    inner->>inner: lock(mtx) 阻塞!\n    Note over outer,inner: 死锁: 同一线程持有 mtx<br/>又尝试再次获取 mtx\n```\n\n`std::mutex` 的 `lock()` 在同一线程重复调用时是**未定义行为**（通常表现为死锁）:\n\n```cpp\n// deadlock_self.cpp\n#include <iostream>\n#include <mutex>\n\nstd::mutex mtx;\n\nvoid inner() {\n    std::lock_guard<std::mutex> lock(mtx);  // 第二次加锁 -- 死锁\n    std::cout << \"inner\\n\";\n}\n\nvoid outer() {\n    std::lock_guard<std::mutex> lock(mtx);  // 第一次加锁\n    inner();                                 // 调用 inner，再次加锁\n}\n\nint main() {\n    outer();  // 死锁\n    return 0;\n}\n```\n\n### 3.2 修复方案\n\n**方案 A: 分离锁职责**\n\n`outer()` 和 `inner()` 不应共享同一把锁。如果它们保护不同的数据，使用不同的锁:\n\n```cpp\nstd::mutex outer_mtx;\nstd::mutex inner_mtx;\n\nvoid inner() {\n    std::lock_guard<std::mutex> lock(inner_mtx);\n    std::cout << \"inner\\n\";\n}\n\nvoid outer() {\n    std::lock_guard<std::mutex> lock(outer_mtx);\n    inner();  // 安全: 不同的锁\n}\n```\n\n**方案 B: 提供无锁内部版本**\n\n如果 `outer()` 和 `inner()` 确实保护同一份数据，提供一个不加锁的内部实现:\n\n```cpp\nclass DataStore {\npublic:\n    void Update() {\n        std::lock_guard<std::mutex> lock(mtx_);\n        DoUpdate();          // 调用无锁内部版本\n        LogState();          // 同样调用无锁版本\n    }\n\n    void LogState() {\n        std::lock_guard<std::mutex> lock(mtx_);\n        DoLogState();\n    }\n\nprivate:\n    void DoUpdate() { /* 无锁实现 */ }\n    void DoLogState() { /* 无锁实现 */ }\n\n    std::mutex mtx_;\n};\n```\n\n公开接口加锁，内部方法无锁。公开接口之间不互相调用，只调用无锁的 `Do*` 方法。\n\n---\n\n## 4. 优先级反转\n\n### 4.1 什么是优先级反转\n\n优先级反转是实时系统中的「准死锁」: 高优先级任务被低优先级任务**间接**阻塞。\n\n```mermaid\ngantt\n    title 优先级反转 (Priority Inversion)\n    dateFormat X\n    axisFormat %s\n\n    section Task A (高优先级)\n    尝试获取锁                   :crit, a1, 2, 3\n    阻塞等待 C 释放锁...         :crit, a2, 3, 8\n    获取锁, 执行                 :done, a3, 8, 9\n\n    section Task B (中优先级)\n    抢占 Task C 执行             :active, b1, 3, 7\n\n    section Task C (低优先级)\n    获取锁, 执行                 :done, c1, 0, 3\n    被 B 抢占, 无法运行          :crit, c2, 3, 7\n    恢复执行, 释放锁              :done, c3, 7, 8\n```\n\n> Task A (高优先级) 等待 Task C 释放锁，但 Task C 被 Task B 抢占无法运行。结果: A 的实际优先级低于 B。\n\n关键: Task A（高优先级）等待 Task C（低优先级）释放锁，但 Task B（中优先级）抢占了 Task C 的 CPU 时间，导致 C 无法执行从而无法释放锁。**高优先级任务实际上被中优先级任务阻塞了**。\n\n最著名的案例是 1997 年 Mars Pathfinder: VxWorks RTOS 上的气象数据采集任务（低优先级）持有共享内存总线锁，通信任务（高优先级）等待该锁，被中优先级任务持续抢占，导致看门狗超时系统反复重启。NASA 最终通过地面上传补丁启用优先级继承解决了问题。\n\n### 4.2 问题复现\n\n```cpp\n// priority_inversion.cpp\n// g++ -std=c++17 -pthread -o priority_inversion priority_inversion.cpp\n// 需要 root 权限或 CAP_SYS_NICE 运行 SCHED_FIFO\n#include <iostream>\n#include <mutex>\n#include <thread>\n#include <chrono>\n#include <pthread.h>\n#include <sched.h>\n\nstd::mutex shared_resource;\n\nvoid set_realtime_priority(int priority) {\n    struct sched_param param;\n    param.sched_priority = priority;\n    if (pthread_setschedparam(pthread_self(), SCHED_FIFO, &param) != 0) {\n        perror(\"pthread_setschedparam\");\n    }\n}\n\n// 低优先级任务: 持有锁做长时间计算\nvoid task_low() {\n    set_realtime_priority(10);\n    std::lock_guard<std::mutex> lock(shared_resource);\n    std::cout << \"[Low ] Acquired lock, working...\\n\";\n\n    // 模拟长时间计算 (持有锁期间)\n    auto start = std::chrono::steady_clock::now();\n    while (std::chrono::steady_clock::now() - start < std::chrono::seconds(3)) {\n        // busy work\n    }\n\n    std::cout << \"[Low ] Done, releasing lock.\\n\";\n}\n\n// 中优先级任务: 不需要锁，但会抢占低优先级任务\nvoid task_medium() {\n    set_realtime_priority(50);\n    std::cout << \"[Med ] Running, preempting low priority...\\n\";\n\n    auto start = std::chrono::steady_clock::now();\n    while (std::chrono::steady_clock::now() - start < std::chrono::seconds(2)) {\n        // busy work: 持续占用 CPU，阻止低优先级任务运行\n    }\n\n    std::cout << \"[Med ] Done.\\n\";\n}\n\n// 高优先级任务: 需要锁\nvoid task_high() {\n    set_realtime_priority(80);\n    std::cout << \"[High] Trying to acquire lock...\\n\";\n\n    auto t0 = std::chrono::steady_clock::now();\n    std::lock_guard<std::mutex> lock(shared_resource);\n    auto t1 = std::chrono::steady_clock::now();\n\n    auto wait_ms = std::chrono::duration_cast<std::chrono::milliseconds>(t1 - t0).count();\n    std::cout << \"[High] Acquired lock after \" << wait_ms << \" ms\\n\";\n}\n\nint main() {\n    std::thread t_low(task_low);\n    std::this_thread::sleep_for(std::chrono::milliseconds(100));  // 让低优先级先获取锁\n\n    std::thread t_med(task_medium);\n    std::thread t_high(task_high);\n\n    t_low.join();\n    t_med.join();\n    t_high.join();\n    return 0;\n}\n```\n\n**预期输出** (单核或绑定同一核心时):\n\n```\n[Low ] Acquired lock, working...\n[Med ] Running, preempting low priority...\n[High] Trying to acquire lock...\n[Med ] Done.                          <-- 中优先级先于高优先级完成!\n[Low ] Done, releasing lock.\n[High] Acquired lock after ~5000 ms   <-- 高优先级等待了 5 秒\n```\n\n高优先级任务本应最快完成，实际等待时间等于 **低优先级持锁时间 + 中优先级抢占时间**。\n\n### 4.3 修复方案一: 优先级继承 (PTHREAD_PRIO_INHERIT)\n\n优先级继承的原理: 当高优先级任务 A 阻塞在低优先级任务 C 持有的锁上时，内核**临时提升** C 的优先级到 A 的级别。这样 C 不会被中优先级任务 B 抢占，可以尽快释放锁。\n\n```cpp\n#include <pthread.h>\n\n// 创建支持优先级继承的 mutex\npthread_mutex_t pi_mutex;\n\nvoid init_pi_mutex() {\n    pthread_mutexattr_t attr;\n    pthread_mutexattr_init(&attr);\n    pthread_mutexattr_setprotocol(&attr, PTHREAD_PRIO_INHERIT);  // 关键\n    pthread_mutex_init(&pi_mutex, &attr);\n    pthread_mutexattr_destroy(&attr);\n}\n```\n\n启用优先级继承后的时序:\n\n```mermaid\ngantt\n    title 优先级继承 (Priority Inheritance) 修复后\n    dateFormat X\n    axisFormat %s\n\n    section Task A (高优先级)\n    尝试获取锁                   :crit, a1, 2, 3\n    等待 C 释放锁               :active, a2, 3, 5\n    获取锁, 执行                 :done, a3, 5, 6\n\n    section Task B (中优先级)\n    等待 (无法抢占已提升的 C)    :active, b1, 3, 6\n    执行                         :done, b2, 6, 8\n\n    section Task C (低->高优先级)\n    获取锁, 执行                 :done, c1, 0, 3\n    优先级提升到 A 级别, 继续    :done, c2, 3, 5\n    释放锁, 恢复原优先级          :milestone, c3, 5, 5\n```\n\n> C 被提升到与 A 相同的优先级，B 无法抢占 C，C 快速完成并释放锁。A 的等待时间大幅缩短。\n\n**内核要求**: `PTHREAD_PRIO_INHERIT` 需要 Linux 内核配置 `CONFIG_RT_MUTEXES=y`。标准内核通常已启用，PREEMPT_RT 补丁集一定启用。可通过以下命令确认:\n\n```bash\nzcat /proc/config.gz | grep RT_MUTEX\n# 或\ngrep RT_MUTEX /boot/config-$(uname -r)\n```\n\n**C++ 标准库的限制**: `std::mutex` 不支持设置优先级继承属性。需要使用 POSIX `pthread_mutex_t` 或封装一个 RAII 包装器:\n\n```cpp\nclass PiMutex {\npublic:\n    PiMutex() {\n        pthread_mutexattr_t attr;\n        pthread_mutexattr_init(&attr);\n        pthread_mutexattr_setprotocol(&attr, PTHREAD_PRIO_INHERIT);\n        pthread_mutex_init(&mtx_, &attr);\n        pthread_mutexattr_destroy(&attr);\n    }\n\n    ~PiMutex() { pthread_mutex_destroy(&mtx_); }\n\n    void lock() { pthread_mutex_lock(&mtx_); }\n    void unlock() { pthread_mutex_unlock(&mtx_); }\n    bool try_lock() { return pthread_mutex_trylock(&mtx_) == 0; }\n\n    PiMutex(const PiMutex&) = delete;\n    PiMutex& operator=(const PiMutex&) = delete;\n\nprivate:\n    pthread_mutex_t mtx_;\n};\n\n// 使用方式与 std::mutex 一致\nPiMutex shared_resource;\nstd::lock_guard<PiMutex> lock(shared_resource);\n```\n\n### 4.4 修复方案二: 无锁架构\n\n如果高优先级任务的数据通路可以设计为无锁，则从根本上消除优先级反转。这正是姊妹篇中 newosp `RealtimeExecutor` 的方案: **SCHED_FIFO 调度线程 + 无锁 CAS 消息总线**，整条实时路径不持有任何 mutex。\n\n详见: [嵌入式系统死锁防御 -- 第10节: 实时调度与优先级反转防御](../deadlock_prevention/#10-实时调度与优先级反转防御)\n\n### 4.5 修复方案三: 最小化持锁时间\n\n优先级反转的严重程度与**持锁时间成正比**。缩短临界区是最具普适性的缓解措施:\n\n```cpp\n// 不好: 在锁内做 I/O\nvoid task_low_bad() {\n    std::lock_guard<std::mutex> lock(shared_resource);\n    read_sensor();          // 可能阻塞数毫秒\n    compute_result();       // CPU 密集\n    write_log();            // 磁盘 I/O，可能阻塞数十毫秒\n}\n\n// 好: 只在锁内做最小必要操作\nvoid task_low_good() {\n    SensorData raw = read_sensor();     // 锁外读取\n    Result res = compute_result(raw);   // 锁外计算\n\n    {\n        std::lock_guard<std::mutex> lock(shared_resource);\n        shared_state_ = res;            // 锁内只做赋值\n    }\n\n    write_log(res);                     // 锁外写日志\n}\n```\n\n---\n\n## 5. 纠正常见误解: 编译优化不会导致锁重排\n\n### 5.1 误解来源\n\n有一种广泛传播的说法: 「`-O3` 编译优化可能重排 mutex 的获取顺序，导致死锁」。这是**不正确的**。\n\n### 5.2 为什么编译器不会重排锁操作\n\nC++ 标准明确规定: `std::mutex::lock()` 和 `std::mutex::unlock()` 是**同步操作**（synchronization operations），具有 acquire 和 release 语义。编译器和 CPU 都**不允许**将普通内存操作移出临界区，更不允许重排 mutex 操作本身。\n\n```cpp\nstd::lock_guard<std::mutex> lockA(mutexA);  // acquire 语义\n// --- 编译器保证以下操作不会被提前到 lockA 之前 ---\nx = 1;\ny = 2;\n// --- 编译器保证以上操作不会被延后到 lockB 之后 ---\nstd::lock_guard<std::mutex> lockB(mutexB);  // acquire 语义\n```\n\n即使在 `-O3` 下，编译器也不会将 `lockA` 和 `lockB` 的获取顺序调换。可以通过查看汇编确认:\n\n```bash\ng++ -std=c++17 -O3 -S -o output.s deadlock_abba.cpp\n# 检查汇编中 pthread_mutex_lock 的调用顺序\n```\n\n### 5.3 死锁的真正原因\n\n第 1 节的 AB-BA 死锁示例在**任何优化级别**下都会死锁（`-O0`、`-O1`、`-O2`、`-O3`），因为死锁的根因是**锁获取顺序不一致**，与编译优化无关。\n\n`-O3` 能影响的是: 临界区**内部**的指令重排和优化（寄存器分配、循环展开、内联等），但这些不会改变锁操作的顺序。\n\n### 5.4 编译优化真正影响的场景\n\n编译器优化确实会导致多线程问题，但是**数据竞争**，不是锁重排:\n\n```cpp\n// 没有同步的共享变量\nint x = 0, y = 0;\n\n// 线程 1\nvoid thread1() {\n    x = 1;    // 可能被编译器/CPU 重排到 a = y 之后\n    int a = y;\n}\n\n// 线程 2\nvoid thread2() {\n    y = 1;\n    int b = x;\n}\n```\n\n这里 `x` 和 `y` 不是原子变量，也没有锁保护，编译器可以自由重排。解决方案是使用 `std::atomic` 或加锁，而不是「避免 `-O3`」。\n\n**结论**: 如果你的程序在 `-O0` 下正常但在 `-O3` 下死锁，问题出在数据竞争或未定义行为，不是锁重排。应该用 TSan 检测数据竞争。\n\n---\n\n## 6. 检测工具\n\n### 6.1 Thread Sanitizer (TSan)\n\nTSan 是目前最强大的死锁和数据竞争检测工具:\n\n```bash\n# 编译\ng++ -std=c++17 -fsanitize=thread -g -o test deadlock_abba.cpp -pthread\n\n# 运行\n./test\n```\n\nTSan 输出（检测到锁序违反）:\n\n```\nWARNING: ThreadSanitizer: lock-order-inversion (potential deadlock)\n  Cycle in lock order graph: M0 (mutex_a) => M1 (mutex_b) => M0\n\n  Mutex M1 acquired here while holding mutex M0:\n    #0 pthread_mutex_lock\n    #1 thread1() deadlock_abba.cpp:9\n\n  Mutex M0 acquired here while holding mutex M1:\n    #0 pthread_mutex_lock\n    #1 thread2() deadlock_abba.cpp:15\n```\n\n**嵌入式集成**: newosp 的 CI 对所有测试启用 TSan，确保 979 个测试用例无锁序违反。参见姊妹篇第 11.3 节的验证阶段建议。\n\n### 6.2 Valgrind Helgrind\n\n```bash\nvalgrind --tool=helgrind ./deadlock_abba\n```\n\nHelgrind 同样能检测锁序违反和数据竞争，但运行速度比 TSan 慢 20-100 倍。优势是不需要重新编译。\n\n### 6.3 Linux lockdep (内核模块)\n\n如果死锁发生在内核空间（驱动程序），可以启用内核的 lockdep:\n\n```bash\n# 内核配置\nCONFIG_PROVE_LOCKING=y\nCONFIG_LOCKDEP=y\n\n# 运行时查看\ncat /proc/lockdep_stats\n```\n\nlockdep 在**第一次**出现潜在的锁序违反时就会告警，即使死锁尚未实际发生。\n\n### 6.4 GDB 死锁诊断\n\n如果程序已经死锁，用 GDB 附加并检查所有线程的调用栈:\n\n```bash\ngdb -p $(pidof deadlock_abba)\n\n(gdb) thread apply all bt\n\nThread 2 (LWP 12346):\n#0 __lll_lock_wait () at lowlevellock.c:49\n#1 pthread_mutex_lock ()\n#2 thread2 () at deadlock_abba.cpp:15    <-- 等待 mutex_a\n\nThread 1 (LWP 12345):\n#0 __lll_lock_wait () at lowlevellock.c:49\n#1 pthread_mutex_lock ()\n#2 thread1 () at deadlock_abba.cpp:9     <-- 等待 mutex_b\n```\n\n两个线程都在 `__lll_lock_wait`，并且持有对方等待的锁 -- 确认死锁。\n\n---\n\n## 7. 嵌入式系统中的特殊考量\n\n### 7.1 ISR 中的死锁\n\n中断服务程序（ISR）不能调用阻塞操作。如果 ISR 尝试获取已被主循环持有的锁，系统会永久挂起（ISR 优先级高于所有线程，被阻塞的线程永远无法运行释放锁）:\n\n```c\n// 错误: ISR 中使用 mutex\nvoid UART_IRQHandler(void) {\n    mutex_lock(&uart_buf_lock);    // 永久阻塞!\n    // ...\n    mutex_unlock(&uart_buf_lock);\n}\n```\n\n**解决方案**:\n\n| 方案 | 实现 | 适用场景 |\n|------|------|----------|\n| 禁中断 | `__disable_irq()` / `__enable_irq()` | 极短临界区 (< 1 us) |\n| SPSC 无锁队列 | ISR 写入，主循环读取 | 数据缓冲 |\n| 原子标志 | `std::atomic_flag` | 简单通知 |\n\nSPSC 无锁队列正是姊妹篇第 4.2 节详细介绍的 `SpscRingbuffer`，天然支持 ISR-to-thread 的单向数据流。\n\n### 7.2 RTOS 优先级反转\n\nFreeRTOS 提供了 `xSemaphoreCreateMutex()` 自带优先级继承，但 **Binary Semaphore 不支持**:\n\n```c\n// 正确: 使用 Mutex (支持优先级继承)\nSemaphoreHandle_t lock = xSemaphoreCreateMutex();\n\n// 错误: 使用 Binary Semaphore (不支持优先级继承)\nSemaphoreHandle_t lock = xSemaphoreCreateBinary();\n```\n\nRT-Thread 的 `rt_mutex_create()` 同样默认启用优先级继承。\n\n### 7.3 看门狗作为安全网\n\n无论防御措施多完善，生产系统都应该有看门狗作为最后防线。如果死锁导致关键线程停止喂狗，看门狗超时触发系统复位:\n\n```\n正常: 线程 -> 喂狗 -> 看门狗复位计数器\n死锁: 线程阻塞 -> 停止喂狗 -> 看门狗超时 -> 系统复位\n```\n\n姊妹篇第 7 节介绍了 newosp 的 `ThreadWatchdog` 实现，它使用 Collect-Release-Execute 模式确保看门狗自身不会死锁。\n\n---\n\n## 8. 总结: 死锁防御检查清单\n\n| 场景 | 问题 | 解决方案 | 示例位置 |\n|------|------|----------|----------|\n| 两把锁顺序不一致 | AB-BA 死锁 | `std::scoped_lock` / 全局锁序 | 本文第 1 节 |\n| 回调在锁内执行 | 重入死锁 | Collect-Release-Execute | 本文第 2 节 / 姊妹篇第 7 节 |\n| 同一线程重复加锁 | 自死锁 | 分离锁职责 / 无锁内部方法 | 本文第 3 节 |\n| 高优先级任务等锁 | 优先级反转 | `PTHREAD_PRIO_INHERIT` / 无锁 | 本文第 4 节 / 姊妹篇第 10 节 |\n| ISR 中加锁 | 永久阻塞 | SPSC 无锁队列 / 禁中断 | 本文第 7.1 节 / 姊妹篇第 4.2 节 |\n| 系统关停资源竞争 | 关停死锁 | LIFO 有序释放 | 姊妹篇第 8 节 |\n| 高频通信路径 | 锁竞争瓶颈 | 无锁 MPSC/SPSC | 姊妹篇第 4 节 |\n\n**核心思路**: 本文解决「如何修 bug」，姊妹篇解决「如何不出 bug」。前者是战术，后者是战略。\n",
      "ctime": "1771552561",
      "mtime": "1771552561",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/embedded_callback_zero_overhead.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357843994",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式消息总线的回调优化: 从 std::function 到零开销分发",
      "brief_content": "在嵌入式 C++ 消息总线中，`std::function` 回调看似方便，实则是延迟抖动和代码膨胀的隐性来源。本文分析回调链路的逐层开销，给出三个递进式优化方案：`std::visit` 编译期分发",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/158075122)\n\n> 在嵌入式 C++ 消息总线中，`std::function` 回调看似方便，实则是延迟抖动和代码膨胀的隐性来源。本文分析回调链路的逐层开销，给出三个递进式优化方案：`std::visit` 编译期分发、CRTP 静态组件、`FixedFunction` 栈上类型擦除，最终在保留动态订阅能力的同时，为编译期确定的场景实现零开销分发。\n\n## 问题: 一条消息的分发经过了多少间接调用\n\n一条消息从生产者到消费者，典型路径如下：\n\n```\nPublish() → MPSC RingBuffer → ProcessBatch() → DispatchMessage() → 回调执行\n```\n\n以一个基于 `std::variant` 的消息总线为例，分发函数的典型实现：\n\n```cpp\nusing CallbackType = std::function<void(const EnvelopeType&)>;\n\nvoid DispatchMessage(const EnvelopeType& envelope) noexcept {\n  size_t type_idx = envelope.payload.index();       // 1. variant 类型索引\n  std::shared_lock<std::shared_mutex> lock(callback_mutex_);  // 2. 读锁\n  const CallbackSlot& slot = callback_table_[type_idx];\n  for (uint32_t i = 0U; i < MAX_CALLBACKS_PER_TYPE; ++i) {\n    if (slot.entries[i].active) {\n      slot.entries[i].callback(envelope);            // 3. std::function 间接调用\n    }\n  }\n}\n```\n\n每条消息经过：`payload.index()` 查表 -> 读锁获取 -> 遍历 N 个 slot -> `std::function::operator()` 间接调用。前三步开销可控，真正的问题在第四步。\n\n### std::function 的三重代价\n\n`std::function` 的内部实现（以 libstdc++ 为例）包含三个问题：\n\n1. **堆分配风险**。lambda 捕获超过 SBO 阈值（通常 16 字节）时触发 `operator new`。典型的安全订阅模式中，lambda 捕获 `weak_ptr`（16B）+ 用户回调（8B+），几乎必然越界。\n2. **间接调用不可内联**。编译器无法穿透内部函数指针看到实际 callable 类型，回调体无法被内联。\n3. **异常路径代码膨胀**。即使指定了 `-fno-exceptions`，析构器和管理器中仍可能残留异常相关代码，增大 `.text` 段。\n\n实测数据：在同一个无锁 MPSC 总线上，跳过回调分发的裸路径吞吐量约 19.6M msg/s（51 ns/msg），完整回调路径约 5.4M msg/s（187 ns/msg）。功能开销约 136 ns/msg，相当一部分来自回调链路。\n\n## 哪些回调可以完全消除\n\n优化前需要先分类。嵌入式系统中的回调场景可以分为两大类：\n\n**编译期确定的分发** -- 传感器数据总是交给同一个处理函数，电机指令总是交给同一个执行器。`std::function` 的运行时灵活性完全多余，可以用模板参数 / CRTP / `std::visit` 替代，实现零开销。\n\n**运行时动态注册** -- 订阅关系在运行时变化，或回调跨编译单元/动态库边界传递。类型擦除不可避免，但可以用更轻量的手段（`FixedFunction` 或 `void(*)(void*, const T&)`）替代 `std::function`。\n\n判断矩阵：\n\n| 场景 | 需要类型擦除 | 推荐方案 |\n|------|:---:|--------|\n| 编译期已知的消息处理 | 否 | 模板参数 / CRTP / `std::visit` |\n| 固定数量的订阅者 | 否 | `std::array<FuncPtr, N>` |\n| 运行时动态增删订阅 | **是** | `FixedFunction<Sig, 64>` |\n| 跨编译单元 / 动态库边界 | **是** | `void(*)(void* ctx, const T&)` + `void*` |\n\n下面按三个层次展开优化方案。\n\n## 优化 1: std::visit 替代回调表\n\n核心思路：**不改动现有动态订阅路径**，新增一条编译期分发路径 `ProcessBatchWith`，让消费者可以绕过整个回调基础设施。\n\n```cpp\ntemplate <typename PayloadVariant>\nclass AsyncBus {\n public:\n  // 新增: 编译期分发 (零开销，无锁，可内联)\n  template <typename Visitor>\n  uint32_t ProcessBatchWith(Visitor&& vis) noexcept {\n    uint32_t processed = 0U;\n    uint32_t cons_pos = consumer_pos_.load(std::memory_order_relaxed);\n    for (uint32_t i = 0U; i < BATCH_PROCESS_SIZE; ++i) {\n      auto& node = ring_buffer_[cons_pos & BUFFER_MASK];\n      if (node.sequence.load(std::memory_order_acquire) != cons_pos + 1U) break;\n      std::visit(vis, node.envelope.payload);  // 编译器生成跳转表\n      node.sequence.store(cons_pos + BUFFER_SIZE + 1U, std::memory_order_release);\n      ++cons_pos;\n      ++processed;\n    }\n    if (processed > 0U)\n      consumer_pos_.store(cons_pos, std::memory_order_relaxed);\n    return processed;\n  }\n\n  // 保留: 动态订阅路径\n  uint32_t ProcessBatch() noexcept { /* 现有实现不变 */ }\n};\n```\n\n使用方：\n\n```cpp\nauto visitor = make_overloaded(\n    [](const SensorData& d) { process_sensor(d); },\n    [](const MotorCmd& c)   { execute_motor(c); }\n);\n\nwhile (running) {\n  bus.ProcessBatchWith(visitor);  // 无 std::function，无锁，无回调表遍历\n}\n```\n\n`std::visit` 在 GCC/Clang 上生成跳转表，与手写 `switch-case` 等价。visitor 中每个 lambda 的函数体可被内联到跳转目标中。对比两条路径：\n\n| 操作 | ProcessBatch | ProcessBatchWith |\n|------|:---:|:---:|\n| `shared_mutex` 读锁 | 有 | **无** |\n| 回调表遍历 | 有 | **无** |\n| `std::function::operator()` | 有 | **无** |\n| `std::visit` 跳转表 (可内联) | 无 | 有 |\n\n适用于消费者逻辑在编译期确定的场景，在嵌入式系统中覆盖大多数情况。两条路径共存，调用方自行选择。\n\n## 优化 2: CRTP 静态组件\n\n许多消息总线的 `Component` 基类使用 `shared_from_this()` + `weak_ptr` 保护回调生命周期，避免 use-after-free。代价是每次分发都要付出多层间接调用：\n\n```\nstd::function::operator()          <- 间接调用 (不可内联)\n  +-> weak_ptr::lock()             <- 原子 fetch_add (引用计数 +1)\n       +-> std::get_if<T>()        <- 运行时类型检查\n            +-> user_callback()    <- 实际业务逻辑\n       +-> ~shared_ptr()           <- 原子 fetch_sub (引用计数 -1)\n```\n\n四层间接，两层原子操作。在 ARM 上，每次原子操作意味着 `LDXR/STXR` 指令对 + 可能的 DMB 屏障。\n\nCRTP 方案将这四层全部消除：\n\n```cpp\ntemplate <typename Derived, typename PayloadVariant>\nclass StaticComponent {\n public:\n  auto MakeVisitor() noexcept {\n    return make_overloaded(\n        [this](const auto& data) {\n          using T = std::decay_t<decltype(data)>;\n          if constexpr (HasHandler<Derived, T>::value) {\n            static_cast<Derived*>(this)->Handle(data);  // 编译期分发，可内联\n          }\n        }\n    );\n  }\n  ~StaticComponent() = default;  // 非 virtual\n};\n\nclass MyComponent : public StaticComponent<MyComponent, Payload> {\n public:\n  void Handle(const SensorData& d) { /* ... */ }\n  void Handle(const MotorCmd& c)   { /* ... */ }\n  // 不处理 SystemStatus -- 编译期忽略，不是运行时检查\n};\n\nMyComponent comp;\nbus.ProcessBatchWith(comp.MakeVisitor());  // 零开销分发 + 零开销组件\n```\n\n| 开销项 | 动态 Component | StaticComponent |\n|--------|:---:|:---:|\n| virtual 析构 (vtable 8B) | 有 | **无** |\n| `weak_ptr::lock()` 原子操作 | 有 | **无** |\n| `std::function` 间接调用 | 有 | **无** |\n| `std::get_if` 运行时类型检查 | 有 | **无** (`if constexpr`) |\n\n**代价**：放弃 `weak_ptr` 生命周期保护，要求调用方保证组件存活覆盖整个分发周期。嵌入式系统中组件通常是全局或模块级静态对象，这个约束容易满足。生命周期不确定的场景（插件系统、网络连接管理）仍使用动态 Component。\n\n## 优化 3: FixedFunction 替代 std::function\n\n对仍需运行时动态增删回调的场景，类型擦除不可避免，但 `std::function` 不是唯一选择。\n\n`FixedFunction<Sig, BufferSize>` 用固定大小的栈缓冲区替代堆分配，用函数指针替代虚表：\n\n```cpp\ntemplate <typename Ret, typename... Args, size_t BufferSize>\nclass FixedFunction<Ret(Args...), BufferSize> final {\n  using Storage = typename std::aligned_storage<BufferSize, alignof(void*)>::type;\n  using Invoker = Ret (*)(const Storage&, Args...);\n  using Destroyer = void (*)(Storage&);\n\n  Storage storage_{};\n  Invoker invoker_ = nullptr;\n  Destroyer destroyer_ = nullptr;\n\n public:\n  template <typename F>\n  FixedFunction(F&& f) noexcept {\n    using Decay = typename std::decay<F>::type;\n    static_assert(sizeof(Decay) <= BufferSize,\n                  \"Callable too large for FixedFunction buffer\");\n    ::new (&storage_) Decay(static_cast<F&&>(f));\n    invoker_ = [](const Storage& s, Args... args) -> Ret {\n      return (*reinterpret_cast<const Decay*>(&s))(static_cast<Args&&>(args)...);\n    };\n    destroyer_ = [](Storage& s) {\n      reinterpret_cast<Decay*>(&s)->~Decay();\n    };\n  }\n\n  Ret operator()(Args... args) const {\n    return invoker_(storage_, static_cast<Args&&>(args)...);\n  }\n};\n```\n\n应用只需改一行类型别名：\n\n```cpp\n// 修改前\nusing CallbackType = std::function<void(const EnvelopeType&)>;\n// 修改后: 64B SBO，容纳 weak_ptr + 函数指针 + 上下文\nusing CallbackType = FixedFunction<void(const EnvelopeType&), 64>;\n```\n\n三种类型擦除方案对比：\n\n| 特性 | `std::function` | `FixedFunction<Sig, 64>` | `void(*)(void*, const T&)` |\n|------|:---:|:---:|:---:|\n| 堆分配 | 可能 (>16B 捕获) | **永不** (`static_assert`) | **永不** |\n| 调用方式 | 虚调用 | 函数指针 | 裸函数指针 |\n| 异常路径 | 有 | **无** | **无** |\n| 类型安全 | 有 | 有 | **无** (void*) |\n| 超大 callable | 运行时堆分配 | **编译期报错** | 不适用 |\n\n## 三层优化的关系\n\n三个优化分层递进，覆盖不同场景：\n\n```\n                    编译期确定？\n                   /          \\\n                 是             否\n                /                \\\n    优化 1 + 优化 2           运行时动态？\n    (ProcessBatchWith        /          \\\n     + StaticComponent)    是             否\n    零开销路径              /                \\\n                    优化 3                直接函数指针\n                  (FixedFunction)        + void* context\n                  栈上类型擦除            零开销但无类型安全\n```\n\n嵌入式系统中约 80% 的消息处理逻辑在编译期确定，走优化 1 + 2 的零开销路径；剩余 20% 需要运行时灵活性，用优化 3 消除堆分配和异常路径。三条路径共存，调用方按场景选择，没有全局开关，没有额外抽象层。\n\n回调优化的本质不是\"消除所有回调\"，而是**在正确的抽象层级使用正确的分发机制**：编译期用 `std::visit` + CRTP 让编译器生成可内联的跳转表，运行时用 `FixedFunction` 在栈上完成类型擦除。为确定的多数提供零开销，为动态的少数提供可控开销。\n",
      "ctime": "1771552565",
      "mtime": "1771552565",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/embedded_deadlock_prevention_lockfree.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469620270",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式系统死锁防御: 从有序锁到无锁架构的工程实践",
      "brief_content": "死锁是嵌入式多线程系统中最隐蔽的故障之一。本文从一个典型的双锁死锁场景出发，逐步演示有序锁、lock_guard、try_lock、无锁队列四种防御策略，分析各方案在嵌入式实时系统中的工程权衡。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 在多任务并发系统中，不当的锁管理是导致系统死锁或永久阻塞的根本原因。本文从死锁原理出发，先介绍经典的有序锁获取与超时回退策略，再结合 [newosp](https://github.com/DeguiLiu/newosp) 工业级嵌入式框架的真实代码，深入解析无锁 MPSC 总线、Wait-Free SPSC 队列、自旋锁指数退避、Collect-Release-Execute 回调模式、LIFO 有序关停等工程实践，构建从设计层面根除死锁的完整方法论。\n>\n> 相关文章:\n> - [多线程死锁与优先级反转实战](../deadlock_priority_inversion_practice/) -- 代码级的死锁复现与修复\n> - [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/) -- 运行时锁竞争的量化诊断\n> - [锁竞争基准测试: Spinlock vs Mutex vs ConcurrentQueue](../lock_contention_benchmark/) -- 有锁与无锁的性能实测\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- 从有锁到无锁的理论基础\n\n---\n\n## 1. 死锁原理与应对策略\n\n### 1.1 死锁的四个必要条件\n\n只有当以下四个条件同时满足时，死锁才会发生:\n\n1. **互斥使用** (Mutual Exclusion): 资源 (如硬件外设) 一次只能被一个任务占用。\n2. **持有并等待** (Hold and Wait): 一个任务已经持有了至少一个资源，并且正在请求另一个被其他任务占用的资源。\n3. **不可抢占** (No Preemption): 资源只能由持有它的任务主动释放，不能被强制剥夺。\n4. **循环等待** (Circular Wait): 存在一个任务等待链 T1->T2->...->Tn->T1，形成闭环。\n\n> **场景模拟: 死锁是如何发生的?**\n>\n> - 任务A: `lock(I2C)` 成功 -> 尝试 `lock(SPI)` (等待任务B释放)\n> - 任务B: `lock(SPI)` 成功 -> 尝试 `lock(I2C)` (等待任务A释放)\n>\n> 此时，A和B互相持有对方需要的资源，并等待对方释放，形成了循环等待，系统死锁。\n\n### 1.2 核心破坏策略\n\n| 策略 | 破坏的条件 | 适用场景 |\n|------|-----------|---------|\n| 全局锁顺序 | 循环等待 | 多锁共存的 RTOS 系统 |\n| 超时与回退 | 持有并等待 | 需要容错的工业控制 |\n| 无锁数据结构 | 互斥使用 | 高吞吐量消息通信 |\n| 单消费者架构 | 循环等待 | 消息总线、事件分发 |\n| LIFO 有序释放 | 持有并等待 | 系统关停、资源清理 |\n\n---\n\n## 2. 策略一: 全局锁获取顺序 (经典方案)\n\n### 2.1 锁优先级设计与编号\n\n```c\ntypedef enum {\n    LOCK_ID_I2C   = 10,\n    LOCK_ID_SPI   = 20,\n    LOCK_ID_UART  = 30,\n    LOCK_ID_NVM   = 40,\n    // 新增锁时继续按升序编号\n} LockID_t;\n```\n\n- ID 唯一且全局可见。\n- 按升序获取，打破循环等待。\n\n### 2.2 带优先级 ID 的锁结构\n\n```c\ntypedef struct {\n    const LockID_t id;  // 锁的全局唯一 ID\n    Mutex_t        mtx; // 底层 RTOS 互斥量句柄\n} OrderedLock_t;\n```\n\n将 ID 与互斥量句柄绑定，便于统一管理。\n\n### 2.3 按序获取与逆序释放的实现\n\n```c\n/**\n * @brief 对锁指针数组按其 ID 进行升序排序\n */\nstatic void sort_locks_by_id(OrderedLock_t *arr[], int n) {\n    for (int i = 0; i < n - 1; i++) {\n        for (int j = i + 1; j < n; j++) {\n            if (arr[i]->id > arr[j]->id) {\n                OrderedLock_t *tmp = arr[i];\n                arr[i] = arr[j];\n                arr[j] = tmp;\n            }\n        }\n    }\n}\n\n/**\n * @brief 按 ID 升序获取多个锁 (阻塞式)\n */\nvoid lock_multiple(OrderedLock_t *locks[], int count) {\n    OrderedLock_t *local_locks[count];\n    memcpy(local_locks, locks, sizeof(OrderedLock_t*) * count);\n    sort_locks_by_id(local_locks, count);\n    for (int i = 0; i < count; i++) {\n        mutex_lock(&local_locks[i]->mtx);\n    }\n}\n\n/**\n * @brief 按 ID 降序释放多个锁 (LIFO 原则)\n */\nvoid unlock_multiple(OrderedLock_t *locks[], int count) {\n    OrderedLock_t *local_locks[count];\n    memcpy(local_locks, locks, sizeof(OrderedLock_t*) * count);\n    sort_locks_by_id(local_locks, count);\n    for (int i = count - 1; i >= 0; i--) {\n        mutex_unlock(&local_locks[i]->mtx);\n    }\n}\n```\n\n---\n\n## 3. 策略二: 超时与回退\n\n### 3.1 带超时的尝试锁函数\n\n```c\n#define DEFAULT_LOCK_TIMEOUT_MS 100\n\nbool try_lock_with_timeout(OrderedLock_t *lock, uint32_t timeout_ms) {\n    if (mutex_timed_lock(&lock->mtx, timeout_ms) == true) {\n        return true;\n    }\n    log_warning(\"Locking timeout for lock ID: %d\", lock->id);\n    return false;\n}\n```\n\n### 3.2 批量获取与原子回退\n\n在批量获取过程中，一旦有任何一个锁超时失败，必须立即释放所有已经成功获取的锁:\n\n```c\nbool lock_multiple_with_timeout(OrderedLock_t *locks[], int count,\n                                uint32_t timeout_ms) {\n    OrderedLock_t *local_locks[count];\n    memcpy(local_locks, locks, sizeof(OrderedLock_t*) * count);\n    sort_locks_by_id(local_locks, count);\n\n    for (int i = 0; i < count; i++) {\n        if (!try_lock_with_timeout(local_locks[i], timeout_ms)) {\n            // 获取失败，执行回退: 逆序释放已持有的锁\n            for (int j = i - 1; j >= 0; j--) {\n                mutex_unlock(&local_locks[j]->mtx);\n            }\n            return false;\n        }\n    }\n    return true;\n}\n```\n\n### 3.3 指数退避 + 随机抖动\n\n```c\nvoid complex_task(void) {\n    OrderedLock_t *req[] = { &g_spi_lock, &g_nvm_lock, &g_i2c_lock };\n    int cnt = sizeof(req) / sizeof(req[0]);\n    int retry_count = 0;\n    const int MAX_RETRIES = 3;\n\n    while (retry_count < MAX_RETRIES) {\n        if (lock_multiple_with_timeout(req, cnt, DEFAULT_LOCK_TIMEOUT_MS)) {\n            /* 临界区 */\n            access_spi();\n            access_nvm();\n            access_i2c();\n\n            unlock_multiple(req, cnt);\n            return;\n        } else {\n            retry_count++;\n            log_warning(\"Failed to lock resources, retry %d/%d...\",\n                        retry_count, MAX_RETRIES);\n\n            /* 指数退避 + 随机抖动，避免活锁 */\n            uint32_t backoff_delay = (1 << retry_count) * 10 + (rand() % 10);\n            task_delay_ms(backoff_delay);\n        }\n    }\n\n    log_error(\"Failed to lock resources after %d retries.\", MAX_RETRIES);\n    /* 降级或报警逻辑 */\n}\n```\n\n---\n\n## 4. 策略三: 无锁数据结构 (newosp 实践)\n\n经典的有序锁方案虽然正确，但在高吞吐量场景下，锁本身的开销成为瓶颈。newosp 采用无锁 (Lock-Free) 和无等待 (Wait-Free) 数据结构，从架构层面消除互斥条件。\n\n### 4.1 无锁 MPSC 消息总线 (CAS 原子操作)\n\nnewosp 的 AsyncBus 是系统的核心通信枢纽，采用 CAS (Compare-And-Swap) 环形缓冲区实现无锁多生产者单消费者 (MPSC) 模式:\n\n```cpp\n// newosp bus.hpp -- 无锁 MPSC 发布 (简化)\ntemplate <typename PayloadVariant>\nbool AsyncBus<PayloadVariant>::PublishInternal(/* ... */) noexcept {\n    uint32_t prod_pos;\n    Slot* target;\n\n    do {\n        prod_pos = producer_pos_.load(std::memory_order_relaxed);\n        target = &ring_buffer_[prod_pos & kBufferMask];\n\n        // 检查 slot 是否可用 (消费者已释放)\n        uint32_t seq = target->sequence.load(std::memory_order_acquire);\n        if (seq != prod_pos) {\n            return false;  // 缓冲区满，非阻塞返回\n        }\n    } while (!producer_pos_.compare_exchange_weak(\n        prod_pos, prod_pos + 1,\n        std::memory_order_acq_rel,\n        std::memory_order_relaxed));\n\n    // CAS 成功，填充数据并发布\n    target->envelope = MessageEnvelope{/* ... */};\n    target->sequence.store(prod_pos + 1, std::memory_order_release);\n    return true;\n}\n```\n\n**为何不会死锁:**\n\n- **无互斥**: 生产者之间通过 CAS 竞争，失败者重试而非阻塞，不满足\"互斥使用\"条件。\n- **单消费者**: 只有一个线程调用 `ProcessBatch()`，消除了消费者之间的循环等待。\n- **非阻塞返回**: 缓冲区满时直接返回 `false`，不满足\"持有并等待\"条件。\n- **固定容量**: 编译期确定的环形缓冲区大小，避免动态分配引发的资源耗尽。\n\n### 4.2 Wait-Free SPSC 队列\n\n对于已知只有一个生产者和一个消费者的场景，newosp 使用 Wait-Free SPSC 环形缓冲区，提供最强的无死锁保证:\n\n```cpp\n// newosp spsc_ringbuffer.hpp -- Wait-Free SPSC (简化)\ntemplate <typename T, size_t BufferSize = 16, bool FakeTSO = false>\nclass SpscRingbuffer {\n    struct alignas(kCacheLineSize) PaddedIndex {\n        std::atomic<IndexT> value{0};\n    };\n\n    PaddedIndex head_;  // 仅生产者写入\n    PaddedIndex tail_;  // 仅消费者写入\n    std::array<T, BufferSize> data_buff_{};\n\n    bool Push(T&& data) noexcept {\n        const IndexT cur_head = head_.value.load(std::memory_order_relaxed);\n        const IndexT cur_tail = tail_.value.load(AcquireOrder());\n\n        if ((cur_head - cur_tail) == BufferSize) {\n            return false;  // 满\n        }\n\n        data_buff_[cur_head & kMask] = std::forward<T>(data);\n        head_.value.store(cur_head + 1, ReleaseOrder());\n        return true;\n    }\n\n    bool Pop(T& data) noexcept {\n        const IndexT cur_tail = tail_.value.load(std::memory_order_relaxed);\n        const IndexT cur_head = head_.value.load(AcquireOrder());\n\n        if (cur_tail == cur_head) {\n            return false;  // 空\n        }\n\n        data = std::move(data_buff_[cur_tail & kMask]);\n        tail_.value.store(cur_tail + 1, ReleaseOrder());\n        return true;\n    }\n};\n```\n\n**设计要点:**\n\n| 特性 | 说明 |\n|------|------|\n| Wait-Free | Push/Pop 均为有界操作，不存在无限循环 |\n| 缓存行隔离 | `head_` 和 `tail_` 各占独立缓存行 (64B)，消除 False Sharing |\n| FakeTSO 模式 | 单核 MCU 可用 `relaxed` 替代 `acquire/release`，减少内存屏障开销 |\n| Power-of-2 掩码 | `BufferSize` 必须为 2 的幂，用位与替代取模 |\n\n### 4.3 无锁与有锁方案对比\n\n```\n                有锁方案                          无锁方案\n         ┌─────────────────┐             ┌──────────────────┐\n  线程A  │  lock(mutex)    │      线程A  │  CAS(pos, pos+1) │\n         │  临界区操作      │             │  写入数据         │\n         │  unlock(mutex)  │             │  release store    │\n         └────────┬────────┘             └────────┬─────────┘\n                  │                               │\n  线程B  ┌────────▼────────┐      线程B  ┌────────▼─────────┐\n  (阻塞) │  lock(mutex)    │      (重试) │  CAS(pos, pos+1) │\n         │  等待A释放...   │             │  CAS失败则重试    │\n         │  [死锁风险]     │             │  [无死锁可能]     │\n         └─────────────────┘             └──────────────────┘\n```\n\n---\n\n## 5. 策略四: 自旋锁与指数退避 (冷路径保护)\n\n对于无法完全避免互斥的场景 (如回调注册)，newosp 使用自旋锁配合指数退避，将临界区限制在极短的非嵌套操作中:\n\n### 5.1 独占自旋锁\n\n```cpp\n// newosp bus.hpp -- SpinLock with exponential backoff\nclass SpinLock {\n    std::atomic_flag flag_ = ATOMIC_FLAG_INIT;\n    static constexpr uint32_t kMaxBackoff = 1024U;\n\n    void lock() noexcept {\n        uint32_t backoff = 1;\n        while (flag_.test_and_set(std::memory_order_acquire)) {\n            // 指数退避: 1 -> 2 -> 4 -> ... -> 1024\n            for (uint32_t i = 0; i < backoff; ++i) {\n                CpuRelax();  // x86: PAUSE, ARM: YIELD\n            }\n            if (backoff < kMaxBackoff) {\n                backoff <<= 1;\n            }\n        }\n    }\n\n    void unlock() noexcept {\n        flag_.clear(std::memory_order_release);\n    }\n};\n```\n\n### 5.2 读写自旋锁\n\n回调分发场景中，读多写少 (发布消息时读回调表，注册回调时写)，newosp 使用读写自旋锁优化:\n\n```cpp\n// newosp bus.hpp -- SharedSpinLock (Reader-Writer)\nclass SharedSpinLock {\n    std::atomic<int32_t> state_{0};  // >= 0: 读者数, -1: 写者\n\n    void lock_shared() noexcept {     // 读锁 (多个读者并发)\n        uint32_t backoff = 1;\n        for (;;) {\n            int32_t s = state_.load(std::memory_order_relaxed);\n            if (s >= 0 &&\n                state_.compare_exchange_weak(\n                    s, s + 1,\n                    std::memory_order_acquire,\n                    std::memory_order_relaxed)) {\n                return;\n            }\n            Backoff(backoff);\n        }\n    }\n\n    void lock() noexcept {            // 写锁 (独占)\n        uint32_t backoff = 1;\n        for (;;) {\n            int32_t expected = 0;\n            if (state_.compare_exchange_weak(\n                    expected, -1,\n                    std::memory_order_acquire,\n                    std::memory_order_relaxed)) {\n                return;\n            }\n            Backoff(backoff);\n        }\n    }\n};\n```\n\n**为何不会死锁:**\n\n- **非嵌套**: 自旋锁仅保护单一短操作 (回调表读写)，不存在嵌套获取。\n- **有限等待**: 指数退避确保其他线程获得 CPU 时间，最终释放锁。\n- **CAS 竞争**: 读写锁基于原子操作，不会出现优先级反转。\n\n---\n\n## 6. 策略五: 架构级死锁消除\n\nnewosp 最核心的死锁防御不在于某个具体的锁策略，而在于架构层面的单向数据流设计:\n\n### 6.1 单消费者总线架构\n\n```\n生产者 (任意线程)                消费者 (唯一)\n    │                              │\n    ▼ [lock-free CAS]              │\n┌───────────────────────┐          │\n│  AsyncBus MPSC        │          │\n│  Ring Buffer          │──────────▶ Dispatcher 线程\n└───────────────────────┘          │\n                                   │ [round-robin 分发]\n                        ┌──────────┼──────────┐\n                        ▼          ▼          ▼\n                    Worker[0]  Worker[1]  Worker[2]\n                       │          │          │\n                       ▼          ▼          ▼\n                     SPSC       SPSC       SPSC\n                   RingBuffer  RingBuffer  RingBuffer\n                       │          │          │\n                       ▼          ▼          ▼\n                    工作线程    工作线程    工作线程\n```\n\n**关键不变量:**\n\n1. **总线单消费者**: 只有 Dispatcher 线程调用 `ProcessBatch()`，消除消费者间竞争。\n2. **工作队列单生产者**: Round-Robin 分发确保每条消息只进入一个 SPSC 队列。\n3. **工作队列单消费者**: 每个 Worker 线程独占一个 SPSC 队列。\n4. **热路径零互斥**: 整条数据通路仅使用原子操作 (CAS / load / store)。\n\n### 6.2 三阶段自适应退避 (WorkerPool)\n\nWorker 线程在无消息时的等待策略直接影响系统的响应延迟和 CPU 利用率:\n\n```cpp\n// newosp worker_pool.hpp -- AdaptiveBackoff\nclass AdaptiveBackoff {\n    uint32_t spin_count_{0};\n    static constexpr uint32_t kSpinLimit  = 6;   // 2^6 = 64 次 CPU Relax\n    static constexpr uint32_t kYieldLimit = 4;    // 4 次 yield\n\n    void Wait() noexcept {\n        if (spin_count_ < kSpinLimit) {\n            // Phase 1: 自旋 (最低延迟, 消耗 CPU)\n            const uint32_t iters = 1U << spin_count_;\n            for (uint32_t i = 0U; i < iters; ++i) {\n                CpuRelax();\n            }\n            ++spin_count_;\n        } else if (spin_count_ < kSpinLimit + kYieldLimit) {\n            // Phase 2: 让出时间片 (中等延迟)\n            std::this_thread::yield();\n            ++spin_count_;\n        } else {\n            // Phase 3: 休眠 50us (最低 CPU 占用)\n            std::this_thread::sleep_for(std::chrono::microseconds(50));\n        }\n    }\n};\n```\n\n| 阶段 | 操作 | 延迟 | CPU 占用 | 适用场景 |\n|------|------|------|---------|---------|\n| Phase 1 | CPU Relax (PAUSE/YIELD指令) | ~ns 级 | 高 | 消息密集的热路径 |\n| Phase 2 | `std::this_thread::yield()` | ~us 级 | 中 | 短暂空闲 |\n| Phase 3 | `sleep_for(50us)` | ~50us | 低 | 持续空闲 |\n\n---\n\n## 7. 策略六: Collect-Release-Execute 回调模式\n\n当需要在锁保护的数据结构上触发回调时，最常见的死锁场景是: 回调函数内部又尝试获取同一把锁 (Re-entrancy)。newosp 的 Watchdog 模块通过 Collect-Release-Execute 模式彻底避免此问题:\n\n```cpp\n// newosp watchdog.hpp -- Collect-Release-Execute pattern\nuint32_t ThreadWatchdog::Check() noexcept {\n    PendingCallback timeout_pending[MaxThreads];\n    uint32_t timeout_count = 0U;\n\n    // Phase 1: Collect -- 在锁内收集超时信息\n    {\n        std::lock_guard<std::mutex> lock(mutex_);\n        for (uint32_t i = 0U; i < MaxThreads; ++i) {\n            if (!slots_[i].active.load(std::memory_order_acquire)) {\n                continue;\n            }\n            const uint64_t last_beat = slots_[i].heartbeat.LastBeatUs();\n            if (IsTimedOut(last_beat)) {\n                slots_[i].timed_out = true;\n                timeout_pending[timeout_count++] = {/* 拷贝回调信息 */};\n            }\n        }\n    }\n    // Phase 2: Release -- 锁已自动释放 (RAII)\n\n    // Phase 3: Execute -- 在锁外执行回调\n    for (uint32_t i = 0U; i < timeout_count; ++i) {\n        timeout_pending[i].fn(/* ... */);  // 回调可安全获取任意锁\n    }\n\n    return timeout_count;\n}\n```\n\n**模式本质:** 将\"数据读取\"和\"回调执行\"解耦，回调在锁外执行，天然免疫 Re-entrancy 死锁。\n\n同时，热路径 (工作线程喂狗) 仅执行一次原子 store，零锁开销:\n\n```cpp\n// 工作线程热路径: 单原子操作，无锁\nvoid Feed(WatchdogSlotId id) noexcept {\n    slots_[id].heartbeat.Beat();  // relaxed atomic store\n}\n```\n\n---\n\n## 8. 策略七: LIFO 有序关停\n\n系统关停是另一个死锁高发区。如果资源释放顺序不当，后释放的模块可能依赖已释放的模块，导致悬挂引用或死锁。newosp 的 ShutdownManager 强制 LIFO (后注册先执行) 释放顺序:\n\n```cpp\n// newosp shutdown.hpp -- LIFO graceful shutdown\nclass ShutdownManager final {\n    std::atomic<bool> shutdown_flag_{false};\n    int pipe_fd_[2];                        // 异步信号安全唤醒\n    ShutdownFn callbacks_[kMaxCallbacks];   // 栈分配，固定容量\n\n    // 信号处理函数: 仅使用 async-signal-safe 操作\n    static void SignalHandler(int signo) {\n        self->shutdown_flag_.store(true);    // 原子写\n        const uint8_t byte = 1;\n        (void)::write(self->pipe_fd_[1], &byte, 1);  // pipe write\n    }\n\n    void WaitForShutdown() noexcept {\n        // 阻塞等待信号\n        uint8_t buf = 0;\n        (void)::read(pipe_fd_[0], &buf, 1);\n\n        // LIFO 顺序执行清理回调\n        for (uint32_t i = callback_count_; i > 0U; --i) {\n            if (callbacks_[i - 1U] != nullptr) {\n                callbacks_[i - 1U](signo);\n            }\n        }\n    }\n};\n```\n\n**注册顺序 A -> B -> C，执行顺序 C -> B -> A:**\n\n```\n注册阶段:                        关停阶段:\n  Register(A) -- 基础设施         Execute(C) -- 应用逻辑 (依赖 B, A)\n  Register(B) -- 中间件           Execute(B) -- 中间件 (依赖 A)\n  Register(C) -- 应用逻辑         Execute(A) -- 基础设施 (无依赖)\n```\n\n**为何不会死锁:**\n\n- **Pipe 唤醒**: `write()` 是 POSIX 异步信号安全函数，信号处理函数中无锁操作。\n- **单线程执行**: 所有清理回调在主线程串行执行，不存在并发竞争。\n- **逆序释放**: 符合依赖关系的自然顺序，避免\"已释放资源被访问\"。\n\n---\n\n## 9. ARM 内存序与死锁预防\n\n在 ARM 平台上，与 x86 的 TSO (Total Store Ordering) 不同，ARM 允许写操作重排序。如果内存序不正确，可能导致生产者的数据写入对消费者不可见，造成消费者无限等待 (类似死锁的活锁):\n\n```cpp\n// newosp shm_transport.hpp -- ARM memory ordering for shared memory IPC\n\n// 生产者端: 确保 memcpy 在 sequence 发布之前完成\nstd::memcpy(slot.data, payload, size);\nstd::atomic_thread_fence(std::memory_order_release);  // DMB on ARM\nslot.sequence.store(prod_pos + 1, std::memory_order_release);\n\n// 消费者端: 确保看到生产者的所有写入\nuint32_t seq = slot.sequence.load(std::memory_order_acquire);\nstd::atomic_thread_fence(std::memory_order_acquire);  // DMB on ARM\nstd::memcpy(data, slot.data, size);\n```\n\n| 内存序 | x86 行为 | ARM 行为 | 使用场景 |\n|--------|---------|---------|---------|\n| `relaxed` | 无额外开销 | 无额外开销 | 计数器、标志位 (单核/信号) |\n| `acquire` | 无额外开销 (TSO 保证) | 插入 DMB 屏障 | 消费者读取共享数据前 |\n| `release` | 无额外开销 (TSO 保证) | 插入 DMB 屏障 | 生产者发布共享数据后 |\n| `seq_cst` | MFENCE 全屏障 | DMB + DSB | 最强保证，通常应避免 |\n\n> 在单核 MCU 上，newosp 的 SPSC 队列支持 `FakeTSO` 模式: 使用 `relaxed` + `atomic_signal_fence` 替代硬件屏障，因为单核不存在跨核可见性问题，仅需防止编译器重排序。\n\n---\n\n## 10. 实时调度与优先级反转防御\n\n在实时系统中，优先级反转是另一种形式的\"准死锁\": 高优先级任务被低优先级任务间接阻塞。newosp 的 RealtimeExecutor 通过以下手段防御:\n\n```cpp\n// newosp executor.hpp -- RealtimeExecutor configuration\nstatic void ApplyRealtimeConfig(const RealtimeConfig& cfg) noexcept {\n    // 1. 锁定内存: 防止页面换出导致的不确定延迟\n    if (cfg.lock_memory) {\n        mlockall(MCL_CURRENT | MCL_FUTURE);\n    }\n\n    // 2. CPU 亲和性: 绑定核心，减少上下文切换\n    if (cfg.cpu_affinity >= 0) {\n        cpu_set_t cpuset;\n        CPU_ZERO(&cpuset);\n        CPU_SET(cfg.cpu_affinity, &cpuset);\n        pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);\n    }\n\n    // 3. SCHED_FIFO: 严格优先级调度，避免优先级反转\n    if (cfg.sched_policy != 0) {\n        struct sched_param param;\n        param.sched_priority = cfg.sched_priority;\n        pthread_setschedparam(pthread_self(), cfg.sched_policy, &param);\n    }\n}\n```\n\n**关键: 实时调度路径完全无锁。** Dispatcher 线程使用 `SCHED_FIFO` + CPU 绑定，通过 AsyncBus 的无锁 CAS 接收消息，整条路径不持有任何 mutex，从根本上免疫优先级反转。\n\n---\n\n## 11. 嵌入式系统集成要点与最佳实践\n\n### 11.1 设计阶段\n\n- **锁的作用域最小化**: 仅在必要时持有锁，临界区代码应尽可能简短高效。\n- **优先无锁**: 对高频通信路径，优先选择 SPSC/MPSC 无锁队列，将 mutex 保留给低频冷路径。\n- **资源预算**: 编译期确定队列深度、回调数量等上限，避免运行时资源耗尽。\n\n### 11.2 实现阶段\n\n- **初始化**: 在系统启动的单线程阶段，完成所有锁和队列的初始化。\n- **超时参数调优**: 应根据该锁保护的临界区代码的最大正常执行时间来评估。一个好的起点是: `Timeout > (最大执行时间 * 1.5) + 系统抖动`。\n- **活锁规避**: 采用带有随机抖动的指数退避 (Exponential Backoff with Jitter) 策略，有效错开不同任务的重试高峰。\n- **回调解耦**: 凡是在锁内触发的回调，一律采用 Collect-Release-Execute 模式。\n\n### 11.3 验证阶段\n\n- **Thread Sanitizer (TSan)**: 检测数据竞争和锁顺序违规。\n- **Address Sanitizer (ASan)**: 检测内存越界，间接发现因错误释放导致的锁损坏。\n- **代码审查**: 将\"遵守全局锁顺序\"和\"回调不在锁内执行\"作为必检项。\n- **Watchdog 联动**: 超时失败是系统异常的明确信号。累计超时次数，达到阈值后主动进入安全模式或计划性复位。\n\n---\n\n## 12. 总结: 死锁防御技术矩阵\n\n| 技术 | 破坏的条件 | 适用层次 | 性能开销 | newosp 应用 |\n|------|-----------|---------|---------|-------------|\n| 全局锁顺序 | 循环等待 | RTOS/MCU 多锁场景 | 排序开销 | -- |\n| 超时回退 | 持有并等待 | 容错要求高的工业系统 | 超时检测 | -- |\n| 无锁 MPSC (CAS) | 互斥使用 | 高吞吐量消息通信 | CAS 重试 | AsyncBus |\n| Wait-Free SPSC | 互斥使用 | 单生产者-单消费者 | 零额外开销 | SpscRingbuffer, WorkerPool |\n| 自旋锁 + 退避 | 循环等待 (限单锁) | 短临界区冷路径 | 退避等待 | 回调注册 |\n| 单消费者架构 | 循环等待 | 事件分发系统 | 架构约束 | Bus + Executor |\n| Collect-Release-Execute | 持有并等待 | 回调通知场景 | 临时缓冲区 | Watchdog |\n| LIFO 有序关停 | 持有并等待 | 系统生命周期管理 | 无额外开销 | ShutdownManager |\n| ARM 内存序 | (防活锁) | 跨核/跨进程通信 | 内存屏障 | ShmTransport |\n| SCHED_FIFO + 无锁 | (防优先级反转) | 实时调度路径 | CPU 绑定 | RealtimeExecutor |\n\n**核心原则: 最好的锁是不需要锁。** 通过架构层面的单向数据流、生产者-消费者分离、固定容量资源预算，在设计阶段就消除死锁的结构性条件，而非在实现阶段通过锁策略去\"修补\"。\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/156591921)\n> 参考实现: [newosp](https://github.com/DeguiLiu/newosp) -- ARM-Linux 工业级嵌入式 C++17 基础设施库\n",
      "ctime": "1771552568",
      "mtime": "1771552568",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/eventpp_arm_optimization_report.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038437414",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "eventpp 性能优化实战: 6 个瓶颈定位与 5 倍吞吐提升",
      "brief_content": "通过逐行阅读 eventpp v0.1.3 核心代码，定位到回调遍历加锁、双锁入队、排他锁查 map 等 6 个性能瓶颈。逐一实施优化后，Active Object 吞吐量从 1.5 M/s 提升至 ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 仓库: [gitee.com/liudegui/eventpp](https://gitee.com/liudegui/eventpp) v0.4.0\n> 基准版本: eventpp v0.1.3 (wqking/eventpp)\n> 平台: 跨平台 (ARM + x86) | C++14\n\n---\n\n## 一、根因分析\n\n通过逐行阅读 eventpp v0.1.3 核心头文件，定位到 6 个性能瓶颈：\n\n| # | 根因 | 位置 | 严重程度 |\n|---|------|------|:--------:|\n| 1 | CallbackList 遍历时**每个节点都加锁** | `callbacklist.h` doForEachIf | 致命 |\n| 2 | EventQueue enqueue **双锁** (freeListMutex + queueListMutex) | `eventqueue.h` doEnqueue | 高 |\n| 3 | EventDispatcher dispatch 时**加排他锁查 map** | `eventdispatcher.h` | 高 |\n| 4 | SpinLock 无 YIELD 指令，纯烧 CPU | `eventpolicies.h` | 中 |\n| 5 | std::list 每节点堆分配，cache 不友好 | `eventpolicies_i.h` | 中 |\n| 6 | 无 cache-line 对齐，多核 false sharing | 全局 | 中 |\n\n---\n\n## 二、优化方案 (OPT-1 ~ OPT-15)\n\n### OPT-1/11: SpinLock 指数退避 [Batch 1 -> Batch 5]\n\nv0.2.0 初版添加 CPU hint (OPT-1)，v0.4.0 升级为指数退避 (OPT-11)，高竞争场景下显著降低总线流量：\n\n```cpp\nvoid lock() {\n    // Fast path: no contention\n    if(!locked.test_and_set(std::memory_order_acquire)) {\n        return;\n    }\n    // Slow path: exponential backoff\n    unsigned backoff = 1;\n    while(locked.test_and_set(std::memory_order_acquire)) {\n        for(unsigned i = 0; i < backoff; ++i) {\n#if defined(__aarch64__) || defined(__arm__)\n            __asm__ __volatile__(\"yield\");\n#elif defined(__x86_64__) || defined(_M_X64) || defined(__i386__)\n            __builtin_ia32_pause();\n#endif\n        }\n        if(backoff < kMaxBackoff) {\n            backoff <<= 1;  // 1 -> 2 -> 4 -> ... -> 64\n        }\n    }\n}\nstatic constexpr unsigned kMaxBackoff = 64;\n```\n\n### OPT-6/10: Cache-Line 对齐 [Batch 1 -> Batch 5]\n\n对 EventQueue 热成员进行 cache-line 隔离，消除 false sharing。v0.2.0 初版硬编码 64B (OPT-6)，v0.4.0 升级为平台自适应 (OPT-10)：\n\n```cpp\n// OPT-10: 平台自适应 cache-line 大小\n#ifndef EVENTPP_CACHELINE_SIZE\n    #if defined(__APPLE__) && defined(__aarch64__)\n        #define EVENTPP_CACHELINE_SIZE 128   // Apple Silicon (M1/M2/M3)\n    #else\n        #define EVENTPP_CACHELINE_SIZE 64    // x86 / Cortex-A\n    #endif\n#endif\n#define EVENTPP_ALIGN_CACHELINE alignas(EVENTPP_CACHELINE_SIZE)\n\nEVENTPP_ALIGN_CACHELINE mutable ConditionVariable queueListConditionVariable;\nEVENTPP_ALIGN_CACHELINE mutable Mutex queueListMutex;\nEVENTPP_ALIGN_CACHELINE Mutex freeListMutex;\n```\n\n### OPT-7: 内存序降级 [Batch 1]\n\n`CounterGuard` 从 `seq_cst` 降级为 `acq_rel`/`release`。ARM 上避免额外的 `dmb ish` 全屏障：\n\n```cpp\nstruct CounterGuard {\n    explicit CounterGuard(T & v) : value(v) {\n        value.fetch_add(1, std::memory_order_acq_rel);\n    }\n    ~CounterGuard() {\n        value.fetch_sub(1, std::memory_order_release);\n    }\n};\n```\n\n### OPT-2: CallbackList 批量预取 [Batch 2] -- 核心改动\n\n原始代码每访问一个 `node->next` 都加锁（N 个回调 = N 次 mutex），这是 128us 最大延迟的根因。\n\n改为批量预取：一次加锁读取 8 个节点，无锁遍历批次，再加锁取下一批。锁操作减少约 8 倍。\n\n```cpp\nstatic constexpr size_t kBatchSize = 8;\nNodePtr batch[kBatchSize];\nwhile(node) {\n    size_t count = 0;\n    {\n        std::lock_guard<Mutex> lockGuard(mutex);  // 每 8 个节点锁一次\n        NodePtr cur = node;\n        while(cur && count < kBatchSize) { batch[count++] = cur; cur = cur->next; }\n    }\n    for(size_t i = 0; i < count; ++i) { /* 无锁执行回调 */ }\n    { std::lock_guard<Mutex> lockGuard(mutex); node = batch[count - 1]->next; }\n}\n```\n\n> 最初尝试\"一次快照全部节点\"，但破坏了重入 append 语义（counter overflow 测试失败）。批量预取保留了重入语义。\n\n### OPT-3: EventDispatcher 读写锁分离 [Batch 3]\n\ndispatch（高频）用读锁，appendListener（低频）用写锁，多线程 dispatch 不再互斥：\n\n```cpp\nusing SharedMutex = std::shared_timed_mutex;  // C++14\n// dispatch: std::shared_lock<SharedMutex>   (读锁)\n// append:   std::unique_lock<SharedMutex>   (写锁)\n```\n\n### OPT-4: doEnqueue try_lock [Batch 4]\n\n`freeListMutex` 改为 `try_lock`，竞争时跳过回收直接分配新节点，不阻塞热路径。外层无锁预检查避免不必要的锁操作：\n\n```cpp\nif(! freeList.empty()) {  // 无锁预检查\n    std::unique_lock<Mutex> lock(freeListMutex, std::try_to_lock);\n    if(lock.owns_lock() && !freeList.empty()) {\n        tempList.splice(tempList.end(), freeList, freeList.begin());\n    }\n}\n```\n\n### OPT-8: waitFor 自适应 Spin [Batch 4]\n\n四阶段等待：快速检查 -> CPU hint spin (128 次) -> 让出时间片 (16 次) -> 回退到 CV wait：\n\n```cpp\nif(doCanProcess()) return true;           // Phase 1: 快速检查\nfor(int i = 0; i < 128; ++i) {           // Phase 2: spin + CPU hint (~0.5-2us)\n    if(doCanProcess()) return true;\n    /* yield / pause */\n}\nfor(int i = 0; i < 16; ++i) {            // Phase 3: 让出时间片 (~2-20us)\n    if(doCanProcess()) return true;\n    std::this_thread::yield();\n}\nreturn cv.wait_for(lock, duration, ...);  // Phase 4: CV wait (futex)\n```\n\n### OPT-5/9: PoolAllocator 池化分配器 [Batch 5]\n\n静态 per-type 池化分配器，通过 Policy 机制 opt-in。保留 `splice()` 兼容性（14 处调用）：\n\n```cpp\nstruct MyPolicies {\n    template <typename T>\n    using QueueList = eventpp::PoolQueueList<T, 4096>;\n};\neventpp::EventQueue<int, void(const Payload&), MyPolicies> queue;\n```\n\n关键设计：静态单例池 -> `operator==` 恒 true -> `splice()` 安全；多 slab 动态增长 (OPT-9a)，无锁 CAS free list (OPT-9b)，仅 `grow()` 冷路径使用 SpinLock。\n\n```cpp\n// OPT-14: 一站式高性能策略预设\nstruct HighPerfPolicy {\n    template <typename T>\n    using QueueList = eventpp::PoolQueueList<T, 8192>;\n    using Threading = eventpp::GeneralThreading<SpinLock>;\n};\neventpp::EventQueue<int, void(const Payload&), HighPerfPolicy> queue;\n```\n\n### OPT-15: processQueueWith 零开销访问者分发 [Batch 6]\n\nOPT-1 ~ OPT-14 优化了锁策略、内存分配和缓存布局，但 `process()` 的分发热路径仍经过 5 层间接调用：\n\n```\nprocess()\n  for each queued event:\n    doDispatchQueuedEvent()            // tuple 解包\n      directDispatch(event, args...)   // EventDispatcher 入口\n        shared_lock<SharedMutex>       // listenerMutex 读锁\n        map.find(event)                // 事件 ID -> CallbackList 查找\n        CallbackList::operator()()     // 回调链表调用\n          doForEachIf()                // 批量预取遍历 (每 8 节点加锁)\n            shared_ptr<Node> traversal // 引用计数开销\n            std::function(args...)     // 类型擦除间接调用\n```\n\n对于**单消费者**场景 (一个线程消费所有事件，事件处理逻辑编译期已知)，上述基础设施开销完全不必要:\n\n- 不需要 shared_lock -- 只有一个消费者\n- 不需要 map.find -- 消费者已知如何处理所有事件\n- 不需要 CallbackList -- 不需要动态注册/注销回调\n- 不需要 std::function -- 处理函数编译期已知\n\n[newosp](https://github.com/DeguiLiu/newosp) 项目的 `ProcessBatchWith<Visitor>` 已验证此优化方向: 绕过 FixedFunction 回调表 + SharedSpinLock，使用 `std::visit` 编译期跳转表 (C++17)，实测 15x 加速 (2 ns/msg vs 30 ns/msg)。\n\n#### API 设计\n\n**processQueueWith** -- 处理队列中的所有事件:\n\n```cpp\ntemplate <typename Visitor>\nbool processQueueWith(Visitor && visitor);\n```\n\n- 每个事件直接调用 `visitor(event, args...)` -- 无间接调用\n- 返回 `true` 如果处理了至少一个事件\n\n**processOneWith** -- 处理队列中的一个事件:\n\n```cpp\ntemplate <typename Visitor>\nbool processOneWith(Visitor && visitor);\n```\n\n- 返回 `true` 如果处理了一个事件\n\n**Visitor 协议**: Visitor 接收的第一个参数为事件 ID (EventType)，后续参数与 EventQueue 原型签名中的 Args... 相同。\n\n```cpp\n// 函数对象 (推荐: 编译器可内联)\nstruct MyVisitor {\n    void operator()(int event, const std::string & data) {\n        switch(event) {\n            case EVENT_SENSOR: handleSensor(data); break;\n            case EVENT_MOTOR:  handleMotor(data);  break;\n        }\n    }\n};\n\n// Lambda\nqueue.processQueueWith([](int event, const std::string & data) {\n    // ...\n});\n```\n\n#### 热路径对比\n\n| 开销项 | process() | processQueueWith() |\n|--------|:---------:|:-------------------:|\n| `shared_lock<SharedMutex>` (listenerMutex) | 每条消息 | **无** |\n| `map.find(event)` 查找 | 每条消息 | **无** |\n| CallbackList mutex (每 8 节点加锁) | 每批次 | **无** |\n| `shared_ptr<Node>` 链表遍历 | 每个回调 | **无** |\n| `std::function` 间接调用 | 每个回调 | **无** |\n| Mixin beforeDispatch 检查 | 每条消息 | **无** |\n| Visitor 直接调用 (可内联) | -- | **每条消息** |\n\n共享的基础设施 (无差异):\n- 队列 swap (lock_guard + std::swap) -- 两者相同\n- CounterGuard (emptyQueue 语义) -- 两者相同\n- BufferedItem clear + freeList 回收 -- 两者相同\n\n#### 核心实现\n\n```cpp\n// eventqueue.h, EventQueueBase 类内\n\ntemplate <typename Visitor>\nbool processQueueWith(Visitor && visitor)\n{\n    if(! queueList.empty()) {\n        BufferedItemList tempList;\n        CounterGuard<decltype(queueEmptyCounter)> counterGuard(queueEmptyCounter);\n        {\n            std::lock_guard<Mutex> queueListLock(queueListMutex);\n            std::swap(queueList, tempList);\n        }\n        if(! tempList.empty()) {\n            for(auto & item : tempList) {\n                doVisitQueuedEvent(\n                    visitor,\n                    item.get(),\n                    typename MakeIndexSequence<sizeof...(Args)>::Type()\n                );\n                item.clear();\n            }\n            std::lock_guard<Mutex> queueListLock(freeListMutex);\n            freeList.splice(freeList.end(), tempList);\n            return true;\n        }\n    }\n    return false;\n}\n\n// Helper: tuple 解包 + visitor 直接调用\ntemplate <typename V, typename T, size_t ...Indexes>\nvoid doVisitQueuedEvent(V && visitor, T && item, IndexSequence<Indexes...>)\n{\n    visitor(item.event, std::get<Indexes>(item.arguments)...);\n}\n```\n\n#### C++14 兼容性\n\n| 特性 | C++17 (newosp) | C++14 (eventpp) |\n|------|:-:|:-:|\n| 分发机制 | `std::visit` + `std::variant` | `visitor(event, args...)` 直接调用 |\n| 参数展开 | fold expression | IndexSequence + pack expansion |\n| 条件编译 | `if constexpr` | SFINAE / `enable_if` |\n| 索引序列 | `std::index_sequence` | eventpp 自有 `MakeIndexSequence` |\n\neventpp 的 EventQueue 是**同构**的 (所有事件共享相同回调签名)，不需要 variant/visit。\nVisitor 接收的参数类型在编译期由模板参数确定，天然 C++14 兼容。\n\n#### 与 process() 的关系\n\n- **processQueueWith** 是 `process()` 的**替代品**，不是叠加使用\n- 两者消费同一个队列 (queueList)\n- 适用于单消费者 (MPSC) 场景\n- 如需多消费者或动态注册回调，仍使用 `process()`\n\n#### 使用场景: 单消费者事件循环\n\n```cpp\neventpp::EventQueue<int, void(int, const SensorData &)> queue;\n\nstruct EventHandler {\n    void operator()(int event, int id, const SensorData & data) {\n        switch(event) {\n            case SENSOR_UPDATE: processSensor(id, data); break;\n            case MOTOR_CMD:     executeMotor(id, data);  break;\n        }\n    }\n};\n\n// 事件循环 -- 零开销分发\nEventHandler handler;\nwhile(running) {\n    queue.processQueueWith(handler);\n}\n```\n\n#### 与 newosp ProcessBatchWith 的对照\n\n| 维度 | newosp | eventpp |\n|------|--------|---------|\n| 队列 | Lock-free MPSC ring buffer | std::list + swap |\n| 类型系统 | std::variant (异构) | 同构 (相同签名) |\n| 分发 | std::visit 跳转表 | visitor(event, args...) 直接调用 |\n| C++ 标准 | C++17 | C++14 |\n| 回调模式 | FixedFunction + callback_table | std::function + CallbackList |\n| 绕过的层 | SharedSpinLock + callback遍历 + FixedFunction | SharedMutex + map.find + CallbackList + std::function |\n\n---\n\n## 三、性能数据\n\n测试环境：Ubuntu 24.04, GCC 13.3, `-O3 -march=native`\n\n### Raw EventQueue (1M 消息)\n\n| 指标 | 优化前 (v0.1.3) | 优化后 | 变化 |\n|------|:---------------:|:------:|:----:|\n| 吞吐量 | 22.2 M/s | 24.8 M/s | +12% |\n| 入队延迟 | 46 ns | 42 ns | -9% |\n\n### Active Object 模式（多线程）\n\n| 指标 | 优化前 | 优化后 | 提升 |\n|------|:------:|:------:|:----:|\n| 吞吐量 (10K) | ~1.6 M/s | 8.5 M/s | 5.3x |\n| 持续吞吐 (5s) | ~1.25 M/s | 3.1 M/s | 2.5x |\n| E2E P50 | ~1,200 ns | 11,588 ns | 吞吐-延迟权衡 |\n| E2E P99 | ~8,953 ns | 24,289 ns | 吞吐-延迟权衡 |\n\n### PoolQueueList (OPT-5, 10K 消息)\n\n| 方案 | 吞吐量 | 入队延迟 |\n|------|:------:|:-------:|\n| std::list (默认) | 22.2 M/s | 46 ns |\n| PoolQueueList | 28.5 M/s | 36 ns |\n\n### processQueueWith (OPT-15, CPU pinned to core 1)\n\n| 场景 | process() | processQueueWith() | 加速比 |\n|------|:---------:|:-------------------:|:------:|\n| 单事件 ID, 100K 消息 | 152.4 ns/msg | 9.1 ns/msg | **16.7x** |\n| 10 个事件 ID, 100K 消息 | 151.5 ns/msg | 10.0 ns/msg | **15.2x** |\n| 10 个事件 ID, 1M 消息 | 76.6 ns/msg | 21.2 ns/msg | **3.6x** |\n\n分析:\n- 100K 消息场景加速比约 15-17x，与 newosp 的 15x 加速一致\n- 1M 消息场景加速比降至 3.6x，因为大队列下 std::list 的 freeList 回收成为共同瓶颈\n- 中位数 (P50) 更能反映稳态性能: 6.1 ns/msg vs 154.9 ns/msg = 25x\n\n### 资源消耗\n\n| 指标 | 优化前 | 优化后 | 变化 |\n|------|:------:|:------:|:----:|\n| 测试套件时间 | ~23 s | ~18 s | -22% |\n| 峰值内存 | 113 MB | 113 MB | 不变 |\n| 上下文切换 | ~90 | 84 | -7% |\n\n---\n\n## 四、设计决策\n\n| 问题 | 选择 | 原因 |\n|------|------|------|\n| OPT-2: 快照 vs 批量预取 | 批量预取 (8 节点) | 快照破坏重入 append 语义 |\n| OPT-3: shared_mutex vs 无锁 map | shared_mutex | 改动小，C++14 兼容 |\n| OPT-5/9: Ring Buffer vs Pool Allocator | Pool Allocator + 多 slab + CAS | Ring Buffer 不支持 splice()（14 处调用）；CAS 无锁 free list 消除热路径锁竞争 |\n| OPT-15: process() vs processQueueWith | processQueueWith 作为替代 API | 单消费者场景不需要 5 层间接调用基础设施；C++14 天然兼容 |\n\n---\n\n## 五、修改文件\n\n| 文件 | 涉及 OPT |\n|------|----------|\n| `include/eventpp/eventpolicies.h` | OPT-1, OPT-3, OPT-6, OPT-10, OPT-11 |\n| `include/eventpp/callbacklist.h` | OPT-2 |\n| `include/eventpp/eventdispatcher.h` | OPT-3 |\n| `include/eventpp/hetereventdispatcher.h` | OPT-3 |\n| `include/eventpp/eventqueue.h` | OPT-4, OPT-6, OPT-8, OPT-14, OPT-15 |\n| `include/eventpp/internal/eventqueue_i.h` | OPT-7 |\n| `include/eventpp/internal/poolallocator_i.h` | OPT-5, OPT-9 (新增) |\n\n---\n\n## 六、验证体系\n\n| 验证项 | 方法 | 通过标准 |\n|--------|------|----------|\n| 编译 | `cmake --build . --target unittest` | 零错误 |\n| 功能 | `ctest` (410 个测试用例) | 410/410 PASS |\n| processQueueWith | 10 项专项测试 (218 assertions) | 10/10 PASS |\n| 线程安全 | `-fsanitize=thread` | 无新增 data race |\n| 内存安全 | `-fsanitize=address` + `detect_leaks=1` | 零错误零泄漏 |\n| 性能 | `eventpp_raw_benchmark` | 无回退 >5% |\n\nprocessQueueWith 测试覆盖:\n- 基本分发、多事件全量处理、空队列返回 false\n- 事件顺序保持、processOneWith 单事件/剩余保留\n- 自定义 Policy (SingleThreading) 兼容\n- processQueueWith vs process 结果一致性\n- 非整型事件 ID (std::string)、复杂参数 (多参数、移动语义)\n\n```bash\ncd refs/eventpp/tests && mkdir -p build && cd build\ncmake .. -DCMAKE_BUILD_TYPE=Release\ncmake --build . --target unittest -j$(nproc)\nctest --output-on-failure\n```\n\n---\n\n## 七、致谢\n\n- [wqking/eventpp](https://github.com/wqking/eventpp) -- 原始库\n- [iceoryx](https://github.com/eclipse-iceoryx/iceoryx) -- PoolAllocator 设计灵感\n- [newosp](https://github.com/DeguiLiu/newosp) -- ProcessBatchWith Visitor 模式验证\n",
      "ctime": "1771552571",
      "mtime": "1771552571",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/high_performance_system_design_principles.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038453798",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809641167680962568
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "高性能系统设计的五个反直觉原则: 从消息队列优化中提炼的通用方法论",
      "brief_content": "在优化无锁消息总线的过程中，我们发现五个违反直觉的性能原则: 状态机提升 100% 吞吐、上下文切换减少 99.8%、队列容量无法解决速率失衡、批处理提升 76 倍吞吐、单核自旋性能下降 91%。每个",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 结论先行\n\n优化一个无锁 MPSC 消息总线的过程中，我们提炼出五条反直觉的性能原则:\n\n| # | 原则 | 反直觉之处 | ARM 实测收益 |\n|---|------|-----------|---------|\n| 1 | 状态机是性能工具 | 增加复杂度反而提升性能 | +100% 吞吐 |\n| 2 | 上下文切换是隐藏杀手 | 多线程不等于高性能 | -99.8% 切换次数 |\n| 3 | 速率平衡才是关键 | 增大队列无法解决丢失 | 丢失率 98% → 0% |\n| 4 | 测量方法决定优化方向 | CPU 占用高不等于瓶颈 | 批处理 76x 吞吐 |\n| 5 | 优化存在适用边界 | 好的优化换个场景可能有害 | 单核下 -91% |\n\n这些原则不限于消息队列，适用于任何需要处理高频数据流的系统: 网络协议栈、传感器数据管线、数据库引擎、实时音视频处理。\n\n下文逐一展开，每个原则包含案例数据、原理分析和适用边界。\n\n> 注: 本文中的性能数据来自 ARM Neoverse-N2 (4 核) 平台实测，不同平台和负载下数值会有差异。Benchmark 源码开源，可在目标环境中复现验证。\n\n## 原则 1: 状态机不仅是逻辑工具，更是性能工具\n\n### 常识 vs 现实\n\n多数工程师认为状态机是一种逻辑抽象工具 -- 增加代码复杂度，换取可维护性。但优化案例中的数据讲了一个不同的故事:\n\n| 实现方式 | 吞吐量 | 延迟 | 性能差异 |\n|---------|--------|------|---------|\n| 无状态机 (if-else 链) | 1693 M/s | 0.6 ns | 基准 |\n| 有状态机 (状态原子读) | 3393 M/s | 0.3 ns | +100% |\n\n100% 的性能提升不是来自状态机本身，而是来自状态机带来的代码结构变化。\n\n### 关键区分: 状态检查 vs 状态转换\n\n性能差异的根源在于如何使用状态机。错误用法是让每条消息都触发状态转换:\n\n```cpp\n// 错误: 每条消息触发状态机事件 (~600ns 开销)\nvoid on_message(const Data& data) {\n    hsm_.process_event(MessageEvent{data});  // 状态查找 + guard 求值 + 转换\n}\n```\n\n正确用法是将状态机限定在低频控制面，数据面只做原子读:\n\n```cpp\n// 正确: 数据面只读取状态 (~20ns 开销)\nvoid on_message(const Data& data) {\n    auto state = current_state_.load(std::memory_order_acquire);\n    if (state == State::kRunning) {\n        process(data);  // 直接处理，无状态机开销\n    }\n    // 状态转换由独立的控制线程/事件驱动，频率低几个数量级\n}\n```\n\n### 性能提升的三个来源\n\n状态机带来的 100% 提升并非单一因素，而是三个效应叠加:\n\n```mermaid\ngraph TD\n    A[引入状态机] --> B[代码结构更清晰]\n    A --> C[分支模式更可预测]\n    A --> D[数据访问更局部]\n    B --> E[编译器生成更优指令]\n    C --> E\n    D --> E\n    E --> F[净收益 +100%]\n```\n\n1. 分支预测命中率提升 -- 状态变量通常长时间保持不变，CPU 分支预测器几乎 100% 命中\n2. 缓存局部性改善 -- 状态检查集中在一个 cache line 的原子变量上，而 if-else 链可能散布在多个条件判断中\n3. 编译器优化空间增大 -- 清晰的状态分支让编译器更容易做死代码消除和指令重排\n\n单次状态检查开销约 0.3ns (一次 `acquire` load)，而 4 个 volatile bool 分散在不同 cache line 上需要 1.2ns。多线程场景下差异更大: 4x volatile bool 847 M/s vs 1x atomic 3387 M/s (+300%)。\n\n### 适用边界\n\n| 场景 | 是否适用 | 原因 |\n|------|---------|------|\n| 网络连接状态管理 | 适用 | 状态转换频率远低于数据包频率 |\n| 任务调度器生命周期 | 适用 | 状态变化是秒级事件 |\n| 每个数据包触发状态转换 | 不适用 | 状态机开销 > 收益 |\n| 纯计算密集型热路径 | 不适用 | 没有状态可管理 |\n\n核心原则: **状态机管理低频控制面，数据面只做原子读。两者频率差至少两个数量级。**\n\n## 原则 2: 上下文切换是隐藏的性能杀手\n\n### 一个令人困惑的优化结果\n\n优化前后的 `/usr/bin/time -v` 输出几乎一样:\n\n| 指标 | sleep(1ms) | 自适应退避 |\n|------|-----------|-----------|\n| 自愿上下文切换 | 950 | 2 |\n| 非自愿上下文切换 | 9 | 5 |\n| 总耗时 | 1008 ms | 1063 ms |\n\nCPU 时间完全相同，但自愿上下文切换从 950 次降至 2 次，减少 99.8%。这个差异在传统 profiling 中完全不可见 -- 它不会出现在火焰图里，不会被 `perf top` 捕获，却实实在在地影响着尾延迟。\n\n### 上下文切换的真实成本\n\n单次上下文切换的成本远超寄存器保存/恢复 (以下为典型 Linux x86_64 估算值):\n\n```\n单次上下文切换:\n  直接成本:  1-5 us   (保存/恢复寄存器、切换页表)\n  间接成本: 10-100 us (L1/L2 缓存失效、TLB 刷新、流水线排空)\n  典型总成本: ~50 us\n\n48,261 次切换的累积成本:\n  48,261 x 50 us = 2.4 秒 (在 5 秒测试窗口中占 48%)\n```\n\n间接成本是直接成本的 10-20 倍。缓存失效意味着切换回来后，前几百次内存访问都是 cache miss，每次 miss 在 ARM 平台上约 50-100ns。\n\n### 自适应退避: 用可控的 CPU 换不可控的延迟\n\n解决方案不是消除 sleep，而是在高频和低频之间自适应切换:\n\n```cpp\nclass AdaptiveBackoff {\n    enum class Phase { kSpin, kYield, kSleep };\n\n    Phase phase_ = Phase::kSpin;\n    uint32_t idle_count_ = 0;\n\n    static constexpr uint32_t kSpinThreshold  = 64;    // 自旋次数上限\n    static constexpr uint32_t kYieldThreshold = 256;   // yield 次数上限\n\npublic:\n    void wait() {\n        ++idle_count_;\n\n        if (idle_count_ < kSpinThreshold) {\n            // 阶段 1: 纯自旋，~10ns/次，适合消息即将到达的场景\n            for (int i = 0; i < 32; ++i) {\n                #if defined(__x86_64__)\n                __builtin_ia32_pause();\n                #elif defined(__aarch64__)\n                asm volatile(\"yield\");\n                #endif\n            }\n        } else if (idle_count_ < kYieldThreshold) {\n            // 阶段 2: 让出时间片但不 sleep，~1us\n            std::this_thread::yield();\n        } else {\n            // 阶段 3: 真正 sleep，触发上下文切换\n            std::this_thread::sleep_for(std::chrono::milliseconds(1));\n        }\n    }\n\n    void reset() { idle_count_ = 0; }\n};\n```\n\n三阶段退避的状态转换:\n\n```mermaid\nstateDiagram-v2\n    [*] --> Spin: 队列为空\n    Spin --> Yield: 连续空闲 > 64 次\n    Yield --> Sleep: 连续空闲 > 256 次\n    Spin --> [*]: 有新消息\n    Yield --> [*]: 有新消息\n    Sleep --> [*]: 有新消息\n```\n\n### 收益的数学模型\n\n自适应退避是否值得，取决于消息到达间隔:\n\n```\n收益 = 节省的上下文切换成本 - 自旋消耗的 CPU 时间\n\n高频场景 (消息间隔 < 100us):\n  节省: 50us (一次上下文切换)\n  消耗: 64 x 10ns = 0.64us (自旋)\n  净收益: +49.36us\n\n低频场景 (消息间隔 > 100ms):\n  节省: 0 (无论如何都会 sleep)\n  消耗: 64 x 10ns + 256 x 1us = 256.64us (白白自旋)\n  净收益: -256.64us\n```\n\n**适用条件: 消息到达频率 > 10K/s，且有空闲 CPU 核心。** 单核系统上自旋会阻止生产者线程运行，性能反而下降 91%。\n\n## 原则 3: 生产者-消费者必须满足速率平衡\n\n### 增大队列是最常见的错误直觉\n\n面对消息丢失，第一反应通常是增大队列容量。某次优化中的对比数据:\n\n| 配置 | 队列容量 | 生产速率 | 消费速率 | 丢失率 |\n|------|---------|---------|---------|--------|\n| A | 4K | 93 M/s | 1.5 M/s | 98.4% |\n| B | 4K | 2.8 M/s | 2.8 M/s | 0% |\n| C | 64K | 74 M/s | 1.5 M/s | 98.0% |\n\n配置 C 将队列扩大 8 倍，丢失率纹丝不动。配置 B 队列不变，只是让消费速率超过生产速率，丢失率归零。\n\n### 数学本质: 队列是缓冲器，不是解决方案\n\n当生产速率 P > 消费速率 C 时，队列填充速率恒为正:\n\n```\n填充速率 = P - C\n\n配置 A: 4.0 - 0.9 = 3.1 M msg/s\n  128K 队列填满时间 = 131,072 / 3,100,000 = 42ms\n  之后每秒丢失 3.1M 条消息\n\n配置 C: 同样 3.1 M msg/s 填充速率\n  1M 队列填满时间 = 1,048,576 / 3,100,000 = 338ms\n  之后丢失率与配置 A 完全相同\n```\n\n增大队列只是把问题从 42ms 后推迟到 338ms 后。在持续运行的系统中，这个延迟毫无意义。\n\n```mermaid\ngraph LR\n    P[\"生产者 4.0 M/s\"] -->|\"入队\"| Q[\"队列 (128K)\"]\n    Q -->|\"出队\"| C[\"消费者 0.9 M/s\"]\n    Q -.->|\"溢出 3.1 M/s\"| D[\"丢失\"]\n    style D fill:#ff6b6b,color:#fff\n```\n\n### 三种解决方案\n\n**方案 1: 背压 (Backpressure)** -- 让生产者感知队列压力\n\n```cpp\nbool publish_with_backpressure(const Message& msg) {\n    uint32_t utilization = queue_.size() * 100 / queue_.capacity();\n\n    if (utilization > 90) {\n        return false;  // 拒绝入队，让调用者决定重试策略\n    }\n    if (utilization > 75) {\n        std::this_thread::sleep_for(std::chrono::microseconds(10));  // 减速\n    }\n\n    return queue_.try_push(msg);\n}\n```\n\n**方案 2: 批处理提升消费速率** -- 减少每条消息的固定开销\n\n```cpp\n// 单条处理: 每条消息承担一次函数调用 + 缓存预热开销\n// 批处理: N 条消息分摊一次开销\nvoid consume_batch() {\n    Message batch[2048];\n    uint32_t count = queue_.try_pop_batch(batch, 2048);\n\n    for (uint32_t i = 0; i < count; ++i) {\n        process(batch[i]);  // 连续内存访问，缓存友好\n    }\n}\n```\n\n**方案 3: 多消费者并行** -- 水平扩展消费能力\n\n```cpp\n// 确保 N 个消费者的总速率 > 生产速率\nfor (uint32_t i = 0; i < num_consumers; ++i) {\n    workers.emplace_back([&queue]() {\n        while (running) {\n            consume_batch();\n        }\n    });\n}\n```\n\n三种方案不互斥，生产环境通常组合使用: 背压作为安全阀，批处理提升单消费者效率，多消费者应对峰值。\n\n### 适用边界\n\n速率平衡原则有一个例外: **突发流量 (burst)**。如果生产者是突发式的 (例如每秒一次、每次 10K 条消息)，而消费者是匀速的 (10K/s)，那么队列容量确实能解决问题 -- 前提是突发量 < 队列容量，且两次突发之间消费者能清空队列。\n\n判断公式:\n\n```\n队列容量 >= 突发量 - (突发间隔 x 消费速率)\n\n例: 突发 10K 条，间隔 1s，消费 10K/s\n  需要容量 >= 10K - (1s x 10K/s) = 0  (消费者刚好跟上)\n\n例: 突发 50K 条，间隔 1s，消费 10K/s\n  需要容量 >= 50K - (1s x 10K/s) = 40K  (需要 40K 缓冲)\n```\n\n## 原则 4: 测量方法决定优化方向\n\n### CPU 占用率的误导性\n\n一个真实的优化案例:\n\n```bash\n# 优化前\n$ /usr/bin/time -v ./message_bus_bench\nUser time:              9.07 s\nSystem time:            1.01 s\nPercent of CPU:         166%\nVoluntary ctx switches: 48,261\n\n# 优化后 (引入自适应退避)\n$ /usr/bin/time -v ./message_bus_bench\nUser time:              9.07 s\nSystem time:            1.01 s\nPercent of CPU:         166%\nVoluntary ctx switches: 6,938\n```\n\n如果只看 CPU 时间和占用率，会得出\"没有优化空间\"的错误结论。真正的改善隐藏在上下文切换次数中。\n\n### 不同指标指向不同优化方向\n\n| 指标 | 含义 | 优化方向 |\n|------|------|---------|\n| User Time 高 | 用户态计算密集 | 算法优化、SIMD、缓存对齐 |\n| System Time 高 | 系统调用频繁 | 减少 I/O、批量系统调用、io_uring |\n| Context Switches 多 | 线程频繁切换 | 自适应退避、减少锁竞争 |\n| Cache Misses 高 | 数据局部性差 | 结构体重排、预取、池化 |\n| Branch Mispredictions 高 | 分支不可预测 | 无分支编程、查表、likely/unlikely |\n\n### 测量工具链\n\n从粗到细的三级测量:\n\n```bash\n# 第一级: 宏观概览 (秒级)\n/usr/bin/time -v ./program\n\n# 第二级: 硬件计数器 (指令级)\nperf stat -e cycles,instructions,cache-misses,branch-misses,\\\ncontext-switches,cpu-migrations ./program\n\n# 第三级: 采样分析 (函数级)\nperf record -g -F 99 ./program\nperf script | stackcollapse-perf.pl | flamegraph.pl > flame.svg\n```\n\n核心原则: **先用第一级确定瓶颈类别 (计算/IO/调度)，再用第二级量化具体指标，最后用第三级定位热点函数。** 跳过前两步直接看火焰图，容易在错误的方向上深挖。\n\n## 原则 5: 每种优化都有适用边界\n\n### 同一优化在不同场景下的表现\n\n以自旋等待为例:\n\n| 场景 | 吞吐量 | 性能变化 | 原因 |\n|------|--------|---------|------|\n| 多核 (4 核 ARM) | 7.5 M/s | 基准 | 生产者消费者各占一核 |\n| 单核 (pin to core 0) | 0.69 M/s | -91% | 自旋占用唯一核心，阻止生产者运行 |\n\n一个在服务器上表现优异的优化，放到嵌入式设备上可能是灾难。\n\n### 用代码表达适用条件\n\n将优化的适用边界显式编码，而不是靠注释或文档:\n\n```cpp\nstruct OptimizationContext {\n    uint32_t cpu_cores;\n    double   message_rate;       // messages/second\n    bool     battery_powered;\n    double   context_switch_us;  // 平台实测值\n};\n\nbool should_enable_spin_wait(const OptimizationContext& ctx) {\n    // 条件 1: 多核 (自旋不能阻塞生产者)\n    if (ctx.cpu_cores <= 1) return false;\n\n    // 条件 2: 高频 (自旋期间消息大概率到达)\n    constexpr double kSpinDurationUs = 0.64;  // 64 次 x 10ns\n    double msg_interval_us = 1e6 / ctx.message_rate;\n    if (kSpinDurationUs > msg_interval_us * 0.1) return false;\n\n    // 条件 3: 非电池供电 (自旋阻止 CPU 休眠)\n    if (ctx.battery_powered) return false;\n\n    // 条件 4: 收益为正\n    return ctx.context_switch_us > kSpinDurationUs;\n}\n```\n\n### 运行时自适应\n\n更好的做法是让系统在运行时根据实际负载自动调整:\n\n```cpp\nclass AdaptiveStrategy {\n    std::atomic<uint64_t> ctx_switches_per_sec_{0};\n    std::atomic<uint64_t> queue_utilization_pct_{0};\n    bool spin_enabled_ = false;\n    bool backpressure_enabled_ = false;\n\npublic:\n    void adjust() {\n        // 上下文切换过多 → 启用自旋\n        if (ctx_switches_per_sec_ > 10000 && !spin_enabled_) {\n            spin_enabled_ = true;\n        } else if (ctx_switches_per_sec_ < 1000 && spin_enabled_) {\n            spin_enabled_ = false;\n        }\n\n        // 队列压力过大 → 启用背压\n        if (queue_utilization_pct_ > 75 && !backpressure_enabled_) {\n            backpressure_enabled_ = true;\n        } else if (queue_utilization_pct_ < 50 && backpressure_enabled_) {\n            backpressure_enabled_ = false;\n        }\n    }\n};\n```\n\n核心原则: **优化策略应该是条件化的，而不是无条件启用的。** 最好的系统不是\"最快的\"，而是\"在当前条件下最合适的\"。\n\n## 优化决策树\n\n将五个原则串联成一个实用的决策流程:\n\n```mermaid\nflowchart TD\n    A[\"性能问题\"] --> B{\"第一步: 测量\"}\n    B -->|\"System Time 高\"| C[\"减少系统调用\"]\n    B -->|\"User Time 高\"| D[\"算法/缓存优化\"]\n    B -->|\"Context Switch 多\"| E[\"调度优化\"]\n\n    E --> F{\"多核?\"}\n    F -->|\"否\"| G[\"减少线程数\"]\n    F -->|\"是\"| H{\"消息频率 > 10K/s?\"}\n    H -->|\"是\"| I[\"启用自适应退避\"]\n    H -->|\"否\"| J[\"增大 sleep 间隔\"]\n\n    C --> K{\"队列丢失?\"}\n    K -->|\"是\"| L{\"P > C?\"}\n    L -->|\"是\"| M[\"背压 + 批处理\"]\n    L -->|\"否 (突发)\"| N[\"增大队列容量\"]\n    K -->|\"否\"| O[\"减少 I/O 频率\"]\n\n    D --> P[\"perf record + 火焰图\"]\n    P --> Q[\"定位热点函数\"]\n```\n\n## 实践清单\n\n将五个原则转化为可执行的检查项:\n\n1. **状态机分离** -- 检查热路径中是否有状态转换逻辑。如果有，将状态转换移到控制面，数据面只做原子读\n2. **上下文切换审计** -- 用 `/usr/bin/time -v` 检查 voluntary context switches。超过 10K/s 考虑自适应退避\n3. **速率平衡验证** -- 计算生产速率和消费速率。如果 P > C，增大队列只是延迟问题，需要背压或提升消费能力\n4. **多维度测量** -- 不要只看 CPU 占用率。User Time、System Time、Context Switches、Cache Misses 各指向不同瓶颈\n5. **边界条件测试** -- 在目标平台的最差条件下 (单核、低频、电池) 验证优化是否仍然有效\n\n---\n\n> 本文 benchmark 源码: [benchmark_five_principles.cpp](https://github.com/DeguiLiu/tech-notes/blob/main/examples/benchmark_five_principles.cpp)\n\n测试环境: ARM Neoverse-N2, 4 核, Linux 6.14.0, GCC 13.3.0, aarch64 (GitHub Actions ARM runner)\n数据来源: 无锁 SPSC 队列 benchmark，3 轮取稳定值\n",
      "ctime": "1771552575",
      "mtime": "1771552575",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/lockfree_async_log.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038470182",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "无锁异步日志设计: Per-Thread SPSC 环形缓冲与分级路由",
      "brief_content": "在多核 ARM Linux 嵌入式系统中，同步日志的 I/O 阻塞导致控制回路超时和看门狗复位。本文设计一种基于 Per-Thread SPSC 环形缓冲与分级路由的异步日志架构，实现 wait-fr",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 在多核 ARM Linux 嵌入式系统中，传统的同步日志记录方式（如直接调用 `fprintf` 或 `write`）由于受限于磁盘 I/O 延迟及内核态切换开销，往往成为系统的性能瓶颈。本文提出并实现了一种基于 **Per-Thread SPSC 环形缓冲** 与 **分级路由** 的异步日志架构，在 ARM 平台上实现了 wait-free 热路径 (~200-300ns)、零竞争生产者、崩溃安全的关键日志保障，以及背压丢弃的自动上报机制。\n>\n> 相关文章:\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- SPSC/MPSC 无锁队列的理论基础\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- Per-Thread SPSC 的底层实现详解\n\n## 1. 同步日志的问题\n\n工业传感器在故障诊断、状态切换等场景下会突发大量日志。同步 `fprintf(stderr, ...)` 的 I/O 系统调用阻塞调用线程 (~1-3us/条)，直接影响实时业务:\n\n- 控制回路超时\n- 看门狗触发复位\n- 传感器数据丢失\n\n异步日志的核心思想是将日志的\"生成\"与\"落盘\"解耦: 业务线程仅负责将数据写入内存缓冲区，独立的后台线程负责批量持久化。\n\n## 2. 存储选型: 为何摒弃链表?\n\n在设计日志缓冲区时，基于定长数组的环形缓冲区（Ring Buffer）在高性能场景下全面优于动态链表。\n\n### 2.1 内存碎片化与 OOM 风险\n\n链表模式下，每条日志都需要 `malloc` 分配节点并在消费后 `free`。在高频日志场景（如每秒 1000 次以上写入）下，频繁的申请与释放会导致堆内存碎片化。在嵌入式设备 7x24 小时运行的过程中，即使系统剩余总内存充足，也可能因无法申请到连续的大块内存而触发 OOM。\n\n### 2.2 内存分配的系统开销\n\n`malloc` 与 `free` 内部维护着复杂的空闲链表。为保证线程安全，分配器内部通常持有锁。随着碎片增加，分配器寻找合适空洞的时间复杂度非线性增长。\n\n### 2.3 CPU 缓存不友好 (Cache Miss)\n\nCPU 访问不同存储层级的耗时差异巨大:\n\n| 层级 | 延迟 | 典型容量 |\n|------|------|---------|\n| L1 Cache | ~1ns | 32-64KB |\n| L2 Cache | ~3-10ns | 256KB-1MB |\n| L3 Cache | ~10-20ns | 多核共享 |\n| 主内存 (RAM) | ~60-100ns | GB 级 |\n\nCPU 以 Cache Line（通常 64 字节）为单位访问内存:\n\n- **数组 (Ring Buffer)**: 内存物理连续，读取第一个元素时后续元素已通过缓存行预取至 L1/L2，Cache Hit 率高\n- **链表**: 节点离散分布，遍历需随机跳跃，频繁 Cache Miss，对于 2GHz CPU 意味着数百个指令周期的停顿\n\n## 3. 并发模型选型: MPSC vs Per-Thread SPSC\n\n### 3.1 MPSC 方案\n\n传统做法是多生产者单消费者 (MPSC)，所有线程通过 CAS 竞争同一个 `tail` 指针:\n\n```\nThread 0 -->|CAS push|--> [  共享 Ring Buffer  ] --> Consumer\nThread 1 -->|CAS push|-->\nThread N -->|CAS push|-->\n```\n\nMPSC 的问题:\n- **CAS 竞争**: 高并发时 CAS 失败重试，延迟波动 ~50-100ns\n- **缓存行弹跳**: 共享 `tail` 指针在多核间的 MESI 一致性协议导致频繁缓存失效\n- **committed 标志**: CAS 分配 slot 后、`vsnprintf` 完成前，消费者不能读取该 slot，需额外的原子标志协调\n\n### 3.2 Per-Thread SPSC 方案 (推荐)\n\n每个线程拥有独立的 SPSC (单生产者单消费者) 环形缓冲，后台写线程轮询所有缓冲:\n\n```\nThread 0 --> [SPSC RingBuffer 0] --+\nThread 1 --> [SPSC RingBuffer 1] --+--> Writer Thread --> Sink\nThread N --> [SPSC RingBuffer N] --+    (round-robin poll)\n```\n\n| 维度 | MPSC (CAS) | Per-Thread SPSC |\n|------|-----------|-----------------|\n| 生产者延迟 | CAS 重试 ~50-100ns | **wait-free ~10-20ns** |\n| 缓存行为 | 共享 tail 跨核弹跳 | **每线程独立，零 false sharing** |\n| 额外复杂度 | committed 标志 | **无** |\n| 内存 | 1 x N x entry_size | MaxThreads x N x entry_size |\n| 适用场景 | 线程数多/动态 | **线程数固定 (嵌入式 2-8)** |\n\n嵌入式场景线程数少且编译期可确定 (2-8 个)，Per-Thread SPSC 的 **wait-free 确定性延迟**更适合实时系统。多出的内存开销 (8 x 80KB = 640KB) 在 ARM Linux 平台上可接受且编译期可控。\n\n## 4. 针对 ARM 平台的深度优化\n\n### 4.1 消除伪共享 (False Sharing)\n\n在多核 ARM 处理器 (Cortex-A53/A72) 中，若不同核心频繁写入同一 Cache Line 的不同变量，MESI 协议会导致缓存行在核心间不断失效和重载。\n\n解决方案: 将热点原子变量对齐到独立的缓存行:\n\n```cpp\n// SPSC Ring Buffer 内部: head 和 tail 分别对齐\nalignas(64) std::atomic<uint32_t> head_{0};\nalignas(64) std::atomic<uint32_t> tail_{0};\n\n// 统计计数器: 各占独立缓存行\nalignas(64) std::atomic<uint64_t> entries_written{0};\nalignas(64) std::atomic<uint64_t> entries_dropped{0};\n```\n\n### 4.2 ARM 弱内存模型与 acquire/release 语义\n\nARM 架构采用弱内存模型 (Weakly Ordered)，store 操作可能被重排到 load 之后。简单的原子自增不足以保证多核间的数据可见性。\n\n使用 C++ `std::atomic` 的 `memory_order_release` (写屏障) 与 `memory_order_acquire` (读屏障) 语义:\n\n```cpp\n// 生产者: 先写数据，再 release 更新 tail\nbuf->queue.Push(entry);  // 内部: store(tail, new_tail, release)\n\n// 消费者: 先 acquire 读 tail，再读数据\nauto n = buf->queue.PopBatch(batch, 32);  // 内部: load(tail, acquire)\n```\n\n编译器和 CPU 保证: **release 之前的所有写入对 acquire 之后的读取可见**。在 ARM 上映射为 `DMB` (Data Memory Barrier) 指令。\n\n### 4.3 三阶段自适应退避 (AdaptiveBackoff)\n\n后台写线程的等待策略直接影响 CPU 占用率和响应延迟:\n\n```cpp\nclass LogBackoff {\n  void Wait() noexcept {\n    if (spin_count_ < 6) {\n      // Phase 1: CPU pause/yield 指数退避 (1/2/4/8/16/32 次)\n      for (uint32_t i = 0; i < (1U << spin_count_); ++i) {\n        CpuRelax();  // ARM: yield; x86: pause\n      }\n      ++spin_count_;\n    } else if (spin_count_ < 10) {\n      // Phase 2: 让出 CPU 时间片\n      std::this_thread::yield();\n      ++spin_count_;\n    } else {\n      // Phase 3: 短暂睡眠，最小化 CPU 占用\n      std::this_thread::sleep_for(std::chrono::microseconds(50));\n    }\n  }\n};\n```\n\n| 阶段 | 延迟 | 适用场景 |\n|------|------|---------|\n| Spin (pause/yield) | ~10-100ns | 高频日志突发，写线程快速响应 |\n| Yield | ~1us | 中等负载，让出 CPU 时间片 |\n| Sleep (50us) | 50us | 空闲期，最小化 CPU 占用 |\n\n相比文章早期版本的固定 `usleep(1000)` (1ms)，自适应退避在突发日志场景下将响应延迟从 1ms 降低到 ~10ns。\n\n## 5. 分级路由: 关键日志同步写\n\n异步日志的最大风险是 **崩溃时丢失关键信息**。解决方案: 按日志级别分级路由。\n\n```\nOSP_LOG_XXX(category, fmt, ...)\n     |\n     v  编译期级别过滤 (OSP_LOG_MIN_LEVEL)\nAsyncLogWrite(level, ...)\n     |\n     +-- level >= ERROR?  ----yes----> fprintf(stderr) [同步, crash-safe]\n     |                                 FATAL: fprintf + fflush + abort()\n     +-- AcquireLogBuffer()\n     |     +-- thread_local 快路径 (~1ns, 已注册)\n     |     +-- CAS 首次注册 (仅一次)\n     |     +-- slot 全满? -> sync fallback\n     |\n     +-- vsnprintf(entry.message, 256, fmt, args)  [~100-200ns]\n     |\n     +-- buf->queue.Push(entry)  [wait-free SPSC, ~10-20ns]\n           +-- 队列满? -> entries_dropped++ [不阻塞]\n```\n\n设计原则:\n- **ERROR/FATAL**: 同步写 `fprintf(stderr)` + `fflush`，保证崩溃前输出完整\n- **DEBUG/INFO/WARN**: 异步写，不阻塞业务线程\n- **队列满**: 丢弃非关键日志（计数上报），不阻塞生产者\n\n## 6. 背压丢弃与主动上报\n\n队列满时丢弃日志是正确的嵌入式策略: 业务线程的实时性优先于日志完整性。但丢弃不应是\"静默\"的:\n\n### 6.1 定时上报\n\n后台写线程每 N 秒检查一次丢弃计数，有新增丢弃时输出到 stderr:\n\n```\n[AsyncLog] WARN: 42 entries dropped in last 10s (total: written=10000 dropped=42 fallbacks=0)\n```\n\n### 6.2 Shutdown 最终上报\n\n写线程退出前，上报自上次定时上报以来的剩余丢弃:\n\n```\n[AsyncLog] WARN: 3 entries dropped since last report (total: written=10342 dropped=45 fallbacks=0)\n```\n\n### 6.3 运行时统计查询\n\n暴露 `GetAsyncStats()` API，可集成到 Shell 诊断命令:\n\n```\nnewosp> osp_log_stats\nAsyncLog: written=10342 dropped=17 fallbacks=0 enabled=true\n```\n\n## 7. 核心数据结构\n\n### 7.1 LogEntry (320B, trivially copyable)\n\n```cpp\nstruct LogEntry {\n  uint64_t timestamp_ns;    //  8B  CLOCK_MONOTONIC\n  uint32_t wallclock_sec;   //  4B  挂钟秒\n  uint16_t wallclock_ms;    //  2B  挂钟毫秒\n  Level    level;           //  1B  日志级别\n  uint8_t  padding0;        //  1B  对齐\n  char     category[16];    // 16B  分类\n  char     message[256];    //256B  格式化消息\n  char     file[24];        // 24B  源文件名\n  uint32_t line;            //  4B  行号\n  uint32_t thread_id;       //  4B  线程 ID\n};                          // 合计 320B = 5 cache lines\n```\n\n设计要点:\n- **trivially_copyable**: SPSC 使用 memcpy 批处理路径，单条 copy ~10ns (L1 命中)\n- **固定大小**: 避免动态分配，支持数组连续存储\n- **调用线程格式化**: `va_list` 参数生命周期限于当前栈帧，不能跨线程传递\n\n### 7.2 线程注册 (CAS 首次, thread_local 后续)\n\n```cpp\ninline LogBuffer* AcquireLogBuffer() noexcept {\n  static thread_local TlsCleanup tls_cleanup;\n  if (tls_cleanup.buf != nullptr) {\n    return tls_cleanup.buf;  // 快路径: ~1ns\n  }\n  // 首次调用: CAS 遍历 slot 数组 (仅一次)\n  for (uint32_t i = 0; i < MAX_THREADS; ++i) {\n    bool expected = false;\n    if (buffers[i].active.compare_exchange_strong(expected, true)) {\n      tls_cleanup.buf = &buffers[i];\n      return tls_cleanup.buf;\n    }\n  }\n  return nullptr;  // 所有 slot 已满: fallback 同步\n}\n```\n\n线程退出时，`~TlsCleanup()` 自动释放 slot (`active = false`)，可被新线程复用。\n\n## 8. 生命周期: 自动管理\n\n异步日志作为基础设施，用户不应关心后台线程的启停:\n\n- **自动启动**: 首次 `AsyncLogWrite()` 调用时，CAS 原子自启动写线程\n- **自动停止**: `atexit(StopAsync)` 注册，进程退出前自动 drain 所有缓冲\n- **强制同步**: 编译期定义 `OSP_LOG_SYNC_ONLY` 禁用异步路径\n\n```cpp\n// 用户代码: 无需 Start/Stop\n#include \"osp/async_log.hpp\"\n\nint main() {\n    OSP_LOG_INFO(\"Main\", \"system started\");  // 首次调用自动启动\n    // ...\n    return 0;  // atexit 自动 drain\n}\n```\n\n## 9. C++14 生产级实现\n\n以下是核心写入函数的完整实现:\n\n```cpp\ninline void AsyncLogWrite(Level level, const char* category,\n                          const char* file, int line,\n                          const char* fmt, ...) noexcept {\n  // 1. 运行时级别过滤\n  if (static_cast<uint8_t>(level) < static_cast<uint8_t>(LogLevelRef()))\n    return;\n\n  // 2. ERROR/FATAL: 同步写 (crash-safe)\n  if (static_cast<uint8_t>(level) >= static_cast<uint8_t>(Level::kError)) {\n    va_list args;\n    va_start(args, fmt);\n    LogWriteVa(level, category, file, line, fmt, args);\n    va_end(args);\n    return;\n  }\n\n  auto& ctx = AsyncLogContext::Instance();\n\n  // 3. 自动启动 (首次调用)\n  if (!ctx.running.load(std::memory_order_acquire)) {\n    StartAsync();\n  }\n\n  // 4. 获取 per-thread SPSC buffer\n  LogBuffer* buf = AcquireLogBuffer();\n  if (buf == nullptr) {\n    ctx.sync_fallbacks.fetch_add(1, std::memory_order_relaxed);\n    va_list args;\n    va_start(args, fmt);\n    LogWriteVa(level, category, file, line, fmt, args);\n    va_end(args);\n    return;\n  }\n\n  // 5. 在调用线程栈上构建 LogEntry\n  LogEntry entry;\n  entry.timestamp_ns = SteadyNowNs();\n  CaptureWallclock(entry.wallclock_sec, entry.wallclock_ms);\n  entry.level = level;\n  entry.thread_id = buf->thread_id;\n  entry.line = static_cast<uint32_t>(line);\n  SafeStrCopy(entry.category, sizeof(entry.category), category);\n  SafeStrCopy(entry.file, sizeof(entry.file), Basename(file));\n\n  va_list args;\n  va_start(args, fmt);\n  vsnprintf(entry.message, sizeof(entry.message), fmt, args);\n  va_end(args);\n\n  // 6. Wait-free SPSC Push\n  if (!buf->queue.Push(entry)) {\n    ctx.entries_dropped.fetch_add(1, std::memory_order_relaxed);\n  }\n}\n```\n\n后台写线程:\n\n```cpp\ninline void WriterLoop() noexcept {\n  LogBackoff backoff;\n  LogEntry batch[32];\n\n  while (!ctx.shutdown.load(std::memory_order_acquire)) {\n    uint32_t total = 0;\n    // Round-robin 轮询所有活跃 buffer\n    for (uint32_t i = 0; i < MAX_THREADS; ++i) {\n      if (!buffers[i].active.load(std::memory_order_acquire)\n          && buffers[i].queue.IsEmpty()) continue;\n\n      size_t n = buffers[i].queue.PopBatch(batch, 32);\n      if (n > 0) {\n        sink(batch, n, sink_ctx);  // 批量写入 sink\n        entries_written.fetch_add(n, std::memory_order_relaxed);\n        total += n;\n      }\n    }\n\n    total > 0 ? backoff.Reset() : backoff.Wait();\n\n    // 定时丢弃上报 (每 10s)\n    PeriodicDropReport();\n  }\n\n  // Shutdown: 多轮 drain 确保不丢\n  for (int round = 0; round < 10; ++round) {\n    uint32_t drained = DrainAll();\n    if (drained == 0) break;\n  }\n  FinalDropReport();\n}\n```\n\n## 10. 编译期配置\n\n| 宏 | 默认值 | 说明 |\n|----|--------|------|\n| `OSP_ASYNC_LOG_QUEUE_DEPTH` | 256 | 每线程 SPSC 深度 |\n| `OSP_ASYNC_LOG_MAX_THREADS` | 8 | 最大并发日志线程数 |\n| `OSP_ASYNC_LOG_DROP_REPORT_INTERVAL_S` | 10 | 丢弃上报间隔 (秒, 0=禁用) |\n| `OSP_LOG_MIN_LEVEL` | 0 (Debug) / 1 (Release) | 编译期最低日志级别 |\n| `OSP_LOG_SYNC_ONLY` | 未定义 | 定义后禁用异步路径 |\n\n## 11. 资源预算\n\n| 资源 | 数值 | 说明 |\n|------|------|------|\n| SPSC 缓冲 (per-thread) | 80KB | 256 x 320B |\n| 总 SPSC 缓冲 | 640KB | 8 threads x 80KB |\n| 后台写线程 | +1 | 低优先级 |\n| 热路径延迟 | ~200-300ns | vs 同步 ~1-3us |\n\n## 12. 性能分析\n\n### 12.1 延迟分解\n\n| 步骤 | 延迟 | 说明 |\n|------|------|------|\n| 编译期过滤 | 0ns | 宏展开为空 |\n| 运行时级别过滤 | ~5ns | 原子 load + 比较 |\n| thread_local 快路径 | ~1ns | 已注册线程 |\n| vsnprintf 格式化 | ~100-200ns | 256B 缓冲，调用线程 |\n| SPSC Push | ~10-20ns | wait-free，memcpy |\n| **异步热路径总计** | **~200-300ns** | **vs 同步 ~1-3us** |\n\n### 12.2 与 MPSC 方案对比\n\n| 指标 | MPSC (CAS) | Per-Thread SPSC |\n|------|-----------|-----------------|\n| P99 延迟 | ~100-500ns (CAS 竞争) | **~300ns (确定性)** |\n| 吞吐量上限 | 受 CAS 竞争限制 | **受 vsnprintf 限制** |\n| 额外原子操作 | 2 (CAS tail + committed) | **0 (wait-free)** |\n| 内存开销 | 低 (1 buffer) | 中等 (8 buffers, 编译期可控) |\n\n### 12.3 批量写入优化\n\n消费者使用 `PopBatch(batch, 32)` 一次取出最多 32 条 entry，然后统一调用 sink。在 ARM Linux 中，减少系统调用次数是关键优化:\n\n- **单条 dprintf**: 每条日志一次 `write` 系统调用 (~2-5us)\n- **批量 32 条**: 累积后一次 `write`，均摊系统调用开销至 ~60-150ns/条\n\n## 13. 工程实践建议\n\n### 13.1 存储介质保护\n\nFlash 存储有擦写寿命限制。异步日志应配合:\n- 文件滚动 (Log Rotation): 限制单文件最大容量\n- `O_APPEND` 模式: 保证顺序写入\n- 写入频率控制: 避免 Flash 过早磨损\n\n### 13.2 Sink 可替换设计\n\n使用函数指针 + context 而非虚函数，实现零开销的 sink 替换:\n\n```cpp\nusing LogSinkFn = void (*)(const LogEntry* entries, uint32_t count, void* ctx);\n```\n\n内置 `StderrSink` (默认)，可替换为文件 sink、网络 sink、或自定义处理。\n\n### 13.3 测试验证\n\n生产级异步日志必须通过:\n- **ASan (AddressSanitizer)**: 检测内存越界、use-after-free\n- **TSan (ThreadSanitizer)**: 检测数据竞争\n- **UBSan (UndefinedBehaviorSanitizer)**: 检测未定义行为\n- **Release + Debug 双构建**: 确保优化级别不影响正确性\n- **-fno-exceptions 构建**: 嵌入式场景兼容\n\n## 14. 结论\n\n本文提出的 Per-Thread SPSC 异步日志架构，相比传统 MPSC 方案，在嵌入式 ARM Linux 平台上具备以下优势:\n\n1. **wait-free 热路径**: 生产者零竞争，延迟确定性强，适合实时系统\n2. **分级路由**: ERROR/FATAL 崩溃安全，非关键日志异步不阻塞\n3. **背压可观测**: 丢弃计数 + 定时上报 + Shell 查询，运维可感知\n4. **零配置**: 自动启动/停止，用户无感知\n5. **编译期可控**: 队列深度、线程数、上报间隔均为宏配置\n\n该方案已在 [newosp](https://github.com/DeguiLiu/newosp) 框架 v0.3.2 中落地，通过 1078 个单元测试 (ASan + UBSan + TSan 全绿)，适用于激光雷达、机器人、边缘计算等工业嵌入式场景。\n",
      "ctime": "1771552578",
      "mtime": "1771552578",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/lockfree_programming_fundamentals.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469636654",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "无锁编程核心原理: 从 CAS 原子操作到三种队列设计模式",
      "brief_content": "无锁编程的基础性原理文章。从 CAS 原子操作的硬件实现出发，严格定义 lock-free 与 wait-free 的进展保证差异，深入分析 ABA 问题及其解决方案，阐明 acquire-relea",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [内存屏障的硬件原理: 从 Store Buffer 到 ARM DMB/DSB/ISB](../memory_barrier_hardware/) -- 内存序的硬件根因 (Store Buffer/Invalidation Queue/MESI)\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- Wait-free SPSC 的逐行代码分析\n> - [无锁异步日志设计](../lockfree_async_log/) -- Per-Thread SPSC 在日志系统中的应用\n> - [嵌入式系统死锁防御: 从有序锁到无锁架构](../deadlock_prevention/) -- newosp 的无锁 MPSC 总线架构\n> - [嵌入式线程间消息传递重构: MCCC 无锁消息总线](../mccc_message_passing/) -- MPSC 消息总线的完整工程实现\n> - [锁竞争基准测试: Spinlock vs Mutex vs ConcurrentQueue](../lock_contention_benchmark/) -- 有锁与无锁的性能实测\n> - [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/) -- 何时需要从有锁迁移到无锁\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- 跨进程场景的无锁 Ring Buffer\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- 无锁 MPSC 总线在完整框架中的集成\n>\n> 参考:\n> - [iceoryx Lock-Free Queue Design](https://github.com/eclipse-iceoryx/iceoryx/blob/main/doc/design/lockfree_queue.md)\n> - [Herb Sutter: Lock-Free Programming](https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/)\n> - [Jeff Preshing: An Introduction to Lock-Free Programming](https://preshing.com/20120612/an-introduction-to-lock-free-programming/)\n\n---\n\n## 1. 从锁到无锁: 何时值得\n\n锁（mutex）是多线程编程最直觉的同步工具，但它有两个根本性开销:\n\n1. **系统调用**: Linux 的 `pthread_mutex_lock` 在竞争时进入内核 futex，两次用户态/内核态切换 + 上下文切换，延迟 1-100+ us\n2. **序列化**: 锁保护的临界区同一时刻只有一个线程执行，并行度为 1\n\n> 这两个开销可以用 `perf lock contention` 量化。详见 [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/)。\n\n无锁编程的目标不是消灭所有同步，而是**用原子操作替代锁，让多个线程能同时推进**。但无锁不是银弹 -- 它增加了代码复杂度，且只在特定数据结构（队列、栈、计数器）上有成熟方案。\n\n**决策原则**: 不要在没有数据支撑的情况下追求无锁。先用 `perf lock` 量化锁竞争，确认它确实是瓶颈，再考虑无锁替代。\n\n---\n\n## 2. CAS: 无锁编程的原子基石\n\n### 2.1 CAS 操作原理\n\nCAS（Compare-And-Swap）是一条硬件原子指令，伪代码如下:\n\n```\nbool CAS(addr, expected, desired):\n    atomically {\n        if (*addr == expected):\n            *addr = desired\n            return true\n        else:\n            expected = *addr  // 更新 expected 为当前值\n            return false\n    }\n```\n\n整个「比较 + 交换」操作在硬件层面是**不可分割的**。没有任何线程能在比较和交换之间看到中间状态。\n\n### 2.2 硬件实现\n\n不同架构的 CAS 实现差异显著:\n\n| 架构 | 指令 | 机制 |\n|------|------|------|\n| x86/x64 | `CMPXCHG` | 单条指令，总线锁或缓存锁 |\n| ARMv8 (AArch64) | `LDXR` + `STXR` (LL/SC) | 独占加载 + 独占存储，通过独占监视器 |\n| ARMv8.1+ | `CAS` / `CASP` | 原生 CAS 指令（LSE 扩展） |\n\nARM 的 LL/SC（Load-Linked / Store-Conditional）与 x86 的 CMPXCHG 有本质区别:\n\n```mermaid\ngraph LR\n    subgraph \"x86: CMPXCHG\"\n        A1[\"比较 + 交换<br/>一条指令完成\"] --> B1[\"成功/失败\"]\n    end\n\n    subgraph \"ARM: LL/SC\"\n        A2[\"LDXR: 独占加载<br/>设置本核独占监视器\"] --> B2[\"计算新值\"]\n        B2 --> C2[\"STXR: 条件存储<br/>检查独占监视器\"]\n        C2 -->|\"监视器有效<br/>无其他核写入\"| D2[\"成功\"]\n        C2 -->|\"监视器被清除<br/>其他核有写入\"| E2[\"失败, 重试\"]\n    end\n\n    style D2 fill:#c8e6c9\n    style E2 fill:#ffcdd2\n```\n\nARM 的 STXR 可能因为**任何原因**失败（不仅是目标地址被修改，甚至中断、缓存行被驱逐也可能清除独占监视器）。这是 `compare_exchange_weak` 允许「伪失败」（spurious failure）的硬件原因。\n\n### 2.3 weak vs strong\n\nC++ 提供两个 CAS 变体:\n\n```cpp\n// weak: 可能伪失败（ARM LL/SC 的特性），但开销更低\nbool compare_exchange_weak(T& expected, T desired, ...);\n\n// strong: 不会伪失败，但在 ARM 上内部包含重试循环\nbool compare_exchange_strong(T& expected, T desired, ...);\n```\n\n**选择原则**:\n\n| 场景 | 选择 | 原因 |\n|------|------|------|\n| 已在循环中使用 | `weak` | 循环本身会重试，伪失败的代价只是多一次迭代 |\n| 单次判断（非循环） | `strong` | 伪失败会导致逻辑错误 |\n\n典型的 CAS 循环（无锁计数器）:\n\n```cpp\n// 原子递增: lock-free\nvoid increment(std::atomic<int>& counter) {\n    int old = counter.load(std::memory_order_relaxed);\n    while (!counter.compare_exchange_weak(\n               old, old + 1,\n               std::memory_order_relaxed,\n               std::memory_order_relaxed)) {\n        // CAS 失败: old 已被自动更新为当前值，直接重试\n    }\n}\n```\n\n这段代码永远不会阻塞另一个线程。如果 CAS 失败，说明另一个线程成功了 -- 系统整体有进展。\n\n---\n\n## 3. 进展保证: Lock-Free vs Wait-Free\n\n### 3.1 严格定义\n\n这两个术语常被混淆。严格定义如下:\n\n| 属性 | 保证 | 含义 |\n|------|------|------|\n| **Wait-free** | 每个线程在**有限步**内完成操作 | 最强。无论其他线程如何运行，当前线程都能在 O(1) 或 O(n) 步内完成 |\n| **Lock-free** | **至少一个**线程在有限步内完成操作 | 系统整体有进展，但单个线程可能被**饿死** |\n| **Obstruction-free** | 在**无竞争**时线程能在有限步内完成 | 最弱。一旦竞争，可能无限等待 |\n\n```mermaid\ngraph TD\n    A[并发数据结构] --> B{是否使用锁?}\n    B -->|是| C[阻塞: Mutex / Spinlock]\n    B -->|否| D{单个线程<br/>是否可能饿死?}\n    D -->|可能| E[Lock-free<br/>CAS 重试循环<br/>MPMC 队列]\n    D -->|不可能| F[Wait-free<br/>无循环/重试<br/>SPSC 队列]\n\n    style C fill:#ffcdd2\n    style E fill:#fff9c4\n    style F fill:#c8e6c9\n```\n\n### 3.2 SPSC 是 Wait-Free\n\n单生产者单消费者（SPSC）队列的 Push 操作:\n\n```cpp\nbool Push(T data) {\n    IndexT head = head_.load(relaxed);       // 1. 读自己的索引\n    IndexT tail = tail_.load(acquire);       // 2. 读对方的索引\n    if ((head - tail) == BufferSize)         // 3. 满检查\n        return false;\n    data_buff_[head & kMask] = data;         // 4. 写数据\n    head_.store(head + 1, release);          // 5. 发布\n    return true;\n}\n```\n\n**没有任何循环或重试**。每次调用恒定 5 步完成。无论消费者如何运行，生产者都能在有限步内返回。这就是 wait-free。\n\n> SPSC 的完整设计剖析见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/)。\n\n### 3.3 MPMC CAS 队列是 Lock-Free\n\n多生产者多消费者（MPMC）队列的入队操作:\n\n```cpp\nbool Enqueue(const T& data) {\n    uint32_t head = head_.load(std::memory_order_relaxed);\n    while (true) {                           // CAS 重试循环\n        uint32_t tail = tail_.load(std::memory_order_acquire);\n        if ((head - tail) >= capacity_)\n            return false;\n        if (head_.compare_exchange_weak(     // CAS 竞争\n                head, head + 1,\n                std::memory_order_acq_rel,\n                std::memory_order_relaxed)) {\n            queue_[head & mask_] = data;\n            return true;\n        }\n        // CAS 失败: 其他生产者抢先，head 已更新，再试\n    }\n}\n```\n\n`while (true)` 循环是 lock-free 的特征。CAS 失败意味着另一个生产者成功了（系统有进展），但当前线程可能多次重试。在极端情况下（4+ 生产者），某些线程可能自旋数十次。\n\n### 3.4 自旋锁不是无锁\n\n一个常见的误区是将 `std::atomic_flag` 自旋锁称为\"无锁\":\n\n```cpp\nclass Spinlock {\n    std::atomic_flag flag_ = ATOMIC_FLAG_INIT;\npublic:\n    void lock() {\n        while (flag_.test_and_set(std::memory_order_acquire))\n            ; // 自旋等待\n    }\n    void unlock() {\n        flag_.clear(std::memory_order_release);\n    }\n};\n```\n\n虽然没有使用 OS mutex，但自旋锁本质上是**互斥的** -- 同一时刻只有一个线程能进入临界区。持有锁的线程被调度走后，等待线程无限自旋，系统没有进展。这不满足 lock-free 的定义。\n\n> 自旋锁、互斥锁与无锁队列的性能对比，见 [锁竞争基准测试](../lock_contention_benchmark/)。结论: 无锁队列在 MPMC 场景下吞吐量领先 1-2 个数量级。\n\n---\n\n## 4. ABA 问题\n\n### 4.1 什么是 ABA\n\nABA 是 CAS 操作特有的正确性问题。考虑一个无锁栈的 pop 操作:\n\n```\n初始状态: top -> A -> B -> C\n\nThread 1: 读到 top = A, next = B\n          (准备 CAS: top A -> B)\n          -- 被抢占 --\n\nThread 2: pop A  -> top = B\n          pop B  -> top = C\n          push A -> top = A -> C\n\nThread 1: 恢复执行\n          CAS(top, A, B) -- 成功! (top 确实是 A)\n          但 B 已经被释放了!\n```\n\n```mermaid\nsequenceDiagram\n    participant T1 as Thread 1\n    participant Stack as 无锁栈\n    participant T2 as Thread 2\n\n    Note over Stack: top -> A -> B -> C\n    T1->>Stack: 读 top=A, next=B\n    Note over T1: 准备 CAS(top, A, B)\n    Note over T1: -- 被抢占 --\n\n    T2->>Stack: pop A (top=B)\n    T2->>Stack: pop B (top=C)\n    T2->>Stack: push A (top=A->C)\n    Note over Stack: top -> A -> C<br/>B 已释放!\n\n    T1->>Stack: CAS(top, A, B) 成功!\n    Note over Stack: top = B (悬挂指针!)\n    Note over T1: B 已被释放,<br/>使用它是未定义行为\n```\n\nCAS 只比较**值**是否相等，无法判断值是否在中间被改变过又改回来。\n\n### 4.2 解决方案: 版本号标记\n\n为每个指针或索引附加一个单调递增的**版本号（tag）**:\n\n```cpp\nstruct TaggedPointer {\n    Node* ptr;\n    uint64_t tag;  // 每次修改 +1\n};\n\n// CAS 同时比较 ptr 和 tag\nstd::atomic<TaggedPointer> top;\n```\n\n即使 ptr 回到原值，tag 已经不同，CAS 会正确失败。\n\n在 64 位系统上，可以利用**指针高位未使用**的特性（x86-64 的虚拟地址只用 48 位），将 tag 打包到高 16 位:\n\n```cpp\n// 打包方案: 高 16 位存 tag，低 48 位存地址\nuintptr_t pack(void* ptr, uint16_t tag) {\n    return (static_cast<uintptr_t>(tag) << 48) |\n           (reinterpret_cast<uintptr_t>(ptr) & 0x0000FFFFFFFFFFFF);\n}\n```\n\n### 4.3 iceoryx 的周期索引设计\n\niceoryx 的无锁队列采用了一种优雅的 ABA 防护: **周期索引（Cyclic Index）**。\n\n索引 `j` 表示为 `(cycle, index)` 对:\n- `index = j % n` -- 数组中的实际位置\n- `cycle = j / n` -- 第几轮\n\n```\n容量 n = 4 时:\nj = 0  -> (cycle=0, index=0)\nj = 1  -> (cycle=0, index=1)\nj = 4  -> (cycle=1, index=0)  // 第二轮\nj = 8  -> (cycle=2, index=0)  // 第三轮\n```\n\n**head 和 tail 是单调递增的无符号整数，不做回绕**。推送使 tail 增加 1，弹出使 head 增加 1。只在访问数组时用 `& (n-1)` 映射到实际位置。\n\n每个数组元素也存储一个 cycle 值。推送时，只有当元素的 cycle 恰好比 tail 的 cycle 小 1 时才进行写入:\n\n```cpp\n// 伪代码: iceoryx 索引队列 push\nbool push(uint64_t value) {\n    uint64_t tail = tail_.load(relaxed);\n    uint64_t cycle = tail / n;\n    uint64_t index = tail % n;\n\n    // 检查槽位是否空闲 (cycle 差 1)\n    if (slots[index].cycle != cycle - 1)\n        return false;  // 队列满\n\n    if (tail_.CAS(tail, tail + 1)) {  // CAS 推进 tail\n        slots[index].value = value;\n        slots[index].cycle = cycle;    // 更新槽位 cycle\n        return true;\n    }\n    return false;  // CAS 失败, 重试\n}\n```\n\n由于 head 和 tail 严格单调递增，要发生 ABA，需要完整的 `uint64_t` 溢出回绕 -- 即 2^64 次操作。以每秒 10 亿次操作计算，需要约 584 年。实际上不可能发生。\n\n### 4.4 SPSC 不存在 ABA\n\nSPSC 队列中，`head` 只有一个写者（生产者），`tail` 只有一个写者（消费者）。**不存在写-写竞争**，因此不使用 CAS，自然没有 ABA 问题。这是 SPSC 比 MPMC 简单得多的根本原因之一。\n\n---\n\n## 5. 内存序: 无锁编程的正确性基础\n\n### 5.1 为什么 relaxed 不够\n\n考虑一个简单的生产者-消费者通信:\n\n```cpp\nint data = 0;\nstd::atomic<bool> ready{false};\n\n// 生产者\nvoid producer() {\n    data = 42;                                        // 写数据\n    ready.store(true, std::memory_order_relaxed);     // 通知\n}\n\n// 消费者\nvoid consumer() {\n    while (!ready.load(std::memory_order_relaxed));   // 等待通知\n    assert(data == 42);  // 在 ARM 上可能失败!\n}\n```\n\n在 x86（TSO 模型）上，这段代码碰巧正确 -- 硬件保证 store-store 有序。但在 ARM（弱序模型）上，CPU 可能将 `data = 42` 重排到 `ready = true` 之后，消费者看到 `ready == true` 但 `data` 还是 0。重排序的硬件根因是 Store Buffer 和 Invalidation Queue，详见 [内存屏障的硬件原理](../memory_barrier_hardware/)。\n\n### 5.2 acquire-release 配对\n\n修复方案: 使用 `release` 写和 `acquire` 读:\n\n```cpp\n// 生产者: release 保证 data 写入在 ready 之前\nready.store(true, std::memory_order_release);\n\n// 消费者: acquire 保证 data 读取在 ready 之后\nwhile (!ready.load(std::memory_order_acquire));\n```\n\n`release-acquire` 配对的语义:\n\n```\n生产者:                          消费者:\n  所有之前的写入                    acquire load ready\n  ────────────────                ────────────────\n  release store ready    ──同步──>  所有之后的读取\n                                   看到生产者 release\n                                   之前的全部写入\n```\n\n这是无锁编程中最核心的同步原语。SPSC 队列的正确性完全建立在这个语义之上:\n- 生产者写数据后 `release store head` -> 消费者 `acquire load head` 后读数据\n- 消费者读数据后 `release store tail` -> 生产者 `acquire load tail` 后检查空间\n\n### 5.3 ARM vs x86 差异\n\n| 内存序 | x86 (TSO) | ARM (弱序) | 开销差异 |\n|--------|-----------|-----------|---------|\n| `relaxed` | 普通 load/store | 普通 load/store | 无 |\n| `acquire` | 无额外开销 (TSO 保证) | `LDAR` 或 `DMB ISHLD` | ARM 多 10-40 周期 |\n| `release` | 无额外开销 (TSO 保证) | `STLR` 或 `DMB ISH` | ARM 多 10-40 周期 |\n| `seq_cst` | `MFENCE` 全屏障 | `DMB ISH` + load/store + `DMB ISH` | 两者都有开销 |\n\nx86 硬件天然保证了大多数排序，所以在 x86 上用 `relaxed` 的代码\"碰巧正确\"。但移植到 ARM 后会出 bug。**正确的做法是始终使用恰当的内存序**，让编译器在 x86 上自动省略不必要的屏障。\n\n### 5.4 精确内存序选择原则\n\n| 操作 | 内存序 | 原因 |\n|------|--------|------|\n| 读自己写的变量 | `relaxed` | 只有自己写，无需跨线程同步 |\n| 读对方写的变量 | `acquire` | 需要看到对方的 release 之前的所有写入 |\n| 写后让对方可见 | `release` | 保证之前的数据写入不会被重排到此之后 |\n| 不确定时 | `seq_cst` | 安全但代价高；确认正确后再降级优化 |\n\n> 每种内存序在 ARM 上的具体指令映射和代价分析，见 [SPSC 无锁环形缓冲区设计剖析 -- 第 6 节](../spsc_ringbuffer_design/)。四种屏障类型 (StoreStore/LoadLoad/LoadStore/StoreLoad) 和 ARM DMB/DSB/ISB 的精确语义，见 [内存屏障的硬件原理](../memory_barrier_hardware/)。\n\n---\n\n## 6. 三种无锁队列设计模式\n\n### 6.1 设计谱系总览\n\n```mermaid\ngraph TD\n    A[无锁队列] --> B[SPSC<br/>单生产者单消费者]\n    A --> C[MPSC<br/>多生产者单消费者]\n    A --> D[MPMC<br/>多生产者多消费者]\n\n    B --- B1[\"进展保证: Wait-free<br/>原子操作: load + store<br/>竞争: 零<br/>延迟: ~10-20 ns\"]\n    C --- C1[\"进展保证: Lock-free<br/>原子操作: CAS (生产端)<br/>竞争: 生产者间<br/>延迟: ~30-100 ns\"]\n    D --- D1[\"进展保证: Lock-free<br/>原子操作: CAS (双端)<br/>竞争: 全方位<br/>延迟: ~50-500 ns\"]\n\n    style B fill:#c8e6c9\n    style C fill:#fff9c4\n    style D fill:#ffcdd2\n```\n\n### 6.2 SPSC: Wait-Free, 零竞争\n\n**适用场景**: 严格的一对一通道 -- ISR 到处理线程、日志生产者到写盘线程、传感器采集到融合线程。\n\n**核心设计**:\n\n```\nProducer Thread                    Consumer Thread\n    |                                  |\n    | load head_ (relaxed)             | load tail_ (relaxed)\n    | load tail_ (acquire)             | load head_ (acquire)\n    | write data_buff_[head & mask]    | read data_buff_[tail & mask]\n    | store head_+1 (release)          | store tail_+1 (release)\n```\n\n**为什么 wait-free**: `head_` 只有生产者写，`tail_` 只有消费者写。两个线程各操作各的索引，无写-写竞争，无需 CAS，无需重试循环。\n\n**关键工程决策**:\n\n| 决策 | 原因 |\n|------|------|\n| 缓存行对齐 (`alignas(64)`) | head 和 tail 独占缓存行，消除 false sharing |\n| 2 的幂 + 位掩码 | `& (size-1)` 替代取模，ARM 单周期 |\n| 索引不回绕 | 无符号溢出是 well-defined，省一次取模 |\n| memcpy 批量操作 | 摊薄 acquire/release 屏障开销 |\n| FakeTSO 单核模式 | 单核 MCU 用 relaxed 替代硬件屏障 |\n\n> 完整的逐行分析见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/)。\n> 在异步日志中的实际应用见 [无锁异步日志设计](../lockfree_async_log/)。\n\n### 6.3 MPSC: 单消费者简化\n\n**适用场景**: 多个线程向同一个队列发送消息，一个专用线程消费 -- 消息总线、事件分发器、日志聚合。\n\n**核心设计**: 生产者之间通过 CAS 竞争 `tail`（写入端），消费者独占 `head`（读取端）。\n\n```cpp\n// MPSC 入队: CAS 竞争写入端\nbool Publish(T payload) {\n    uint32_t pos;\n    Slot* target;\n    do {\n        pos = producer_pos_.load(std::memory_order_relaxed);\n        target = &ring_buffer_[pos & kBufferMask];\n\n        uint32_t seq = target->sequence.load(std::memory_order_acquire);\n        if (seq != pos)\n            return false;  // 缓冲区满\n    } while (!producer_pos_.compare_exchange_weak(\n        pos, pos + 1,\n        std::memory_order_acq_rel,\n        std::memory_order_relaxed));\n\n    target->payload = std::move(payload);\n    target->sequence.store(pos + 1, std::memory_order_release);\n    return true;\n}\n\n// MPSC 消费: 单线程，无 CAS\nuint32_t ProcessBatch() {\n    uint32_t count = 0;\n    while (count < kBatchSize) {\n        Slot& slot = ring_buffer_[consumer_pos_ & kBufferMask];\n        uint32_t seq = slot.sequence.load(std::memory_order_acquire);\n        if (seq != consumer_pos_ + 1)\n            break;  // 没有新数据\n\n        dispatch(slot.payload);\n        slot.sequence.store(consumer_pos_ + kBufferSize,\n                           std::memory_order_release);\n        ++consumer_pos_;\n        ++count;\n    }\n    return count;\n}\n```\n\n**关键差异**: 消费者不用 CAS -- 它是唯一的读者，`consumer_pos_` 是普通变量（非原子）。这比 MPMC 少了一半的 CAS 操作。\n\n**每个 Slot 的 sequence 字段**用于协调生产者和消费者:\n\n```\nsequence == pos     : 槽空闲，生产者可写入\nsequence == pos + 1 : 数据就绪，消费者可读取\nsequence == pos + N : 消费者已释放，下一轮可用\n```\n\n> newosp 的 AsyncBus 就是这种模式。架构解析见 [嵌入式系统死锁防御](../deadlock_prevention/)。\n> 完整工程实现见 [MCCC 无锁消息总线](../mccc_message_passing/)。\n\n### 6.4 MPMC: 完全通用, 双端 CAS\n\n**适用场景**: 多个生产者和多个消费者都需要并发访问同一个队列 -- 线程池任务队列、通用工作分发。\n\nMPMC 队列是最复杂的无锁数据结构之一。一种经典的实现方案（iceoryx 采用）是**索引队列 + 数据缓冲区分离**:\n\n```\n+---------------------------+\n| 空闲索引队列 (freeList)    |  <- 存储可用的槽位编号\n+---------------------------+\n| 已用索引队列 (usedList)    |  <- 存储有数据的槽位编号\n+---------------------------+\n| 数据缓冲区 buffer[N]      |  <- 存储实际数据\n+---------------------------+\n```\n\n**Push 流程**:\n\n```\n1. 从 freeList 弹出一个空闲索引 i    (CAS pop)\n2. 将数据写入 buffer[i]\n3. 将 i 推入 usedList               (CAS push)\n```\n\n**Pop 流程**:\n\n```\n1. 从 usedList 弹出一个已用索引 i    (CAS pop)\n2. 从 buffer[i] 读取数据\n3. 将 i 推回 freeList               (CAS push)\n```\n\n这种设计的优点:\n- **数据不移动**: push/pop 只传递索引，数据始终在 buffer 原地，适合大对象\n- **ABA 安全**: 索引队列使用周期索引，单调递增消除 ABA 风险\n- **lock-free**: 生产者和消费者各自独立推进，互不阻塞\n\n缺点:\n- 每次操作涉及**两次 CAS**（一次索引弹出 + 一次索引推入）\n- 内存访问不连续（索引队列 + 数据缓冲区分散在不同缓存行）\n\n### 6.5 三种模式对比\n\n| 维度 | SPSC | MPSC | MPMC |\n|------|------|------|------|\n| 进展保证 | **Wait-free** | Lock-free | Lock-free |\n| 生产端操作 | load + store | **CAS 循环** | **CAS 循环** |\n| 消费端操作 | load + store | load + store | **CAS 循环** |\n| CAS 次数 / 操作 | 0 | 1 | 2 |\n| 缓存行为 | head/tail 各一核 | tail 多核乒乓 | head+tail 多核乒乓 |\n| ABA 风险 | 无 | 生产端 | 双端 |\n| 适用线程模型 | 1:1 | N:1 | N:M |\n| 典型延迟 | ~10-20 ns | ~30-100 ns | ~50-500 ns |\n\n### 6.6 选型决策\n\n```mermaid\ngraph TD\n    A[需要无锁队列] --> B{生产者数量?}\n    B -->|1 个| C{消费者数量?}\n    B -->|多个| D{消费者数量?}\n\n    C -->|1 个| E[\"SPSC<br/>(Wait-free, 最优)\"]\n    C -->|多个| F[\"不推荐<br/>考虑 N 个 SPSC\"]\n\n    D -->|1 个| G[\"MPSC<br/>(单消费者简化)\"]\n    D -->|多个| H{能否改为<br/>MPSC + 分发?}\n\n    H -->|能| I[\"MPSC + round-robin<br/>分发到 N 个 SPSC\"]\n    H -->|不能| J[\"MPMC<br/>(最复杂, 最后选择)\"]\n\n    style E fill:#c8e6c9\n    style G fill:#fff9c4\n    style I fill:#c8e6c9\n    style J fill:#ffcdd2\n```\n\n**核心原则**: 能用 SPSC 就不用 MPSC，能用 MPSC 就不用 MPMC。每多一端 CAS 竞争，延迟和复杂度都显著增加。\n\nnewosp 的架构正是这个原则的实践: MPSC 总线接收所有消息，Dispatcher 线程 round-robin 分发到每个 Worker 的独立 SPSC 队列。热路径上只有 SPSC（wait-free），MPSC 的 CAS 竞争限制在入口处。\n\n---\n\n## 7. 工程实践清单\n\n### 7.1 消除 false sharing\n\n两个线程频繁写入同一缓存行的不同变量，会触发 MESI 协议的缓存行乒乓:\n\n```cpp\n// 错误: head_ 和 tail_ 可能在同一缓存行\nstruct BadQueue {\n    std::atomic<uint32_t> head_;  // 生产者写\n    std::atomic<uint32_t> tail_;  // 消费者写\n};\n\n// 正确: 各占独立缓存行\nstruct GoodQueue {\n    alignas(64) std::atomic<uint32_t> head_;  // Cache Line 0\n    alignas(64) std::atomic<uint32_t> tail_;  // Cache Line 1\n};\n```\n\nARM Cortex-A 系列缓存行通常为 64 字节。false sharing 导致的 L1 miss 延迟约 40-80 周期，而 L1 hit 仅需 2-4 周期。\n\n### 7.2 2 的幂位掩码\n\n```cpp\nstatic constexpr uint32_t kMask = BufferSize - 1;\n\n// 位与: ARM 单周期\nuint32_t index = head & kMask;\n\n// 取模: ARM 4-12 周期 (无硬件除法或延迟高)\nuint32_t index = head % BufferSize;\n```\n\n编译期约束:\n\n```cpp\nstatic_assert((BufferSize & (BufferSize - 1)) == 0,\n              \"Buffer size must be a power of 2.\");\n```\n\n### 7.3 批量操作摊薄屏障开销\n\n单元素操作每次都需要一个 acquire load + 一个 release store。批量操作将 N 个元素包裹在一对 acquire/release 之间:\n\n```cpp\n// 单元素: N 次 acquire + N 次 release\nfor (int i = 0; i < N; ++i) {\n    queue.Push(data[i]);  // 每次: acquire load tail + release store head\n}\n\n// 批量: 1 次 acquire + 1 次 release\nsize_t written = queue.PushBatch(data, N);\n// 内部: 一次 acquire load tail -> N 次 memcpy -> 一次 release store head\n```\n\n在 ARM 上，每个 DMB 屏障约 10-40 周期。1000 个元素批量操作比逐个操作节省 ~999 个 acquire 和 ~999 个 release 屏障。\n\n### 7.4 trivially_copyable 约束\n\n批量 memcpy 路径要求数据类型是 `trivially_copyable`:\n\n```cpp\nstatic_assert(std::is_trivially_copyable<T>::value,\n              \"Type T must be trivially copyable for memcpy.\");\n```\n\n如果 T 有自定义拷贝构造函数、析构函数或虚函数表，memcpy 会绕过这些逻辑。热路径上的数据类型应该是 POD-like 的。\n\n### 7.5 非阻塞返回\n\n无锁队列的 Push/Pop 在队列满/空时应立即返回 `false`，而非阻塞等待:\n\n```cpp\nif (queue_full)\n    return false;  // 非阻塞: 调用者决定如何处理\n```\n\n阻塞等待违反了无锁的进展保证。如果生产者在队列满时 spin-wait 消费者释放空间，就退化成了互斥等待。正确的做法是:\n- **背压丢弃**: 丢弃低优先级消息，计数上报\n- **回退策略**: 超时后走同步 fallback 路径\n- **准入控制**: 按优先级设定不同的丢弃阈值\n\n---\n\n## 8. 验证与调试\n\n无锁代码的正确性验证比有锁代码困难得多。编译通过、测试通过不代表没有数据竞争。\n\n### 8.1 ThreadSanitizer (TSan)\n\n```bash\ng++ -fsanitize=thread -g -O1 -o test test.cpp -lpthread\n./test\n```\n\nTSan 能检测到:\n- 非原子变量的数据竞争\n- 原子操作的内存序过弱\n- lock/unlock 的顺序违规\n\n### 8.2 关键检查项\n\n| 检查项 | 常见错误 |\n|--------|----------|\n| 所有共享变量是否为 `std::atomic` | 非原子读写是数据竞争（UB） |\n| CAS 循环中 expected 是否正确更新 | `compare_exchange_weak` 失败时会自动更新 expected |\n| release 之前的写入是否完整 | 数据写入必须在 release store 之前 |\n| acquire 之后才读取数据 | 读数据必须在 acquire load 之后 |\n| 队列满/空的边界条件 | 差一错误（off-by-one）是最常见的 bug |\n| 无符号溢出的正确处理 | `head - tail` 在溢出后仍需正确 |\n\n---\n\n## 9. 总结\n\n无锁编程的知识体系可以沿一条主线展开:\n\n```\nCAS 原子操作 (硬件基础)\n    |\n    v\n进展保证层级 (wait-free > lock-free > 阻塞)\n    |\n    v\nABA 问题 (CAS 的正确性陷阱)\n    |\n    v\n内存序 (acquire-release: 跨线程可见性保证)\n    |\n    v\n队列设计模式 (SPSC -> MPSC -> MPMC: 复杂度递增)\n    |\n    v\n工程实践 (缓存行对齐、批量操作、非阻塞返回)\n```\n\n**核心原则**:\n\n1. **数据驱动**: 先量化锁竞争（perf lock），确认是瓶颈再迁移到无锁\n2. **最简适配**: 能 SPSC 不 MPSC，能 MPSC 不 MPMC\n3. **精确内存序**: 不用 seq_cst 求安全，也不用 relaxed 求性能，用恰当的 acquire/release\n4. **硬件意识**: 理解 CAS 在 ARM LL/SC 上的伪失败、DMB 屏障的代价、缓存行的粒度\n\n无锁不是\"高级版的有锁\"，而是一种完全不同的并发思维方式: **不阻止其他线程执行，而是让每个线程在竞争中自适应地完成自己的操作**。\n",
      "ctime": "1771552581",
      "mtime": "1771552581",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/mccc_lockfree_mpsc_design.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469653038",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "Lock-free MPSC 消息总线的设计与实现: 从 Ring Buffer 到零堆分配",
      "brief_content": "在嵌入式系统中，消息总线是组件间通信的核心基础设施。本文剖析 MCCC 消息总线的设计决策与工程权衡：为什么选择 Lock-free MPSC 而非互斥锁？Envelope 内嵌如何消除热路径堆分配？",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 问题: 嵌入式系统需要什么样的消息总线\n\n在工业嵌入式系统 (激光雷达、机器人控制、边缘计算) 中，组件间通信面临一组相互矛盾的约束：\n\n- **确定性延迟**: 电机控制回路要求微秒级响应，不允许偶发的毫秒级抖动。\n- **零动态分配**: 热路径上的 `malloc`/`new` 会引入不可预测的延迟，且在某些 MCU 平台上根本不可用。\n- **多生产者安全**: 多个传感器线程同时发布数据，总线必须保证线程安全。\n- **优先级区分**: 紧急停止指令不能因日志消息占满队列而被丢弃。\n- **可裁剪**: 同一套代码需要运行在 64 核 Linux 服务器和单核 Cortex-M MCU 上。\n\n传统方案要么用 `std::mutex` 加锁 (延迟不确定)，要么用 `std::function` + `std::unordered_map` 做回调管理 (堆分配不可控)。MCCC (Message-Centric Component Communication) 的设计目标，就是在不引入任何外部依赖的前提下，用纯 C++17 同时满足上述所有约束。\n\n本文将从核心设计决策出发，剖析 MCCC 消息总线的架构与工程权衡。这些设计后来被 [newosp](https://github.com/DeguiLiu/newosp) 框架采纳，在更大规模的工业系统中得到验证。\n\n## 架构总览\n\nMCCC 的核心是一条 **Lock-free MPSC (Multi-Producer, Single-Consumer) Ring Buffer**，所有设计决策围绕它展开：\n\n```mermaid\nflowchart TB\n    subgraph Producers[多生产者 - Lock-free]\n        P1[Producer 1]\n        P2[Producer 2]\n        P3[Producer 3]\n    end\n\n    subgraph AsyncBus[\"AsyncBus&lt;PayloadVariant&gt;\"]\n        subgraph AdmissionControl[准入控制]\n            HC{HIGH<br/>99%}\n            MC{MEDIUM<br/>80%}\n            LC{LOW<br/>60%}\n        end\n        subgraph RingBuffer[Lock-free Ring Buffer]\n            RB[(128K Slots<br/>Envelope 内嵌<br/>Sequence Sync)]\n        end\n        Stats[Statistics]\n    end\n\n    subgraph Consumer[单消费者 - Batch]\n        C1[Batch Processor]\n    end\n\n    P1 --> HC\n    P2 --> MC\n    P3 --> LC\n    HC --> RB\n    MC --> RB\n    LC --> RB\n    RB --> C1\n    RB --> Stats\n```\n\n用户通过 `std::variant` 定义自己的消息载荷类型，AsyncBus 以此为模板参数实例化。这个设计使得消息类型在编译期完全确定，为后续的零堆分配和编译期分发奠定基础。\n\n```cpp\nstruct SensorData { float temp; };\nstruct MotorCmd   { int speed; };\nusing MyPayload = std::variant<SensorData, MotorCmd>;\nusing MyBus = mccc::AsyncBus<MyPayload>;\n```\n\n## 决策一: Lock-free MPSC vs 互斥锁\n\n### 为什么不用 mutex\n\n`std::mutex` 的问题不在于\"慢\"，而在于**不可预测**。在 Linux SCHED_OTHER 调度下，持有锁的线程可能被抢占，导致其他生产者等待不确定时长。对于需要确定性延迟的实时系统，这是不可接受的。\n\nLock-free 的保证是：即使某个线程被挂起，其他线程仍能继续推进。代价是实现复杂度显著增加。\n\n### Sequence-based Ring Buffer\n\nMCCC 的 Ring Buffer 借鉴了 Disruptor 的序列号同步机制。每个槽位内嵌一个原子序列号，生产者和消费者通过序列号协调，无需额外的锁：\n\n```mermaid\nflowchart LR\n    subgraph Producer[Producer]\n        P1[1. Load prod_pos]\n        P2[2. Check seq == prod_pos]\n        P3[3. CAS prod_pos++]\n        P4[4. Write envelope in-place]\n        P5[5. seq = prod_pos + 1]\n    end\n\n    subgraph Consumer[Consumer]\n        C1[1. Load cons_pos]\n        C2[2. Check seq == cons_pos + 1]\n        C3[3. Read envelope]\n        C4[4. seq = cons_pos + SIZE]\n        C5[5. cons_pos++]\n    end\n\n    P1 --> P2 --> P3 --> P4 --> P5\n    C1 --> C2 --> C3 --> C4 --> C5\n```\n\n生产者用 `compare_exchange_weak` (CAS) 竞争槽位，写入后将序列号推进到 `pos + 1`，通知消费者数据就绪。消费者读取后将序列号推进到 `pos + SIZE`，表示槽位可被复用。\n\n关键权衡：CAS 在高竞争下会退化 (自旋重试)，但 MPSC 场景下消费者只有一个，竞争仅存在于生产者之间，实际冲突率远低于 MPMC。\n\n## 决策二: Envelope 内嵌 -- 零堆分配的核心\n\n这是 MCCC 最重要的设计决策。\n\n传统消息队列将消息指针存入队列，消息本体在堆上分配。每条消息至少一次 `new` + 一次 `delete`，在高吞吐场景下 (数十 M/s)，内存分配器成为瓶颈。\n\nMCCC 的做法是将 `MessageEnvelope<PayloadVariant>` 直接内嵌到 Ring Buffer 的槽位中：\n\n```cpp\nstruct MCCC_ALIGN_CACHELINE RingBufferNode {\n    std::atomic<uint32_t> sequence{0U};\n    MessageEnvelope<PayloadVariant> envelope;  // 直接内嵌，非指针\n};\n```\n\n这意味着：消息数据直接写入预分配的环形缓冲区，发布路径上**零堆分配**。代价是 Ring Buffer 的内存占用等于 `槽位数 x envelope 大小`，需要在启动时一次性分配。对于嵌入式系统，这恰好是期望的行为 -- 资源在初始化时确定，运行时不再变化。\n\nEnvelope 内嵌还带来一个隐含收益：数据局部性。连续处理的消息在内存中物理相邻，对 CPU Cache 友好。\n\n## 决策三: 编译期类型索引替代 unordered_map\n\n消息总线需要根据消息类型分发到对应的回调函数。常见做法是 `std::unordered_map<std::type_index, std::vector<callback>>`，但这引入了两个问题：哈希表查找的不确定延迟，以及 `std::vector` 的动态分配。\n\nMCCC 利用 `std::variant` 的编译期特性，用模板元编程计算类型索引：\n\n```cpp\n// 编译期计算: VariantIndex<SensorData, MyPayload>::value == 0\n//             VariantIndex<MotorCmd, MyPayload>::value == 1\ntemplate <typename T, typename Variant>\nstruct VariantIndex;\n\n// 固定回调表 (栈上分配)\nstd::array<CallbackSlot, MCCC_MAX_MESSAGE_TYPES> callback_table_;\n```\n\n类型到索引的映射在编译期完成，运行时的分发退化为一次数组下标访问 -- O(1) 且完全确定。\n\n## 决策四: FixedFunction 替代 std::function\n\n`std::function` 的 Small Buffer Optimization (SBO) 阈值通常只有 16 字节 (libstdc++)。一旦 lambda 捕获超过这个大小 (例如捕获一个 `this` 指针加几个成员)，就会触发堆分配。更糟糕的是，这个行为在不同标准库实现中不一致。\n\nMCCC 实现了 `FixedFunction<Sig, Capacity>`，将 SBO 容量提升到 64 字节，并用 `static_assert` 在编译期拒绝超容量的 callable：\n\n| 特性 | `std::function` | `FixedFunction<Sig, 64>` |\n|------|:---:|:---:|\n| 堆分配 | 可能 (>16B) | **永不** |\n| 超容量行为 | 运行时 malloc | **编译期报错** |\n| 异常路径 | 有 (bad_function_call) | **无** |\n| 虚函数表 | 有 | **函数指针 Ops 表** |\n\n内部使用函数指针三元组 (destroy/move/invoke) 替代虚基类，消除了 vtable 间接寻址的开销。在 `-fno-rtti -fno-exceptions` 环境下，这套方案比 `std::function` 更轻量，且行为完全可预测。\n\n## 决策五: 优先级准入控制\n\n嵌入式系统中，并非所有消息同等重要。当队列接近满载时，日志消息应该首先被丢弃，而紧急停止指令必须尽可能送达。\n\nMCCC 采用**容量预留策略**，为不同优先级设定准入阈值：\n\n```mermaid\nflowchart LR\n    subgraph Queue[队列容量]\n        L[0-60%<br/>全部接受]\n        M[60-80%<br/>丢弃 LOW]\n        H[80-99%<br/>丢弃 LOW+MEDIUM]\n        F[99-100%<br/>全部丢弃]\n    end\n    L --> M --> H --> F\n```\n\n| 队列深度 | LOW | MEDIUM | HIGH |\n|----------|-----|--------|------|\n| 0-60% | Accept | Accept | Accept |\n| 60-80% | Drop | Accept | Accept |\n| 80-99% | Drop | Drop | Accept |\n| 99-100% | Drop | Drop | Drop |\n\n阈值的选取是一个工程判断：HIGH 预留 99% 容量意味着只有在队列几乎完全满载时才可能丢失；LOW 仅使用前 60% 容量，在系统压力上升时率先被牺牲。这个策略保证了关键消息在极端负载下的可达性，同时避免了复杂的优先级队列数据结构。\n\n准入检查本身引入约 3-5 ns 的开销。为了降低这个开销，MCCC 使用了**索引缓存**：生产者侧缓存消费者位置，仅当缓存估算超过阈值时才跨核读取真实的 `consumer_pos_`，减少了 cache line bouncing。\n\n## 决策六: SPSC Wait-free 快速路径\n\n当系统确认只有一个生产者时 (通过编译宏 `MCCC_SINGLE_PRODUCER=1`)，CAS 循环是多余的。MCCC 在编译期切换到 wait-free 路径：\n\n```cpp\n// MPSC: CAS 循环竞争槽位\ndo {\n    prod_pos = producer_pos_.load(std::memory_order_relaxed);\n    // ... 序列号检查 ...\n} while (!producer_pos_.compare_exchange_weak(prod_pos, prod_pos + 1U, ...));\n\n// SPSC: wait-free，无 CAS\nprod_pos = producer_pos_.load(std::memory_order_relaxed);\n// ... 序列号检查 ...\nproducer_pos_.store(prod_pos + 1U, std::memory_order_relaxed);\n```\n\nSPSC 路径将 `compare_exchange_weak` 替换为普通的 `store`，完全消除了 CAS 的自旋重试开销。实测 SPSC BARE_METAL 吞吐量比 MPSC 高约 31%。\n\n## 决策七: ProcessBatchWith -- 编译期 Visitor 分发\n\nMCCC 的常规处理路径 (`ProcessBatch`) 通过 `shared_mutex` 读锁保护回调表，再通过 `FixedFunction` 间接调用回调。这条路径功能完备但存在两层间接调用开销。\n\n对于性能敏感的场景，`ProcessBatchWith<Visitor>` 提供了一条零间接调用路径：绕过回调表和锁，直接使用 `std::visit` 将消息分发到用户提供的 visitor，编译器可以将整条路径内联：\n\n```cpp\nclass MySensor : public StaticComponent<MySensor, MyPayload> {\npublic:\n    void Handle(const SensorData& d) noexcept { /* ... */ }\n    void Handle(const MotorCmd& c) noexcept { /* ... */ }\n    // 未定义 Handle 的类型在编译期静默忽略 (SFINAE)\n};\n\nMySensor sensor;\nauto visitor = sensor.MakeVisitor();\nbus.ProcessBatchWith(visitor);  // 全路径可内联\n```\n\n这是\"为不需要的功能不付费\"原则的体现：如果你不需要运行时动态订阅/退订，就不应该为 `shared_mutex` 和间接调用付出代价。\n\n## 决策八: Signal Fence -- 单核 MCU 适配\n\n在多核系统上，`memory_order_acquire/release` 会编译为硬件内存屏障指令 (ARM 的 DMB)。但在单核 Cortex-M MCU 上，核间可见性问题不存在，真正需要防止的只是**编译器重排序**。\n\nMCCC 通过 `MCCC_SINGLE_CORE=1` 切换到 relaxed ordering + `atomic_signal_fence`：\n\n```cpp\n#if MCCC_SINGLE_CORE\n#define MCCC_MO_ACQUIRE  std::memory_order_relaxed\n#define MCCC_MO_RELEASE  std::memory_order_relaxed\ninline void AcquireFence() {\n    std::atomic_signal_fence(std::memory_order_acquire);  // 编译器屏障，零硬件开销\n}\n#endif\n```\n\n`atomic_signal_fence` 仅约束编译器，不生成任何硬件指令。在单核 MCU 上，这将原子操作的开销降到接近零。\n\n此选项需要用户同时定义 `MCCC_I_KNOW_SINGLE_CORE_IS_UNSAFE=1` 作为安全确认 -- 因为如果在多核平台上误用，将导致数据竞争。这是一个显式的\"你知道你在做什么\"接口设计。\n\n## 决策九: 编译期配置矩阵\n\n同一套代码需要适配从 64 核服务器到单核 MCU 的不同硬件。MCCC 通过编译宏构建配置矩阵：\n\n| 宏 | 默认值 | 嵌入式建议 | 影响 |\n|----|--------|-----------|------|\n| `MCCC_QUEUE_DEPTH` | 131072 (128K) | 1024 / 4096 | 内存占用 |\n| `MCCC_CACHELINE_SIZE` | 64 | 32 / 0 | 对齐填充 |\n| `MCCC_SINGLE_PRODUCER` | 0 | 1 | CAS vs wait-free |\n| `MCCC_SINGLE_CORE` | 0 | 1 | DMB vs signal fence |\n| `MCCC_MAX_MESSAGE_TYPES` | 8 | 按需 | 回调表大小 |\n| `MCCC_MAX_CALLBACKS_PER_TYPE` | 16 | 按需 | 每类型回调数 |\n\n所有配置在编译期确定，运行时零开销。例如在 Cortex-M4 上，一个典型的裁剪配置为：\n\n```bash\ncmake .. -DCMAKE_CXX_FLAGS=\"-DMCCC_QUEUE_DEPTH=4096 -DMCCC_SINGLE_PRODUCER=1 \\\n  -DMCCC_SINGLE_CORE=1 -DMCCC_I_KNOW_SINGLE_CORE_IS_UNSAFE=1 \\\n  -DMCCC_CACHELINE_SIZE=0\"\n```\n\n队列从 128K 缩小到 4K，关闭 CAS 和硬件屏障，去除缓存行填充 -- 在资源受限的 MCU 上最大限度降低内存占用和指令开销。\n\n## 批处理: 减少共享状态更新\n\n消费者的 `ProcessBatch` 是另一个值得关注的优化点。朴素实现中，每处理一条消息就更新一次 `consumer_pos_` 和统计计数器，导致频繁的原子写入。\n\nMCCC 将更新推迟到批次结束：\n\n```cpp\nuint32_t ProcessBatch() noexcept {\n    uint32_t cons_pos = consumer_pos_.load(std::memory_order_relaxed);\n    uint32_t processed = 0U;\n    for (uint32_t i = 0U; i < BATCH_PROCESS_SIZE; ++i) {\n        if (!ProcessOneInBatch(cons_pos, bare_metal)) break;\n        ++cons_pos; ++processed;\n    }\n    // 循环结束后一次性更新\n    consumer_pos_.store(cons_pos, std::memory_order_relaxed);\n    stats_.messages_processed.fetch_add(processed, std::memory_order_relaxed);\n}\n```\n\n一个批次 (默认 1024 条) 只产生两次原子写入，而非 1024 次。这在多核系统上显著减少了 store buffer 压力。\n\n## 性能实测\n\n> 测试环境: Ubuntu 24.04, GCC 13.3, -O3 -march=native, Intel Xeon Cascadelake 64 vCPU.\n> SP = `MCCC_SINGLE_PRODUCER`, SC = `MCCC_SINGLE_CORE`.\n\n### 入队吞吐量\n\n| 配置 | SP | SC | FULL_FEATURED | BARE_METAL | 功能开销 |\n|------|:--:|:--:|:---:|:---:|:---:|\n| **MPSC (默认)** | 0 | 0 | 27.7 M/s (36 ns) | 33.0 M/s (30 ns) | 5.8 ns |\n| **SPSC** | 1 | 0 | 30.3 M/s (33 ns) | 43.2 M/s (23 ns) | 9.8 ns |\n| **MPSC + 单核** | 0 | 1 | 29.2 M/s (34 ns) | 38.2 M/s (26 ns) | 8.1 ns |\n| **SPSC + 单核** | 1 | 1 | 29.4 M/s (34 ns) | 39.9 M/s (25 ns) | 8.9 ns |\n\nFULL_FEATURED 模式包含优先级准入、背压监控和统计计数，是生产环境的默认模式。BARE_METAL 模式剥离所有非核心功能，用于衡量纯队列性能基线。\n\n两点值得注意：SPSC 比 MPSC 快约 31% (CAS 消除)；SINGLE_CORE 比多核快约 15% (relaxed ordering 减少了 store buffer 序列化)。而 FULL_FEATURED 各配置趋于接近 (~28-30 M/s)，说明 `shared_mutex` 读锁成为该模式下的主要瓶颈。\n\n### 端到端延迟 (FULL_FEATURED)\n\n| 配置 | P50 | P95 | P99 | Max |\n|------|-----|-----|-----|-----|\n| MPSC | 585 ns | 783 ns | 933 ns | 18 us |\n| SPSC | 680 ns | 892 ns | 1063 ns | 13 us |\n| MPSC + 单核 | **310 ns** | **389 ns** | **442 ns** | 17 us |\n| SPSC + 单核 | 625 ns | 878 ns | 1011 ns | 18 us |\n\nMPSC + 单核配置的 P50 仅 310 ns，是默认配置的 53%。在 ARM Cortex-M 上，省去 DMB 硬件屏障的收益会更加显著。\n\n### 背压准入控制\n\n| 优先级 | 发送 | 丢弃率 |\n|--------|------|--------|\n| HIGH | 30,000 | **0.0%** |\n| MEDIUM | 39,321 | 12.6% |\n| LOW | 39,320 | 47.6% |\n\nHIGH 优先级消息在压力测试中实现了零丢弃，验证了容量预留策略的有效性。\n\n### 功能开销分解\n\n| 开销项 | 每消息开销 |\n|--------|-----------|\n| 优先级检查 (含索引缓存) | ~3-5 ns |\n| shared_mutex 读锁 | ~3-5 ns |\n| 统计计数 (批量) | ~1-2 ns |\n| **总功能开销** | ~6-10 ns |\n\n全功能模式的总开销约 6-10 ns/消息。对于大多数嵌入式应用，这个开销是完全可接受的 -- 一个 1 kHz 控制回路的周期为 1 ms，消息传递仅占千分之一。\n\n## 总结与反思\n\n回顾 MCCC 的设计，几个核心权衡贯穿始终：\n\n**编译期确定 vs 运行时灵活**。从 `std::variant` 载荷类型、`FixedFunction` 容量、到 SPSC/单核模式，MCCC 大量使用编译期决策替代运行时分支。这牺牲了一定的灵活性 (例如不能在运行时改变队列深度)，但换来了可预测的性能和零运行时开销。\n\n**内存预分配 vs 按需分配**。Envelope 内嵌意味着启动时一次性分配全部 Ring Buffer 内存。在资源受限的 MCU 上，这可能是一个问题 (128K 槽位 x 消息大小)，因此提供了 `MCCC_QUEUE_DEPTH` 宏允许缩小队列。\n\n**功能完备 vs 极致性能**。FULL_FEATURED 和 BARE_METAL 两种模式，以及 `ProcessBatch` 和 `ProcessBatchWith` 两条处理路径，让用户在功能和性能之间做出显式选择，而非用一个\"一刀切\"的方案。\n\n这些设计决策不是在真空中做出的。它们源自嵌入式系统开发中反复遇到的实际问题：不可预测的锁等待、不受控的堆分配、跨平台移植时的性能陷阱。MCCC 的架构思想后来被 [newosp](https://github.com/DeguiLiu/newosp) 框架在更广泛的场景中采纳和演化，包括 Lock-free MPSC Bus、FixedFunction SBO 回调、编译期配置矩阵等核心机制，在近千个测试用例下通过了 ASan/UBSan/TSan 验证。\n\n> 参考: [mccc-bus](https://gitee.com/liudegui/mccc-bus)\n",
      "ctime": "1771552585",
      "mtime": "1771552585",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/mccc_message_passing.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038486566",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式线程间消息传递重构: 用 MCCC 无锁消息总线替代 mutex + priority_queue",
      "brief_content": "本文基于一个实际的线程间消息传递需求（Windows 风格的 SendMessage/PostMessage），分析传统 mutex + priority_queue + promise/future",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [Linux 实现一个简单的 SendMessage 和 PostMessage](https://blog.csdn.net/stallion5632/article/details/144097813)\n>\n> 相关文章:\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- MCCC 的 C++17 演进: newosp AsyncBus\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- MPSC 无锁队列的理论基础\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- 底层环形缓冲区的设计详解\n>\n> 配套代码: [mccc-message-cpp](https://gitee.com/liudegui/mccc-message-cpp) -- C++17 实现，8 个 Catch2 测试，ASan+UBSan clean\n>\n> 依赖库: [mccc-bus](https://gitee.com/liudegui/mccc-bus) -- 无锁 MPSC 消息总线，171 个单元测试\n\n## 1. 问题回顾：为什么需要 SendMessage / PostMessage\n\n在嵌入式 Linux 系统和工业控制软件中，线程间消息传递是最基本的协作机制。Windows 提供了两个经典 API：\n\n- **SendMessage**：同步消息。调用线程阻塞，直到目标线程处理完消息并返回结果。\n- **PostMessage**：异步消息。消息入队后调用线程立即返回，不等待处理结果。\n\n在 Linux 上没有原生对应物，需要自行实现。原文给出了一个基于 `std::mutex` + `std::priority_queue` + `std::promise/future` 的方案。\n\n## 2. 原始方案分析\n\n原文的核心数据结构：\n\n```cpp\nstruct Message {\n    int msg_id;\n    int w_param;\n    int l_param;\n    std::shared_ptr<std::promise<int>> promise_ptr;  // 同步返回值\n    MessageType type;  // kSync / kAsync\n\n    // 优先级排序：同步消息优先\n    bool operator<(const Message& other) const {\n        return type > other.type;\n    }\n};\n\nclass MessageQueue {\n    std::priority_queue<Message> queue_;\n    std::mutex mtx_;\n    std::condition_variable cv_;\n    bool terminate_flag_ = false;\n};\n```\n\n消息处理线程的运行方式：\n\n```cpp\nvoid MessageHandler() {\n    while (true) {\n        Message msg = g_message_queue.Dequeue();  // 阻塞等待\n        int result = msg.w_param + msg.l_param;   // 处理\n        if (msg.promise_ptr) {\n            msg.promise_ptr->set_value(result);    // 同步返回\n        }\n    }\n}\n```\n\n### 2.1 问题诊断\n\n这个方案在功能上是正确的，但在以下维度存在工程问题：\n\n| 维度 | 问题 | 影响 |\n|------|------|------|\n| 锁竞争 | 每次 Enqueue/Dequeue 都加 `std::mutex` | 多生产者场景下吞吐量受限于锁粒度 |\n| 堆分配 | 每个同步消息创建 `std::shared_ptr<std::promise<int>>` | 热路径堆分配，延迟不可预测；嵌入式系统 heap 碎片化 |\n| 优先级 | `std::priority_queue` 的 O(log n) 插入 | 队列深时开销增加；且只有\"同步优先\"一种策略 |\n| 背压 | 无队列深度限制 | 生产者速率 > 消费者速率时，内存无限增长 |\n| 类型安全 | `int msg_id` + `int w_param` | 编译期无法检查消息类型匹配 |\n| 全局单例 | `MessageQueue g_message_queue` | 无法隔离多个消息域 |\n\n### 2.2 锁竞争的具体表现\n\n当 4 个生产者线程同时向队列 `Enqueue` 消息时，`std::mutex` 导致序列化：\n\n```\nThread 0: [lock] [push] [unlock] ----wait---- [lock] ...\nThread 1: ----wait---- [lock] [push] [unlock] ----wait----\nThread 2: ----wait----wait---- [lock] [push] [unlock] ...\nThread 3: ----wait----wait----wait---- [lock] [push] ...\n```\n\n锁持有时间虽短（push 操作本身很快），但锁的获取和释放涉及系统调用（futex），上下文切换开销在高频场景下成为瓶颈。\n\n### 2.3 堆分配的具体开销\n\n```cpp\nauto promise_ptr = std::make_shared<std::promise<int>>();\n```\n\n这一行代码的实际开销：\n\n1. `std::make_shared` 调用 `operator new`（一次堆分配，约 50-200 ns）\n2. 构造 `shared_ptr` 控制块（引用计数、weak 计数、deleter）\n3. 构造 `std::promise`（内部包含 shared state、mutex、condition variable）\n4. 析构时再次调用 `operator delete`\n\n在嵌入式系统中，`malloc/free` 的延迟不确定性是实时性的天敌。\n\n## 3. MCCC 消息总线\n\n[MCCC](https://gitee.com/liudegui/mccc-bus)（Message-Centric Component Communication）是一个 header-only 的 C++17 无锁消息总线，专为嵌入式系统设计。\n\n### 3.1 架构要点\n\n```\nProducer 0 ──┐\nProducer 1 ──┤  lock-free CAS\nProducer 2 ──┤  enqueue\nProducer N ──┘\n              ↓\n+-----------------------------------------------+\n|        MPSC Ring Buffer (pre-allocated)        |\n|  [seq|envelope] [seq|envelope] ... [seq|env]   |\n|  cache-line aligned, power-of-2 size           |\n+-----------------------------------------------+\n              ↓\n         Consumer Thread\n         ProcessBatch()\n              ↓\n     variant dispatch → callbacks\n```\n\n关键特性：\n\n| 特性 | 说明 |\n|------|------|\n| 无锁 MPSC | 多生产者通过 CAS 原子操作入队，无 mutex |\n| 零堆分配 | 消息内嵌在预分配的 Ring Buffer 中，热路径无 malloc |\n| 优先级准入 | 3 级：LOW（60% 丢弃）、MEDIUM（80% 丢弃）、HIGH（99% 才丢弃） |\n| 类型安全 | `std::variant` 编译期类型检查 |\n| 批处理消费 | `ProcessBatch()` 一次最多处理 1024 条消息 |\n\n### 3.2 为什么 MCCC 适合替代原始方案\n\n| 原始方案 | MCCC 对应 |\n|----------|-----------|\n| `std::mutex` 保护队列 | CAS-based lock-free ring buffer |\n| `std::priority_queue` 排序 | 准入控制（HIGH 优先级 ≈ 零丢弃保证） |\n| `std::shared_ptr<promise>` 同步返回 | 预分配 `ResponseSlot` 池 |\n| `int msg_id` 手动分发 | `std::variant` + `Subscribe<T>` 类型分发 |\n| 无背压控制 | 3 级优先级准入阈值 |\n\n## 4. 方案重构\n\n### 4.1 消息类型定义\n\n```cpp\n// 异步消息 (PostMessage)\nstruct AsyncMessage {\n    uint32_t msg_id;\n    int32_t w_param;\n    int32_t l_param;\n};\n\n// 同步请求 (SendMessage) -- 携带响应槽索引\nstruct SyncRequest {\n    uint32_t msg_id;\n    int32_t w_param;\n    int32_t l_param;\n    uint32_t reply_slot;  // 预分配响应槽的索引\n};\n\nusing MsgPayload = std::variant<AsyncMessage, SyncRequest>;\nusing MsgBus = mccc::AsyncBus<MsgPayload>;\n```\n\n两种消息类型通过 `std::variant` 区分，编译期确定类型索引，分发无需运行时 switch。\n\n### 4.2 ResponsePool -- 零堆分配的同步响应机制\n\nMCCC 是纯异步总线（fire-and-forget），不提供内建的请求-应答模式。为实现 `SendMessage` 的同步语义，需要一个响应通道。\n\n传统方案使用 `std::promise/std::future`，每次调用产生堆分配。重构方案使用**预分配的响应槽池**：\n\n```cpp\n// 单个响应槽：缓存行对齐，防止 false sharing\nstruct alignas(64) ResponseSlot {\n    static constexpr uint32_t kEmpty = 0U;\n    static constexpr uint32_t kPending = 1U;\n    static constexpr uint32_t kReady = 2U;\n\n    std::atomic<uint32_t> state{kEmpty};\n    int32_t result{0};\n};\n```\n\n状态转换流程：\n\n```\nkEmpty ──(Acquire)──> kPending ──(SetResult)──> kReady ──(WaitResult)──> kEmpty\n  ^                                                                        |\n  └────────────────────────────────────────────────────────────────────────┘\n```\n\n响应槽池的完整实现：\n\n```cpp\ntemplate <uint32_t MaxSlots = 64U>\nclass ResponsePool {\n public:\n    // 获取一个空闲槽（生产者线程调用）\n    uint32_t Acquire() noexcept {\n        uint32_t idx =\n            next_.fetch_add(1U, std::memory_order_relaxed) & (MaxSlots - 1U);\n\n        uint32_t expected = ResponseSlot::kEmpty;\n        while (!slots_[idx].state.compare_exchange_weak(\n            expected, ResponseSlot::kPending,\n            std::memory_order_acquire, std::memory_order_relaxed)) {\n            expected = ResponseSlot::kEmpty;\n            std::this_thread::yield();\n        }\n        return idx;\n    }\n\n    // 写入结果并标记完成（消费者线程调用）\n    void SetResult(uint32_t idx, int32_t result) noexcept {\n        slots_[idx].result = result;\n        slots_[idx].state.store(ResponseSlot::kReady,\n                                std::memory_order_release);\n    }\n\n    // 等待结果并释放槽（生产者线程调用）\n    int32_t WaitResult(uint32_t idx) noexcept {\n        while (slots_[idx].state.load(std::memory_order_acquire)\n               != ResponseSlot::kReady) {\n            std::this_thread::yield();\n        }\n        int32_t result = slots_[idx].result;\n        slots_[idx].state.store(ResponseSlot::kEmpty,\n                                std::memory_order_release);\n        return result;\n    }\n\n private:\n    ResponseSlot slots_[MaxSlots]{};\n    std::atomic<uint32_t> next_{0U};\n};\n```\n\n关键设计决策：\n\n| 决策 | 原因 |\n|------|------|\n| 固定大小数组 | 零堆分配，编译期确定内存占用 |\n| `alignas(64)` 缓存行对齐 | 不同槽位于不同缓存行，消除 false sharing |\n| Round-robin 分配 | `fetch_add` 无锁递增，取模用位与（2 的幂） |\n| CAS 获取空闲槽 | 多生产者竞争同一槽时自旋等待，无需全局锁 |\n| `yield()` 而非 busy-wait | 让出 CPU 时间片，避免浪费 CPU 资源 |\n\n### 4.3 PostMessage 实现\n\n```cpp\nbool PostMessage(uint32_t msg_id, int32_t w_param,\n                 int32_t l_param) noexcept {\n    AsyncMessage msg{msg_id, w_param, l_param};\n    return MsgBus::Instance().PublishWithPriority(\n        std::move(msg), sender_id_, mccc::MessagePriority::MEDIUM);\n}\n```\n\n直接映射到 MCCC 的 `Publish`：消息通过 CAS 操作入队到预分配的 Ring Buffer，零堆分配，返回值表示是否入队成功（背压控制）。\n\n### 4.4 SendMessage 实现\n\n```cpp\nint32_t SendMessage(uint32_t msg_id, int32_t w_param,\n                    int32_t l_param) noexcept {\n    // 1. 获取预分配的响应槽\n    uint32_t slot = response_pool_.Acquire();\n\n    // 2. 发布同步请求（HIGH 优先级 -> 99% 队列深度才丢弃）\n    SyncRequest req{msg_id, w_param, l_param, slot};\n    MsgBus::Instance().PublishWithPriority(\n        std::move(req), sender_id_, mccc::MessagePriority::HIGH);\n\n    // 3. 阻塞等待消费者写入结果\n    return response_pool_.WaitResult(slot);\n}\n```\n\n对比原始方案的 `SendMessage`：\n\n```cpp\n// 原始方案 -- 每次堆分配\nint SendMessage(int msg_id, int w_param, int l_param) {\n    auto promise_ptr = std::make_shared<std::promise<int>>();  // 堆分配\n    std::future<int> fut = promise_ptr->get_future();\n    // ... enqueue ...\n    return fut.get();  // 阻塞\n}\n\n// MCCC 方案 -- 零堆分配\nint32_t SendMessage(uint32_t msg_id, int32_t w_param,\n                    int32_t l_param) noexcept {\n    uint32_t slot = response_pool_.Acquire();  // 预分配槽\n    // ... publish ...\n    return response_pool_.WaitResult(slot);    // 原子等待\n}\n```\n\n### 4.5 消费者端处理\n\n```cpp\nvoid RegisterHandler(MessageHandlerFn handler) noexcept {\n    handler_ = handler;\n\n    // 订阅异步消息\n    MsgBus::Instance().Subscribe<AsyncMessage>(\n        [this](const MsgEnvelope& env) {\n            const auto* msg = std::get_if<AsyncMessage>(&env.payload);\n            if (msg != nullptr && handler_ != nullptr) {\n                handler_(msg->msg_id, msg->w_param, msg->l_param);\n            }\n        });\n\n    // 订阅同步请求（处理后写回响应槽）\n    MsgBus::Instance().Subscribe<SyncRequest>(\n        [this](const MsgEnvelope& env) {\n            const auto* req = std::get_if<SyncRequest>(&env.payload);\n            if (req != nullptr && handler_ != nullptr) {\n                int32_t result =\n                    handler_(req->msg_id, req->w_param, req->l_param);\n                response_pool_.SetResult(req->reply_slot, result);\n            }\n        });\n}\n```\n\n消费者线程通过 `ProcessBatch()` 批量处理：\n\n```cpp\nvoid Start() noexcept {\n    running_.store(true, std::memory_order_release);\n    consumer_thread_ = std::thread([this]() {\n        while (running_.load(std::memory_order_acquire)) {\n            uint32_t processed = MsgBus::Instance().ProcessBatch();\n            if (processed == 0U) {\n                std::this_thread::sleep_for(std::chrono::microseconds(100));\n            }\n        }\n        // 退出前清空残留消息\n        while (MsgBus::Instance().ProcessBatch() > 0U) {}\n    });\n}\n```\n\n## 5. 完整使用示例\n\n### 5.1 基础用法（对标原文 main()）\n\n```cpp\n#include <mccc_message/message_service.hpp>\n\nstatic int32_t MessageHandler(uint32_t msg_id, int32_t w_param,\n                               int32_t l_param) {\n    printf(\"Processing Message ID: %u, wParam: %d, lParam: %d\\n\",\n           msg_id, w_param, l_param);\n    return w_param + l_param;\n}\n\nint main() {\n    mccc_msg::MessageService<> service(1U);\n    service.RegisterHandler(MessageHandler);\n    service.Start();\n\n    // 同步消息（SendMessage）\n    int32_t result = service.SendMessage(1U, 10, 20);\n    printf(\"SendMessage result: %d\\n\", result);  // 输出: 30\n\n    // 异步消息（PostMessage）\n    service.PostMessage(2U, 30, 40);\n\n    std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    service.Stop();\n    return 0;\n}\n```\n\n输出：\n\n```\nProcessing Message ID: 1, wParam: 10, lParam: 20\nSendMessage result: 30\nProcessing Message ID: 2, wParam: 30, lParam: 40\n```\n\n### 5.2 多生产者并发\n\n```cpp\nconstexpr uint32_t kNumProducers = 4U;\nconstexpr uint32_t kMessagesPerProducer = 100U;\n\nstd::vector<std::thread> producers;\nfor (uint32_t p = 0U; p < kNumProducers; ++p) {\n    producers.emplace_back([&service, p]() {\n        for (uint32_t i = 0U; i < kMessagesPerProducer; ++i) {\n            int32_t wp = static_cast<int32_t>(p * 1000U + i);\n            if (i % 5U == 0U) {\n                // 每 5 条消息发一次同步请求\n                int32_t r = service.SendMessage(2U, wp, i);\n                assert(r == wp + static_cast<int32_t>(i));\n            } else {\n                service.PostMessage(1U, wp, i);\n            }\n        }\n    });\n}\n```\n\n4 个生产者线程同时向同一个 MCCC Bus 发送消息，无锁竞争。\n\n### 5.3 优先级准入控制\n\n```cpp\n// HIGH: 99% 队列深度才丢弃\nservice.PostMessageWithPriority(1U, 0, 0, mccc::MessagePriority::HIGH);\n\n// MEDIUM: 80% 队列深度丢弃（默认）\nservice.PostMessage(1U, 0, 0);\n\n// LOW: 60% 队列深度丢弃\nservice.PostMessageWithPriority(1U, 0, 0, mccc::MessagePriority::LOW);\n```\n\n## 6. 数据流对比\n\n### 6.1 原始方案的数据流\n\n```\nProducer                       Consumer\n   |                              |\n   | mutex.lock()                 |\n   | priority_queue.push()        |\n   | mutex.unlock()               |\n   | cv.notify_one()              |\n   |                              | cv.wait()\n   |                              | mutex.lock()\n   |                              | priority_queue.top()\n   |                              | priority_queue.pop()\n   |                              | mutex.unlock()\n   |                              | handler()\n   |                              | promise.set_value()\n   | future.get()                 |\n   |   (context switch)           |\n```\n\n关键开销点：\n\n1. `mutex.lock()` / `unlock()` -- 2 次系统调用（futex）\n2. `cv.notify_one()` -- 唤醒阻塞线程（上下文切换）\n3. `priority_queue.push()` -- O(log n) 堆调整\n4. `promise.set_value()` -- 内部包含 mutex + cv\n\n### 6.2 MCCC 方案的数据流\n\n```\nProducer                       Consumer\n   |                              |\n   | CAS enqueue (lock-free)      |\n   |                              | ProcessBatch()\n   |                              |   load sequence (acquire)\n   |                              |   variant dispatch\n   |                              |   handler()\n   |                              |   store sequence (release)\n   |                              |\n   | [SendMessage only:]          | [SyncRequest only:]\n   | response_pool_.WaitResult()  | response_pool_.SetResult()\n   |   atomic load (spin)         |   atomic store (release)\n```\n\n关键优势：\n\n1. CAS 入队 -- 无系统调用，无上下文切换\n2. `ProcessBatch()` -- 批量处理最多 1024 条，摊薄开销\n3. `ResponseSlot` -- 纯原子操作，无 mutex/cv 开销\n\n## 7. 测试验证\n\n### 7.1 测试覆盖\n\n| 测试文件 | 测试内容 | 用例数 |\n|----------|----------|--------|\n| `test_response_pool.cpp` | ResponseSlot 获取/释放/并发 | 2 |\n| `test_post_message.cpp` | 异步消息投递和接收 | 1 |\n| `test_send_message.cpp` | 同步请求-应答/并发正确性 | 3 |\n| `test_multi_producer.cpp` | 多生产者混合同步异步/生命周期 | 2 |\n\n### 7.2 测试结果\n\n```\n$ ctest --output-on-failure\n1/8 ResponsePool basic acquire/release ......... Passed   0.00 sec\n2/8 ResponsePool concurrent acquire/release .... Passed   0.00 sec\n3/8 PostMessage delivers async messages ........ Passed   0.17 sec\n4/8 SendMessage returns handler result ......... Passed   0.02 sec\n5/8 SendMessage with different handlers ........ Passed   0.02 sec\n6/8 SendMessage concurrent from multiple threads Passed   0.02 sec\n7/8 Multi-producer mixed sync/async ............ Passed   0.22 sec\n8/8 Service lifecycle .......................... Passed   0.02 sec\n\n100% tests passed, 0 tests failed out of 8\n```\n\n### 7.3 Sanitizer 验证\n\n```\n$ cmake .. -DCMAKE_CXX_FLAGS=\"-fsanitize=address,undefined\"\n$ make && ctest\n100% tests passed (ASan + UBSan clean)\n```\n\n## 8. 对比总结\n\n| 维度 | 原始方案 | MCCC 方案 |\n|------|----------|-----------|\n| 入队复杂度 | O(log n)（priority_queue push） | O(1)（CAS + 位与） |\n| 同步机制 | `mutex` + `condition_variable` | 无锁 CAS（MPSC） |\n| 同步返回值 | `shared_ptr<promise<int>>`（堆分配） | `ResponseSlot`（预分配，零堆） |\n| 优先级策略 | 二元（sync > async） | 三级准入控制（HIGH/MEDIUM/LOW） |\n| 背压控制 | 无（无限增长） | 队列深度阈值自动丢弃 |\n| 类型安全 | `int` 手动匹配 | `std::variant` 编译期检查 |\n| 多生产者扩展性 | 受 mutex 锁粒度限制 | CAS 无锁，线性扩展 |\n| 缓存友好性 | `priority_queue` 堆结构（随机访问） | Ring Buffer 顺序访问（缓存行对齐） |\n| 内存布局 | 堆碎片化风险 | 固定连续内存块 |\n\n## 9. 移植到嵌入式目标\n\nMCCC 设计时就考虑了嵌入式目标。通过编译期宏可以适配不同硬件：\n\n```bash\n# 单生产者 SPSC 模式（跳过 CAS，更低延迟）\ncmake .. -DCMAKE_CXX_FLAGS=\"-DMCCC_SINGLE_PRODUCER=1\"\n\n# 单核 MCU 模式（relaxed 原子 + signal_fence）\ncmake .. -DCMAKE_CXX_FLAGS=\"-DMCCC_SINGLE_CORE=1 \\\n  -DMCCC_I_KNOW_SINGLE_CORE_IS_UNSAFE=1\"\n\n# 缩小队列深度（节省 RAM）\ncmake .. -DCMAKE_CXX_FLAGS=\"-DMCCC_QUEUE_DEPTH=4096\"\n```\n\n| 配置 | 适用场景 | 队列 RAM |\n|------|----------|----------|\n| 默认 MPSC | 多核 Linux，多生产者 | 约 8 MB（131072 槽） |\n| SPSC | 单生产者，更低延迟 | 约 8 MB |\n| SPSC + 4096 | 嵌入式 MCU，RAM 受限 | 约 256 KB |\n| 单核 + SPSC + 4096 | Cortex-M 裸机 | 约 256 KB |\n\n## 10. 总结\n\n原文的 `mutex + priority_queue + promise/future` 方案是一个功能正确的教学实现，但在多生产者高频场景下存在锁竞争、堆分配、缺乏背压控制等工程问题。\n\n用 MCCC 无锁消息总线重构后：\n\n1. **PostMessage** 直接映射到 `bus.Publish()`，零堆分配，O(1) 入队\n2. **SendMessage** 通过预分配 `ResponsePool` 实现同步返回，替代 `shared_ptr<promise>`\n3. **优先级** 从手动排序升级为 MCCC 内建的 3 级准入控制，同步消息使用 HIGH 优先级\n4. **多生产者** 从 mutex 序列化升级为 CAS 无锁并发\n\n配套代码 [mccc-message-cpp](https://gitee.com/liudegui/mccc-message-cpp) 提供了完整的实现、示例和测试，可直接编译运行验证。\n",
      "ctime": "1771552588",
      "mtime": "1771552588",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/mccc_zero_heap_optimization_benchmark.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038502950",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "MCCC 消息总线零堆分配优化与性能实测",
      "brief_content": "从 MCCC 消息总线优化实践中提炼 5 个零堆分配模式 (Envelope 内嵌、编译期类型索引、函数指针 RAII、FixedFunction/FixedVector/FixedString、编译",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 核心结论 (Key Takeaways)\n\n> **MCCC Lock-free 提供优先级保护和背压控制，同时保持高性能。**\n> **eventpp 优化分支 (OPT-1~8) 显著提升 Active Object 吞吐量。**\n\n| 结论 | 数据支撑 |\n|------|----------|\n| **MCCC BARE_METAL 极高性能** | 18.7 M/s, 54 ns/msg（Lock-free + 线程安全） |\n| **MCCC FULL_FEATURED 生产可用** | 5.8 M/s, 172 ns/msg（全功能 + 线程安全） |\n| **eventpp 优化后 AO 大幅提升** | 8.5 M/s, 118 ns/msg（优化前 1.5 M/s, 689 ns） |\n| **HIGH 消息零丢失** | 背压测试中 HIGH 优先级丢弃率 **0%** |\n| **功能开销可控** | 全功能模式增加 ~118 ns/消息 |\n| **尾部延迟稳定** | MCCC E2E P99 仅 449 ns |\n\n---\n\n## 对比层级说明\n\n> **重要**: 不同层级的对比有不同的语义，不能混淆。\n\n### 层级定义\n\n| 层级 | 实现 | 特点 | 适用场景 |\n|------|------|------|----------|\n| **L1: Raw Queue** | eventpp 值语义 (优化后) | 无堆分配、无线程切换 | 理论上限参考 |\n| **L1.5: Raw + PoolQueueList** | eventpp + 池化分配器 | 零 per-node malloc | 小批量最优 |\n| **L2: Queue + shared_ptr** | eventpp + shared_ptr | 有堆分配、无线程切换 | AO 封装开销参考 |\n| **L3: Active Object** | eventpp + AO + 线程 (优化后) | 有堆分配、有线程切换 | 生产环境 eventpp |\n| **L4: MCCC BARE_METAL** | Lock-free Ring Buffer | 无堆分配、有线程切换、无锁 | 公平对比 L3 |\n| **L5: MCCC FULL** | L4 + 优先级/背压/统计 | 全功能 | 生产环境 MCCC |\n\n### 性能对比图\n\n```\n吞吐量 (M msg/s) - 10K 消息\n│\n30  ┤ █████████████████████████████ 28.5 L1.5: PoolQueueList (小批量最优)\n    │\n25  ┤ ██████████████████████ 22.2 L1: Raw eventpp (优化后)\n    │\n20  ┤ ███████████████████ 18.7 L4: MCCC BARE_METAL\n    ┤ █████████████████ 17.0 L2: eventpp + shared_ptr\n15  ┤\n    │\n10  ┤ █████████ 8.5 L3: eventpp + AO (优化后, 原 1.5)\n    │\n 5  ┤ ██████ 5.8 L5: MCCC FULL_FEATURED\n    │\n 0  └─────────────────────────────────────────────────────────────────\n```\n\n> **关键发现**:\n> - L1.5 (PoolQueueList) 在小批量场景下达 28.5 M/s，超越默认 std::list\n> - L3 (eventpp + AO) 优化后从 1.5 M/s 提升至 8.5 M/s（**5.7x**），吞吐量超过 L5\n> - L4 (MCCC BARE_METAL) 吞吐量 18.7 M/s，接近 Raw eventpp\n> - L5 (MCCC FULL) 吞吐量 5.8 M/s，但 E2E 延迟远优于 L3（P50 367 ns vs 11.6 us）\n\n### 数值汇总\n\n| 层级 | 方案 | 吞吐量 | 入队延迟 | 堆分配 | 线程安全 |\n|:----:|------|--------|---------|:------:|:--------:|\n| L1 | Raw eventpp (优化后) | 22.2 +/- 3.4 M/s | 46 +/- 8 ns | - | - |\n| L1.5 | Raw + PoolQueueList | 28.5 +/- 3.1 M/s | 36 +/- 4 ns | - | - |\n| L2 | eventpp + shared_ptr | 17.0 +/- 5.7 M/s | 54 +/- 5 ns | 有 | - |\n| L3 | eventpp + AO (优化后) | 8.5 +/- 0.6 M/s | 118 +/- 8 ns | 有 | 有 |\n| **L4** | **MCCC BARE_METAL** | **18.7 +/- 1.4 M/s** | **54 +/- 4 ns** | **无** | **有** |\n| **L5** | **MCCC FULL_FEATURED** | **5.8 +/- 0.3 M/s** | **172 +/- 8 ns** | **无** | **有** |\n\n---\n\n## 开销来源分析\n\n> **优化后 MCCC BARE_METAL 已接近 Raw eventpp 性能**\n\n### 开销分解\n\n| 分类 | 开销来源 | 估算 | 说明 |\n|:----:|----------|------|------|\n| **已消除** | ~~shared_ptr 堆分配~~ | 0 ns | Envelope 内嵌在 RingBufferNode |\n| **已消除** | ~~unordered_map hash 查找~~ | 0 ns | 固定数组 + 编译期类型索引 |\n| **已消除** | ~~原子引用计数~~ | 0 ns | 无 shared_ptr |\n| **保留** | 优先级检查 + 背压判断 | ~30-70 ns | FULL_FEATURED 模式 |\n| **保留** | 统计计数 (atomic fetch_add) | ~20-40 ns | FULL_FEATURED 模式 |\n| **保留** | CAS 竞争 | ~10-30 ns | 多生产者场景 |\n| | **BARE_METAL 总开销** | ~54 ns | 仅 CAS + 序列号同步 |\n| | **FULL 功能开销** | ~118 ns | 优先级 + 背压 + 统计 |\n\n### MCCC 如何避免传统开销\n\n| 开销 | eventpp + AO | MCCC (优化后) | 差异原因 |\n|------|:------------:|:----:|----------|\n| 堆分配 | 每消息 make_shared | **零** | Envelope 内嵌 Ring Buffer |\n| 引用计数 | 原子操作 | **零** | 无 shared_ptr |\n| 队列锁 | 互斥锁 | **零 (CAS)** | Lock-free MPSC |\n| 回调查找 | unordered_map hash | **O(1) 数组** | 编译期 VariantIndex |\n| 线程切换 | 独立线程 | 独立线程 | 两者相同 |\n\n> **总结**：优化后 BARE_METAL 吞吐从 3.1 M/s 提升至 18.7 M/s (6.0x)，\n> 主要得益于消除 shared_ptr 堆分配和 unordered_map 查找。\n\n---\n\n## 五个零堆分配模式\n\n> 从 MCCC 优化实践中提炼的通用模式，每个模式附带代码对比。\n\n### 模式一: Envelope 内嵌 (消除每消息堆分配)\n\n**问题**: `std::make_shared<Envelope>` 在每次 Publish 时堆分配。\n\n```cpp\n// 优化前: 每消息堆分配\nstruct RingBufferNode {\n    std::atomic<uint32_t> sequence;\n    std::shared_ptr<MessageEnvelope> envelope;  // 堆分配\n};\n\n// 优化后: 零堆分配\nstruct RingBufferNode {\n    std::atomic<uint32_t> sequence;\n    MessageEnvelope envelope;  // 直接内嵌\n};\n```\n\n### 模式二: 编译期类型索引 (消除 hash 查找)\n\n**问题**: `std::unordered_map<std::type_index, vector<callback>>` 每次 dispatch 需要 hash 计算。\n\n```cpp\n// 编译期计算类型在 variant 中的索引\ntemplate <typename T, typename Variant>\nstruct VariantIndex;\n\n// 固定大小数组替代 hash map\nstd::array<CallbackSlot, std::variant_size_v<MessagePayload>> callbacks_;\n// dispatch: callbacks_[VariantIndex<T, MessagePayload>::value]  -- O(1)\n```\n\n### 模式三: 函数指针 RAII (消除虚表 + unique_ptr)\n\n**问题**: 资源释放通过虚基类 + `std::unique_ptr`，每次 `Borrow()` 堆分配。\n\n```cpp\n// 优化前: 虚基类 + unique_ptr\nclass ITokenReleaser { virtual void Release() = 0; };\nDataToken(ptr, len, ts, std::make_unique<DMABufferReleaser>(pool, idx));\n\n// 优化后: 函数指针 (零堆分配, 零虚表)\nusing ReleaseCallback = void (*)(void* context, uint32_t index) noexcept;\nDataToken(ptr, len, ts, &DMABufferPool::ReleaseBuffer, this, idx);\n```\n\n### 模式四: 零堆分配容器 (栈上定长替代动态容器)\n\n| 标准库类型 | 零堆分配替代 | 容量 | 溢出行为 |\n|-----------|------------|------|----------|\n| `std::string` | `FixedString<N>` | 编译期固定 | 截断 (显式标记) |\n| `std::vector<T>` | `FixedVector<T, N>` | 编译期固定 | `push_back` 返回 false |\n| `std::function` | `FixedFunction<Size>` | SBO 存储 (56B) | `static_assert` 编译期检查 |\n\n### 模式五: 编译期配置矩阵 (适配不同硬件)\n\n| 宏 | 默认值 | MCU 配置 | ARM Linux | 说明 |\n|----|:------:|:--------:|:---------:|------|\n| `QUEUE_DEPTH` | 131072 | 256 | 8192 | Ring Buffer 容量 |\n| `CACHELINE_SIZE` | 64 | 4 (关闭) | 64 | 对齐填充 |\n| `CACHE_COHERENT` | 1 | 0 | 1 | 是否需要 cache line 隔离 |\n| `MAX_MSG_TYPES` | 32 | 8 | 32 | 回调表大小 |\n\nMCU 配置 (`-DQUEUE_DEPTH=256 -DCACHE_COHERENT=0`): RAM 从 ~16 MB 降至 ~23 KB。\n\n### 模式适用性\n\n| 模式 | 适用条件 | 不适用 |\n|------|----------|--------|\n| Envelope 内嵌 | 消息大小编译期已知 | 消息大小动态变化 |\n| 编译期类型索引 | 消息类型集合编译期固定 | 需运行时注册新类型 |\n| 函数指针 RAII | 释放逻辑简单, 无需多态 | 需要复杂的析构链 |\n| 零堆分配容器 | 容量上界编译期可确定 | 容量不可预测 |\n| 编译期配置 | 需适配多种硬件平台 | 单一目标平台 |\n\n> 共同原则: **将运行时决策提前到编译期, 用编译期已知信息换取运行时零开销**。\n\n---\n\n## 背压与优先级测试\n\n> **测试目的**: 验证系统过载时，高优先级消息（如紧急停止）不会被低优先级消息阻塞。\n\n### 测试方法\n\n| 步骤 | 操作 |\n|------|------|\n| 1 | 暂停消费者线程（模拟处理瓶颈） |\n| 2 | 突发发送 150,000 条消息（超过队列容量 131,072） |\n| 3 | 按优先级分布：HIGH 20%, MEDIUM ~26%, LOW ~26% |\n| 4 | 统计各优先级丢弃率 |\n\n### 测试结果\n\n```\n丢弃率 (%) - HIGH 应该最低\n│\n50% ┤                              ████████ 47.6% LOW (优先丢弃)\n    │\n30% ┤\n    │\n10% ┤              ████████ 12.6% MEDIUM\n    │\n 0% ┤ ████ 0.0% HIGH  (完全保护)\n    └─────────────────────────────────────────────────────────────────\n         HIGH           MEDIUM          LOW\n```\n\n| 优先级 | 发送 | 成功 | 丢弃 | 丢弃率 | 状态 |\n|--------|------|------|------|--------|:----:|\n| **HIGH** | 30,000 | 30,000 | 0 | **0.0%** | 完全保护 |\n| MEDIUM | 39,321 | 33,642 | 5,679 | 12.6% | 次级保护 |\n| LOW | 39,320 | 3,640 | 35,680 | 47.6% | 优先丢弃 |\n\n**结论**: 优先级准入控制验证通过！\n\n---\n\n## 端到端延迟测试\n\n> **测试目的**: 测量消息从发布到回调执行的完整延迟（包含队列等待时间）。\n\n### MCCC E2E 延迟 (10,000 样本)\n\n| 分位数 | MCCC | 说明 |\n|--------|------|------|\n| Mean | 380 ns | 平均延迟 |\n| StdDev | 334 ns | 标准差 |\n| Min | 287 ns | 最小延迟 |\n| **P50** | **367 ns** | 中位数 |\n| P95 | 396 ns | 95% 分位 |\n| **P99** | **449 ns** | 99% 分位 |\n| Max | 17,649 ns | 最大延迟 |\n\n### eventpp + AO E2E 延迟 (10,000 样本, 优化后)\n\n| 分位数 | eventpp + AO (优化后) | 说明 |\n|--------|----------------------|------|\n| Mean | 11,715 ns | 平均延迟 |\n| StdDev | 2,888 ns | 标准差 |\n| Min | 966 ns | 最小延迟 |\n| **P50** | **11,588 ns** | 中位数 |\n| P95 | 15,545 ns | 95% 分位 |\n| **P99** | **24,289 ns** | 99% 分位 |\n| Max | 41,844 ns | 最大延迟 |\n\n### E2E 延迟对比\n\n| 分位数 | MCCC | eventpp + AO (优化后) | 差距 |\n|--------|:----:|:--------------------:|:----:|\n| P50 | 367 ns | 11,588 ns | 32x |\n| P95 | 396 ns | 15,545 ns | 39x |\n| P99 | 449 ns | 24,289 ns | 54x |\n| Max | 18 us | 42 us | 2.3x |\n\n**分析**:\n- MCCC P50 约 367 ns，P99 仅 449 ns，尾部延迟极其稳定（无锁设计）\n- eventpp + AO 优化后吞吐量大幅提升（8.5 M/s），但 E2E P50 约 11.6 us（内部批量调度开销）\n- MCCC 在 E2E 延迟上优势更加显著（P50 相差 32x）\n\n---\n\n## 详细测试数据\n\n### MCCC 批量测试 (FULL_FEATURED, 10 轮统计)\n\n| 场景 | 消息数 | 吞吐量 | 入队延迟 |\n|------|--------|--------|---------|\n| Small | 1K | 5.19 +/- 0.50 M/s | 194 +/- 20 ns |\n| Medium | 10K | 5.41 +/- 0.17 M/s | 185 +/- 6 ns |\n| Large | 100K | 5.52 +/- 0.10 M/s | 181 +/- 3 ns |\n\n> 大批量测试方差更小 (StdDev 0.10 vs 0.50)，说明性能在持续负载下更稳定。\n\n### MCCC 性能模式对比 (100K 消息, 10 轮)\n\n| 模式 | 吞吐量 | 入队延迟 | 说明 |\n|------|--------|---------|------|\n| FULL_FEATURED | 5.84 +/- 0.28 M/s | 172 +/- 8 ns | 优先级+背压+统计 |\n| BARE_METAL | 18.70 +/- 1.38 M/s | 54 +/- 4 ns | 仅队列操作 |\n| **功能开销** | - | **~118 ns** | 全功能额外开销 |\n| **BARE_METAL 提升** | **220%** | **69% 降低** | 相对 FULL_FEATURED |\n\n### eventpp Raw 测试 (优化后, 值语义, 10 轮统计)\n\n| 场景 | 消息数 | 吞吐量 | 入队延迟 |\n|------|--------|--------|---------|\n| Small | 1K | 17.6 +/- 2.8 M/s | 58 +/- 9 ns |\n| Medium | 10K | 22.2 +/- 3.4 M/s | 46 +/- 8 ns |\n| Large | 100K | 26.5 +/- 4.6 M/s | 40 +/- 12 ns |\n| VeryLarge | 1M | 24.8 +/- 4.0 M/s | 42 +/- 11 ns |\n\n### eventpp PoolQueueList 测试 (OPT-5 池化分配器, 10 轮统计)\n\n| 场景 | 消息数 | 吞吐量 | 入队延迟 |\n|------|--------|--------|---------|\n| Small | 1K | 26.1 +/- 3.4 M/s | 39 +/- 6 ns |\n| Medium | 10K | 28.5 +/- 3.1 M/s | 36 +/- 4 ns |\n| Large | 100K | 25.1 +/- 2.0 M/s | 40 +/- 4 ns |\n| VeryLarge | 1M | 23.5 +/- 1.0 M/s | 43 +/- 2 ns |\n\n> PoolQueueList 在 Small/Medium 批量下优势明显（26-29 M/s vs 18-22 M/s），\n> 大批量时与默认 std::list 持平（池耗尽后回退到堆分配）。\n\n### eventpp + shared_ptr 测试 (10 轮统计)\n\n| 场景 | 消息数 | 吞吐量 | 入队延迟 |\n|------|--------|--------|---------|\n| Small | 1K | 16.9 +/- 1.5 M/s | 60 +/- 5 ns |\n| Medium | 10K | 17.0 +/- 5.7 M/s | 59 +/- 5 ns |\n| Large | 100K | 18.7 +/- 1.6 M/s | 54 +/- 5 ns |\n| VeryLarge | 1M | 17.0 +/- 2.1 M/s | 60 +/- 11 ns |\n\n### eventpp + Active Object 测试 (优化后, 10 轮统计)\n\n| 场景 | 消息数 | 吞吐量 | 入队延迟 |\n|------|--------|--------|---------|\n| Small | 1K | 6.05 +/- 0.46 M/s | 166 +/- 12 ns |\n| Medium | 10K | 8.52 +/- 0.58 M/s | 118 +/- 8 ns |\n| Large | 100K | 4.22 +/- 0.23 M/s | 238 +/- 13 ns |\n\n> Large 批量方差较大，因为 100K 消息超过 eventpp 内部队列容量时触发锁竞争。\n\n### 持续吞吐测试 (5 秒)\n\n| 指标 | MCCC | eventpp + AO (优化后) |\n|------|:----:|:--------------------:|\n| 持续时间 | 5.00 秒 | 5.00 秒 |\n| 消息发送 | 17,077,858 | 15,626,412 |\n| 消息处理 | 17,077,858 | 15,626,412 |\n| 消息丢弃 | 3,644,451 | 0 |\n| 吞吐量 | 3.42 M/s | 3.13 M/s |\n\n> MCCC 持续测试中生产者速度超过消费者处理速度，优先级准入控制正常工作。\n> 丢弃的消息全部为低优先级，高优先级消息零丢失。\n> eventpp + AO 无背压机制，持续测试中不丢弃消息。\n\n---\n\n## eventpp 优化前后对比\n\n> eventpp 优化分支实施了 8 项优化 (OPT-1~8)。\n> 详见 [eventpp_Optimization_Report.md](eventpp_Optimization_Report.md)。\n\n### eventpp 优化项\n\n| OPT | 优化内容 | 主要收益 |\n|:---:|----------|----------|\n| 1 | SpinLock ARM YIELD / x86 PAUSE | 降低自旋功耗 |\n| 2 | CallbackList 批量预取 (8x 减少锁) | **P99 延迟大幅降低** |\n| 3 | EventDispatcher shared_mutex 读写分离 | **多线程 dispatch 不互斥** |\n| 4 | doEnqueue try_lock (非阻塞 freeList) | 减少入队锁竞争 |\n| 5 | PoolAllocator 池化分配器 | 小批量吞吐提升 |\n| 6 | Cache-line 对齐 | 消除 false sharing |\n| 7 | 内存序 acq_rel (ARM 屏障降级) | ARM 上减少 dmb 指令 |\n| 8 | waitFor 自适应 spin | 减少 futex 系统调用 |\n\n### Active Object 优化前后\n\n| 指标 | 优化前 (vanilla v0.1.3) | 优化后 (OPT-1~8) | 提升 |\n|------|:----------------------:|:-----------------:|:----:|\n| Small 1K 吞吐量 | ~1.9 M/s | 6.05 M/s | **3.2x** |\n| Medium 10K 吞吐量 | ~1.6 M/s | 8.52 M/s | **5.3x** |\n| Large 100K 吞吐量 | ~1.5 M/s | 4.22 M/s | **2.8x** |\n| E2E P50 | ~1,200 ns | 11,588 ns | 吞吐-延迟权衡 |\n| E2E P99 | ~8,953 ns | 24,289 ns | 吞吐-延迟权衡 |\n| 持续吞吐 | ~1.25 M/s | 3.13 M/s | **2.5x** |\n\n### Raw eventpp 优化前后\n\n| 指标 | 优化前 (vanilla v0.1.3) | 优化后 (OPT-1~8) | 提升 |\n|------|:----------------------:|:-----------------:|:----:|\n| Medium 10K | 23.5 M/s | 22.2 M/s | 持平 |\n| VeryLarge 1M | 22.2 M/s | 24.8 M/s | +12% |\n| PoolQueueList 10K | - | 28.5 M/s | **+28%** (vs 默认) |\n\n> Raw 值语义场景下优化前后持平（单线程无锁竞争，OPT-2/3/4 不生效）。\n> PoolQueueList 在小批量场景下提供额外 28% 吞吐提升。\n\n---\n\n## MCCC 优化前后对比\n\n> 本轮优化核心改动：Envelope 内嵌 + 固定回调表 + DataToken 函数指针\n\n| 指标 | 优化前 | 优化后 | 提升 |\n|------|--------|--------|------|\n| FULL_FEATURED 吞吐量 | ~2.0 M/s | ~5.8 M/s | **2.9x** |\n| BARE_METAL 吞吐量 | ~3.1 M/s | ~18.7 M/s | **6.0x** |\n| FULL 入队延迟 | ~505 ns | ~172 ns | **66% 降低** |\n| BARE 入队延迟 | ~318 ns | ~54 ns | **83% 降低** |\n| 功能开销 | ~187 ns | ~118 ns | **37% 降低** |\n| Publish 堆分配 | 1 次 (make_shared) | 0 次 | **消除** |\n| Borrow 堆分配 | 1 次 (unique_ptr) | 0 次 | **消除** |\n\n---\n\n## 架构对比\n\n| 特性 | eventpp + Active Object (优化后) | MCCC Lock-free |\n|------|--------------------------------|----------------|\n| 底层实现 | eventpp::EventQueue (OPT-1~8) | Lock-free MPSC Ring Buffer |\n| 同步机制 | shared_mutex + 批量预取 | CAS 原子操作 |\n| 内存分配 | 每消息 shared_ptr (可选 PoolAllocator) | 固定 Ring Buffer (Envelope 内嵌) |\n| 回调查找 | type_index + unordered_map | 编译期 VariantIndex + 固定数组 |\n| 优先级支持 | - | HIGH/MEDIUM/LOW |\n| 背压控制 | - | 60%/80%/99% 阈值 |\n| 类型安全 | void* 类型擦除 | std::variant 强类型 |\n| 外部依赖 | eventpp (优化分支) | 无 |\n| MISRA 合规 | 部分 | 大部分合规 |\n| 编译期可配置 | PoolQueueList (opt-in) | 队列深度/缓存行/回调表大小 |\n\n---\n\n## 适用场景建议\n\n| 场景 | 推荐方案 | 原因 |\n|------|----------|------|\n| 安全关键系统 | **MCCC** | 优先级保护 + MISRA 合规 |\n| 需要背压控制 | **MCCC** | 分级丢弃验证通过 |\n| 尾部延迟敏感 | **MCCC** | P99 449 ns，Max 18 us |\n| 零依赖要求 | **MCCC** | 纯 C++17 实现 |\n| 高吞吐低延迟 | **MCCC** | BARE_METAL 18.7 M/s, 54 ns |\n| 嵌入式/MCU | **MCCC** | 编译宏裁剪，零堆分配 |\n| 已有 eventpp 代码 | **eventpp + AO (优化后)** | 迁移成本低，优化后 3.1 M/s 持续吞吐 |\n| 单线程高吞吐 | **eventpp PoolQueueList** | 29 M/s (小批量) |\n\n---\n\n## 验证体系\n\n| 验证项 | 方法 | 通过标准 |\n|--------|------|----------|\n| 编译 | Release + Debug 构建 | 零错误零警告 |\n| 功能 | 全量消息收发测试 | 100% 投递成功 |\n| 内存安全 | AddressSanitizer | 零错误零泄漏 |\n| 线程安全 | ThreadSanitizer | 无 data race |\n| 未定义行为 | UBSanitizer | 零告警 |\n| 热路径堆分配 | malloc hook 运行时检测 | 0 次 |\n| 性能回归 | 基准测试 | 无 > 5% 回退 |\n\n---\n\n## 测试环境\n\n| 项目 | 配置 |\n|------|------|\n| OS | Ubuntu 24.04 LTS |\n| Compiler | GCC 13.3.0 |\n| Optimization | -O3 -march=native -faligned-new |\n| C++ Standard | C++17 |\n| eventpp | 优化版 (OPT-1~8), Gitee: liudegui/eventpp |\n\n---\n\n## 复现测试\n\n```bash\nmkdir -p build && cd build\ncmake .. -DCMAKE_BUILD_TYPE=Release && make -j$(nproc)\n\n# 运行测试\n./mccc_benchmark             # MCCC 性能测试\n./eventpp_raw_benchmark      # eventpp Raw + PoolQueueList + shared_ptr 对比\n./eventpp_benchmark          # eventpp + Active Object 性能测试\n./demo_mccc                  # 功能验证\n```\n",
      "ctime": "1771552591",
      "mtime": "1771552591",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/memory_barrier_hardware.md": {
    "err_no": 0,
    "data": {
      "id": "7607589189267243046",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "内存屏障的硬件原理: 从 Store Buffer 到 ARM DMB/DSB/ISB",
      "brief_content": "内存屏障是无锁编程的底层基石，但多数文章停留在 acquire/release 的使用层面，没有解释 **为什么** CPU 会重排序。本文从 Store Buffer、Invalidation Qu",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 配套代码: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) -- header-only C++17 嵌入式基础设施库\n>\n> 相关文章:\n> - [无锁编程核心原理: 从 CAS 到三种队列模式](../lockfree_programming_fundamentals/) -- acquire/release 内存序在无锁队列中的应用\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- ARM 指令映射、FakeTSO 单核优化\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- 跨进程场景的 ARM 内存序加固\n> - [C++ 单例模式的线程安全实现](../cpp_singleton_dclp/) -- DCLP 失败的内存序根因\n> - [无锁异步日志设计](../lockfree_async_log/) -- ARM 弱序模型下的日志缓冲区设计\n>\n> CSDN 原文: [C++多线程编程中的内存屏障/内存栅栏](https://blog.csdn.net/stallion5632/article/details/141271819)\n\n## 1. 为什么 CPU 会重排序\n\n多数内存屏障教程直接从 `std::memory_order` 六个枚举值讲起，告诉你 acquire 防止后面的读写提前、release 防止前面的读写延后。但**为什么** CPU 要重排序？这个问题的答案藏在两个硬件组件里: **Store Buffer** 和 **Invalidation Queue**。\n\n### 1.1 Store Buffer: 写操作的隐藏队列\n\n现代 CPU 的 L1 Cache 访问延迟约 1-4 个时钟周期，但当写操作 cache miss 时，需要等待 MESI 协议完成 (获取 cache line 的独占权)，延迟可达 **几十到上百个周期**。如果 CPU 每次写操作都阻塞等待缓存一致性完成，流水线将频繁停顿。\n\nStore Buffer 的作用是**让写操作立即完成**: CPU 将写入值暂存到 Store Buffer，然后继续执行后续指令，无需等待缓存一致性协议完成。\n\n```\nCPU Core 0                          CPU Core 1\n┌──────────┐                        ┌──────────┐\n│ Pipeline  │                        │ Pipeline  │\n│  执行 str │                        │  执行 ldr │\n└────┬─────┘                        └────┬─────┘\n     │ (1) 写入值暂存                     │ (4) 从 L1 Cache 读取\n┌────▼─────┐                        ┌────▼─────┐\n│  Store    │                        │ Invalidation│\n│  Buffer   │ (2) 异步刷新 ──────→   │  Queue      │ (3) 延迟处理失效\n└────┬─────┘                        └────┬─────┘\n     │                                   │\n┌────▼─────────────────────────────────────▼──────┐\n│              L1 Cache / L2 Cache (MESI 协议)     │\n└─────────────────────────────────────────────────┘\n```\n\n**关键问题**: Core 0 的写入暂存在 Store Buffer 中，**对 Core 1 不可见**。Core 1 从自己的 L1 Cache 中读到的仍然是旧值。这不是 bug，而是 CPU 为了性能做出的设计决策。\n\nStore Buffer 还引入了一个微妙的行为 -- **Store Forwarding**: 当 Core 0 读取自己刚写过的地址时，会直接从 Store Buffer 中获取最新值，绕过 L1 Cache。这意味着**同一个 CPU 核心看到的写入顺序与其他核心看到的不同**。\n\n### 1.2 Invalidation Queue: 读操作的延迟\n\nMESI 协议中，当一个核心要写入某条 cache line 时，需要向所有持有该 line 的其他核心发送 Invalidate 消息。接收方收到 Invalidate 后应该立即将对应 cache line 标记为 Invalid。\n\n但如果接收方正在忙于其他操作 (流水线满载)，立即处理 Invalidate 会导致停顿。因此硬件引入了 **Invalidation Queue**: 将收到的 Invalidate 消息排队，先回复 Acknowledge (让发送方继续)，稍后再实际处理失效。\n\n```\nCore 1 收到 Invalidate(addr=0x1000):\n  ┌──────────────────────────────┐\n  │ 1. 将 Invalidate 消息入队     │\n  │ 2. 立即回复 Ack (让 Core 0    │\n  │    认为失效已完成)             │\n  │ 3. 稍后处理: 将 cache line    │\n  │    标记为 Invalid              │\n  └──────────────────────────────┘\n\n  在步骤 2 和 3 之间，Core 1 仍然\n  可以从自己的 L1 Cache 读到旧值!\n```\n\n**关键问题**: Core 1 已经回复了 Ack，Core 0 认为其他核心都已经看到了自己的写入，但 Core 1 实际上还在用旧的 cache line。这就是**过期读 (stale read)** 的硬件根源。\n\n### 1.3 两个队列，两种乱序\n\nStore Buffer 和 Invalidation Queue 分别导致了两种可见性问题:\n\n| 硬件组件 | 导致的问题 | 影响 |\n|----------|-----------|------|\n| Store Buffer | 写操作延迟对外可见 | 其他核心看不到最新写入 |\n| Invalidation Queue | 读操作使用过期数据 | 本核心看到的是失效前的旧值 |\n\n这两个机制的组合使得**多核系统中，内存操作的执行顺序可能与程序顺序不同**。这不是编译器优化，而是硬件行为 -- 即使你用 `volatile` 禁止编译器优化，CPU 仍然可能重排序。\n\n## 2. MESI 协议: 缓存一致性不等于内存一致性\n\n### 2.1 四种状态\n\nMESI 协议是多核 CPU 维护缓存一致性的标准协议。每条 cache line 有四种状态:\n\n| 状态 | 含义 | 可读 | 可写 | 其他核心状态 |\n|------|------|:----:|:----:|-------------|\n| **M** (Modified) | 已修改，与内存不一致 | 是 | 是 | 无 (独占) |\n| **E** (Exclusive) | 独占，与内存一致 | 是 | 是 (→M) | 无 (独占) |\n| **S** (Shared) | 共享，与内存一致 | 是 | 否 (需先 Invalidate) | 多核共享 |\n| **I** (Invalid) | 无效 | 否 | 否 | - |\n\n### 2.2 一致性 vs 一致性\n\nMESI 保证的是 **Cache Coherence** (缓存一致性): 对同一地址的所有写入，所有核心最终看到相同的值和相同的顺序。但它**不保证** Memory Consistency (内存一致性): 不同地址的写入顺序在不同核心上的可见顺序可能不同。\n\n```cpp\n// 初始: x = 0, y = 0\n\n// Core 0                    // Core 1\nx = 1;  // (1)               y = 1;  // (3)\nr1 = y; // (2)               r2 = x; // (4)\n\n// 可能的结果: r1 == 0 && r2 == 0\n```\n\n这个经典的 **Store Buffer Litmus Test** 在 ARM 上可以真实发生:\n\n- Core 0 执行 (1): x=1 进入 Core 0 的 Store Buffer (对 Core 1 不可见)\n- Core 1 执行 (3): y=1 进入 Core 1 的 Store Buffer (对 Core 0 不可见)\n- Core 0 执行 (2): 读 y，从 L1 Cache 读到旧值 0\n- Core 1 执行 (4): 读 x，从 L1 Cache 读到旧值 0\n\n**MESI 保证 x 最终为 1、y 最终为 1，但不保证 Core 0 在写 x 后立即看到 Core 1 写的 y。**\n\n这就是内存屏障的存在意义: 强制 Store Buffer 刷新或 Invalidation Queue 处理，使特定的内存操作按程序顺序对其他核心可见。\n\n## 3. 四种屏障类型\n\n根据 Store Buffer 和 Invalidation Queue 的组合，内存屏障被分为四种基本类型:\n\n### 3.1 StoreStore Barrier\n\n```\nStore A\n--- StoreStore ---\nStore B\n```\n\n保证: Store A 在 Store B 之前刷出 Store Buffer，即其他核心先看到 A 的写入，再看到 B 的写入。\n\n**硬件机制**: 标记 Store Buffer 中的当前条目，后续的 Store 必须等待这些条目刷新到缓存后才能继续。\n\n**典型场景**: 生产者写数据，然后写 flag 通知消费者。StoreStore 保证消费者看到 flag=1 时，数据已经可见。\n\n```cpp\n// 生产者 (Core 0)\ndata = 42;            // Store A\n// --- StoreStore ---\nflag = 1;             // Store B\n\n// 消费者 (Core 1)\nwhile (flag != 1);    // 看到 flag=1 时\nuse(data);            // data 保证是 42\n```\n\n### 3.2 LoadLoad Barrier\n\n```\nLoad A\n--- LoadLoad ---\nLoad B\n```\n\n保证: Load A 完成后再执行 Load B，Load B 不会使用比 Load A 更旧的数据。\n\n**硬件机制**: 处理 Invalidation Queue 中的所有待处理失效消息，确保后续 Load 读到最新值。\n\n**典型场景**: 消费者先读 flag，再读 data。LoadLoad 保证读到 flag=1 后，读 data 不会命中过期的 cache line。\n\n### 3.3 LoadStore Barrier\n\n```\nLoad A\n--- LoadStore ---\nStore B\n```\n\n保证: Load A 完成后再执行 Store B。防止 Store 被提前到 Load 之前执行。\n\n**使用较少**: x86 TSO 天然禁止 LoadStore 重排，ARM 弱序需要。\n\n### 3.4 StoreLoad Barrier (Full Fence)\n\n```\nStore A\n--- StoreLoad ---\nLoad B\n```\n\n保证: Store A 对所有核心可见后再执行 Load B。这是**最强也是最昂贵**的屏障。\n\n**硬件机制**: 刷新 Store Buffer 中的所有条目 + 处理 Invalidation Queue 中的所有消息。相当于 StoreStore + LoadLoad + LoadStore 的组合。\n\n**为什么最贵**: Store Buffer 刷新需要等待 MESI 协议完成 (可能需要等待远端核心的 Ack)，这个延迟通常是几十到上百个时钟周期。\n\n### 3.5 四种屏障与硬件机制的映射\n\n| 屏障类型 | 作用于 | 硬件效果 |\n|---------|--------|---------|\n| StoreStore | Store Buffer | 刷新已有条目后才允许新 Store |\n| LoadLoad | Invalidation Queue | 处理待失效消息后才允许新 Load |\n| LoadStore | 两者 | Load 完成后才允许 Store 提交 |\n| StoreLoad | 两者 | 完全刷新 Store Buffer + Invalidation Queue |\n\n## 4. 三个层次: 编译器屏障、硬件屏障、C++ memory_order\n\n代码到硬件之间有三层可能的重排序，需要三个层次的屏障:\n\n```\n         源代码\n           │\n     ┌─────▼─────┐\n     │ 编译器优化  │ ← 编译器屏障 (阻止编译器重排)\n     └─────┬─────┘\n           │\n     ┌─────▼─────┐\n     │ CPU 乱序   │ ← 硬件屏障 (阻止 CPU 重排)\n     │ 执行引擎   │\n     └─────┬─────┘\n           │\n     ┌─────▼─────┐\n     │ Store Buffer│ ← 内存屏障 (强制刷新/排空)\n     │ Inv. Queue  │\n     └─────┬─────┘\n           │\n         内存\n```\n\n### 4.1 编译器屏障\n\n编译器屏障只阻止编译器重排序指令，不生成任何硬件屏障指令。\n\n```cpp\n// GCC/Clang 内联汇编编译器屏障\nasm volatile(\"\" ::: \"memory\");\n\n// C++11 标准方式\nstd::atomic_signal_fence(std::memory_order_acq_rel);\n```\n\n`asm volatile(\"\" ::: \"memory\")` 的含义:\n- `\"\"`: 空指令 (不生成机器码)\n- `volatile`: 不被编译器消除\n- `\"memory\"`: 告诉编译器内存已被修改，不要跨越此点重排内存操作\n\n**适用场景**: 单核 MCU (无 CPU 乱序执行问题)，或仅需要阻止编译器优化时。`atomic_signal_fence` 用于同一线程中信号处理函数与主线程的同步。\n\n```cpp\n// newosp SPSC 在 FakeTSO 单核模式下:\n// 只用编译器屏障替代硬件屏障 (零硬件开销)\n#ifdef OSP_FAKE_TSO\n  std::atomic_signal_fence(std::memory_order_release);  // 编译器屏障\n#else\n  std::atomic_thread_fence(std::memory_order_release);  // 硬件屏障\n#endif\n```\n\n详见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) 中的 FakeTSO 机制。\n\n### 4.2 硬件屏障\n\n硬件屏障生成实际的 CPU 屏障指令，阻止 CPU 乱序执行和 Store Buffer/Invalidation Queue 的延迟效应。\n\n```cpp\n// C++11 标准方式 (独立屏障)\nstd::atomic_thread_fence(std::memory_order_acquire);   // LoadLoad + LoadStore\nstd::atomic_thread_fence(std::memory_order_release);   // LoadStore + StoreStore\nstd::atomic_thread_fence(std::memory_order_acq_rel);   // 以上全部\nstd::atomic_thread_fence(std::memory_order_seq_cst);   // Full fence (含 StoreLoad)\n```\n\n在 ARM 上的编译结果:\n\n```asm\n; atomic_thread_fence(acquire)  →  dmb ishld   (Load barrier)\n; atomic_thread_fence(release)  →  dmb ish     (Full barrier)\n; atomic_thread_fence(seq_cst)  →  dmb ish     (Full barrier)\n```\n\n注意: ARM 没有单独的 StoreStore 屏障指令，`release` 和 `seq_cst` 都映射到 `dmb ish` (完全数据屏障)。这意味着 ARM 上 release fence 的开销与 seq_cst fence 相同。\n\n### 4.3 C++ memory_order: 绑定到原子操作的屏障\n\nC++11 定义了六种 memory_order，它们不是独立屏障，而是**附加在原子操作上**的排序约束:\n\n| memory_order | 语义 | 组合的屏障效果 |\n|-------------|------|-------------|\n| `relaxed` | 仅保证原子性 | 无屏障 |\n| `consume` | 数据依赖序 (deprecated) | 理论上比 acquire 弱 |\n| `acquire` | 后续读写不提前到此 load 之前 | LoadLoad + LoadStore |\n| `release` | 前面读写不延后到此 store 之后 | LoadStore + StoreStore |\n| `acq_rel` | acquire + release | LoadLoad + LoadStore + StoreStore |\n| `seq_cst` | 全序 (所有线程看到相同顺序) | Full fence (含 StoreLoad) |\n\n**独立屏障 vs 原子操作上的 memory_order**:\n\n```cpp\n// 方式一: 独立屏障 (atomic_thread_fence)\ndata.store(42, std::memory_order_relaxed);\nstd::atomic_thread_fence(std::memory_order_release);\nflag.store(1, std::memory_order_relaxed);\n\n// 方式二: 原子操作附加 memory_order (更常用)\ndata.store(42, std::memory_order_relaxed);\nflag.store(1, std::memory_order_release);  // release 语义附加在 flag 的 store 上\n```\n\n两种方式在 ARM 上生成的指令几乎相同，但方式二更简洁。C++ 标准推荐在原子操作上直接指定 memory_order，仅在需要与非原子操作建立 happens-before 关系时使用独立屏障。\n\n### 4.4 三个层次总结\n\n| 层次 | 机制 | 阻止的重排序 | 硬件开销 |\n|-----|------|------------|---------|\n| 编译器屏障 | `asm volatile(\"\" ::: \"memory\")` / `atomic_signal_fence` | 仅编译器重排 | **零** (无机器指令) |\n| 硬件屏障 | `atomic_thread_fence` / 内联汇编 | 编译器 + CPU 重排 | DMB/DSB 指令 (几十周期) |\n| 原子操作 memory_order | `atomic.store/load(order)` | 编译器 + CPU 重排 (绑定到特定操作) | 取决于 order 级别 |\n\n## 5. x86 vs ARM: 强序与弱序\n\n### 5.1 x86 TSO (Total Store Order)\n\nx86 实现了 **TSO (Total Store Order)** 模型，这是一种接近顺序一致性的强序模型:\n\n- 每个核心的 Store 按程序顺序对所有核心可见 (StoreStore 天然保证)\n- 每个核心的 Load 按程序顺序执行 (LoadLoad 天然保证)\n- Load 不会被重排到 Store 之后 (LoadStore 天然保证)\n- **唯一允许的重排**: Store 可以被后续的 Load 越过 (StoreLoad 可重排)\n\n```\nx86 允许的重排序:\n  Store A → Load B   可能变成   Load B → Store A   (StoreLoad 重排)\n\nx86 禁止的重排序:\n  Store A → Store B  (StoreStore ✓ 保序)\n  Load A  → Load B   (LoadLoad ✓ 保序)\n  Load A  → Store B  (LoadStore ✓ 保序)\n```\n\n因此，x86 上大部分 `acquire` 和 `release` 操作**不需要生成屏障指令** -- 硬件已经提供了足够的保证。只有 `seq_cst` 的 store 操作需要额外的 `MFENCE` 或 `XCHG` 指令来阻止 StoreLoad 重排。\n\n这也是为什么很多并发 bug 在 x86 上不会复现，却在 ARM 上崩溃 -- x86 的 TSO 掩盖了缺失的内存屏障。\n\n### 5.2 ARM 弱序模型\n\nARM 实现了 **弱序 (Weakly Ordered)** 内存模型，四种重排序都可能发生:\n\n```\nARM 允许的重排序:\n  Store → Store   (StoreStore 可重排) ✗\n  Load  → Load    (LoadLoad 可重排)   ✗\n  Load  → Store   (LoadStore 可重排)  ✗\n  Store → Load    (StoreLoad 可重排)  ✗\n\nx86 上只有最后一种可重排\n```\n\n这意味着 ARM 上每个需要排序保证的操作都必须显式插入屏障指令。编译器在生成 ARM 代码时，会根据 `memory_order` 自动插入必要的 `DMB` 指令。\n\n### 5.3 C++ memory_order 在两种架构上的代价\n\n| memory_order | x86 (TSO) | ARM (弱序) |\n|-------------|-----------|-----------|\n| `relaxed` | 无额外指令 | 无额外指令 |\n| `acquire` (load) | 无额外指令 | `dmb ishld` (或 `ldar`) |\n| `release` (store) | 无额外指令 | `dmb ish` (或 `stlr`) |\n| `seq_cst` (store) | `MFENCE` 或 `XCHG` | `dmb ish` |\n| `seq_cst` (load) | 无额外指令 | `ldar` + `dmb ish` |\n\n**嵌入式实践**: 在 ARM 上，`acquire`/`release` 与 `seq_cst` 的实际开销差异取决于具体微架构，但原则是**用最弱的足够的 memory_order**。`relaxed` 最快 (零开销)，`seq_cst` 最慢 (完全屏障)。\n\n```cpp\n// 嵌入式 SPSC: 只需要 acquire/release (不需要 seq_cst)\n// 生产者\nbuffer[head] = data;\nhead_.store(new_head, std::memory_order_release);  // ARM: stlr 或 dmb ish + str\n\n// 消费者\nauto h = head_.load(std::memory_order_acquire);    // ARM: ldar 或 ldr + dmb ishld\nauto data = buffer[h];\n```\n\n详见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) 和 [共享内存进程间通信](../shm_ipc_newosp/) 中的 ARM 内存序实战分析。\n\n## 6. ARM 三条屏障指令\n\nARM 提供三条屏障指令，语义精确且不可互换:\n\n### 6.1 DMB (Data Memory Barrier)\n\n```asm\nDMB ISH      ; 全屏障: 在此之前的所有内存访问完成后, 才允许之后的内存访问\nDMB ISHLD    ; Load 屏障: 在此之前的所有 Load 完成后, 才允许之后的 Load/Store\nDMB ISHST    ; Store 屏障: 在此之前的所有 Store 完成后, 才允许之后的 Store\n```\n\n**语义**: 确保 DMB 之前和之后的**数据内存访问**的顺序性。DMB 只影响内存访问指令 (Load/Store)，不影响其他指令的执行。\n\n**后缀含义**:\n- `ISH` (Inner Shareable): 作用于内部共享域 (通常是所有 CPU 核心)\n- `OSH` (Outer Shareable): 作用于外部共享域 (含 DMA 控制器等)\n- `SY` (System): 作用于整个系统\n- `LD`: 仅限 Load 操作\n- `ST`: 仅限 Store 操作\n\n**C++ 映射**:\n\n```\nmemory_order_acquire  →  DMB ISHLD  (Load 屏障)\nmemory_order_release  →  DMB ISH    (Full 屏障, ARM 无单独 StoreStore)\nmemory_order_seq_cst  →  DMB ISH    (Full 屏障)\n```\n\n**代价**: DMB 的延迟在 ARM Cortex-A 系列上通常为 **20-60 个时钟周期** (取决于 Store Buffer 深度和缓存一致性延迟)。\n\n### 6.2 DSB (Data Synchronization Barrier)\n\n```asm\nDSB ISH      ; 等待之前的所有内存访问完成, 且对其他核心可见\nDSB ISHST    ; 等待之前的所有 Store 完成并对其他核心可见\n```\n\n**语义**: DSB 比 DMB 更强。DMB 只保证**顺序性** (A 在 B 之前完成)，DSB 保证**完成性** (A 已经完成，所有核心都已看到结果)。DSB 之后的**任何指令** (不仅是内存访问) 都不会执行，直到 DSB 之前的所有内存访问完成。\n\n**DMB vs DSB 的区别**:\n\n```\nDMB: \"屏障之前的内存操作先于屏障之后的内存操作\"\nDSB: \"屏障之前的内存操作全部完成后，才执行屏障之后的任何指令\"\n```\n\n| 特性 | DMB | DSB |\n|-----|-----|-----|\n| 保证内存操作顺序 | 是 | 是 |\n| 等待内存操作完成 | 否 | **是** |\n| 阻塞后续非内存指令 | 否 | **是** |\n| 典型延迟 | 20-60 周期 | **更高** (需等待写入对所有核心可见) |\n\n**适用场景**: 修改页表、修改 MMU 配置、DMA 操作完成确认等需要确保写入**已完成** (而非仅已排序) 的场景。\n\n```cpp\n// 修改页表后必须用 DSB (而非 DMB)\nmodify_page_table_entry();\nasm volatile(\"dsb ish\" ::: \"memory\");  // 等待页表修改对所有核心可见\nasm volatile(\"isb\" ::: \"memory\");      // 刷新指令流水线\n```\n\n### 6.3 ISB (Instruction Synchronization Barrier)\n\n```asm\nISB SY       ; 刷新指令流水线\n```\n\n**语义**: 刷新 CPU 的指令流水线和预取缓冲。ISB 之后获取的所有指令都从缓存或内存中重新获取，确保 ISB 之前的系统寄存器修改 (如 MMU 配置、中断控制器配置) 对后续指令可见。\n\n**ISB 与 DMB/DSB 的本质区别**: DMB 和 DSB 作用于**数据**流 (Load/Store)，ISB 作用于**指令**流 (指令预取和解码)。\n\n**适用场景**:\n- 修改 SCTLR (系统控制寄存器) 后刷新流水线\n- 使能/关闭 MMU 后\n- 修改中断向量表后\n- 自修改代码 (Self-Modifying Code) 后\n\n```cpp\n// 自修改代码: 修改内存中的指令后\nwrite_new_instruction(addr);\nasm volatile(\"dsb ish\" ::: \"memory\");  // 确保新指令写入完成\nasm volatile(\"isb\" ::: \"memory\");      // 刷新流水线, 使新指令生效\n```\n\n### 6.4 选择指南\n\n```\n需要保证数据访问顺序?        → DMB (最轻量, C++ atomic 首选)\n需要确保数据写入已完成?      → DSB (页表/DMA/MMIO 场景)\n需要刷新指令流水线?          → ISB (系统寄存器/自修改代码)\n```\n\n**嵌入式开发中的使用频率**: C++ `std::atomic` 和 `atomic_thread_fence` 只会生成 `DMB`，不会生成 `DSB` 或 `ISB`。后两者是系统级编程 (内核、Bootloader、BSP) 的工具，应用层代码几乎不会直接使用。\n\n## 7. 实战: 内存屏障如何保护无锁数据结构\n\n### 7.1 生产者-消费者 (Acquire-Release)\n\n这是最常见的内存屏障使用模式，也是 SPSC 环形缓冲区的核心:\n\n```cpp\n// 生产者 (写数据 → release store flag)\nvoid produce(T data) {\n    buffer[slot] = data;                              // (1) 普通 Store\n    head.store(new_head, std::memory_order_release);  // (2) Release Store\n}\n\n// 消费者 (acquire load flag → 读数据)\nbool consume(T& out) {\n    auto h = head.load(std::memory_order_acquire);    // (3) Acquire Load\n    if (h == tail) return false;\n    out = buffer[tail];                               // (4) 普通 Load\n    return true;\n}\n```\n\n**ARM 生成的指令**:\n\n```asm\n; 生产者\nstr   r1, [buffer, slot]    ; (1) 普通 Store: data\ndmb   ish                   ; release fence\nstr   r2, [head]            ; (2) Store: new_head\n\n; 消费者\nldr   r3, [head]            ; (3) Load: head\ndmb   ishld                 ; acquire fence\nldr   r4, [buffer, tail]    ; (4) 普通 Load: data\n```\n\n`dmb ish` 保证 (1) 在 (2) 之前对消费者可见; `dmb ishld` 保证 (3) 在 (4) 之前完成。两者配合，消费者看到 head 更新时，data 一定已写入。\n\n### 7.2 DCLP (Double-Checked Locking Pattern)\n\n[C++ 单例模式的线程安全实现](../cpp_singleton_dclp/) 详细分析了 DCLP 在 C++03 中失败的原因。其核心就是缺少内存屏障:\n\n```cpp\n// C++11 正确的 DCLP\nSingleton* Singleton::getInstance() {\n    auto* p = instance.load(std::memory_order_acquire);  // (1) acquire\n    if (!p) {\n        std::lock_guard<std::mutex> lock(mtx);\n        p = instance.load(std::memory_order_relaxed);    // (2) 在锁内 relaxed 即可\n        if (!p) {\n            p = new Singleton();\n            instance.store(p, std::memory_order_release); // (3) release\n        }\n    }\n    return p;\n}\n```\n\n(3) 的 `release` 保证 `new Singleton()` 的所有构造操作在指针发布之前完成; (1) 的 `acquire` 保证其他线程通过指针访问对象时，看到完全构造的状态。\n\n### 7.3 newosp FakeTSO: 单核优化\n\n在单核 MCU (Cortex-M 系列) 上，没有多核缓存一致性问题，硬件屏障指令是纯粹的浪费。newosp 的 SPSC 环形缓冲区提供了 FakeTSO 编译选项:\n\n```cpp\n// 单核模式: 所有 atomic_thread_fence 降级为 atomic_signal_fence\n// 效果: 零硬件屏障指令, 仅阻止编译器重排序\n#define OSP_FAKE_TSO 1\n```\n\n这是编译器屏障与硬件屏障的典型工程权衡:\n- 多核 ARM: 必须用 `atomic_thread_fence` → 生成 `DMB`\n- 单核 MCU: 只需 `atomic_signal_fence` → 零硬件开销\n\n详见 [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) 中的 FakeTSO 分析。\n\n## 8. 常见误区\n\n### 误区一: volatile = 内存屏障\n\n`volatile` 只阻止编译器对该变量的优化 (不消除读写、不合并、不重排同一 volatile 变量的操作)。它**不阻止**:\n- 编译器对 volatile 和非 volatile 操作之间的重排\n- CPU 的乱序执行和 Store Buffer 延迟\n\n```cpp\nvolatile int flag = 0;\nint data = 0;\n\n// 线程 A\ndata = 42;      // 编译器可能将这条重排到 flag=1 之后\nflag = 1;       // volatile 不保护 data 和 flag 之间的顺序\n\n// 正确做法: 用 atomic + memory_order\nstd::atomic<int> flag{0};\ndata = 42;\nflag.store(1, std::memory_order_release);  // data 写入在 flag 之前可见\n```\n\n### 误区二: seq_cst 最安全，应该到处用\n\n`seq_cst` 是最强的排序保证，但也是最昂贵的。在 ARM 上，每个 `seq_cst` 操作都会生成 `DMB` 指令。如果代码中有大量 atomic 操作 (如无锁队列的 CAS 循环)，过度使用 `seq_cst` 会显著降低性能。\n\n**原则**: 分析数据流向，使用**最弱的足够**的 memory_order:\n- 单纯的计数器/统计: `relaxed`\n- 生产者-消费者: `acquire`/`release`\n- 需要全序 (如 Dekker 互斥算法): `seq_cst`\n\n### 误区三: 在 x86 上测试通过 = 内存序正确\n\nx86 的 TSO 模型天然保证了大部分排序 (只有 StoreLoad 可重排)。一段代码在 x86 上跑了一年没出问题，移植到 ARM 后可能立即出现数据竞争。\n\n**实践建议**: 使用 ThreadSanitizer (`-fsanitize=thread`) 检测数据竞争，不依赖特定架构的内存模型。\n\n## 参考资料\n\n1. [C++多线程编程中的内存屏障/内存栅栏](https://blog.csdn.net/stallion5632/article/details/141271819) -- 本文的 CSDN 原始版本\n2. [Memory Barriers: a Hardware View for Software Hackers](http://www.rdrop.com/~paulmck/scalability/paper/whymb.2010.06.07c.pdf) -- Paul McKenney 经典论文\n3. [A Tutorial Introduction to the ARM and POWER Relaxed Memory Models](https://www.cl.cam.ac.uk/~pes20/ppc-supplemental/test7.pdf) -- ARM 弱序模型形式化教程\n4. [Herb Sutter: atomic<> Weapons](https://herbsutter.com/2013/02/11/atomic-weapons-the-c-memory-model-and-modern-hardware/) -- C++ 内存模型与硬件\n5. [Jeff Preshing: Memory Barriers Are Like Source Control Operations](https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/) -- 四种屏障类型的直觉解释\n6. [ARM Architecture Reference Manual](https://developer.arm.com/documentation/ddi0487/latest) -- DMB/DSB/ISB 官方规范\n7. [newosp GitHub 仓库](https://github.com/DeguiLiu/newosp) -- SPSC/MPSC 无锁实现中的内存序实战\n",
      "ctime": "1771552594",
      "mtime": "1771552594",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/message_bus_benchmark_methodology.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853717514",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "如何公平地对比消息总线性能: 基准测试方法论与陷阱",
      "brief_content": "性能基准测试远比 '跑个循环、算个平均' 复杂得多。队列溢出会虚高吞吐 30%，时钟调用本身构成 60-160% 的测量开销，功能差异让 'apples-to-apples' 几乎不可能。本文从实际踩",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "性能对比是技术选型中最具说服力的依据，但也是最容易产生误导的环节。一个设计不当的基准测试，不仅无法反映真实性能，还可能引导团队做出错误决策。\n\n本文总结了在消息总线 (message bus) 基准测试实践中遇到的真实陷阱，并提出了一套可复用的方法论。虽然示例来自具体项目，但所有原则适用于任何并发数据结构的性能对比 -- 无论是 lock-free queue、event dispatcher，还是 actor framework。\n\n---\n\n## 1. 为什么 \"Apples-to-Apples\" 比想象中更难\n\n### 1.1 设计哲学差异\n\n不同消息总线的设计目标天然不同。一个面向嵌入式的总线可能内建优先级队列、背压控制和运行时统计；而一个通用事件库可能只做最基础的回调分发。直接用相同的 benchmark 循环去测试两者，就像让一辆装甲车和一辆赛车跑直线比速度 -- 结果没有参考价值。\n\n```\n框架 A (工业级):  消息 → 优先级判断 → 背压检查 → 原子统计 → CAS 入队 → RingBuffer\n框架 B (轻量级):  消息 → 直接调用回调函数\n```\n\n框架 A 在每条消息上多做了 3-4 步操作。如果你发现框架 A \"只慢了 20%\"，那实际上说明它的核心路径效率极高。但如果你只看绝对数字，框架 B 永远 \"更快\"。\n\n### 1.2 同步 vs 异步的不可比性\n\n同步分发 (直接函数调用) 和异步分发 (入队 + 消费者线程处理) 测量的是完全不同的东西:\n\n- **同步 dispatch**: 测量的是函数调用开销，单线程即可完成\n- **异步 publish**: 测量的是入队操作 + 跨线程通信 + 消费者处理的端到端延迟\n\n将两者的 \"吞吐量\" 直接比较毫无意义。合理的做法是分层对比：队列入队速度与队列入队速度比，端到端延迟与端到端延迟比。\n\n### 1.3 解决方案: 功能剥离模式\n\n为了实现真正公平的核心性能对比，可以引入功能剥离模式 (bare-metal mode)。在该模式下，完全跳过非核心路径上的优先级判断、背压检查和原子统计计数，仅保留核心的 CAS 入队操作和 RingBuffer 索引计算。\n\n| 模式 | 内部行为 | 对比意义 |\n| :--- | :--- | :--- |\n| **FULL_FEATURED** | 完整执行优先级、背压、统计 | 确立生产环境基线 |\n| **BARE_METAL** | 仅保留核心队列操作 | 与轻量级框架公平对比 |\n\n这样，当你声称 \"核心队列性能与框架 B 相当\" 时，你对比的确实是同一层面的东西。\n\n---\n\n## 2. 队列溢出陷阱: 你的吞吐量可能虚高 30%\n\n这是最隐蔽也最常见的基准测试陷阱。\n\n### 2.1 问题描述\n\n考虑一个典型的吞吐量测试: 向一个深度为 128K 的环形队列连续发送 1M 条消息，不启动消费者线程，测量总耗时。\n\n直觉上，这应该测量的是纯入队速度。但实际发生的是:\n\n```\n前 128K 条消息:  执行完整的 CAS + 内存拷贝 → 入队成功\n后 872K 条消息:  队列已满 → 立即返回 false → 几乎零开销\n```\n\n后 872K 条消息的 \"处理时间\" 接近于零 (一次条件判断 + 返回)，但它们被计入了总消息数。结果就是: 名义吞吐量被 872K 条 \"秒返回\" 的失败消息严重稀释了分母。\n\n### 2.2 实测数据\n\n以下是某 lock-free MPSC 队列在相同硬件上的实测数据:\n\n| 场景 | 吞吐量 | 说明 |\n| :--- | :--- | :--- |\n| 1M 消息 / 无消费者 | 31.09 M msg/s | 虚高 -- 87.2% 的消息 fast-fail |\n| 100K 消息 / 无消费者 | 22.95 M msg/s | 真实入队速度 (队列未满) |\n| 1M 消息 / 有消费者 | 15.95 M msg/s | 真实端到端吞吐 |\n\n从 31.09 到 22.95，虚高幅度约 35%。如果你拿 31 M msg/s 去做技术宣传，那就是一个不诚实的数字。\n\n### 2.3 控制实验设计\n\n```mermaid\nflowchart TD\n    A[吞吐量测试] --> B{消息数 vs 队列深度}\n    B -->|消息数 <= 队列深度| C[纯入队速度]\n    B -->|消息数 >> 队列深度 且无消费者| D[混合了 fast-fail 的虚高数据]\n    B -->|消息数 >> 队列深度 且有消费者| E[真实 E2E 吞吐]\n\n    C --> F[报告为 raw enqueue throughput]\n    D --> G[必须标注溢出比例]\n    E --> H[报告为 E2E throughput]\n```\n\n正确做法:\n\n1. **纯入队测试**: 消息数不超过队列深度，或在循环中检查返回值只计入成功的消息\n2. **E2E 测试**: 必须启动消费者线程，测量生产者和消费者协同工作的真实吞吐\n3. **对照组**: 同时报告两组数据，明确标注测试条件\n\n---\n\n## 3. 测量开销: 当尺子比被测物体还大\n\n### 3.1 时钟调用的代价\n\n在主流 x86-64 平台上，`std::chrono::high_resolution_clock::now()` 的单次调用开销约为 20-50 ns (依赖于内核的 vDSO 实现和 TSC 校准状态)。在 ARM 平台上，这个数字可能更高。\n\n当你的目标操作本身只需 30 ns (例如一次 CAS 入队) 时:\n\n```\n测量开销 / 操作耗时 = 2 x 50ns / 30ns = 333%\n```\n\n也就是说，你测到的数字中，只有不到四分之一是真正的操作耗时，其余全是时钟调用的噪声。\n\n### 3.2 解决方案: 批量计时\n\n不要对每条消息单独计时。改为对一批消息整体计时，然后除以消息数:\n\n```\nstart = now()\nfor i in 0..N:\n    queue.push(msg)\nelapsed = now() - start\nthroughput = N / elapsed\n```\n\n这样，两次 `now()` 调用的开销被 N 条消息平摊。当 N = 100,000 时，测量开销降低到可忽略的水平。\n\n### 3.3 延迟测量中的时间戳策略\n\n对于需要逐消息延迟数据的场景 (如 P99 延迟统计)，完全避免时钟调用是不可能的。折中方案是 **时间戳缓存**:\n\n- 每 K 条消息更新一次 `cached_ts = now()`\n- 中间的消息复用 `cached_ts`，引入的误差不超过 K 条消息的处理时间\n- K 的选择需要在精度和开销之间权衡 (典型值: 100-1000)\n\n对于吞吐量测试，更彻底的做法是完全不在消息中传递时间戳，仅在批次级别计时。\n\n---\n\n## 4. 统计学严谨性: 单次运行的数字毫无价值\n\n### 4.1 性能测量的随机性\n\n影响单次 benchmark 结果的随机因素极多:\n\n- 操作系统调度: 进程是否被抢占、是否发生上下文切换\n- 缓存状态: cold cache vs warm cache 的性能差距可达 10 倍\n- 频率调节: CPU 从节能状态提升到 boost 频率需要时间\n- 后台活动: 内核线程、中断处理、其他进程的干扰\n- NUMA 拓扑: 内存分配在哪个 NUMA 节点\n\n一次 \"跑得快\" 的结果不代表你的代码快，可能只是你运气好。\n\n### 4.2 预热与多轮次\n\n```mermaid\nflowchart LR\n    W1[Warmup 1] --> W2[Warmup 2] --> W3[Warmup 3]\n    W3 --> R1[Run 1] --> R2[Run 2] --> R3[...] --> R10[Run 10]\n    R1 --> S[统计分析]\n    R2 --> S\n    R3 --> S\n    R10 --> S\n    S --> O[Mean / StdDev / P50 / P95 / P99]\n\n    style W1 fill:#ccc,stroke:#999\n    style W2 fill:#ccc,stroke:#999\n    style W3 fill:#ccc,stroke:#999\n```\n\n**预热轮次** (warmup rounds) 的作用:\n- 让 CPU 频率稳定在工作状态\n- 填充指令缓存和数据缓存\n- 触发 JIT 编译 (如果有的话，C++ 通常不涉及，但 JVM 基准测试中至关重要)\n- 让操作系统的调度器 \"认识\" 你的线程\n\n预热轮次的结果必须丢弃，不计入统计。典型配置: 3 轮预热 + 10 轮正式测试。\n\n### 4.3 分位数比平均值更重要\n\n对于实时系统和嵌入式场景，P99 延迟 (第 99 百分位) 往往比平均延迟更关键。一个平均延迟 100 ns 但 P99 为 10 us 的系统，在实时控制中可能完全不可接受。\n\n关键指标:\n\n| 指标 | 意义 | 关注场景 |\n| :--- | :--- | :--- |\n| Mean | 整体趋势 | 吞吐量规划 |\n| StdDev | 性能抖动 (Jitter) | 确定性系统 |\n| StdDev/Mean | 变异系数 (CV) | 结果可信度判断 |\n| P50 | 典型延迟 | 用户体验 |\n| P95 | 长尾开始 | SLA 保障 |\n| P99 | 最坏情况近似 | 实时系统 |\n| Min/Max | 极端值 | 异常检测 |\n\n**StdDev/Mean 比值** 是判断测试结果可信度的关键: 如果这个比值超过 0.3，说明性能波动太大，结果不可靠，应当排查干扰源或增加测试轮次。\n\n---\n\n## 5. 端到端延迟的精确测量\n\n### 5.1 为什么逐消息时间戳不工作\n\n在纳秒级别测量端到端延迟时，最直觉的方案 -- 在消息中嵌入发送时间戳，在消费者端计算差值 -- 存在两个问题:\n\n1. **测量开销污染**: 前面已经分析过，`now()` 调用本身的开销与被测操作同数量级\n2. **内存带宽压力**: 每条消息多写入 8 字节时间戳，在高频场景下增加 cache line 竞争\n\n### 5.2 原子屏障 + 采样方案\n\n更好的方案是 \"采样式\" 测量，利用原子变量做同步:\n\n```mermaid\nsequenceDiagram\n    participant P as Producer\n    participant Q as Queue\n    participant C as Consumer\n\n    P->>P: publish_ts = now()\n    P->>Q: publish(msg)\n    P->>P: spin on atomic(ready)\n    Q->>C: deliver msg\n    C->>C: callback_ts = now()\n    C->>P: atomic(ready) = true\n    P->>P: latency = callback_ts - publish_ts\n```\n\n具体步骤:\n\n1. **生产者**: 记录 `publish_ts`，调用 `publish()`，然后在原子变量 `measurement_ready` 上自旋等待 (带超时保护)\n2. **消费者**: 在回调函数的第一行获取 `callback_ts`，然后设置 `measurement_ready = true`\n3. **计算**: `latency = callback_ts - publish_ts`\n\n这种方法将时钟调用从每条消息降低到每次采样 (例如每 1000 条消息采样一次)，同时获得的延迟数据精度更高，因为没有消息级别的测量干扰。\n\n### 5.3 自旋等待的注意事项\n\n自旋等待期间，生产者线程不会发送新消息，这意味着测到的延迟是 \"空闲队列\" 状态下的延迟。如果你需要测量 \"满载状态\" 下的延迟，需要使用不同的策略: 例如在后台维持一个稳定的消息流，同时在采样点插入带标记的测量消息。\n\n---\n\n## 6. CPU 亲和性与缓存一致性\n\n### 6.1 跨核通信的代价\n\n在多线程基准测试中，如果不绑定 CPU 核心，操作系统调度器可能会:\n\n- 将生产者和消费者调度到同一个核心 (结果异常好，因为 L1 cache 共享)\n- 将线程在不同核心之间迁移 (结果波动巨大)\n- 将线程调度到不同 NUMA 节点 (结果异常差)\n\n### 6.2 控制变量: 固定核心绑定\n\n推荐的做法是通过 CPU affinity 固定线程到指定核心:\n\n```\nProducer → Core 0 (同一物理核心)\nConsumer → Core 1 (同一物理核心)\n```\n\n这样测到的是跨核 L3 cache 一致性协议 (MESI/MOESI) 的真实开销。实测数据表明，跨核通信相比同核通信，吞吐量下降约 30%。\n\n### 6.3 cache line 对齐与 false sharing\n\n当生产者和消费者各自维护的索引变量 (head/tail) 落在同一个 cache line (通常 64 字节) 时，每次写操作都会触发 cache line 的独占权转移，即 false sharing。\n\n解决方案是对关键共享变量做 cache line 对齐:\n\n```cpp\nstruct alignas(64) AlignedCounter {\n    std::atomic<uint64_t> value{0};\n    // padding 自动填充到 64 字节\n};\n```\n\n在基准测试中，是否应用 cache line 对齐应当是一个明确的测试变量，而不是被忽略的隐含条件。\n\n---\n\n## 7. 编译环境的统一\n\n编译器优化级别对性能的影响远超大多数人的预期:\n\n| 配置项 | 要求 | 原因 |\n| :--- | :--- | :--- |\n| 优化级别 | 统一 `-O2` 或 `-O3` | `-O0` 到 `-O2` 的性能差距可达 10 倍 |\n| 标准版本 | 统一 C++ 标准 (如 C++17) | 不同标准的 STL 实现可能有性能差异 |\n| 架构指令 | `-march=native` | 启用 AVX/SSE 等硬件加速 |\n| 对齐支持 | `-faligned-new` | 支持 `alignas` 超过默认对齐的动态分配 |\n| LTO | 统一开启或关闭 | LTO 可以跨编译单元内联 |\n\n不要在 `-O3` 下测试自己的库，然后在 `-O2` 下测试竞品。这种 \"失误\" 在开源项目的 benchmark 中并不罕见。\n\n---\n\n## 8. 结果呈现: 数据需要上下文\n\n### 8.1 避免误导性的图表\n\n一些常见的误导手法 (有时并非有意):\n\n- **截断 Y 轴**: 从非零值开始，夸大差异\n- **混淆单位**: 将 msg/s 和 ops/s 混用 (一条消息可能触发多次操作)\n- **忽略误差线**: 只展示平均值，隐藏巨大的标准差\n- **选择性报告**: 只展示有利的场景\n\n### 8.2 完整报告模板\n\n一份可信的基准测试报告应包含:\n\n```\n## 测试环境\n- 硬件: CPU 型号 / 核心数 / 频率 / L3 Cache 大小\n- 操作系统: 内核版本\n- 编译器: 版本 + 编译选项\n- CPU 调频策略: performance / powersave / ondemand\n\n## 测试参数\n- 消息大小 / 队列深度 / 线程数 / CPU 绑核\n- 预热轮次 / 正式轮次\n\n## 测试结果\n- Mean +/- StdDev\n- P50, P95, P99\n- Min, Max\n- 变异系数 (CV = StdDev/Mean)\n\n## 对比条件说明\n- 功能对齐策略\n- 已知的不对等因素\n```\n\n---\n\n## 9. 公平基准测试检查清单\n\n以下是在设计和执行基准测试时的自检项:\n\n```mermaid\nflowchart TD\n    A[开始设计 Benchmark] --> B{功能对齐了吗?}\n    B -->|否| B1[引入功能剥离模式]\n    B -->|是| C{队列溢出控制了吗?}\n    C -->|否| C1[限制消息数 / 统计实际成功数]\n    C -->|是| D{测量开销可接受吗?}\n    D -->|否| D1[改用批量计时]\n    D -->|是| E{多轮次 + 预热?}\n    E -->|否| E1[加预热 + 10轮以上]\n    E -->|是| F{CPU 绑核了吗?}\n    F -->|否| F1[设置 CPU affinity]\n    F -->|是| G{编译选项统一了吗?}\n    G -->|否| G1[统一 -O3 / -march=native]\n    G -->|是| H{报告了 P99 和 StdDev?}\n    H -->|否| H1[补充完整统计数据]\n    H -->|是| I[Benchmark 可信]\n\n    B1 --> C\n    C1 --> D\n    D1 --> E\n    E1 --> F\n    F1 --> G\n    G1 --> H\n    H1 --> I\n```\n\n**核心原则**: 基准测试的目的不是证明 \"我的更快\"，而是帮助工程师做出正确的技术决策。一个诚实的、条件清晰的 benchmark，即使数字不占优，也远比一个漂亮但误导性的数字更有价值。\n\n---\n\n## 10. 总结与经验教训\n\n经过大量的基准测试实践，以下是最重要的几条经验:\n\n1. **队列溢出是最常见的吞吐量虚高原因**。任何未控制消费者状态的吞吐量数字都应当持怀疑态度。发送 1M 消息到 128K 队列而不启动消费者，87% 的消息只是 fast-fail 返回 -- 你测的不是队列性能，而是条件判断的速度。\n\n2. **测量工具本身是最大的噪声源**。在纳秒级操作上逐次调用 `now()` 是在用米尺量头发丝。批量计时是唯一可行的方案。\n\n3. **功能对齐比性能数字更重要**。如果你的框架多做了三件事，那么 \"只慢 20%\" 可能恰恰说明核心路径极其高效。报告中必须清晰说明功能差异。\n\n4. **P99 才是真正的性能指标**。对于嵌入式和实时系统，一个偶发的 10 us 延迟尖峰可能导致控制环路超时。平均值只能用来做容量规划。\n\n5. **可复现性是基础**。固定 CPU 核心、固定编译选项、固定测试参数、记录环境信息。如果别人无法复现你的结果，那就不是科学。\n\n6. **多组对照实验比单一数字更有说服力**。同时报告有消费者/无消费者、不同队列深度、不同消息大小的数据，让读者自行判断。\n\n---\n\n> 参考: [mccc-bus](https://gitee.com/liudegui/mccc-bus), [newosp](https://github.com/DeguiLiu/newosp)\n",
      "ctime": "1771552598",
      "mtime": "1771552598",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/message_bus_competitive_benchmark.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853733898",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++ 消息总线性能实测: 6 个开源方案的吞吐量与延迟对比",
      "brief_content": "在同一硬件上统一测试 MCCC、eventpp、EnTT、sigslot、ZeroMQ、QP/C++ 六个消息总线方案，从吞吐量、延迟、内存安全、嵌入式适配性四个维度给出选型建议",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 测试环境: Ubuntu 24.04, GCC 13.3, `-O3 -march=native`, Intel Xeon 64 vCPU\n>\n> 测试源码: [mccc-bus/examples/competitive_benchmark.cpp](https://gitee.com/liudegui/mccc-bus)\n\n---\n\n## 1. 为什么需要这次对比\n\n工业嵌入式系统（激光雷达、机器人、传感器融合）中，消息总线是各模块之间解耦通信的核心组件。选型时面临三个矛盾:\n\n1. **吞吐量 vs 线程安全**: 最快的方案（EnTT）不支持多线程，最安全的方案（ZeroMQ）延迟最高\n2. **灵活性 vs 零堆分配**: `std::function` + `shared_ptr` 提供灵活回调，但每条消息 1-3 次 malloc\n3. **通用性 vs 嵌入式适配**: ZeroMQ 功能强大但静态库 2 MB，MCU 上跑不起来\n\n市面上的消息总线库各有侧重，但很少有人在**同一硬件、同一测试条件**下横向对比。本文选取 6 个代表性开源项目，统一测试后给出选型建议。\n\n---\n\n## 2. 对标项目\n\n| 项目 | Stars | 类型 | 标准 | Header-only |\n|------|:-----:|------|:----:|:-----------:|\n| [MCCC](https://gitee.com/liudegui/mccc-bus) | -- | Lock-free MPSC 消息总线 | C++17 | 是 |\n| [eventpp](https://github.com/wqking/eventpp) | ~2,000 | 事件队列/分发器 | C++14 | 是 |\n| [EnTT](https://github.com/skypjack/entt) | ~10,000 | ECS + 事件分发器 | C++17 | 是 |\n| [sigslot](https://github.com/palacaze/sigslot) | ~600 | 信号/槽 | C++14 | 是 |\n| [ZeroMQ](https://github.com/zeromq/libzmq) | ~10,000 | IPC/网络消息 | C/C++ | 否 |\n| [QP/C++](https://github.com/QuantumLeaps/qpcpp) | ~800 | Active Object 框架 | C++11 | 否 |\n\n这 6 个项目覆盖了事件总线、信号槽、IPC 消息三大类，设计哲学各异。MCCC 是笔者开发的 Lock-free MPSC 消息总线（1,535 行，3 个头文件），作为参照基线参与对比。\n\n---\n\n## 3. 测试方法\n\n### 3.1 统一条件\n\n| 参数 | 值 |\n|------|:--:|\n| 消息数 | 1,000,000 / 轮 |\n| 轮次 | 10 (取均值 +/- 标准差) |\n| 载荷 | 24 B (`struct { uint64_t seq; float x,y,z,w; }`) |\n| CPU 亲和 | 生产者 core 0, 消费者 core 1 |\n\n### 3.2 测试模式适配\n\n不同库设计意图不同，采用最接近其原生用法的测试方式:\n\n| 库 | 测试模式 | 说明 |\n|----|----------|------|\n| MCCC | Publish -> ProcessBatch (双线程) | 生产者发布，消费者批量处理 |\n| eventpp | enqueue -> process (单线程) | 先入队再全部分发 |\n| EnTT | enqueue -> update (单线程) | 同上 |\n| sigslot | 同步 emit (单线程) | 信号直接调用槽函数，无队列 |\n| ZeroMQ | push/pull inproc (双线程) | 进程内 socket 传输 |\n\n> 注意: EnTT 和 sigslot 是同步方案，不存在真正的\"异步队列\"。它们的高吞吐数据不能与异步方案直接对比——前者没有线程同步开销。\n\n---\n\n## 4. 吞吐量对比\n\n### 4.1 入队吞吐量\n\n```mermaid\nxychart-beta\n    title \"入队吞吐量 (M msg/s)\"\n    x-axis [\"EnTT\", \"MCCC-SPSC\", \"MCCC-MPSC\", \"sigslot\", \"MCCC-FULL\", \"eventpp-HP\", \"eventpp-Raw\", \"ZMQ\"]\n    y-axis \"M msg/s\" 0 --> 120\n    bar [115.07, 33.42, 31.09, 25.92, 20.61, 6.95, 5.11, 4.48]\n```\n\n| 方案 | 吞吐量 (M/s) | 延迟 (ns) | 同步机制 | 线程安全 |\n|------|:-----------:|:---------:|----------|:--------:|\n| EnTT | 115.07 | 4 | 无 (单线程) | 否 |\n| MCCC SPSC BARE | 33.42 | 30 | Wait-free store | 是 |\n| MCCC MPSC BARE | 31.09 | 32 | CAS 原子操作 | 是 |\n| sigslot | 25.92 | 38 | Mutex | 是 |\n| MCCC MPSC FULL | 20.61 | 48 | CAS + 优先级 + 背压 | 是 |\n| eventpp HighPerf | 6.95 | 30 | SpinLock + CAS 池 | 是 |\n| eventpp Raw | 5.11 | 49 | std::mutex + std::list | 是 |\n| ZeroMQ inproc | 4.48 | 221 | Socket 内部锁 | 是 |\n\n**关键发现**:\n\n- **EnTT 一骑绝尘 (115 M/s)**，但它本质是 `vector::push_back`，不支持多线程。这个数字说明的是\"无同步开销时 CPU 能多快\"\n- **sigslot 同样快 (26 M/s)**，因为它是同步直接调用，没有队列\n- 在**异步线程安全**方案中，MCCC BARE_METAL 以 31 M/s 领先，是 eventpp HighPerf 的 **4.5x**，eventpp Raw 的 **6.1x**\n- MCCC 开启全部安全特性后 (FULL) 仍有 20.6 M/s，是 eventpp Raw 的 **4.0x**\n\n### 4.2 端到端吞吐量 (生产者 + 消费者并发)\n\n| 方案 | E2E 吞吐量 (M/s) | E2E 延迟 (ns) |\n|------|:-----------:|:---------:|\n| MCCC SPSC BARE | 18.85 | 53 |\n| MCCC MPSC BARE | 16.46 | 59 |\n| MCCC SPSC FULL | 7.04 | 143 |\n| MCCC MPSC FULL | 6.82 | 148 |\n\nE2E 吞吐量受消费者处理速度约束，低于纯入队吞吐量。但这才是更贴近真实系统的指标。\n\n### 4.3 不同载荷大小的影响\n\n以 MPSC FULL 模式测试 24B/64B/128B/256B 四种载荷:\n\n| 载荷 | MCCC | eventpp | sigslot | ZeroMQ |\n|:----:|:----:|:-------:|:-------:|:------:|\n| 24B | 6.82 M/s | 5.11 M/s | 25.92 M/s | 4.48 M/s |\n| 64B | 5.09 M/s | 4.61 M/s | 30.63 M/s | 2.88 M/s |\n| 128B | 4.37 M/s | 4.50 M/s | 30.13 M/s | 1.98 M/s |\n| 256B | 4.09 M/s | 3.53 M/s | 31.39 M/s | 2.14 M/s |\n\n- **sigslot** 不受载荷大小影响（同步调用，不拷贝入队）\n- **ZeroMQ** 受影响最大（Socket 协议栈的拷贝成本随载荷线性增长）\n- **MCCC** 和 **eventpp** 在大载荷时差距缩小，因为内存拷贝成为共同瓶颈\n\n---\n\n## 5. 延迟分析\n\n| 方案 | P50 (ns) | P95 (ns) | P99 (ns) | P99/P50 |\n|------|:--------:|:--------:|:--------:|:-------:|\n| EnTT | 4 | 5 | 5 | 1.25x |\n| MCCC SPSC BARE | 30 | 31 | 31 | 1.03x |\n| MCCC MPSC BARE | 32 | 33 | 33 | 1.03x |\n| sigslot | 38 | 40 | 40 | 1.05x |\n| MCCC MPSC FULL | 48 | 51 | 51 | 1.06x |\n| eventpp Raw | 49 | 50 | 50 | 1.02x |\n| ZeroMQ | 221 | 228 | 228 | 1.03x |\n\n**MCCC 的尾部延迟极其稳定**: P99/P50 仅 1.03x，说明 CAS 操作不会产生长尾。对嵌入式实时系统来说，稳定的尾部延迟比极致的中位延迟更有价值。\n\nBARE -> FULL 的功能开销 = 48 - 32 = **16 ns/消息**（优先级检查 + 背压判断 + 统计计数）。\n\n---\n\n## 6. 队列溢出效应: 真实吞吐量比表观数据低 30%\n\n上述 Publish-only 测试使用 1M 消息写入 128K 深度队列。队列满后，后续 Publish 快速失败返回，导致**表观吞吐量偏高**。通过对照实验揭示真实吞吐量:\n\n| 实验 | BARE (M/s) | FULL (M/s) | 说明 |\n|------|:---------:|:---------:|------|\n| 1M 无消费者 | 31.09 | 20.61 | 含 ~872K fast-path failure，表观偏高 |\n| **100K 无消费者** | **22.95** | **17.51** | 100K < 128K，全部成功入队，**真实吞吐量** |\n| 1M 有消费者 | 15.95 | 7.19 | 跨核 cache coherence 成本 |\n\n```mermaid\nxychart-beta\n    title \"MPSC BARE_METAL 吞吐量对照 (M msg/s)\"\n    x-axis [\"1M 无消费者\", \"100K 无消费者\", \"1M 有消费者\"]\n    y-axis \"M msg/s\" 0 --> 35\n    bar [31.09, 22.95, 15.95]\n```\n\n**分析**:\n\n- **真实纯发布吞吐量** (100K 实验) 为 22.95 M/s，比表观值低 ~26%。这是诚实的数据——发布基准测试时不应回避这一点\n- 加入消费者后吞吐量再降 ~30%（22.95 -> 15.95 M/s），这是跨核 cache line 竞争的固有成本\n- FULL 模式下 cache coherence 成本更高（17.51 -> 7.19，-59%），因为 shared_mutex 读锁在高频场景成为瓶颈\n\n---\n\n## 7. ProcessBatchWith: 编译期分发带来 50% 提升\n\nMCCC v2.0 新增 `ProcessBatchWith<Visitor>` 方法，绕过回调表和 `shared_mutex`，使用 `std::visit` 编译期分发:\n\n| 消费路径 | MPSC BARE | MPSC FULL | SPSC FULL |\n|----------|:---------:|:---------:|:---------:|\n| ProcessBatch (回调表) | 16.46 M/s | 6.82 M/s | 7.04 M/s |\n| ProcessBatchWith (Visitor) | 15.28 M/s | **10.20 M/s** | **10.59 M/s** |\n| 变化 | -7% | **+50%** | **+50%** |\n\nFULL 模式下 +50% 的提升来自绕过 `shared_mutex` 读锁和回调表间接调用。BARE 模式本身无 shared_mutex 开销，Visitor 的分支匹配反而略有损耗。\n\n---\n\n## 8. 特性矩阵\n\n性能只是选型的一个维度。对嵌入式系统来说，以下特性同样关键:\n\n| 特性 | MCCC | eventpp | EnTT | sigslot | ZeroMQ | QP/C++ |\n|------|:----:|:-------:|:----:|:-------:|:------:|:------:|\n| 异步队列 | Y | Y | Y | -- | Y | Y |\n| 类型安全分发 | Y | Y | Y | Y | -- | -- |\n| 优先级准入 | Y | -- | -- | -- | -- | Y |\n| 背压控制 | Y | -- | -- | -- | Y | -- |\n| Lock-free | Y | 部分 | -- | -- | 部分 | -- |\n| 零堆分配 (热路径) | Y | -- | -- | Y | -- | Y |\n| 线程安全 | Y | Y | -- | Y | Y | Y |\n| Header-only | Y | Y | Y | Y | -- | -- |\n| MISRA 合规 | Y | -- | -- | -- | -- | Y |\n| 嵌入式可裁剪 | Y | -- | -- | -- | -- | Y |\n| IPC/网络传输 | -- | -- | -- | -- | Y | -- |\n\n### 资源消耗\n\n| 项目 | 核心代码行 | 二进制大小 (-O3 -s) | 最小 RAM |\n|------|:--------:|:---------:|:--------:|\n| MCCC | 1,535 | 14.6 KB | ~4 KB |\n| EnTT signal | 1,433 | 18.3 KB | 不可控 |\n| eventpp | 1,487 | 26.3 KB | 不可控 |\n| sigslot | 1,848 | 34.3 KB | ~100 B |\n| QP/C++ | 5,640 | ~50 KB | ~2 KB |\n| ZeroMQ | ~100K+ | 2.15 MB | ~1 MB |\n\n### 内存安全\n\n| 项目 | 队列结构 | 热路径堆分配 | 溢出保护 |\n|------|----------|:----------:|:--------:|\n| MCCC | 预分配 Ring Buffer | 零 | 优先级丢弃 |\n| eventpp | std::list / CAS 池 | 每消息一次 (Raw) | 无限增长 |\n| EnTT | std::vector | 扩容时 | 无限增长 |\n| sigslot | 无队列 | 零 | N/A |\n| ZeroMQ | 内部队列 | 每消息一次 | HWM 丢弃 |\n| QP/C++ | 事件池 | 零 (池模式) | 池耗尽拒绝 |\n\n---\n\n## 9. 架构对比\n\n```mermaid\nflowchart TB\n    subgraph MCCC[\"MCCC: Lock-free MPSC\"]\n        direction LR\n        P1[\"Producer\"] -->|CAS| RB[\"Ring Buffer\\n128K slots\\nEnvelope 内嵌\"]\n        RB -->|\"BatchProcess\"| CB[\"Callback\\n固定数组\"]\n    end\n\n    subgraph EPP[\"eventpp: Mutex + List\"]\n        direction LR\n        P2[\"Producer\"] -->|mutex| LIST[\"std::list\\n动态分配\"]\n        LIST -->|\"process\"| CB2[\"Callback\\nmap 查找\"]\n    end\n\n    subgraph ZMQ[\"ZeroMQ: Socket\"]\n        direction LR\n        P3[\"Producer\"] -->|socket| PROTO[\"协议栈\\n序列化\"]\n        PROTO -->|\"recv\"| CB3[\"Handler\"]\n    end\n```\n\n核心差异在同步机制:\n\n| 项目 | 入队同步 | 消费同步 |\n|------|----------|----------|\n| MCCC | CAS 原子操作 (无锁) | 序列号检查 (relaxed) |\n| eventpp | SpinLock/Mutex | shared_mutex 读写分离 |\n| EnTT | 无 (单线程) | 无 (单线程) |\n| sigslot | Mutex (emit 时) | 无 (同步) |\n| ZeroMQ | Socket 内部锁 | Socket 内部锁 |\n\n---\n\n## 10. 选型建议\n\n| 场景 | 推荐方案 | 原因 |\n|------|----------|------|\n| 安全关键嵌入式 (汽车/航空) | MCCC, QP/C++ | 优先级保护 + MISRA 合规 + 零堆分配 |\n| 高吞吐单线程事件 | EnTT | 极致单线程性能，无同步开销 |\n| 简单解耦 (观察者模式) | sigslot | 最简 API，同步直接调用 |\n| 通用事件队列 | eventpp | 功能丰富，策略可配置 |\n| 跨进程/网络通信 | ZeroMQ | 多种传输协议，生态成熟 |\n| Active Object 模式 | QP/C++, MCCC | 状态机 + 事件驱动 |\n\n### 综合对比\n\n| 维度 | MCCC vs eventpp | MCCC vs ZeroMQ | MCCC vs EnTT |\n|------|:--------------:|:--------------:|:------------:|\n| 入队吞吐量 | MCCC 快 4.5x | MCCC 快 6.9x | EnTT 快 3.7x (单线程) |\n| E2E 吞吐量 | MCCC 快 2.4x | MCCC 快 3.7x | N/A (EnTT 无异步) |\n| 线程安全 | 均支持 | 均支持 | EnTT 不支持 |\n| 优先级控制 | MCCC 独有 | 均无 | EnTT 无 |\n| 零堆分配 | MCCC 是 | ZeroMQ 否 | EnTT 否 |\n| 二进制大小 | MCCC 小 1.8x | MCCC 小 155x | MCCC 小 1.3x |\n\n---\n\n## 11. 结论\n\n没有\"最好\"的消息总线，只有最适合场景的选择:\n\n- 如果你的系统**不需要多线程**，EnTT 和 sigslot 提供最高的单线程吞吐量，没必要引入异步队列的复杂度\n- 如果你需要**异步、线程安全、且对延迟敏感**，MCCC 在同类方案中性能领先（BARE_METAL 31 M/s，是 eventpp 的 4.5x），且提供优先级准入和背压控制\n- 如果你的系统需要**跨进程/网络通信**，ZeroMQ 是唯一选择，但要接受 2 MB 的体积和 ~220 ns 的延迟\n- 如果你在做**安全关键系统** (MISRA 合规、零堆分配、确定性内存)，选择范围缩小到 MCCC 和 QP/C++\n\n本文所有数据均为同一硬件、同一编译器、同一测试条件下的实测结果，测试源码开源可复现。\n\n---\n\n> 参考: [MCCC 源码](https://gitee.com/liudegui/mccc-bus),\n> [eventpp](https://github.com/wqking/eventpp),\n> [newosp](https://github.com/DeguiLiu/newosp) (MCCC 的架构设计后来融入了 newosp 基础设施库)\n",
      "ctime": "1771552601",
      "mtime": "1771552601",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/object_pool_hidden_costs.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357860378",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "对象池在嵌入式热路径上的三个隐性成本",
      "brief_content": "对象池 (mutex + queue + shared_ptr) 比裸 malloc 快约 60%，是减少堆分配的第一步改进。但在 ARM 嵌入式热路径上，mutex futex 开销、shared_",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- 预分配环形缓冲的完整设计\n> - [无锁编程核心原理: 从 CAS 到三种队列模式](../lockfree_programming_fundamentals/) -- MPSC/SPSC 原理\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- 零堆分配流水线\n>\n> CSDN 原文: [嵌入式 C++ 对象池优化串口数据解析性能](https://blog.csdn.net/stallion5632/article/details/140674036)\n\n## 1. 问题: 串口解析的 malloc 瓶颈\n\n在一个 ARM Cortex-A72 (1.5GHz) 的工业网关项目中，`perf` 火焰图显示串口数据解析函数占用了过多 CPU。瓶颈不在解析算法本身，而在 `ProtocolParse` 对象的频繁创建和销毁 -- 每收到一帧数据就 `new` 一个解析器，处理完毕 `delete`，10kHz 采样率意味着每秒 10000 次堆操作。\n\n对象池是解决这个问题的自然选择: 预分配一批解析器对象，用时取出，用完归还，避免反复 malloc/free。\n\n## 2. 对象池: 改进，但不是终点\n\n### 2.1 典型实现\n\n```cpp\n#include <queue>\n#include <mutex>\n#include <memory>\n\ntemplate<typename T>\nclass ObjectPool {\npublic:\n    std::shared_ptr<T> acquire() {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (!pool_.empty()) {\n            auto obj = std::move(pool_.front());\n            pool_.pop();\n            return obj;\n        }\n        return std::make_shared<T>();  // 池空时回退到堆分配\n    }\n\n    void release(std::shared_ptr<T> obj) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        pool_.push(std::move(obj));\n    }\n\nprivate:\n    std::queue<std::shared_ptr<T>> pool_;\n    std::mutex mutex_;\n};\n```\n\n### 2.2 效果\n\n将串口解析改为对象池后，100 万次解析的耗时从 ~1.2s 降至 ~0.5s，**提升约 60%**。对象池确实有效 -- 它消除了绝大多数 malloc/free 调用，减少了内存碎片，降低了分配器锁竞争。\n\n对于桌面应用或后端服务，这个优化幅度通常已经足够。但在嵌入式实时系统中，\"快了 60%\"不是终点，因为对象池引入了三项新的隐性成本。\n\n## 3. 三项隐性成本\n\n### 3.1 mutex: 即使无竞争也有代价\n\n```cpp\nstd::shared_ptr<T> acquire() {\n    std::lock_guard<std::mutex> lock(mutex_);  // 每次 acquire 都要锁\n    ...\n}\n```\n\n`std::mutex` 在 Linux 上基于 `futex`。无竞争时走 futex 快速路径 (用户态 CAS)，**但仍需要一次 atomic CAS + 函数调用开销**，在 ARM Cortex-A72 上约 **20-40ns**。有竞争时进入内核态等待，延迟跳升到 **数微秒**。\n\n对比:\n- SPSC 环形缓冲 `Push`/`Pop`: wait-free，~5-8ns，**最坏情况也是 O(1)**\n- 对象池 `acquire`/`release`: mutex 保护，~20-40ns 无竞争，**最坏情况取决于持锁线程**\n\n关键区别不在平均延迟，而在**最坏延迟的确定性**。对象池的最坏延迟取决于 mutex 竞争方持有锁的时间，这在 RTOS 中可能触发优先级反转。\n\n### 3.2 shared_ptr: 单向传递不需要引用计数\n\n```cpp\nauto obj = processorPool.acquire();   // refcount: 1 → 2 (pool → caller)\nprocessor->processData();\nprocessorPool.release(processor);      // refcount: 2 → 1 (caller → pool)\n```\n\n`shared_ptr` 的每次拷贝和销毁都执行 `atomic_fetch_add` / `atomic_fetch_sub`。在 ARM 上这是 `LDXR`/`STXR` 独占访问指令对，涉及 cache line 独占状态切换。\n\n但串口解析的数据流是**单向的**: 生产者 (I/O 线程) 构造数据 → 消费者 (解析线程) 处理数据 → 丢弃。对象所有权在任何时刻都是明确的单一持有者，**引用计数的共享语义完全多余**。\n\n替代方案: SPSC 环形缓冲中的数据以 `memcpy` 值语义传递，无引用计数，无原子操作。或者用 `std::variant` 直接内嵌在消息信封中，编译期确定大小，零间接指针。\n\n### 3.3 queue 动态增长: 内存预算不可控\n\n```cpp\nstd::queue<std::shared_ptr<T>> pool_;  // 底层是 std::deque\n```\n\n`std::queue` 的默认容器是 `std::deque`，其内部按块分配 (通常 512B/块)。当池中对象数量超过初始容量时，deque 会 **malloc 新的块**。池为空时 `make_shared<T>()` 直接回退到堆分配。\n\n这意味着:\n- 峰值内存占用无法在编译期预测\n- 运行时可能出现意外的 malloc (deque 扩展或 pool miss)\n- 内存碎片随时间累积\n\n对比: SPSC 环形缓冲在构造时分配 `T[BufferSize]` 数组，此后**零 malloc**。`BufferSize` 是模板参数，内存占用 `sizeof(T) * BufferSize` 在编译期精确确定。\n\n## 4. 改进路径: 从对象池到零分配\n\n| 方案 | 热路径 malloc | 同步机制 | 引用管理 | 内存可预测 | 适用场景 |\n|------|:-----------:|:-------:|:-------:|:---------:|---------|\n| 裸 malloc/free | 每次 | 无 | 无 | 不可预测 | 原型验证 |\n| **对象池** | 首次/miss | **mutex** | **shared_ptr** | **可增长** | 桌面/后端、连接池 |\n| Lock-free 池 (CAS) | 首次/miss | CAS 无锁 | unique_ptr | 可增长 | 多消费者共享 |\n| **预分配环形缓冲** | **零** | **wait-free** | **值语义** | **编译期固定** | **SPSC 数据通道** |\n| variant 消息总线 | 零 | CAS MPSC | 值语义 | 编译期固定 | 多生产者事件驱动 |\n\n从左到右，每一步都在消除上一步的一项成本:\n- 对象池消除了裸 malloc 的分配频率\n- Lock-free 池消除了 mutex\n- 环形缓冲消除了引用计数和动态增长\n- variant 消息总线将类型路由也纳入编译期\n\n对象池处于这个递进链的第二级 -- **比裸 malloc 好，但距离嵌入式热路径的要求还有三步**。\n\n## 5. 何时该用对象池\n\n对象池并非无用，它在以下场景仍然是合理选择:\n\n- **对象构造开销远大于 mutex 开销**: 如数据库连接 (TCP 握手 + 认证 ~ms)、GPU 纹理 (显存分配 ~us)，此时 mutex 的 ~40ns 可以忽略\n- **多消费者共享**: 多个线程需要获取同一类型的对象，生命周期跨越多个作用域，引用计数有实际意义\n- **对象数量动态变化**: 峰值不可预测，需要按需创建/回收\n\n反之，如果数据通道满足以下条件，应跳过对象池，直接使用预分配方案:\n\n- 单生产者单消费者 (或固定的多生产者单消费者)\n- 数据用完即弃，不共享\n- 吞吐量/延迟敏感 (> 1kHz)\n- 内存预算需要编译期确定\n\n## 6. 总结\n\n对象池是\"减少 malloc\"这条路上的第一个路标。它解决了最显眼的问题 (频繁堆分配)，但引入了三个更隐蔽的成本 (mutex 同步、原子引用计数、内存增长不可控)。在桌面和后端场景中，这三项成本通常可以接受；在嵌入式实时热路径上，它们是下一个需要消除的瓶颈。\n\n从对象池继续优化的方向是明确的: 用 CAS 或 wait-free 替代 mutex，用值语义替代引用计数，用固定数组替代动态容器。最终到达预分配环形缓冲和 variant 消息总线 -- 编译期确定全部资源，运行时零 malloc，最坏延迟 O(1)。\n\n## 参考资料\n\n1. [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- wait-free 环形缓冲的完整工程设计\n2. [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- variant 值语义 + 零堆分配流水线\n3. [嵌入式 C++ 对象池优化串口数据解析性能](https://blog.csdn.net/stallion5632/article/details/140674036) -- 本文改进的原始方案\n4. [使用 perf 查看热点函数](https://blog.csdn.net/stallion5632/article/details/138562957) -- perf 火焰图分析方法\n",
      "ctime": "1771552604",
      "mtime": "1771552604",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/parallel_matmul_benchmark.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469669422",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "C++17 并行矩阵乘法: 从单线程到多进程共享内存的性能实测",
      "brief_content": "以 512x512 矩阵乘法为载体，基于 newosp 基础设施库实测对比单线程、线程池、消息总线、多进程共享内存四种并行方案的性能差异，分析各方案在嵌入式 Linux 平台上的架构取舍与加速比。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 并行计算是嵌入式 Linux 平台上绑不开的话题。线程池、消息总线、共享内存 IPC -- 每种并行方案都有其适用场景和性能特征。本文以矩阵乘法为载体，基于 [newosp](https://github.com/DeguiLiu/newosp) 基础设施库，实测对比四种并行方案的性能差异，并分析各方案的架构取舍。\n\n项目地址: [https://gitee.com/liudegui/zmq_parallel_tasks](https://gitee.com/liudegui/zmq_parallel_tasks)\n\n## 1. 问题定义\n\n矩阵乘法 C = A x B 是经典的可并行化计算任务。对于 N x N 矩阵，C 的每一行可以独立计算，天然适合按行拆分的并行策略。\n\n我们选择 512 x 512 的 `float` 矩阵作为基准，原因:\n- 单线程耗时约 200ms，足够体现并行加速效果\n- 单个矩阵 1MB (512 x 512 x 4B)，三个矩阵 3MB，不会触发内存瓶颈\n- 行粒度任务 (512 个) 远大于线程数 (64)，负载均衡充分\n\n## 2. 公共基础: 零拷贝任务设计\n\n传统做法是用 `std::ostringstream` 序列化任务数据，这在嵌入式场景下是不可接受的。我们的设计原则: POD 结构体 + `memcpy`，零堆分配。\n\n```cpp\n// matrix_task.hpp -- 编译期维度，POD 类型，trivially_copyable\n\nstatic constexpr uint32_t kDim = MATRIX_DIM;  // CMake 注入\n\nusing Row    = std::array<float, kDim>;\nusing Matrix = std::array<Row, kDim>;\n\nstruct RowTask {\n  uint32_t row_index;  // 4 字节，仅传递行号\n};\n```\n\n关键设计决策:\n\n- `RowTask` 只有 4 字节的行号，不携带矩阵数据。A/B 矩阵通过全局变量 (线程方案) 或共享内存 (进程方案) 共享，真正的零拷贝。\n- `std::array` 替代裸数组，保持 `trivially_copyable` 的同时获得值语义。\n- `MATRIX_DIM` 通过 CMake `target_compile_definitions` 注入，编译期确定维度，避免运行时分支。\n\n行计算函数:\n\n```cpp\ninline void ComputeRow(const Row& a_row, const Matrix& B, Row& c_row) {\n  for (uint32_t j = 0; j < kDim; ++j) {\n    float sum = 0.0F;\n    for (uint32_t k = 0; k < kDim; ++k) {\n      sum += a_row[k] * B[k][j];\n    }\n    c_row[j] = sum;\n  }\n}\n```\n\n## 3. 方案一: 单线程基线\n\n```cpp\nauto t0 = std::chrono::high_resolution_clock::now();\nfor (uint32_t i = 0; i < kDim; ++i) {\n  ComputeRow(g_A[i], g_B, g_C[i]);\n}\nauto t1 = std::chrono::high_resolution_clock::now();\n```\n\n没有任何框架开销，纯计算。这是所有并行方案的参照基准。\n\n结果: 218 ms。\n\n## 4. 方案二: std::thread + 原子工作窃取\n\n最轻量的并行方案，不依赖任何框架:\n\n```cpp\nstatic std::atomic<uint32_t> g_next_row{0};\n\nauto worker = [&]() {\n  while (true) {\n    uint32_t row = g_next_row.fetch_add(1U, std::memory_order_relaxed);\n    if (row >= kDim) break;\n    ComputeRow(g_A[row], g_B, g_C[row]);\n  }\n};\n\nstd::vector<std::thread> threads;\nfor (uint32_t i = 0; i < num_workers; ++i) {\n  threads.emplace_back(worker);\n}\nfor (auto& t : threads) t.join();\n```\n\n核心思路: 一个原子计数器 `g_next_row`，每个线程通过 `fetch_add` 抢占下一行。没有锁、没有队列、没有消息传递，开销仅为一次原子操作。\n\n`memory_order_relaxed` 足够，因为:\n- 每个线程写不同的行 (无数据竞争)\n- A/B 矩阵在线程启动前已初始化 (happens-before 由 `thread::thread()` 保证)\n\n结果: 8.6 ms，25.4x 加速。\n\n## 5. 方案三: newosp WorkerPool\n\nnewosp 的 `WorkerPool` 是一个基于无锁 MPSC 总线的工作线程池，支持类型安全的消息分发:\n\n```cpp\nusing Payload = std::variant<RowTask>;\n\nosp::WorkerPoolConfig cfg;\ncfg.name = \"matmul\";\ncfg.worker_num = num_workers;\n\nosp::WorkerPool<Payload> pool(cfg);\npool.RegisterHandler<RowTask>(\n    [](const RowTask& task, const osp::MessageHeader& /*hdr*/) {\n      ComputeRow(g_A[task.row_index], g_B, g_C[task.row_index]);\n      g_completed.fetch_add(1U, std::memory_order_release);\n    });\n\npool.Start();\n\nfor (uint32_t i = 0; i < kDim; ++i) {\n  RowTask task{i};\n  while (!pool.Submit(std::move(task))) {\n    std::this_thread::yield();\n  }\n}\n\n// 等待完成\nwhile (g_completed.load(std::memory_order_acquire) < kDim) {\n  std::this_thread::yield();\n}\npool.Shutdown();\n```\n\nWorkerPool 的内部架构:\n1. 主线程调用 `Submit()` 将任务推入无锁 MPSC 环形缓冲\n2. 内部调度线程批量取出消息，分发到 N 个工作线程\n3. 工作线程通过 `RegisterHandler<T>` 注册的回调处理任务\n\n相比裸 `std::thread`，WorkerPool 多了一层消息总线的间接调用，但提供了:\n- 类型安全的消息分发 (`std::variant` + `RegisterHandler<T>`)\n- 自适应退避策略 (AdaptiveBackoff: spin -> yield -> sleep)\n- 生命周期管理 (Start/Shutdown)\n\n结果: 17.4 ms，12.5x 加速。\n\n## 6. 方案四: 多进程共享内存 (零拷贝)\n\n这是最有意思的方案。利用 newosp 的 `SharedMemorySegment` 实现跨进程零拷贝并行:\n\n```cpp\n// 共享内存布局: 三个矩阵 + 原子工作窃取计数器\nstruct ShmMatmulState {\n  Matrix   A;\n  Matrix   B;\n  Matrix   C;\n  std::atomic<uint32_t> next_row;\n  std::atomic<uint32_t> completed;\n  uint32_t total_rows;\n  uint32_t padding[13];  // 缓存行对齐\n};\n```\n\nMaster 进程:\n\n```cpp\nauto shm = osp::SharedMemorySegment::CreateOrReplace(\n    \"pt_matmul_state\", sizeof(ShmMatmulState));\nauto* state = static_cast<ShmMatmulState*>(shm.value().Data());\n\n// 初始化矩阵到共享内存\nRandomFill(state->A, 42U);\nRandomFill(state->B, 137U);\n\n// fork N 个 worker 进程\nfor (uint32_t i = 0; i < num_workers; ++i) {\n  const char* argv[] = {self_path, \"--worker\", nullptr};\n  osp::SubprocessConfig cfg;\n  cfg.argv = argv;\n  osp::Subprocess sub;\n  sub.Start(cfg);\n  workers.push_back(std::move(sub));\n}\n```\n\nWorker 进程:\n\n```cpp\nauto shm = osp::SharedMemorySegment::Open(\"pt_matmul_state\");\nauto* state = static_cast<ShmMatmulState*>(shm.value().Data());\n\n// 与线程方案相同的工作窃取模式\nwhile (true) {\n  uint32_t row = state->next_row.fetch_add(1U, std::memory_order_relaxed);\n  if (row >= state->total_rows) break;\n  ComputeRow(state->A[row], state->B, state->C[row]);\n  state->completed.fetch_add(1U, std::memory_order_release);\n}\n```\n\n这个方案的精妙之处:\n- 没有序列化/反序列化: 矩阵直接在共享内存中，所有进程直接读写\n- 没有 IPC 通道: 不需要管道、socket、消息队列，原子变量就是同步机制\n- 进程隔离: 任何一个 worker 崩溃不影响其他 worker 和 master\n- 与线程方案代码几乎相同: 只是把全局变量换成了共享内存指针\n\n结果: 17.4 ms，12.5x 加速。\n\n## 7. 方案五: ZeroMQ (反面教材)\n\n为了验证\"消息传递\"在细粒度并行任务中的局限性，我们实现了一个基于 ZeroMQ `inproc://` 协议的版本 (`examples/zmq_matmul.cpp`)。\n\n架构:\n- Master 线程创建 PUSH socket 分发任务\n- Worker 线程创建 PULL socket 接收任务\n- 每个任务包含 4 字节的行号 (RowTask)\n\n虽然这也是\"零拷贝\"（指数据载荷小），但 ZMQ 框架本身的开销巨大:\n1. **消息封装**: 每个任务需要创建一个 `zmq_msg_t`\n2. **锁竞争**: PUSH/PULL socket 内部有互斥锁\n3. **信号机制**: 线程唤醒依赖 eventfd/pipe，比原子自旋慢得多\n\n**测试结果 (128x128 矩阵):**\n- 单线程基线: 2.62 ms\n- ZeroMQ: **42.18 ms** (比单线程慢 16 倍!)\n\n这是一个经典的\"粒度错误\"。对于每行仅需几微秒的计算任务，引入一个重量级的消息中间件是致命的。\n\n## 8. 性能对比\n\n测试环境: 512 x 512 float 矩阵 (ZMQ 为 128x128 推算)，64 线程/进程，Release -O3。\n\n| 方案 | 耗时 | 加速比 | 框架开销 |\n|------|------|--------|----------|\n| 单线程基线 | 218 ms | 1.00x | 无 |\n| std::thread + 原子窃取 | 8.6 ms | 25.4x | 极低 (一次 atomic) |\n| newosp WorkerPool | 17.4 ms | 12.5x | 中等 (MPSC 总线分发) |\n| newosp SHM 多进程 | 17.4 ms | 12.5x | 中等 (fork + shm 映射) |\n| ZeroMQ (inproc) | >3000 ms* | <0.1x | 极高 (消息对象 + 锁 + 信号) |\n\n### 8.1 为什么 WorkerPool 比裸线程慢?\n\nWorkerPool 的 17.4ms vs 裸线程的 8.6ms，差距来自架构差异:\n\n- 裸线程: 每个线程直接 `fetch_add` 抢行，零间接调用\n- WorkerPool: 主线程 -> MPSC 队列 -> 调度线程 -> 工作线程，多了两次上下文切换\n\n但 WorkerPool 的价值不在于极致性能，而在于:\n- 类型安全的消息分发 (不同任务类型走不同 handler)\n- 自适应退避 (低负载时降低 CPU 占用)\n- 生产级生命周期管理\n\n对于矩阵乘法这种\"所有任务类型相同、计算密集\"的场景，裸线程是最优解。但在实际嵌入式系统中，一个线程池要处理多种异构任务，WorkerPool 的类型安全分发就体现出价值了。\n\n### 8.2 SHM 多进程的开销分析\n\nSHM 方案与 WorkerPool 耗时相同 (17.4ms)，但开销来源不同:\n- `fork()` + `exec()` 创建进程: 约 1-2ms\n- `shm_open()` + `mmap()` 映射共享内存: 约 0.1ms\n- 计算阶段: 与裸线程相同的原子工作窃取\n\n进程创建的一次性开销被 512 行的计算量摊薄后，与 WorkerPool 的持续性总线开销恰好持平。\n\nSHM 方案的真正优势在大规模系统中:\n- 进程隔离: worker 崩溃不影响 master\n- 独立部署: 每个 worker 可以是不同的二进制\n- 资源隔离: 每个进程有独立的地址空间、文件描述符表\n\n## 9. 关于 AsyncBus 的补充说明\n\nnewosp 的 `AsyncBus` 是一个无锁 MPSC (多生产者单消费者) 消息总线，设计目标是事件驱动的异步通信，而非并行计算。\n\n我们也实现了 AsyncBus 版本 (`osp_bus_matmul.cpp`)，但其性能接近单线程 (约 220ms)。原因很直接: MPSC 的 \"单消费者\" 意味着所有消息最终由一个线程处理，无法实现真正的并行计算。\n\n这不是 AsyncBus 的缺陷，而是设计目标不同:\n- AsyncBus: 适合事件驱动架构 (传感器数据 -> 处理 -> 输出)\n- WorkerPool: 适合并行计算 (同一任务的多实例并行)\n\n选择正确的工具解决正确的问题。\n\n## 10. 构建与运行\n\n```bash\nmkdir build && cd build\n# 开启 ZMQ 示例 (需要 libzmq)\ncmake .. -DCMAKE_BUILD_TYPE=Release -DMATRIX_DIM=512 -DBUILD_ZMQ_EXAMPLE=ON\nmake -j$(nproc)\n\n# 统一基准测试\n./bench_matmul\n\n# 单独运行\n./baseline_matmul\n./osp_thread_matmul\n./osp_shm_matmul\n./zmq_matmul\n```\n\n依赖: newosp 和 libzmq 通过 CMake FetchContent 自动拉取，无需手动安装。\n\n## 11. 总结\n\n四种方案的适用场景:\n\n| 场景 | 推荐方案 |\n|------|----------|\n| 计算密集、同构任务 | std::thread + 原子工作窃取 |\n| 异构任务、需要类型安全分发 | newosp WorkerPool |\n| 需要进程隔离、独立部署 | newosp SHM 多进程 |\n| 跨语言、分布式网络通信 | ZeroMQ |\n| 事件驱动、异步通信 | newosp AsyncBus |\n\n并行方案的选择不是\"哪个最快\"，而是\"哪个最适合你的架构约束\"。\n- **裸线程**: 最快但最脆弱\n- **WorkerPool**: 平衡了性能和工程质量\n- **SHM 多进程**: 提供了最强的隔离性\n- **ZeroMQ**: 在细粒度计算任务上表现糟糕，不要滥用\n\n在嵌入式 Linux 系统中，这三种方案往往共存: WorkerPool 处理节点内的并行任务，SHM 实现节点间的零拷贝通信，AsyncBus 驱动整体的事件流。newosp 提供了统一的基础设施，让这些方案可以无缝组合。\n",
      "ctime": "1771552607",
      "mtime": "1771552607",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/perf_lock_contention_diagnosis.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853750282",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640385980137480
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "perf lock 锁竞争诊断: 从 futex 原理到生产定位实战",
      "brief_content": "以 perf lock 为主线的锁竞争诊断实战。从 Linux mutex 的三条路径（fast/mid/slow）和 futex 内核机制出发，详解 perf lock contention 的每个",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [嵌入式系统死锁防御: 从有序锁到无锁架构的工程实践](../deadlock_prevention/) -- 架构层面如何避免锁问题\n> - [多线程死锁与优先级反转实战](../deadlock_priority_inversion_practice/) -- 死锁与优先级反转的代码级修复\n> - [锁竞争基准测试: Spinlock vs Mutex vs ConcurrentQueue](../lock_contention_benchmark/) -- 三种同步策略的性能实测\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- 从有锁迁移到无锁的理论基础\n>\n> 参考:\n> - 原文: [perf lock 诊断锁竞争](https://blog.csdn.net/stallion5632/article/details/143665002)\n> - 原文: [Linux perf 工具安装与使用](https://blog.csdn.net/stallion5632/article/details/138562957)\n> - [Brendan Gregg: perf Examples](https://www.brendangregg.com/perf.html)\n> - [kernel.org: Mutex design](https://www.kernel.org/doc/html/latest/locking/mutex-design.html)\n> - Ulrich Drepper, \"Futexes Are Tricky\"\n\n---\n\n## 1. 为什么需要量化锁竞争\n\n多线程程序中，锁竞争是最常见的性能杀手。但它的表现形式很隐蔽: 程序不会崩溃，CPU 使用率看起来也正常（甚至很高），只是**吞吐量不达标或延迟偏高**。\n\n问题在于: 你无法通过肉眼阅读代码来判断锁竞争的严重程度。一把锁是否是瓶颈，取决于:\n\n1. 有多少线程同时竞争它\n2. 临界区代码执行了多久\n3. 竞争发生的频率\n\n这三个维度必须用**运行时工具量化**，而非静态分析。`perf lock` 正是做这件事的工具。\n\n---\n\n## 2. Linux mutex 的三条路径\n\n在深入 perf 输出之前，需要理解 Linux `pthread_mutex_t` 底层的工作机制。glibc 的 mutex 实现基于 `futex` 系统调用，分为三条路径:\n\n```mermaid\ngraph TD\n    A[pthread_mutex_lock] --> B{futex 值检查<br/>用户空间 CAS}\n    B -->|CAS 成功<br/>锁空闲| C[Fast Path<br/>直接获取, 零系统调用]\n    B -->|CAS 失败<br/>锁被持有| D{自适应自旋<br/>Adaptive Spinning}\n    D -->|持有者仍在 CPU<br/>自旋等到释放| E[Mid Path<br/>用户空间自旋获取]\n    D -->|持有者不在 CPU<br/>或自旋超限| F[Slow Path<br/>futex_wait 内核休眠]\n    F --> G[被 futex_wake 唤醒]\n    G --> B\n\n    style C fill:#c8e6c9\n    style E fill:#fff9c4\n    style F fill:#ffcdd2\n```\n\n### Fast Path -- 无竞争\n\n锁空闲时，`pthread_mutex_lock` 通过一次用户空间的 CAS（Compare-And-Swap）原子操作直接获取锁。**不进入内核、不触发系统调用**。延迟约 **10-25 ns**。\n\n这是绝大多数锁操作应该走的路径。如果你的程序设计良好（锁粒度足够细、线程不会同时竞争同一把锁），几乎所有锁操作都走 fast path。\n\n### Mid Path -- 自适应自旋\n\n锁被持有时，如果持有者仍在某个 CPU 上运行（没被调度走），当前线程会在用户空间**短暂自旋**等待。理由是: 持有者很快会释放锁，自旋几微秒比进入内核休眠再唤醒更快。\n\nglibc 的 `PTHREAD_MUTEX_ADAPTIVE_NP` 类型或内核 mutex 的 optimistic spinning 都实现了这一策略。\n\n### Slow Path -- 内核休眠\n\n自旋等不到锁释放时，线程调用 `futex(FUTEX_WAIT)` 陷入内核，进入休眠队列。锁释放者调用 `futex(FUTEX_WAKE)` 唤醒等待者。\n\n这条路径涉及:\n- 两次用户态/内核态切换（sleep + wake）\n- 两次上下文切换（让出 CPU + 被唤醒恢复）\n- 内核 futex hash bucket 的自旋锁竞争\n\n**perf lock 追踪的就是 slow path**。`lock:contention_begin` 在线程进入等待时触发，`lock:contention_end` 在获取到锁时触发，两者之间的时间差就是 `wait time`。\n\n### 三条路径的性能差异\n\n| 路径 | 延迟 | CPU 开销 | perf lock 可见 |\n|------|------|----------|---------------|\n| Fast Path | 10-25 ns | 一次 CAS | 不可见（无竞争） |\n| Mid Path | 0.1-10 us | 自旋消耗 CPU | 不可见（未进入内核） |\n| Slow Path | 1-100+ us | 上下文切换 | **可见**（contention 事件） |\n\n这意味着 `perf lock` 报告的 `contended` 次数是**保守下界** -- 实际竞争可能更多，但通过 mid path 自旋解决了，没有进入内核。\n\n---\n\n## 3. perf lock 基本用法\n\n### 3.1 两种模式\n\n| 模式 | 命令 | 原理 | 内核要求 |\n|------|------|------|----------|\n| tracepoint | `perf lock record` + `perf lock report` | 内核 tracepoint 事件 | `CONFIG_LOCK_STAT=y` |\n| BPF | `perf lock contention -b` | eBPF 程序在内核中采集 | 5.19+, BTF 支持 |\n\n**推荐 BPF 模式**（`-b`）: 开销更低（约 2-5%），不需要 `CONFIG_LOCK_STAT`，不生成巨大的 perf.data 文件。\n\n### 3.2 快速扫描\n\n```bash\n# BPF 模式: 实时采集 10 秒，显示竞争最严重的 20 把锁\nsudo perf lock contention -ab -E 20 -- sleep 10\n\n# 或 attach 到运行中的进程\nsudo perf lock contention -ab -E 20 -p $(pidof my_server) -- sleep 10\n```\n\n参数说明:\n\n| 参数 | 作用 |\n|------|------|\n| `-a` | 系统级采集（所有 CPU） |\n| `-b` | 使用 BPF 模式 |\n| `-E 20` | 只显示 top 20 |\n| `-p PID` | 只监控指定进程 |\n| `-- sleep 10` | 采集 10 秒 |\n\n### 3.3 传统模式\n\n如果内核版本 < 5.19 或不支持 BPF:\n\n```bash\n# 录制\nsudo perf lock record -g ./my_program\n\n# 报告\nsudo perf lock report\n```\n\n需要确认内核配置:\n\n```bash\n# 检查 tracepoint 是否存在\nls /sys/kernel/debug/tracing/events/lock/\n# 应看到: contention_begin  contention_end\n```\n\n---\n\n## 4. 报告解读\n\n### 4.1 输出示例\n\n```\n contended   total wait     max wait     avg wait         type   caller\n     38764       4.77 s      18.5 us      1.23 us        mutex   heavy_worker+0x42\n      4123      117.5 ms       4.2 us       285 ns        mutex   light_worker+0x28\n        42       86.3 us       3.1 us       2.1 us     spinlock   rcu_read_lock+0x1c\n```\n\n### 4.2 字段含义\n\n| 字段 | 含义 | 重要性 |\n|------|------|--------|\n| **contended** | 进入 slow path 的次数（即 futex_wait 发生的次数） | 竞争频率 |\n| **total wait** | 所有竞争等待时间之和 | **最关键** -- 直接反映性能损失 |\n| **max wait** | 单次最大等待时间 | 影响尾延迟（P99/P999） |\n| **avg wait** | 平均每次等待时间 | 反映临界区长度 |\n| **type** | 锁类型: mutex / spinlock / rwlock / rwsem | 指导优化方向 |\n| **caller** | 竞争发生的代码位置 | 直接定位问题代码 |\n\n### 4.3 如何判断严重程度\n\n**看 total wait**，它是最直观的指标: 程序运行 30 秒，某把锁的 total wait 是 15 秒，意味着所有线程**累计浪费了 15 秒在等这把锁**。\n\n进一步细分:\n\n| 指标组合 | 含义 | 行动 |\n|----------|------|------|\n| contended 高 + avg wait 低 | 竞争频繁但每次很短 | 锁粒度可能太粗，考虑拆锁或无锁 |\n| contended 低 + avg wait 高 | 竞争不频繁但每次很久 | 临界区太长，I/O 或阻塞操作在锁内 |\n| contended 高 + avg wait 高 | 严重瓶颈 | 必须重新设计: 无锁队列/数据分片 |\n| max wait >> avg wait | 偶发长尾 | 检查是否有优先级反转或调度抖动 |\n\n---\n\n## 5. 进阶: 调用栈与锁持有者分析\n\n### 5.1 调用栈 -- 谁在等锁\n\n```bash\n# 显示竞争的调用栈 (默认 8 层)\nsudo perf lock contention -ab --max-stack=16 -- sleep 10\n```\n\n输出:\n\n```\n contended   total wait     max wait     avg wait    type   caller\n\n     38764       4.77 s      18.5 us      1.23 us   mutex   heavy_worker+0x42\n                  4.12 s                                       pthread_mutex_lock\n                                                                futex_wait\n                                                                do_futex\n                                                                futex_wait_queue\n                658.2 ms                                       pthread_mutex_lock\n                                                                futex_wake\n                                                                wake_up_q\n```\n\n这告诉你:\n\n- **86% 的等待**（4.12s / 4.77s）来自 `futex_wait` -- 线程真的休眠了\n- **14% 的等待**（658ms）来自 `futex_wake` -- 唤醒路径本身的竞争\n\n`futex_wake` 路径出现竞争意味着**内核 futex hash bucket 的自旋锁也在打架** -- 这是高竞争 mutex 的二阶效应，说明竞争已经非常严重。\n\n### 5.2 锁持有者 -- 谁在持锁\n\n`-o` 选项（内核 6.2+）可以显示**锁的持有者**，而非等待者:\n\n```bash\nsudo perf lock contention -abo -- sleep 10\n```\n\n```\n contended   total wait     avg wait    type   caller (owner)\n\n     38764       4.77 s      1.23 us   mutex   heavy_worker+0x15 (持有者)\n                                                  compute_result+0x8a\n                                                  write_log+0x22\n```\n\n这直接回答「谁在持有锁导致别人等待」。如果持有者的调用栈中出现 `write_log`、`malloc`、`read` 等操作，说明**在锁内做了不应该做的事**。\n\n### 5.3 按锁类型过滤\n\n```bash\n# 只看 mutex 竞争\nsudo perf lock contention -ab -Y mutex -- sleep 10\n\n# 只看 spinlock 竞争\nsudo perf lock contention -ab -Y spinlock -- sleep 10\n\n# 只看 rwlock/rwsem 竞争\nsudo perf lock contention -ab -Y rwsem -- sleep 10\n```\n\n不同类型竞争的典型模式:\n\n| 类型 | 高竞争的表现 | 优化方向 |\n|------|------------|----------|\n| mutex | contended 高, avg wait 微秒级 | 缩短临界区 / 无锁队列 |\n| spinlock | On-CPU 火焰图中 `spin_lock` 占比高 | 改 mutex（允许休眠）或无锁 |\n| rwsem (读写锁) | 写端 contended 高 | 检查读写比例，考虑 RCU |\n\n### 5.4 按线程分组\n\n```bash\n# -t 选项: 按线程分组统计\nsudo perf lock contention -abt -- sleep 10\n```\n\n```\n contended   total wait     avg wait   comm            pid\n\n     12453       1.58 s      1.27 us   worker-3       1237\n     11209       1.42 s      1.27 us   worker-1       1235\n     10302       1.21 s      1.17 us   worker-2       1236\n      4800       560 ms      1.17 us   worker-0       1234\n```\n\n如果某个线程的 contended 远高于其他线程，说明它的代码路径比别人更频繁地触碰热锁。\n\n---\n\n## 6. 实战案例: 从 95% 竞争率到零锁热路径\n\n### 6.1 背景\n\nIPC 服务器，8 个工作线程通过共享队列分发消息，吞吐量仅为预期的 30%。\n\n### 6.2 Step 1: perf lock 全局扫描\n\n```bash\nsudo perf lock contention -ab -E 10 -p $(pidof ipc_server) -- sleep 30\n```\n\n```\n contended   total wait     max wait     avg wait    type   caller\n\n   7891234      16.97 s      42.3 us      2.15 us   mutex   dispatch_message+0x42\n     12300       2.21 ms       4.1 us       180 ns   mutex   register_callback+0x28\n       856       1.82 ms      18.7 us       2.1 us   rwsem   config_read+0x1c\n```\n\n**发现**: `dispatch_message` 的 mutex 占 total wait 的 99.9%。竞争次数 789 万次，avg wait 2.15 us。\n\n### 6.3 Step 2: 调用栈定位\n\n```bash\nsudo perf lock contention -ab --max-stack=12 -p $(pidof ipc_server) -- sleep 10\n```\n\n```\n   7891234      16.97 s      2.15 us   mutex   dispatch_message+0x42\n                 14.62 s                          pthread_mutex_lock\n                                                    futex_wait\n                                                    futex_wait_queue\n                  2.35 s                          pthread_mutex_lock\n                                                    futex_wake\n                                                    wake_up_q\n```\n\n`futex_wake` 路径占 14% -- 唤醒本身也在竞争，说明 futex hash bucket 拥挤。\n\n### 6.4 Step 3: 锁持有者分析\n\n```bash\nsudo perf lock contention -abo -p $(pidof ipc_server) -- sleep 10\n```\n\n```\n contended   total wait    type   caller (owner)\n\n   7891234      16.97 s   mutex   dispatch_message+0x15\n                                    deque_push_back+0x2a\n                                    format_log+0x18     <-- 在锁内写日志!\n                                    snprintf+0x45\n```\n\n**根因**: `format_log` 在持有 mutex 的临界区内调用了 `snprintf` 格式化日志。`snprintf` 延迟 1-3 us，直接拉长了临界区。\n\n### 6.5 Step 4: 修复\n\n三层修复:\n\n```\n修复 1 (快速): 把 format_log 移到锁外\n  -> contended 下降 60%, avg wait 从 2.15us 降到 0.8us\n\n修复 2 (中期): 共享队列从 mutex + deque 改为无锁 MPSC 环形缓冲区\n  -> contended 降到 0, 热路径零互斥\n\n修复 3 (架构): 为每个 worker 分配独立 SPSC 队列\n  -> 消除 worker 间竞争\n```\n\n### 6.6 验证\n\n```bash\n# 修复后再次扫描\nsudo perf lock contention -ab -E 10 -p $(pidof ipc_server) -- sleep 30\n```\n\n```\n contended   total wait     max wait     avg wait    type   caller\n\n        12       1.82 ms      18.7 us       152 us   rwsem   config_read+0x1c\n         3        420 ns        180 ns       140 ns   mutex   register_callback+0x28\n```\n\n热路径的 mutex 竞争完全消失。\n\n```\n优化前: contended=7,891,234  total_wait=16.97s  吞吐=85K msg/s\n优化后: contended=0          total_wait=0        吞吐=310K msg/s (3.6x)\n```\n\n```mermaid\ngraph LR\n    subgraph \"优化前: 共享 mutex\"\n        A1[8 worker] -->|竞争| B1[mutex<br/>contended 95%]\n        B1 --> C1[deque + format_log]\n    end\n\n    subgraph \"优化后: 无锁分发\"\n        A2[N 生产者] -->|CAS| B2[MPSC Ring]\n        B2 -->|round-robin| C2[SPSC 0]\n        B2 --> C3[SPSC 1]\n        B2 --> C4[SPSC N]\n    end\n\n    style B1 fill:#ffcdd2\n    style B2 fill:#c8e6c9\n```\n\n---\n\n## 7. 常见竞争模式与优化对照表\n\n| perf lock 表现 | 根因 | 优化方案 |\n|---------------|------|----------|\n| contended 高 + avg wait 低（< 1us） | 锁粒度太粗，频繁短竞争 | 拆锁（per-bucket / per-CPU）或无锁 |\n| contended 低 + avg wait 高（> 10us） | 临界区内有 I/O / malloc / 日志 | 移出锁外 + Collect-Release-Execute |\n| contended 高 + avg wait 高 | 严重设计问题 | 无锁队列（MPSC/SPSC）彻底替代 |\n| spinlock type + 高 contended | 临界区持有时间超过自旋收益 | 改用 mutex（允许休眠） |\n| rwsem 写端高竞争 | 写操作频繁，读写锁退化 | 改用 mutex 或 RCU |\n| max wait >> 10x avg wait | 偶发调度抖动或优先级反转 | SCHED_FIFO + CPU 隔离 + PRIO_INHERIT |\n| futex_wake 路径占比 > 20% | hash bucket 竞争（二阶效应） | 竞争已极严重，必须无锁化 |\n\n---\n\n## 8. 补充: Off-CPU 火焰图验证\n\n`perf lock` 给出了精确的锁竞争数值。如果需要**可视化**线程在等什么，Off-CPU 火焰图是最佳补充:\n\n```bash\n# 需要 bcc-tools\nsudo offcputime-bpfcc -df -p $(pidof my_server) 30 > stacks.txt\n\n# 生成火焰图\nflamegraph.pl --color=io --title=\"Off-CPU\" --countname=us \\\n    stacks.txt > offcpu.svg\n```\n\nOff-CPU 火焰图中 `futex_wait` 越宽，说明锁等待消耗的时间越多 -- 与 `perf lock` 的 `total wait` 相互印证。\n\n---\n\n## 9. 命令速查\n\n```bash\n# 快速扫描 top 20 锁竞争 (BPF 模式, 推荐)\nsudo perf lock contention -ab -E 20 -- sleep 10\n\n# 只看 mutex\nsudo perf lock contention -ab -Y mutex -- sleep 10\n\n# 带调用栈\nsudo perf lock contention -ab --max-stack=16 -- sleep 10\n\n# 锁持有者分析 (6.2+)\nsudo perf lock contention -abo -- sleep 10\n\n# 按线程分组\nsudo perf lock contention -abt -- sleep 10\n\n# 传统模式 (旧内核)\nsudo perf lock record -g -- ./my_program\nsudo perf lock report\n\n# Off-CPU 火焰图辅助\nsudo offcputime-bpfcc -df -p PID 30 > stacks.txt\nflamegraph.pl --color=io --countname=us stacks.txt > offcpu.svg\n```\n",
      "ctime": "1771552611",
      "mtime": "1771552611",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/perf_performance_analysis.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469685806",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640385980137480
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "perf 性能分析实战: 从硬件计数器到火焰图的完整工作流",
      "brief_content": "perf 是 Linux 内核自带的性能分析利器，但多数开发者只停留在 perf top 层面。本文以嵌入式 ARM-Linux 实战为背景，从 PMU 硬件计数器原理出发，系统讲解 perf sta",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/) -- perf lock contention 的深度使用\n> - [锁竞争基准测试: Spinlock vs Mutex vs ConcurrentQueue](../lock_contention_benchmark/) -- 有锁与无锁的性能实测\n> - [C/C++ 系统级性能优化](../system_level_performance_optimization/) -- 从编译器到架构的优化实践\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- perf 定位瓶颈后的无锁迁移方向\n>\n> 参考:\n> - [Brendan Gregg: perf Examples](https://www.brendangregg.com/perf.html)\n> - [kernel.org: perf-stat](https://man7.org/linux/man-pages/man1/perf-stat.1.html)\n> - [Flame Graphs](https://www.brendangregg.com/flamegraphs.html)\n\n---\n\n## 1. perf 工具体系\n\n### 1.1 什么是 perf\n\nperf 是 Linux 内核内置的性能分析框架，通过硬件 PMU（Performance Monitoring Unit）计数器和内核 tracepoint 采集性能数据。它不是一个单一工具，而是一组子命令:\n\n| 子命令 | 功能 | 典型场景 |\n|--------|------|----------|\n| `perf stat` | 统计硬件/软件事件计数 | IPC、缓存命中率、分支预测率 |\n| `perf record` | 采样调用栈 | 定位 CPU 热点函数 |\n| `perf report` | 分析采样数据 | 查看热点函数和调用链 |\n| `perf top` | 实时热点 | 快速查看当前最耗 CPU 的函数 |\n| `perf sched` | 调度事件分析 | 线程唤醒延迟、调度器行为 |\n| `perf lock` | 锁竞争分析 | mutex/spinlock 竞争定位 |\n| `perf probe` | 动态插桩 | 自定义检测点 |\n| `perf script` | 导出原始事件 | 火焰图生成、自定义分析 |\n\n### 1.2 PMU 硬件计数器\n\n性能分析的数据来源是 CPU 内部的 PMU 寄存器。每个 CPU 核心有若干个可编程计数器，能同时监控有限数量的事件。\n\n```\n+------------------------------------------+\n|              CPU Core                     |\n|  +------+  +------+  +------+  +------+  |\n|  | PMC0 |  | PMC1 |  | PMC2 |  | PMC3 |  |\n|  +------+  +------+  +------+  +------+  |\n|  cycles    instr    L1-miss  br-miss     |\n|                                           |\n|  PMU Controller:                          |\n|  - 溢出中断 → perf 采样                    |\n|  - 可编程事件选择器                         |\n+------------------------------------------+\n```\n\nARM Cortex-A53/A72 通常有 6 个可编程 PMU 计数器 + 1 个 cycle 计数器。当监控事件数超过物理计数器数量时，perf 会自动**多路复用**（multiplexing）: 轮流采集不同事件，用统计方法估算总计数。\n\n查看当前平台支持的事件:\n\n```bash\n# 列出所有可用事件\nperf list\n\n# 只看硬件事件\nperf list hw\n\n# 只看缓存相关事件\nperf list cache\n\n# ARM 平台查看 raw PMU 事件\nperf list --raw-dump pmu\n```\n\n### 1.3 采样 vs 计数\n\nperf 有两种工作模式:\n\n| 模式 | 原理 | 工具 | 开销 |\n|------|------|------|------|\n| **计数** (counting) | PMU 计数器直接累加，程序结束时读取 | `perf stat` | 极低 (~1%) |\n| **采样** (sampling) | 每 N 个事件触发一次中断，记录调用栈 | `perf record` | 中等 (~5-15%) |\n\n计数模式几乎没有运行时开销，适合生产环境。采样模式需要中断处理和栈回溯，有一定开销但能定位具体函数。\n\n---\n\n## 2. 编译安装 perf\n\n### 2.1 嵌入式平台为什么需要手动编译\n\n嵌入式 ARM-Linux 系统通常使用交叉编译的定制内核，发行版自带的 perf 版本与目标内核不匹配，导致:\n\n- tracepoint 事件不可用\n- `perf lock contention` 等依赖 BPF 的功能报错\n- PMU 事件名称不识别\n\n正确做法是从**目标内核源码**编译匹配版本的 perf。\n\n### 2.2 从内核源码编译\n\n```bash\n# 1. 获取内核源码 (与目标设备内核版本匹配)\nuname -r\n# 例: 5.10.110\n\n# 2. 安装编译依赖\nsudo apt install -y flex bison libelf-dev libdw-dev \\\n    libunwind-dev libslang2-dev libbabeltrace-dev \\\n    libzstd-dev libtraceevent-dev python3-dev\n\n# 3. 进入 perf 目录\ncd linux-5.10.110/tools/perf\n\n# 4. 编译\nmake -j$(nproc) LDFLAGS=-static\n\n# 5. 验证\n./perf version\n# perf version 5.10.110\n\n# 6. 安装到系统\nsudo cp perf /usr/local/bin/\n```\n\n**交叉编译**（ARM 目标板）:\n\n```bash\n# 设置交叉编译工具链\nexport CROSS_COMPILE=aarch64-linux-gnu-\nexport ARCH=arm64\n\n# 编译\nmake -j$(nproc) LDFLAGS=-static\n\n# 拷贝到目标板\nscp perf root@target:/usr/local/bin/\n```\n\n### 2.3 依赖库说明\n\n| 依赖 | 功能 | 缺失影响 |\n|------|------|----------|\n| `libelf` | ELF 符号解析 | 采样数据无法显示函数名 |\n| `libdw` / `libunwind` | DWARF 栈回溯 | `-g` 采样无调用栈 |\n| `libtraceevent` | tracepoint 解析 | `perf lock`、`perf sched` 不可用 |\n| `libslang` | TUI 界面 | `perf report` 退化为文本模式 |\n| `libbabeltrace` | CTF 数据格式 | `perf data` 转换功能不可用 |\n\n编译完成后用 `perf test` 验证功能完整性:\n\n```bash\nperf test\n# 检查每项测试是否 PASS\n```\n\n---\n\n## 3. perf stat: 硬件计数器分析\n\n### 3.1 基本用法\n\n`perf stat` 是性能分析的第一步工具。它通过 PMU 计数器直接统计事件，开销极低:\n\n```bash\n# 统计整个程序的默认事件\nperf stat ./my_program\n\n# 指定事件\nperf stat -e cycles,instructions,cache-misses,branch-misses ./my_program\n\n# 监控运行中的进程 (10 秒)\nperf stat -p $(pidof my_program) -- sleep 10\n\n# 按 CPU 核心分别统计\nperf stat -e cycles,instructions -A -a -- sleep 5\n\n# 重复 5 次取统计值\nperf stat -r 5 ./my_program\n```\n\n### 3.2 输出解读\n\n```\n Performance counter stats for './my_program':\n\n     3,827,169,023      cycles                    #    3.201 GHz\n     6,142,705,612      instructions              #    1.61  insn per cycle\n       127,844,319      cache-references\n        18,729,613      cache-misses              #   14.65 % of all cache refs\n        45,217,831      branch-misses             #    1.23% of all branches\n             1,195      context-switches\n                42      cpu-migrations\n            12,847      page-faults\n\n       1.195521433 seconds time elapsed\n       1.142987000 seconds user\n       0.052012000 seconds sys\n```\n\n关键指标:\n\n| 指标 | 含义 | 健康范围 |\n|------|------|----------|\n| **IPC** (insn per cycle) | 每周期执行指令数 | >1.0 良好，<0.5 严重瓶颈 |\n| **cache-misses %** | 缓存未命中率 | <5% 良好，>20% 需要优化 |\n| **branch-misses %** | 分支预测失败率 | <2% 良好，>5% 考虑消除分支 |\n| **context-switches** | 上下文切换次数 | 越少越好 |\n\n### 3.3 IPC: 最重要的单一指标\n\nIPC（Instructions Per Cycle）是衡量 CPU 执行效率的核心指标:\n\n```\nIPC = instructions / cycles\n```\n\n```mermaid\ngraph LR\n    A[\"IPC < 0.5\"] -->|\"CPU 饥饿\"| B[\"访存瓶颈<br/>缓存未命中高<br/>内存带宽不足\"]\n    C[\"0.5 < IPC < 1.0\"] -->|\"中等效率\"| D[\"可能有<br/>分支预测失败<br/>或指令依赖链\"]\n    E[\"IPC > 1.0\"] -->|\"高效执行\"| F[\"CPU 充分利用<br/>考虑算法优化\"]\n    G[\"IPC > 2.0\"] -->|\"接近极限\"| H[\"SIMD/超标量<br/>充分发挥\"]\n\n    style A fill:#ffcdd2\n    style C fill:#fff9c4\n    style E fill:#c8e6c9\n    style G fill:#c8e6c9\n```\n\n**IPC 低的常见原因**:\n\n1. **缓存未命中**: 数据不在 L1/L2，等待主内存 (~100 周期)\n2. **分支预测失败**: 流水线冲刷，浪费 10-20 周期\n3. **指令依赖链**: 后续指令等待前序结果，无法并行\n4. **TLB miss**: 页表查找延迟\n\n### 3.4 缓存事件详细分析\n\n```bash\n# L1 数据缓存\nperf stat -e L1-dcache-loads,L1-dcache-load-misses,\\\nL1-dcache-stores,L1-dcache-store-misses ./my_program\n\n# LLC (Last Level Cache，通常是 L2 或 L3)\nperf stat -e LLC-loads,LLC-load-misses,\\\nLLC-stores,LLC-store-misses ./my_program\n\n# 精确的缓存层级 (看平台支持)\nperf stat -e cache-references,cache-misses ./my_program\n```\n\n缓存分析结果示例:\n\n```\n     1,287,443,021      L1-dcache-loads\n        23,671,882      L1-dcache-load-misses     #    1.84% of all L1-dcache loads\n     1,287,443,021      LLC-loads\n         4,129,387      LLC-load-misses            #    0.32% of all LLC loads\n```\n\n层级关系:\n\n```\nCPU Register\n    |\n    v (1-2 cycles)\nL1 Cache (32-64KB, per-core)\n    |\n    v (3-10 cycles)\nL2 Cache (256KB-1MB, per-core or shared)\n    |\n    v (10-40 cycles)\nL3 Cache (if exists, shared)\n    |\n    v (60-200 cycles)\nMain Memory (DRAM)\n```\n\nL1 miss 不一定是问题 -- 如果 L2 命中率很高，实际延迟只有 3-10 周期。真正致命的是**穿透到主内存**的 miss。\n\n### 3.5 分支预测分析\n\n```bash\nperf stat -e branches,branch-misses ./my_program\n```\n\n分支预测失败率高的典型场景:\n\n- 随机数据的 `if/else` 判断\n- 虚函数调用 (间接分支)\n- 大型 switch-case 且分布均匀\n\n优化方向:\n\n```cpp\n// 优化前: 分支预测困难\nfor (auto& item : items) {\n    if (item.type == TypeA) processA(item);\n    else if (item.type == TypeB) processB(item);\n    else processC(item);\n}\n\n// 优化后: 按类型排序，分支预测器容易学习模式\nstd::sort(items.begin(), items.end(),\n    [](const auto& a, const auto& b) {\n        return a.type < b.type;\n    });\n// 同样的循环，但分支预测命中率显著提升\n```\n\n---\n\n## 4. perf record + report: 热点函数定位\n\n### 4.1 采样原理\n\n`perf record` 通过 PMU 溢出中断实现采样: 每当某个事件（默认 `cycles`）累积到阈值时，CPU 触发中断，perf 记录当前的 PC（程序计数器）和调用栈。\n\n```\nPMU Counter --[溢出]--> 中断 --> perf 记录:\n  - 时间戳\n  - CPU ID\n  - PID / TID\n  - PC (指令地址)\n  - 调用栈 (如果启用 -g)\n```\n\n采样频率越高，定位越精确，但开销也越大:\n\n```bash\n# 默认频率 (4000 Hz)\nperf record ./my_program\n\n# 高频采样 (更精确，开销更大)\nperf record -F 10000 ./my_program\n\n# 低频采样 (生产环境)\nperf record -F 99 -p $(pidof my_program) -- sleep 30\n\n# 带调用栈 (推荐 dwarf 回溯)\nperf record -g --call-graph dwarf ./my_program\n\n# 指定事件采样\nperf record -e cache-misses -g ./my_program\n```\n\n### 4.2 perf report 分析\n\n```bash\n# 交互式 TUI\nperf report\n\n# 文本模式 (适合脚本处理)\nperf report --stdio\n\n# 按调用链展开\nperf report -g caller\n\n# 只看占比 > 1% 的函数\nperf report --percent-limit 1\n```\n\n典型输出:\n\n```\nOverhead  Command      Shared Object        Symbol\n  32.17%  my_program   my_program           [.] process_data\n  18.43%  my_program   libc.so.6            [.] memcpy\n  12.89%  my_program   my_program           [.] hash_lookup\n   9.75%  my_program   [kernel.kallsyms]    [k] copy_user_enhanced\n   6.32%  my_program   my_program           [.] serialize_frame\n```\n\n**解读原则**:\n\n1. `Overhead` 是**采样命中比例**，不是精确时间。32% 表示约 32% 的采样点落在 `process_data` 中\n2. 关注前 3-5 个热点，它们通常占据 60-80% 的 CPU 时间\n3. `[kernel.kallsyms]` 表示内核函数，通常与系统调用相关\n4. `libc.so` 中的 `memcpy` 占比高，说明数据拷贝是瓶颈\n\n### 4.3 annotate: 指令级定位\n\n对热点函数进一步下钻到源码行或汇编指令:\n\n```bash\n# 在 TUI 中选中函数后按 'a' 进入 annotate\nperf report\n\n# 或直接命令行 annotate\nperf annotate process_data\n```\n\n前提条件: 编译时带 `-g` (debug info) 和 `-fno-omit-frame-pointer`:\n\n```bash\n# 推荐的 perf 分析编译选项\ngcc -O2 -g -fno-omit-frame-pointer -o my_program main.cpp\n```\n\n`-O2` 保持生产级优化，`-g` 保留符号信息，`-fno-omit-frame-pointer` 保证栈回溯正确。\n\n---\n\n## 5. 火焰图: 可视化性能剖析\n\n### 5.1 火焰图原理\n\n火焰图（Flame Graph）是 Brendan Gregg 发明的可视化方法，将采样数据的调用栈聚合为一张图:\n\n```\n+----------------------------------------------------------+\n|                    main                                    |\n+----------------------------------------------------------+\n|         process_loop           |      io_thread           |\n+-------------------------------+---------------------------+\n| parse_msg  | dispatch | ack   | read_socket | write_log  |\n+------+-----+----------+---+---+------+------+------+-----+\n|decode|valid |route|exec|   |   | recv | poll |format|sync |\n+------+-----+-----+----+   +   +------+------+------+-----+\n\nx 轴: 采样占比 (越宽越耗 CPU)\ny 轴: 调用栈深度 (从下到上)\n```\n\n- **横轴宽度**表示该函数在采样中出现的频率（即 CPU 占用比例）\n- **纵轴**表示调用栈深度，底部是入口函数，顶部是叶子函数\n- **颜色**无特殊含义（随机分配），宽度才是重点\n\n### 5.2 On-CPU 火焰图\n\nOn-CPU 火焰图展示程序**正在 CPU 上执行**的时间分布:\n\n```bash\n#!/bin/bash\n# on_cpu_flamegraph.sh -- 生成 On-CPU 火焰图\n\nPROGRAM=$1\nDURATION=${2:-30}\nOUTPUT=\"oncpu_$(date +%Y%m%d_%H%M%S)\"\n\n# 1. 采样 (DWARF 栈回溯，兼容 ARM)\nperf record -F 99 -g --call-graph dwarf \\\n    -p $(pidof \"$PROGRAM\") -- sleep \"$DURATION\"\n\n# 2. 导出采样数据\nperf script > \"${OUTPUT}.perf\"\n\n# 3. 生成火焰图 (需要 FlameGraph 工具)\n# git clone https://github.com/brendangregg/FlameGraph.git\n./FlameGraph/stackcollapse-perf.pl \"${OUTPUT}.perf\" > \"${OUTPUT}.folded\"\n./FlameGraph/flamegraph.pl \"${OUTPUT}.folded\" > \"${OUTPUT}.svg\"\n\necho \"火焰图已生成: ${OUTPUT}.svg\"\n```\n\n### 5.3 Off-CPU 火焰图\n\nOff-CPU 火焰图展示程序**不在 CPU 上执行**（等待 I/O、锁、调度）的时间分布。对于 I/O 密集型或锁竞争严重的程序，Off-CPU 分析比 On-CPU 更重要:\n\n```bash\n#!/bin/bash\n# off_cpu_flamegraph.sh -- 生成 Off-CPU 火焰图\n\nPROGRAM=$1\nDURATION=${2:-30}\nOUTPUT=\"offcpu_$(date +%Y%m%d_%H%M%S)\"\n\n# 方法 1: perf record + sched:switch 事件\nperf record -e sched:sched_switch -g \\\n    -p $(pidof \"$PROGRAM\") -- sleep \"$DURATION\"\nperf script > \"${OUTPUT}.perf\"\n\n# 方法 2 (推荐，需要 bpftrace):\n# bpftrace -e '\n#   kprobe:finish_task_switch {\n#     @[kstack, ustack, comm] = count();\n#   }\n# ' -p $(pidof \"$PROGRAM\") > \"${OUTPUT}.stacks\"\n\n# 生成火焰图 (倒置: 底部是等待原因)\n./FlameGraph/stackcollapse-perf.pl \"${OUTPUT}.perf\" > \"${OUTPUT}.folded\"\n./FlameGraph/flamegraph.pl --color=io --countname=us \\\n    \"${OUTPUT}.folded\" > \"${OUTPUT}.svg\"\n```\n\n### 5.4 火焰图解读方法\n\n```mermaid\ngraph TD\n    A[\"打开火焰图\"] --> B{\"哪个函数最宽?\"}\n    B --> C[\"定位最宽的<br/>顶部函数\"]\n    C --> D{\"是用户代码?\"}\n    D -->|是| E[\"检查算法复杂度<br/>数据结构选择\"]\n    D -->|否| F{\"是 memcpy/memmove?\"}\n    F -->|是| G[\"数据拷贝过多<br/>考虑零拷贝\"]\n    F -->|否| H{\"是 malloc/free?\"}\n    H -->|是| I[\"堆分配频繁<br/>考虑内存池\"]\n    H -->|否| J{\"是 futex/lock?\"}\n    J -->|是| K[\"锁竞争严重<br/>perf lock 深入分析\"]\n\n    style C fill:#ffcdd2\n    style E fill:#fff9c4\n    style G fill:#fff9c4\n    style I fill:#fff9c4\n    style K fill:#fff9c4\n```\n\n常见模式:\n\n| 火焰图特征 | 含义 | 优化方向 |\n|------------|------|----------|\n| `memcpy` 很宽 | 数据拷贝多 | 零拷贝、就地处理 |\n| `malloc`/`free` 很宽 | 堆分配频繁 | 内存池、栈分配 |\n| `futex_wait` 很宽 | 锁等待严重 | 减小临界区或无锁 |\n| `__GI___poll` 很宽 | I/O 等待 | 异步 I/O、epoll |\n| `_spin_lock` 很宽 | 自旋锁竞争 | 减少持锁时间 |\n\n> 锁竞争的深入分析方法见 [perf lock 锁竞争诊断](../perf_lock_contention_diagnosis/)。\n\n---\n\n## 6. perf sched: 调度延迟分析\n\n### 6.1 调度延迟是什么\n\n线程被唤醒后，并不会立即获得 CPU -- 它需要等待调度器分配时间片。这个等待时间就是**调度延迟**（scheduling latency）。对实时系统，调度延迟直接影响响应时间。\n\n```\n线程状态:\nSleep ──(wake_up)──> Runnable ──(schedule)──> Running\n                     |<--- 调度延迟 --->|\n```\n\n### 6.2 perf sched latency\n\n```bash\n# 录制调度事件 (需要 root)\nperf sched record -- sleep 10\n\n# 或附加到运行中的进程\nperf sched record -p $(pidof my_program) -- sleep 10\n\n# 查看调度延迟统计\nperf sched latency --sort max\n```\n\n输出示例:\n\n```\n  Task                  |   Runtime ms  | Switches | Avg delay ms | Max delay ms |\n  ----------------------|---------------|----------|--------------|--------------|\n  sensor_thread:1234    |    892.431 ms |     1847 | avg:  0.023  | max:  4.127  |\n  bus_consumer:1235     |    445.217 ms |      923 | avg:  0.015  | max:  1.893  |\n  log_writer:1236       |     23.891 ms |      412 | avg:  0.089  | max: 12.341  |\n```\n\n关键指标:\n\n| 指标 | 含义 | 关注点 |\n|------|------|--------|\n| **Max delay** | 最大调度延迟 | 实时线程超过 1ms 需排查 |\n| **Avg delay** | 平均调度延迟 | 整体调度负载指标 |\n| **Switches** | 上下文切换次数 | 过高说明线程切换频繁 |\n| **Runtime** | 实际 CPU 执行时间 | 占比低说明多数时间在等待 |\n\n### 6.3 perf sched map\n\n`perf sched map` 展示每个 CPU 核心上的线程调度时间线:\n\n```bash\nperf sched map\n```\n\n```\n  *A0           999.538 secs A0 => migration/0:15\n  *.A1          999.538 secs A1 => sensor_thread:1234\n  *..A2         999.538 secs A2 => bus_consumer:1235\n   .A1.         999.539 secs\n  *.A1.         999.539 secs\n```\n\n这能直观看到线程在哪些核心上运行、是否频繁迁移。线程在核心间迁移会导致 L1/L2 缓存失效。\n\n### 6.4 减少调度延迟的方法\n\n```bash\n# 1. CPU 亲和性: 绑定线程到指定核心\ntaskset -c 2 ./my_program\n# 或程序内:\n# pthread_setaffinity_np(...)\n\n# 2. 实时调度策略\nchrt -f 80 ./my_program   # SCHED_FIFO, 优先级 80\n\n# 3. isolcpus: 隔离 CPU 核心，避免其他进程干扰\n# 内核启动参数: isolcpus=2,3\n```\n\n---\n\n## 7. ARM 平台缓存与访存分析\n\n### 7.1 ARM PMU 特殊事件\n\nARM Cortex-A 系列的 PMU 提供了 x86 上没有的精细事件，对嵌入式优化尤为重要:\n\n```bash\n# ARM L2 缓存事件 (Cortex-A53/A72)\nperf stat -e armv8_pmuv3/l2d_cache_refill/,\\\narmv8_pmuv3/l2d_cache_wb/,\\\narmv8_pmuv3/l2d_cache/,\\\ninstructions,cycles \\\n./my_program\n```\n\n| ARM PMU 事件 | 含义 | 性能意义 |\n|--------------|------|----------|\n| `l2d_cache_refill` | L2 缓存重填 (从主存加载) | 穿透到 DRAM 的次数 |\n| `l2d_cache_wb` | L2 缓存回写 | 脏数据写回主存的次数 |\n| `l2d_cache` | L2 缓存总访问 | L2 访问总量 |\n| `bus_access` | 总线访问 | 外部存储器带宽压力 |\n| `mem_access` | 内存访问指令 | load + store 总计 |\n\n### 7.2 访存/指令比\n\n**访存/指令比**（Memory Access per Instruction）是 ARM 嵌入式系统的关键指标:\n\n```\n访存/指令比 = mem_access / instructions\n```\n\n```bash\nperf stat -e mem_access,instructions ./my_program\n```\n\n```\n     8,421,337,192      mem_access\n    12,632,005,788      instructions\n\n    访存/指令比 = 8421337192 / 12632005788 = 0.667\n```\n\n| 访存/指令比 | 含义 |\n|------------|------|\n| < 0.3 | 计算密集型，CPU 利用率高 |\n| 0.3 - 0.5 | 平衡型 |\n| 0.5 - 0.8 | 访存密集，可能有缓存问题 |\n| > 0.8 | 严重访存瓶颈，优化数据布局 |\n\n### 7.3 L2 缓存效率分析\n\n```bash\nperf stat -e l2d_cache,l2d_cache_refill,instructions,cycles \\\n    ./my_program\n```\n\n计算:\n\n```\nL2 命中率 = 1 - (l2d_cache_refill / l2d_cache)\n每千条指令的 L2 miss = (l2d_cache_refill / instructions) * 1000  (MPKI)\n```\n\n**MPKI**（Misses Per Kilo Instructions）是比 miss 率更有意义的指标:\n\n| MPKI | 评价 | 优化建议 |\n|------|------|----------|\n| < 1 | 极好 | 无需优化 |\n| 1 - 5 | 良好 | 关注热点数据 |\n| 5 - 20 | 有优化空间 | 重新设计数据布局 |\n| > 20 | 严重 | 缓存预取 + 数据结构重构 |\n\n### 7.4 数据布局优化实例\n\nperf stat 发现高 L2 miss 后的典型优化:\n\n```cpp\n// 优化前: AoS (Array of Structures)\n// 遍历只用 x,y 时，z 和 metadata 浪费缓存行\nstruct Point {\n    float x, y, z;         // 12B\n    uint32_t metadata;     // 4B\n    char name[48];         // 48B\n};  // 64B = 1 cache line, 但只用 8B\nPoint points[10000];\n\n// 优化后: SoA (Structure of Arrays)\n// x,y 连续存储，缓存行利用率 100%\nstruct Points {\n    float x[10000];\n    float y[10000];\n    float z[10000];\n    uint32_t metadata[10000];\n};\n```\n\n用 perf stat 验证优化效果:\n\n```bash\n# 优化前\nperf stat -e L1-dcache-load-misses,LLC-load-misses ./before\n#   23,671,882  L1-dcache-load-misses\n#    4,129,387  LLC-load-misses\n\n# 优化后\nperf stat -e L1-dcache-load-misses,LLC-load-misses ./after\n#    3,412,667  L1-dcache-load-misses   (-85%)\n#      187,234  LLC-load-misses         (-95%)\n```\n\n---\n\n## 8. 自动化 CPU 监控与 perf 联动\n\n### 8.1 问题场景\n\n嵌入式设备在现场运行时，CPU 负载偶尔飙高但难以复现。手动 SSH 登录再跑 perf 往往已经错过现场。需要一个自动监控脚本，在 CPU 超过阈值时自动触发 perf record。\n\n### 8.2 监控脚本\n\n```bash\n#!/bin/bash\n# cpu_monitor.sh -- CPU 超阈值自动触发 perf 采样\n#\n# 用法: ./cpu_monitor.sh [进程名] [CPU阈值%] [采样秒数]\n# 示例: ./cpu_monitor.sh my_program 80 10\n\nPROCESS_NAME=${1:-\"my_program\"}\nCPU_THRESHOLD=${2:-80}\nSAMPLE_DURATION=${3:-10}\nCHECK_INTERVAL=5\nOUTPUT_DIR=\"/var/log/perf_captures\"\n\nmkdir -p \"$OUTPUT_DIR\"\n\necho \"监控进程: $PROCESS_NAME, 阈值: ${CPU_THRESHOLD}%, 采样: ${SAMPLE_DURATION}s\"\n\nwhile true; do\n    # 获取目标进程的 CPU 使用率\n    PID=$(pidof \"$PROCESS_NAME\" 2>/dev/null)\n    if [ -z \"$PID\" ]; then\n        sleep \"$CHECK_INTERVAL\"\n        continue\n    fi\n\n    CPU_USAGE=$(ps -p \"$PID\" -o %cpu= 2>/dev/null | tr -d ' ')\n    if [ -z \"$CPU_USAGE\" ]; then\n        sleep \"$CHECK_INTERVAL\"\n        continue\n    fi\n\n    # 比较 (使用 awk 处理浮点数)\n    EXCEEDED=$(awk \"BEGIN {print ($CPU_USAGE > $CPU_THRESHOLD)}\")\n\n    if [ \"$EXCEEDED\" = \"1\" ]; then\n        TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n        PERF_FILE=\"${OUTPUT_DIR}/perf_${TIMESTAMP}\"\n\n        echo \"[${TIMESTAMP}] CPU ${CPU_USAGE}% > ${CPU_THRESHOLD}%, 触发采样...\"\n\n        # 采集系统快照\n        top -bn1 > \"${PERF_FILE}_top.txt\" 2>/dev/null\n\n        # perf record 采样\n        perf record -F 99 -g --call-graph dwarf \\\n            -p \"$PID\" -o \"${PERF_FILE}.data\" \\\n            -- sleep \"$SAMPLE_DURATION\" 2>/dev/null\n\n        # 生成文本报告\n        perf report -i \"${PERF_FILE}.data\" --stdio \\\n            --percent-limit 1 > \"${PERF_FILE}_report.txt\" 2>/dev/null\n\n        echo \"[${TIMESTAMP}] 采样完成: ${PERF_FILE}.data\"\n\n        # 冷却期: 避免连续触发\n        sleep 60\n    fi\n\n    sleep \"$CHECK_INTERVAL\"\ndone\n```\n\n### 8.3 部署方式\n\n```bash\n# 后台运行\nnohup ./cpu_monitor.sh my_program 80 10 > /var/log/cpu_monitor.log 2>&1 &\n\n# 或用 systemd service\n# /etc/systemd/system/cpu-monitor.service\n# [Service]\n# ExecStart=/opt/scripts/cpu_monitor.sh my_program 80 10\n# Restart=always\n```\n\n采集到的数据可以离线分析:\n\n```bash\n# 在开发机上分析 (需要相同的二进制和符号)\nscp target:/var/log/perf_captures/perf_20260216_*.data .\nperf report -i perf_20260216_143022.data\n```\n\n---\n\n## 9. perf vs 其他分析工具\n\n### 9.1 perf vs Valgrind/Cachegrind\n\n| 维度 | perf | Cachegrind (Valgrind) |\n|------|------|----------------------|\n| 工作方式 | 硬件 PMU 采样 | 软件模拟 CPU 缓存 |\n| 运行时开销 | ~1-15% | **20-50x 慢** |\n| 缓存模型 | 真实硬件 | 模拟（可能与实际不符） |\n| 需要修改程序 | 否 | 否 |\n| ARM 支持 | 原生 | 支持但模拟更慢 |\n| 适用场景 | 生产环境、真实负载 | 开发阶段、详细行级分析 |\n| 输出精度 | 统计采样 | 精确计数 |\n\n**选择建议**:\n\n- **开发阶段** + 需要精确到每行代码的缓存行为: 用 Cachegrind\n- **生产环境** + 真实负载 + 低开销: 用 perf stat\n- **ARM 嵌入式**: 首选 perf（Cachegrind 在 ARM 上模拟开销过大）\n\n### 9.2 Cachegrind 用法参考\n\n```bash\n# 运行 Cachegrind\nvalgrind --tool=cachegrind ./my_program\n\n# 查看结果\ncg_annotate cachegrind.out.<pid>\n\n# 输出示例:\n# Ir          I1mr    ILmr    Dr          D1mr       DLmr\n# 1,234,567   12      5       567,890     23,456     1,234\n#\n# Ir:  指令读取     D1mr: L1 数据读 miss\n# Dr:  数据读取     DLmr: LL 数据读 miss\n```\n\n### 9.3 工具选型决策\n\n```mermaid\ngraph TD\n    A[\"性能问题\"] --> B{\"需要定位<br/>什么层面?\"}\n    B -->|\"CPU 热点函数\"| C[\"perf record<br/>+ 火焰图\"]\n    B -->|\"硬件计数器<br/>IPC/缓存\"| D[\"perf stat\"]\n    B -->|\"锁竞争\"| E[\"perf lock<br/>contention\"]\n    B -->|\"调度延迟\"| F[\"perf sched<br/>latency\"]\n    B -->|\"逐行缓存行为<br/>开发阶段\"| G[\"Cachegrind\"]\n    B -->|\"内存泄漏<br/>非法访问\"| H[\"ASan / Valgrind<br/>memcheck\"]\n\n    style C fill:#c8e6c9\n    style D fill:#c8e6c9\n    style E fill:#c8e6c9\n    style F fill:#c8e6c9\n    style G fill:#fff9c4\n    style H fill:#fff9c4\n```\n\n---\n\n## 10. 完整工作流: 从发现到解决\n\n一个典型的性能分析流程:\n\n```mermaid\ngraph TD\n    A[\"1. 建立基线<br/>perf stat -r 5\"] --> B[\"2. 判断瓶颈类型\"]\n    B -->|\"IPC 低, cache-miss 高\"| C[\"3a. 访存瓶颈<br/>perf stat 缓存事件\"]\n    B -->|\"IPC 正常, CPU 使用率高\"| D[\"3b. 计算瓶颈<br/>perf record 火焰图\"]\n    B -->|\"CPU 使用率低, 吞吐不达标\"| E[\"3c. 等待瓶颈<br/>Off-CPU 火焰图<br/>perf sched / perf lock\"]\n\n    C --> F[\"4a. 优化数据布局<br/>SoA, 缓存行对齐<br/>预取\"]\n    D --> G[\"4b. 优化算法<br/>减少分支, SIMD\"]\n    E --> H[\"4c. 减少等待<br/>无锁, 异步 I/O<br/>实时调度\"]\n\n    F --> I[\"5. 验证<br/>perf stat 对比\"]\n    G --> I\n    H --> I\n    I --> J{\"改善达标?\"}\n    J -->|否| B\n    J -->|是| K[\"6. 回归基准<br/>记录优化前后数据\"]\n\n    style A fill:#e3f2fd\n    style I fill:#e3f2fd\n    style K fill:#c8e6c9\n```\n\n### 实战示例\n\n```bash\n# Step 1: 建立基线\nperf stat -r 5 -e cycles,instructions,cache-misses,\\\nbranch-misses,context-switches ./my_program\n# IPC = 0.45, cache-misses = 23%, 初步判断: 访存瓶颈\n\n# Step 2: 定位缓存问题\nperf stat -e L1-dcache-load-misses,LLC-load-misses,\\\nmem_access,instructions ./my_program\n# MPKI = 18.7, L2 miss 占 L2 access 的 31%\n\n# Step 3: 火焰图定位热点\nperf record -F 99 -g --call-graph dwarf ./my_program\nperf script | ./FlameGraph/stackcollapse-perf.pl | \\\n    ./FlameGraph/flamegraph.pl > flame.svg\n# 发现 process_sensor_data() 占 45%, 内部大量遍历 AoS 结构\n\n# Step 4: 优化 (AoS → SoA)\n# ... 修改代码 ...\n\n# Step 5: 验证\nperf stat -r 5 -e cycles,instructions,cache-misses ./my_program_v2\n# IPC: 0.45 → 1.32, cache-misses: 23% → 4.1%\n```\n\n---\n\n## 11. 常见问题与排查\n\n### 11.1 权限问题\n\n```bash\n# 错误: Permission denied\n# 解决: 调整 perf_event_paranoid\necho 1 | sudo tee /proc/sys/kernel/perf_event_paranoid\n\n# perf_event_paranoid 含义:\n# -1: 无限制\n#  0: 允许非 root 用户访问 tracepoint\n#  1: 允许非 root 用户使用 PMU (默认)\n#  2: 只允许 root\n#  3: 完全禁止 (部分发行版)\n```\n\n### 11.2 符号缺失\n\n```bash\n# perf report 显示 [unknown] 或只有地址\n# 原因: 编译时未保留符号\n\n# 解决 1: 重新编译带符号\ngcc -O2 -g -fno-omit-frame-pointer -o my_program main.cpp\n\n# 解决 2: 安装 debuginfo 包 (系统库)\nsudo apt install libc6-dbg\n\n# 解决 3: 内核符号\necho 0 | sudo tee /proc/sys/kernel/kptr_restrict\n```\n\n### 11.3 多路复用警告\n\n```\n# 输出中出现 <not counted> 或 <not supported>\n# 原因: 监控事件数超过物理 PMU 计数器\n\n# 解决: 减少同时监控的事件数，分多次运行\nperf stat -e cycles,instructions,cache-misses ./prog     # 第一次\nperf stat -e branches,branch-misses,L1-dcache-load-misses ./prog  # 第二次\n```\n\n### 11.4 perf record 数据过大\n\n```bash\n# 长时间采样产生巨大 perf.data\n# 解决: 降低频率 + 限制时间 + 压缩\nperf record -F 99 -z -o perf.data.zstd -- sleep 30\n\n# 或只关注特定函数\nperf record -e cycles --filter 'process_data' -- sleep 30\n```\n\n---\n\n## 12. 总结\n\nperf 的核心价值在于用**硬件计数器的真实数据**替代猜测。一套完整的性能分析工具链:\n\n| 阶段 | 工具 | 产出 |\n|------|------|------|\n| 快速概览 | `perf stat` | IPC、缓存命中率、分支预测率 |\n| 热点定位 | `perf record` + 火焰图 | CPU 时间分布，定位到函数 |\n| 等待分析 | Off-CPU 火焰图 + `perf sched` | I/O、锁、调度延迟 |\n| 锁诊断 | `perf lock contention` | 锁竞争率、持有者 |\n| ARM 缓存 | `perf stat` + PMU 事件 | L2 MPKI、访存/指令比 |\n| 持续监控 | 自动化脚本 | CPU 飙高自动采样 |\n\n**核心原则**:\n\n1. **先 perf stat，再 perf record**: 计数器开销极低，先确定瓶颈类型\n2. **IPC 是入口**: IPC 低看缓存和访存，IPC 正常看算法，CPU 空闲看等待\n3. **火焰图看宽度**: 最宽的函数就是最值得优化的目标\n4. **优化后必须验证**: perf stat 对比优化前后的硬件计数器数据\n5. **ARM 看 L2**: 嵌入式 ARM 通常没有 L3，L2 miss 直接穿透到 DRAM\n",
      "ctime": "1771552614",
      "mtime": "1771552614",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/shared_memory_ipc_lockfree_ringbuffer.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857503282",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "共享内存 IPC 实践: 从 POSIX shm 到 newosp 无锁 Ring Buffer",
      "brief_content": "共享内存是 Linux 进程间通信中延迟最低的机制，但原始的 POSIX shm_open/mmap 接口缺少同步、生命周期管理和崩溃恢复。本文从 POSIX 共享内存原理出发，剖析 newosp 框",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [内存屏障的硬件原理: 从 Store Buffer 到 ARM DMB/DSB/ISB](../memory_barrier_hardware/) -- ARM 内存序加固的硬件根因\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- ShmRingBuffer 底层的 SPSC 设计详解\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- CAS 无锁设计的理论基础\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- newosp 框架全景\n> - [newosp ospgen: YAML 驱动的零堆消息代码生成](../newosp_ospgen_codegen/) -- ShmRingBuffer 传输的消息类型生成\n>\n> 参考: [C++编程：使用 cpp-ipc 实现基于共享内存的进程间发布订阅](https://blog.csdn.net/stallion5632/article/details/140881982)\n>\n> newosp 实现: [shm_transport.hpp](https://github.com/DeguiLiu/newosp) -- POSIX 共享内存 + 无锁 MPSC Ring Buffer\n>\n> 对比库: [cpp-ipc](https://github.com/mutouyun/cpp-ipc) -- 跨平台共享内存 IPC 库\n\n## 1. 为什么选择共享内存\n\nLinux 提供多种 IPC 机制，每种有不同的延迟和吞吐量特征：\n\n| 机制 | 内核拷贝次数 | 典型延迟 | 适用场景 |\n|------|:----------:|:-------:|---------|\n| **共享内存** (shm) | 0 | **< 1 us** | 大数据量、低延迟 |\n| Unix Domain Socket | 2 (用户→内核→用户) | 2-10 us | 通用 IPC |\n| 管道 (pipe) | 2 | 2-10 us | 父子进程 |\n| 消息队列 (mqueue) | 2 | 3-15 us | 小消息 |\n| TCP loopback | 2+ | 10-50 us | 网络兼容 |\n\n共享内存的核心优势：**零内核拷贝**。两个进程通过 `mmap` 将同一块物理内存映射到各自的虚拟地址空间，写入方的数据立即对读取方可见（受 CPU 缓存一致性协议保护），不经过 `read`/`write` 系统调用。\n\n但共享内存只解决了\"数据传输\"问题，以下问题需要应用层自行处理：\n\n- **同步**: 写入方何时完成？读取方何时可以读？\n- **并发控制**: 多个生产者同时写入如何避免竞争？\n- **生命周期**: 进程崩溃后共享内存如何清理？\n- **命名与发现**: 如何让两个独立进程找到同一块共享内存？\n\n## 2. POSIX 共享内存原理\n\n### 2.1 核心 API\n\n```c\n#include <sys/mman.h>\n#include <fcntl.h>\n\n// 创建/打开共享内存对象 (返回文件描述符)\nint fd = shm_open(\"/my_channel\", O_CREAT | O_RDWR, 0600);\n\n// 设置大小\nftruncate(fd, size);\n\n// 映射到进程虚拟地址空间\nvoid* addr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);\n\n// ... 通过 addr 直接读写 ...\n\n// 解除映射\nmunmap(addr, size);\n\n// 关闭文件描述符\nclose(fd);\n\n// 删除共享内存对象 (所有进程关闭后释放)\nshm_unlink(\"/my_channel\");\n```\n\n### 2.2 在文件系统中的体现\n\n```bash\n# 共享内存对象出现在 tmpfs 文件系统中\n$ ls -la /dev/shm/\n-rw------- 1 root root 1048576 Feb 16 10:00 osp_shm_video_ch0\n```\n\n`shm_open` 本质上是在 `/dev/shm/` (tmpfs) 中创建一个文件。tmpfs 完全在内存中，不涉及磁盘 I/O。`mmap` 将该文件的页面映射到进程地址空间，多个进程映射同一文件即共享同一物理页。\n\n### 2.3 生命周期管理难题\n\nPOSIX 共享内存的最大工程难题是**生命周期**：\n\n```\n进程 A: shm_open(CREATE) → mmap → 写入数据 → [SIGKILL/断电]\n         ↑ 此时 shm_unlink 未调用，/dev/shm/ 中残留文件\n\n进程 B: shm_open(OPEN) → 打开了上次的残留数据 → 数据不一致\n```\n\n`shm_unlink` 只是标记删除，实际释放发生在**所有**进程 `munmap + close` 之后。如果进程被 SIGKILL 或断电终止，`shm_unlink` 未执行，共享内存对象会残留在 `/dev/shm/` 中。\n\n## 3. newosp 的共享内存架构\n\nnewosp 的 `shm_transport.hpp` 提供三层抽象：\n\n```\n┌─────────────────────────────────────────┐\n│  ShmChannel                             │  命名通道 (Writer/Reader 端点)\n│  ┌───────────────────────────────────┐  │\n│  │  ShmRingBuffer<SlotSize, Count>   │  │  无锁 MPSC 环缓冲\n│  │  ┌─────────────────────────────┐  │  │\n│  │  │  SharedMemorySegment        │  │  │  POSIX shm RAII 封装\n│  │  └─────────────────────────────┘  │  │\n│  └───────────────────────────────────┘  │\n└─────────────────────────────────────────┘\n```\n\n### 3.1 SharedMemorySegment: RAII 封装\n\n```cpp\nclass SharedMemorySegment final {\npublic:\n  // 创建: shm_open(O_CREAT | O_RDWR | O_EXCL) + ftruncate + mmap\n  static expected<SharedMemorySegment, ShmError> Create(\n      const char* name, uint32_t size) noexcept;\n\n  // 容错创建: 先 shm_unlink 清除残留，再 Create\n  static expected<SharedMemorySegment, ShmError> CreateOrReplace(\n      const char* name, uint32_t size) noexcept;\n\n  // 打开: shm_open(O_RDWR) + fstat + mmap\n  static expected<SharedMemorySegment, ShmError> Open(\n      const char* name) noexcept;\n\n  // RAII 析构: munmap + close\n  ~SharedMemorySegment();\n\n  // 标记删除\n  void Unlink() noexcept;\n\n  void* Data() noexcept;\n  uint32_t Size() const noexcept;\n\nprivate:\n  int32_t fd_;\n  void* addr_;\n  uint32_t size_;\n  FixedString<64> name_;  // 零堆分配的名称存储\n};\n```\n\n**设计要点:**\n\n1. **`O_EXCL` 排他创建**: `Create` 使用 `O_EXCL` 标志，如果同名共享内存已存在则失败。这防止了两个进程同时创建导致的数据不一致。\n\n2. **`CreateOrReplace` 崩溃恢复**: 先 `shm_unlink` 清除可能的残留，再执行标准创建。嵌入式系统中进程被 SIGKILL 或断电是常见场景。\n\n3. **`expected<T, ShmError>` 错误处理**: 不使用异常（`-fno-exceptions` 兼容），通过 `expected` 返回值区分成功/失败。\n\n4. **`FixedString<64>` 名称存储**: 共享内存名称 `/osp_shm_<user_name>` 存储在栈上，零堆分配。\n\n5. **Move-only 语义**: 禁止拷贝，支持移动，确保文件描述符和 mmap 地址的唯一所有权。\n\n### 3.2 ShmRingBuffer: 无锁 MPSC 环缓冲\n\n这是整个 shm_transport 的核心。Ring Buffer 的全部状态 (原子变量 + 数据 slot) 都是 POD 类型，可以直接放在共享内存中，跨进程安全。\n\n```cpp\ntemplate <uint32_t SlotSize = 4096, uint32_t SlotCount = 256>\nclass ShmRingBuffer final {\n  static_assert((SlotCount & (SlotCount - 1)) == 0,\n                \"SlotCount must be power of 2\");\n\n  struct Slot {\n    std::atomic<uint32_t> sequence;  // CAS 同步序号\n    uint32_t size;                   // 实际数据大小\n    char data[SlotSize];             // 数据负载\n  };\n\n  // 缓存行对齐: 防止 producer_pos_ 和 consumer_pos_ 的 false sharing\n  alignas(64) std::atomic<uint32_t> producer_pos_;\n  char pad_[64 - sizeof(std::atomic<uint32_t>)];\n  alignas(64) std::atomic<uint32_t> consumer_pos_;\n  Slot slots_[SlotCount];\n};\n```\n\n#### 3.2.1 CAS 无锁 Push (生产者)\n\n```cpp\nbool TryPush(const void* data, uint32_t size) noexcept {\n    if (size > SlotSize) return false;\n\n    uint32_t prod_pos;\n    Slot* target;\n\n    // CAS 循环: 竞争一个 slot\n    do {\n        prod_pos = producer_pos_.load(std::memory_order_relaxed);\n        target = &slots_[prod_pos & kBufferMask];\n\n        uint32_t seq = target->sequence.load(std::memory_order_acquire);\n        if (seq != prod_pos) {\n            return false;  // 满了\n        }\n    } while (!producer_pos_.compare_exchange_weak(\n        prod_pos, prod_pos + 1,\n        std::memory_order_acq_rel, std::memory_order_relaxed));\n\n    // 写入数据\n    target->size = size;\n    std::memcpy(target->data, data, size);\n\n    // ARM 内存序: 确保 memcpy 完成后再发布序号\n    std::atomic_thread_fence(std::memory_order_release);\n    target->sequence.store(prod_pos + 1, std::memory_order_release);\n\n    return true;\n}\n```\n\n**CAS 协议详解:**\n\n```\n初始状态: slot[0].seq = 0, slot[1].seq = 1, ..., slot[N-1].seq = N-1\n          producer_pos_ = 0, consumer_pos_ = 0\n\n生产者 push 第 k 个消息:\n  1. load producer_pos_ → prod_pos = k\n  2. load slot[k % N].seq → 如果 seq == k，slot 可用\n  3. CAS(producer_pos_, k, k+1) → 原子递增，竞争该 slot\n  4. 写入数据到 slot\n  5. store slot[k % N].seq = k + 1 → 发布 (对消费者可见)\n\n消费者 pop 第 k 个消息:\n  1. load consumer_pos_ → cons_pos = k\n  2. load slot[k % N].seq → 如果 seq == k + 1，数据已就绪\n  3. 读取数据\n  4. store slot[k % N].seq = k + N → 释放 slot (对生产者可见)\n  5. store consumer_pos_ = k + 1\n```\n\n序号 (sequence) 同时承担了**可用性标记**和**发布/释放语义**：\n\n- `seq == prod_pos`: slot 空闲，可被生产者占用\n- `seq == cons_pos + 1`: slot 有数据，可被消费者读取\n- `seq == cons_pos + N`: slot 释放回池中\n\n#### 3.2.2 ARM 内存序加固\n\nx86 是 TSO (Total Store Order) 架构，store-store 顺序天然保证。ARM 是弱序架构，必须显式插入内存屏障 (详见 [内存屏障的硬件原理](../memory_barrier_hardware/) 中 Store Buffer 和 Invalidation Queue 的分析)：\n\n```cpp\n// 生产者端:\nstd::memcpy(target->data, data, size);          // 写入数据\nstd::atomic_thread_fence(std::memory_order_release);  // DMB ST\ntarget->sequence.store(prod_pos + 1, release);  // 发布序号\n\n// 消费者端:\nuint32_t seq = slot.sequence.load(acquire);     // 读取序号\nstd::atomic_thread_fence(std::memory_order_acquire);  // DMB LD\nstd::memcpy(data, slot.data, size);             // 读取数据\n```\n\n如果没有 release fence，ARM 可能将 `sequence.store` 重排到 `memcpy` 之前，消费者看到序号更新但数据尚未写入。\n\n#### 3.2.3 缓存行对齐\n\n```cpp\nalignas(64) std::atomic<uint32_t> producer_pos_;\nchar pad_[64 - sizeof(std::atomic<uint32_t>)];\nalignas(64) std::atomic<uint32_t> consumer_pos_;\n```\n\n`producer_pos_` 和 `consumer_pos_` 分别由不同的 CPU 核心高频更新。如果它们在同一缓存行 (64 字节) 内，一个核心的写入会使另一个核心的缓存行无效 (false sharing)，导致性能降低。`alignas(64)` + padding 确保它们在不同缓存行。\n\n### 3.3 ShmChannel: 命名通道\n\nShmChannel 组合了 SharedMemorySegment 和 ShmRingBuffer，提供面向用户的 API：\n\n```cpp\ntemplate <uint32_t SlotSize = 4096, uint32_t SlotCount = 256>\nclass ShmChannel final {\npublic:\n  // Writer 端: 创建共享内存 + 初始化 Ring Buffer\n  static expected<ShmChannel, ShmError> CreateWriter(const char* name);\n  static expected<ShmChannel, ShmError> CreateOrReplaceWriter(const char* name);\n\n  // Reader 端: 打开共享内存 + 附加到 Ring Buffer\n  static expected<ShmChannel, ShmError> OpenReader(const char* name);\n\n  // 读写操作\n  expected<void, ShmError> Write(const void* data, uint32_t size);\n  expected<void, ShmError> Read(void* data, uint32_t& size);\n\n  // 轮询等待 (指数退避: 50us → 100us → ... → 1ms)\n  expected<void, ShmError> WaitReadable(uint32_t timeout_ms);\n\n  uint32_t Depth() const;\n  void Unlink();\n};\n```\n\n**WaitReadable 的指数退避策略:**\n\n```\n初始 sleep: 50 us\n每次翻倍: 50 → 100 → 200 → 400 → 800 → 1000 us (上限)\n```\n\n这是一个权衡：纯忙等 (spin) 延迟最低但浪费 CPU；固定 sleep 延迟高但省 CPU。指数退避在低负载时快速响应，在高负载时收敛到 1ms 轮询，适合嵌入式的 CPU 预算约束。\n\n## 4. 与 cpp-ipc 的架构对比\n\n[cpp-ipc](https://github.com/mutouyun/cpp-ipc) 是一个成熟的跨平台共享内存 IPC 库，支持 Linux/Windows/FreeBSD。以下从多个维度对比两者的设计取舍。\n\n### 4.1 通信模型\n\n| 维度 | newosp ShmChannel | cpp-ipc |\n|------|:-----------------:|:-------:|\n| 写模式 | MPSC (多写单读) | `ipc::route` SPMC, `ipc::channel` MPMC |\n| 读模式 | 单消费者 | 多消费者广播 (最多 32) |\n| 消息大小 | 固定 SlotSize (编译期) | 动态大小 (运行时) |\n| 消费者最大数 | 1 | 32 (route/channel) |\n| 数据分发 | 点对点 | 广播 / 可选单播 |\n\nnewosp 选择 MPSC 模型是因为嵌入式场景中，一个通道通常对应一个数据流 (如一路视频帧)，由一个消费者处理。如果需要多消费者，每个消费者开一个独立通道，避免广播的复杂性。\n\ncpp-ipc 的广播模型更适合桌面/服务器场景，一份数据需要被多个订阅者消费。\n\n### 4.2 内存管理\n\n| 维度 | newosp ShmChannel | cpp-ipc |\n|------|:-----------------:|:-------:|\n| Slot 大小 | 编译期固定 (`static_assert`) | 运行时动态 |\n| 堆分配 | 零 (热路径) | `std::vector` 用于大数据 |\n| 消息序列化 | memcpy raw bytes | `ipc::buff_t` (支持 vector) |\n| 最大消息 | SlotSize (如 4096 或 81920) | 理论无限 (分段传输) |\n\nnewosp 的固定 Slot 设计牺牲了灵活性 (消息不能超过 SlotSize)，但换来了**编译期确定性**：Ring Buffer 的总内存占用在编译时已知，不存在运行时分配失败的可能。\n\n### 4.3 同步机制\n\n| 维度 | newosp ShmChannel | cpp-ipc |\n|------|:-----------------:|:-------:|\n| 生产者同步 | CAS (`compare_exchange_weak`) | CAS + spin-lock |\n| 消费者等待 | 指数退避轮询 (50us-1ms) | spin 重试 → 信号量等待 |\n| 超时支持 | `WaitReadable(timeout_ms)` | `recv(timeout)` |\n| 背压 | 返回 `kFull` 错误 | 策略可选 |\n\ncpp-ipc 的\"spin 重试 → 信号量等待\"策略更智能：短时间 spin 捕获高频场景，超时后切换到信号量避免 CPU 空转。newosp 使用指数退避轮询达到类似效果，但不依赖信号量 (信号量在跨进程场景中需要 `sem_open` 额外管理)。\n\n### 4.4 平台兼容性\n\n| 维度 | newosp ShmChannel | cpp-ipc |\n|------|:-----------------:|:-------:|\n| 平台 | Linux only (POSIX) | Linux / Windows / FreeBSD |\n| 共享内存 API | `shm_open` / `mmap` | `shm_open` (Linux), `CreateFileMapping` (Win) |\n| 通知机制 | 指数退避轮询 | 信号量 (跨平台) |\n| ARM 加固 | 显式 `atomic_thread_fence` | 依赖编译器内建 |\n| 编译约束 | `-fno-exceptions -fno-rtti` 兼容 | 需要异常支持 |\n| 依赖 | 仅 STL (header-only) | 仅 STL (需编译) |\n\nnewosp 仅面向 Linux 嵌入式，因此可以直接使用 POSIX API 而不需要跨平台抽象层。cpp-ipc 的跨平台支持增加了一层间接 (platform abstraction)，但覆盖面更广。\n\n### 4.5 崩溃恢复\n\n| 维度 | newosp ShmChannel | cpp-ipc |\n|------|:-----------------:|:-------:|\n| 残留清理 | `CreateOrReplace` (shm_unlink + Create) | 需手动清理或重启 |\n| 状态一致性 | Ring Buffer 全 POD，序号协议自恢复 | 依赖原子操作一致性 |\n| 进程监控 | `ThreadWatchdog` + `FaultCollector` 集成 | 无内建 |\n\nnewosp 的 `CreateOrReplace` 模式专为嵌入式设计：SIGKILL、断电后重启时自动清除 `/dev/shm/` 中的残留文件，无需运维手动干预。\n\n## 5. 实战: newosp 视频帧传输\n\nnewosp 的 `examples/shm_ipc/` 演示了一个完整的视频帧跨进程传输系统：\n\n```\n┌─────────────────┐     /dev/shm/osp_shm_video_ch0     ┌─────────────────┐\n│  shm_producer    │  ──────────────────────────────→  │  shm_consumer    │\n│  (HSM 8 状态)    │     ShmChannel<81920, 16>          │  (HSM 8 状态)    │\n│                  │     320x240 帧 = 76,816 B          │                  │\n│  生成帧 → Write  │                                    │  Read → 校验帧   │\n└─────────────────┘                                    └─────────────────┘\n        ↓                                                       ↓\n┌─────────────────┐                                    SpscRingbuffer<ShmStats>\n│  shm_monitor     │  ←───── 统计快照 (48B) ──────────\n│  Shell 调试      │\n│  telnet :9527   │\n└─────────────────┘\n```\n\n### 5.1 帧格式定义\n\n```cpp\nstruct FrameHeader {\n    uint32_t magic;    // 0x4652414D ('FRAM')\n    uint32_t seq_num;  // 递增序号\n    uint32_t width;    // 320\n    uint32_t height;   // 240\n};\n\nstatic constexpr uint32_t kFrameSize = sizeof(FrameHeader) + 320 * 240;  // 76,816 B\nstatic constexpr uint32_t kSlotSize = 81920;   // > kFrameSize\nstatic constexpr uint32_t kSlotCount = 16;     // 16 个 slot 环缓冲\n// 共享内存总大小 ≈ 16 x 82 KB ≈ 1.3 MB\n```\n\n### 5.2 Producer 状态机\n\n```\nOperational (root)\n├── Init       → 创建通道 + 分配帧池 (FixedPool<80KB, 4>)\n├── Running\n│   ├── Streaming  → 正常生产帧 (Write)\n│   ├── Paused     → 环缓冲满，等待 200us\n│   └── Throttled  → 连续 3 次满，降速 5ms\n├── Error      → 可恢复错误，重试初始化\n└── Done       → Unlink 通道 + 输出统计\n```\n\nHSM 驱动的状态管理比简单的 `while(true)` + `if-else` 更健壮：\n\n- **背压处理**: Ring Buffer 满时不是无限重试，而是进入 Paused 状态，避免 CPU 空转\n- **降速机制**: 连续满标志着消费者跟不上，进入 Throttled 主动降速\n- **崩溃恢复**: Error 状态可以重试初始化，不需要人工重启\n\n### 5.3 Consumer 帧校验\n\n```cpp\n// 消费者逐字节校验帧完整性\nbool ValidateFrame(const uint8_t* frame, uint32_t size) {\n    auto* hdr = reinterpret_cast<const FrameHeader*>(frame);\n\n    if (hdr->magic != 0x4652414Du) return false;     // magic 校验\n    if (hdr->width != 320 || hdr->height != 240) return false;  // 尺寸一致性\n\n    // 逐字节验证像素数据\n    const uint8_t* pixels = frame + sizeof(FrameHeader);\n    for (uint32_t i = 0; i < hdr->width * hdr->height; ++i) {\n        if (pixels[i] != ((hdr->seq_num + i) & 0xFF)) {\n            return false;  // 数据不一致\n        }\n    }\n    return true;\n}\n```\n\n这种逐字节校验可以检测到：\n- 内存序错误 (数据未完整写入即被消费)\n- 缓存一致性问题 (ARM 平台)\n- Ring Buffer 索引溢出 (读到了另一帧的数据)\n\n## 6. 与 cpp-ipc 使用方式对比\n\n### 6.1 cpp-ipc: 发布订阅\n\n```cpp\n// 生产者\nipc::route channel{\"my_channel\", ipc::sender};\nchannel.wait_for_recv(1);\nchannel.send(data.data(), data.size());\nchannel.send(ipc::buff_t('\\0'));  // 终止信号\n\n// 消费者\nipc::route channel{\"my_channel\", ipc::receiver};\nwhile (true) {\n    auto buf = channel.recv();\n    if (buf.empty() || static_cast<char*>(buf.data())[0] == '\\0') break;\n    // 处理 buf\n}\n```\n\n**特点**: API 简洁，`send`/`recv` 隐藏了共享内存和同步细节。支持动态大小消息 (`ipc::buff_t` 可变长)。\n\n### 6.2 newosp: 显式控制\n\n```cpp\n// 生产者\nauto result = ShmChannel<81920, 16>::CreateOrReplaceWriter(\"video_ch0\");\nif (!result.has_value()) { /* 错误处理 */ }\nauto channel = std::move(result.value());\n\nuint8_t frame[81920];\n// ... 填充帧数据 ...\nauto write_result = channel.Write(frame, sizeof(FrameHeader) + 320 * 240);\nif (!write_result.has_value()) {\n    // ShmError::kFull -- 环缓冲满，需要背压处理\n}\nchannel.Unlink();\n\n// 消费者\nauto result = ShmChannel<81920, 16>::OpenReader(\"video_ch0\");\nauto channel = std::move(result.value());\n\nuint8_t buffer[81920];\nuint32_t size = 0;\nauto wait = channel.WaitReadable(1000);  // 等待最多 1 秒\nif (wait.has_value()) {\n    auto read_result = channel.Read(buffer, size);\n    // 处理 buffer[0..size]\n}\n```\n\n**特点**: 所有参数编译期确定 (SlotSize, SlotCount)，错误通过 `expected` 返回，零异常零堆分配。API 更底层，但每一步的行为完全可预测。\n\n### 6.3 关键差异总结\n\n| 维度 | cpp-ipc | newosp ShmChannel |\n|------|:-------:|:-----------------:|\n| API 风格 | 高层封装 (`send`/`recv`) | 底层显式控制 (`Write`/`Read` + `expected`) |\n| 消息大小 | 运行时动态 | 编译期固定 (`static_assert`) |\n| 多消费者 | 内建广播 (最多 32) | 每通道单消费者 |\n| 等待机制 | spin → 信号量 | 指数退避轮询 |\n| 异常依赖 | 需要 | `-fno-exceptions` 兼容 |\n| 崩溃恢复 | 手动清理 | `CreateOrReplace` 自动 |\n| 嵌入式适配 | 通用 | ARM 内存序、缓存行对齐、零堆分配 |\n\n## 7. 共享内存 IPC 的工程注意事项\n\n### 7.1 权限与安全\n\n```cpp\nstatic constexpr mode_t kShmPermissions = 0600;  // 仅 owner 读写\n```\n\n共享内存对象在 `/dev/shm/` 中是文件，权限管理与普通文件相同。嵌入式系统中通常所有进程以 root 运行，但在多用户系统中需要注意权限设置。\n\n### 7.2 NUMA 感知\n\n在多 NUMA 节点的服务器上，共享内存的物理页可能分配在创建进程所在的 NUMA 节点上。如果消费者在另一个 NUMA 节点的 CPU 上运行，每次访问需要跨节点，延迟增加 50-100 ns。\n\n嵌入式 ARM Linux 通常是单 NUMA 节点 (UMA)，不存在此问题。\n\n### 7.3 大页 (Huge Pages)\n\n默认页大小 4 KB，76 KB 的视频帧需要 19 次 TLB miss (首次访问)。使用 2 MB 大页可以将 TLB miss 降到 1 次：\n\n```c\nmmap(NULL, size, PROT_READ | PROT_WRITE,\n     MAP_SHARED | MAP_HUGETLB, fd, 0);\n```\n\n大页在高吞吐量场景 (如 4K 视频帧) 中可以带来 5-15% 的性能提升。\n\n### 7.4 SELinux / seccomp 限制\n\n容器化环境 (Docker) 中，`shm_open` 可能被 seccomp 策略拦截。需要在容器启动时添加 `--ipc=host` 或显式允许 `shm_open` 系统调用。嵌入式系统通常不运行在容器中，但如果使用 Yocto 构建的 SELinux 加固镜像，需要配置相应的 policy。\n\n## 8. 总结\n\n| 维度 | 裸 POSIX shm | cpp-ipc | newosp ShmChannel |\n|------|:----------:|:-------:|:-----------------:|\n| 同步机制 | 无 (需自行实现) | CAS + spin-lock + 信号量 | CAS + 指数退避 |\n| 生命周期 | 手动 unlink | 手动管理 | RAII + CreateOrReplace |\n| 堆分配 | 用户决定 | 有 (buff_t) | 零 (编译期固定) |\n| ARM 支持 | 用户负责 | 编译器内建 | 显式 fence + alignas |\n| 多消费者 | 用户实现 | 内建广播 | 每通道单消费者 |\n| 错误处理 | errno | 异常/返回值 | `expected<T, ShmError>` |\n| 适用场景 | 原型验证 | 桌面/服务器跨平台 IPC | **嵌入式实时系统** |\n\nnewosp 的共享内存 IPC 遵循嵌入式系统的核心原则：**编译期确定性、零堆分配、显式内存序、RAII 生命周期**。它牺牲了 cpp-ipc 的灵活性 (动态消息大小、多消费者广播、跨平台)，换来了确定性延迟和可审计的资源占用——这正是安全关键嵌入式系统所需要的。\n\n> 参考实现: [newosp](https://github.com/DeguiLiu/newosp) -- MIT 协议开源，header-only\n>\n> 对比库: [cpp-ipc](https://github.com/mutouyun/cpp-ipc) -- MIT 协议开源，跨平台\n>\n> 相关文章: [C++编程：使用 cpp-ipc 实现基于共享内存的进程间发布订阅](https://blog.csdn.net/stallion5632/article/details/140881982)\n",
      "ctime": "1771552617",
      "mtime": "1771552617",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/spsc_ringbuffer_design.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651619886",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "SPSC 无锁环形缓冲区设计剖析: 从原理到每一行代码的工程抉择",
      "brief_content": "深度剖析 liudegui/ringbuffer 的 SPSC 无锁环形缓冲区实现。逐项解析缓存行对齐、2 的幂位掩码、wait-free 无重试设计、精确 acquire-release 内存序、F",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 配套代码: [liudegui/ringbuffer](https://gitee.com/liudegui/ringbuffer) -- header-only C++14 SPSC 环形缓冲区，Catch2 测试，ASan/UBSan/TSan clean\n>\n> 相关文章:\n> - [内存屏障的硬件原理: 从 Store Buffer 到 ARM DMB/DSB/ISB](../memory_barrier_hardware/) -- acquire/release 背后的硬件机制\n> - [无锁编程核心原理: 从 CAS 到三种队列模式](../lockfree_programming_fundamentals/) -- SPSC/MPSC/MPMC 的理论基础与对比\n> - [无锁异步日志设计: Per-Thread SPSC](../lockfree_async_log/) -- SPSC 在日志系统中的工程应用\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- 跨进程场景的 SPSC Ring Buffer\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- SPSC 在 newosp 消息总线中的角色\n>\n> 参考:\n> - 原始实现: [jnk0le/Ring-Buffer](https://github.com/jnk0le/Ring-Buffer) -- 本项目在其基础上修正了所有权违反、冗余屏障等问题\n> - CSDN 原文: [C++ 无锁环形队列 (LockFreeRingQueue) 的简单实现、测试和分析](https://blog.csdn.net/stallion5632/article/details/139755553)\n> - CSDN 原文: [嵌入式 ARM Linux 平台高性能无锁异步日志系统设计与实现](https://blog.csdn.net/stallion5632/article/details/143567510)\n\n## 1. 为什么是 SPSC 而不是 MPMC\n\n在嵌入式系统中，环形缓冲区是最基础的数据结构之一。笔者之前在 CSDN 上发布过一个基于 CAS 的 MPMC（多生产者多消费者）无锁队列 `LockFreeRingQueue`，它的核心入队逻辑如下：\n\n```cpp\n// MPMC: CAS 重试循环\nbool Enqueue(const T& data) {\n    uint32_t head = head_.load(std::memory_order_relaxed);\n    while (true) {\n        uint32_t tail = tail_.load(std::memory_order_acquire);\n        if ((head - tail) >= capacity_) return false;\n        // CAS 竞争: 多个生产者争抢 head 位置\n        if (head_.compare_exchange_weak(head, head + 1,\n                std::memory_order_acq_rel, std::memory_order_relaxed)) {\n            data_[head & mask_] = data;\n            return true;\n        }\n        // CAS 失败 -> 重新加载 head, 再试\n    }\n}\n```\n\n这个设计功能完备，但存在根本性问题：**CAS 重试循环在多核竞争下的延迟不确定**。当 4 个生产者同时入队时，某些线程可能在 CAS 上自旋数十次才成功，最坏延迟不可预测。\n\n在实际的嵌入式场景中，许多数据通道天然就是**单生产者单消费者**的：\n\n| 场景 | 生产者 | 消费者 |\n|------|--------|--------|\n| ADC 采样 | DMA 完成中断 | 处理线程 |\n| 串口接收 | UART ISR | 协议解析线程 |\n| 日志系统 | 应用线程 | 日志写盘线程 |\n| 传感器数据 | 采集线程 | 融合线程 |\n\n对这些场景，MPMC 的 CAS 竞争是不必要的开销。SPSC 可以做到 **wait-free**（最坏情况也是 O(1)），而 MPMC 只能做到 **lock-free**（全局保证进展，但单个线程可能饿死）。\n\n这就是 [liudegui/ringbuffer](https://gitee.com/liudegui/ringbuffer) 的出发点：**为单生产者单消费者场景提供最优解，而不是为通用场景提供折中方案**。\n\n## 2. 为什么不用对象池\n\n避免热路径上 `malloc`/`free` 的第一反应通常是对象池 -- 预分配一批对象，`acquire()` 取出，用完 `release()` 归还：\n\n```cpp\ntemplate<typename T>\nclass ObjectPool {\n    std::queue<std::shared_ptr<T>> pool_;\n    std::mutex mutex_;\npublic:\n    std::shared_ptr<T> acquire() {\n        std::lock_guard<std::mutex> lock(mutex_);\n        if (pool_.empty()) return std::make_shared<T>();\n        auto obj = std::move(pool_.front());\n        pool_.pop();\n        return obj;\n    }\n    void release(std::shared_ptr<T> obj) {\n        std::lock_guard<std::mutex> lock(mutex_);\n        pool_.push(std::move(obj));\n    }\n};\n```\n\n对象池确实消除了大部分 `malloc`/`free`，比裸分配快约 60%。但在嵌入式 SPSC 场景下，它引入了三个新的性能代价：\n\n**mutex 在每次存取上**。`acquire()` 和 `release()` 各持有一次 mutex。即使是无竞争的 `futex` 快速路径，在 ARM Cortex-A72 上也需要 ~20-40ns；而 SPSC 环形缓冲的 `Push`/`Pop` 是 wait-free 的 ~5-8ns。\n\n**shared_ptr 原子引用计数**。每次 `acquire` 返回 `shared_ptr`，每次拷贝/销毁触发 `atomic_fetch_add`/`atomic_fetch_sub`。SPSC 场景中数据是单向传递（生产者 → 消费者），所有权始终明确，引用计数完全多余。\n\n**queue 动态增长**。`std::queue` 底层是 `std::deque`，节点分配不可控。池为空时 `make_shared<T>()` 直接回退到堆分配，内存预算无法在编译期确定。\n\n| 维度 | 对象池 (mutex + shared_ptr) | SPSC 环形缓冲 |\n|------|:------------------------:|:------------:|\n| 同步机制 | mutex (futex) | 无锁 wait-free |\n| 引用管理 | atomic refcount | 值语义 memcpy |\n| 内存增长 | queue 动态扩展 | 编译期固定数组 |\n| 最坏延迟 | futex slow path ~us | O(1) ~ns |\n| 适用模式 | 多消费者共享、生命周期不确定 | 单生产者单消费者、用完即弃 |\n\n对象池适合**多个消费者共享对象、生命周期跨越多个作用域**的场景（典型如数据库连接池、线程池）。SPSC 通道的数据是**单向流动、用完即弃**的，环形缓冲直接覆写 slot 比\"取出-归还\"更简单、更快、更可预测。\n\n## 3. 整体架构\n\n```\nProducer Thread                    Consumer Thread\n    |                                  |\n    | Push(data)                       | Pop(data)\n    |   load head_ (relaxed)           |   load tail_ (relaxed)\n    |   load tail_ (acquire)           |   load head_ (acquire)\n    |   if full -> return false        |   if empty -> return false\n    |   write data_buff_[head & mask]  |   read data_buff_[tail & mask]\n    |   store head_+1 (release)        |   store tail_+1 (release)\n    |                                  |\n    v                                  v\n\n+----+----+----+----+----+----+----+----+\n| D0 | D1 | D2 | D3 | D4 | D5 | D6 | D7 |  data_buff_[8]\n+----+----+----+----+----+----+----+----+\n           ^                   ^\n           tail_               head_\n           (consumer writes)   (producer writes)\n```\n\n核心数据结构只有三个成员：\n\n```cpp\nPaddedIndex head_;                       // 生产者写，消费者读\nPaddedIndex tail_;                       // 消费者写，生产者读\nalignas(64) T data_buff_[BufferSize]{};  // 环形存储\n```\n\n下面逐项剖析每个设计决策。\n\n## 4. 缓存行对齐与 false sharing 消除\n\n### 4.1 问题\n\n`head_` 由生产者频繁写入，`tail_` 由消费者频繁写入。如果这两个变量位于同一条缓存行（通常 64 字节），会发生 **false sharing**：\n\n```\nCache Line (64B)\n+------------------+------------------+------- ...\n| head_ (8B)       | tail_ (8B)       | ...\n+------------------+------------------+------- ...\n      ^                    ^\n  CPU 0 写             CPU 1 写\n```\n\n当 CPU 0 修改 `head_` 时，整条缓存行被标记为 Modified（MESI 协议）。CPU 1 想读或写同一行上的 `tail_`，必须先通过总线将整条行从 CPU 0 的 L1 Cache 传输过来。反之亦然。**两个 CPU 在逻辑上互不干扰的变量上产生了串行化**。\n\n在 ARM Cortex-A 系列上，缓存行通常为 64 字节（Cortex-A53/A72/A76）。false sharing 导致的 L1 Cache miss 延迟约为 **40-80 个时钟周期**（视具体 SoC 互连架构），而 L1 Cache hit 仅需 **2-4 个时钟周期**。差距约 20x。\n\n### 4.2 解决方案\n\n```cpp\nstruct alignas(64) PaddedIndex {\n    std::atomic<IndexT> value{0};\n    char padding[64 - sizeof(std::atomic<IndexT>)]{};\n    static_assert(sizeof(std::atomic<IndexT>) <= 64,\n                  \"Atomic index exceeds cache line size.\");\n};\n\nPaddedIndex head_;                       // 独占一条缓存行\nPaddedIndex tail_;                       // 独占另一条缓存行\nalignas(64) T data_buff_[BufferSize]{};  // 数据区域从第三条缓存行开始\n```\n\n每个索引变量填充到 64 字节，确保 `head_` 和 `tail_` 分别独占一条缓存行。生产者反复修改 `head_` 时，只会引起自己 CPU 核心上对应缓存行的 Modified 状态转换，不会干扰消费者核心上持有 `tail_` 的缓存行。\n\n`data_buff_` 也用 `alignas(64)` 对齐，确保数据区域不会与 `tail_` 的填充字节共享缓存行。\n\n**代价**：每个 `PaddedIndex` 从 8 字节膨胀到 64 字节，总共多用 120 字节（2 x 56 字节填充）。对于嵌入式系统，这个代价可以忽略不计。\n\n## 5. 2 的幂位掩码\n\n### 5.1 原理\n\n环形缓冲区的索引需要「绕回」，即当索引到达末尾时回到开头。常规做法是取模运算：\n\n```cpp\n// 取模方式\nindex = head % BufferSize;\n```\n\nARM Cortex-M/A 处理器没有硬件除法指令（Cortex-A 的 SDIV/UDIV 是后加的，且延迟远高于位操作），取模运算会被编译器转换为除法或乘法近似，开销约 **4-12 个时钟周期**。\n\n当 `BufferSize` 是 2 的幂时，取模可以用位与替代：\n\n```cpp\n// 位掩码方式（等价于取模，仅当 BufferSize 是 2 的幂）\nstatic constexpr IndexT kMask = BufferSize - 1u;\nindex = head & kMask;\n```\n\n位与操作在所有 ARM 核心上都是 **单周期执行**。\n\n### 5.2 编译期约束\n\n```cpp\nstatic_assert((BufferSize & (BufferSize - 1)) == 0,\n              \"Buffer size must be a power of 2.\");\n```\n\n这个 `static_assert` 利用了 2 的幂的数学性质：`n & (n-1)` 清除最低有效位，如果结果为 0 则 `n` 只有一个位为 1，即 2 的幂。编译期检查，零运行时开销。\n\n### 5.3 索引自然溢出\n\n一个巧妙的设计是 `head_` 和 `tail_` **不做回绕**，它们是单调递增的无符号整数。可用元素数量通过无符号减法计算：\n\n```cpp\nIndexT Size() const noexcept {\n    return head_.value.load(AcquireOrder())\n         - tail_.value.load(std::memory_order_relaxed);\n}\n```\n\n当 `head_` 从 `UINT32_MAX` 溢出到 0 时，`head_ - tail_` 依然正确（C++ 标准保证无符号整数溢出是 well-defined 的模运算）。\n\n只在**访问数组时**才用 `& kMask` 映射到实际位置：\n\n```cpp\ndata_buff_[current_head & kMask] = data;\n```\n\n这比在每次递增时做 `head_ = (head_ + 1) % BufferSize` 更高效，因为减少了一次取模操作。\n\n### 5.4 IndexT 的配置意义\n\n```cpp\ntemplate <typename T, std::size_t BufferSize = 16,\n          bool FakeTSO = false, typename IndexT = std::size_t>\n```\n\n`IndexT` 默认为 `std::size_t`（64 位平台上 8 字节），但可以配置为更小的类型：\n\n| IndexT | 最大 BufferSize | 适用场景 |\n|--------|-----------------|----------|\n| `uint8_t` | 64 | 极小 MCU (RAM < 1 KB) |\n| `uint16_t` | 16384 | 嵌入式 MCU (RAM 几十 KB) |\n| `uint32_t` | ~1G | 通用 Linux 嵌入式 |\n| `size_t` | 理论最大 | 默认，64 位服务器 |\n\n约束条件：\n\n```cpp\nstatic_assert(BufferSize <= ((std::numeric_limits<IndexT>::max)() >> 1),\n              \"Buffer size is too large for the given indexing type.\");\n```\n\n为什么是 `>> 1`（即最大值的一半）？因为需要保证 `head_ - tail_` 在单调递增溢出后仍然正确。当 `BufferSize` 超过索引类型最大值的一半时，满队列状态 `(head - tail) == BufferSize` 和空队列状态 `(head - tail) == 0` 可能混淆。\n\n## 6. Wait-Free 无重试设计\n\n### 6.1 Lock-Free vs Wait-Free\n\n这两个概念经常被混淆：\n\n| 属性 | 保证 | 实现手段 |\n|------|------|----------|\n| **Lock-free** | 系统整体始终有进展（某个线程在有限步内完成），但单个线程可能被饿死 | CAS 重试循环 |\n| **Wait-free** | 每个线程都在有限步内完成操作 | 无重试，所有路径都是 O(1) |\n\nMPMC 队列通常只能做到 lock-free，因为多个生产者必须用 CAS 竞争同一个 `head_`，竞争失败的线程需要重试。\n\nSPSC 队列可以做到 wait-free，因为 `head_` 只有一个写者（生产者），`tail_` 只有一个写者（消费者），**不存在写-写竞争**。\n\n### 6.2 Push 的每一步\n\n```cpp\nbool PushImpl(U&& data) {\n    // 1. 读自己拥有的 head_（relaxed：无需同步，只有自己写）\n    const IndexT current_head = head_.value.load(std::memory_order_relaxed);\n\n    // 2. 读对方的 tail_（acquire：看到消费者最新的释放）\n    const IndexT current_tail = tail_.value.load(AcquireOrder());\n\n    // 3. 满检查（O(1)，无循环）\n    if ((current_head - current_tail) == BufferSize) {\n        return false;\n    }\n\n    // 4. 写数据\n    data_buff_[current_head & kMask] = std::forward<U>(data);\n\n    // 5. 发布新 head_（release：确保数据写入对消费者可见）\n    head_.value.store(current_head + 1, ReleaseOrder());\n    return true;\n}\n```\n\n**没有任何循环或重试**。要么满了返回 false（调用者决策），要么一次性完成写入。最坏路径和最好路径执行相同数量的指令。\n\n对比 MPMC 的 CAS 循环：\n\n```cpp\n// MPMC: 可能重试 N 次\nwhile (!head_.compare_exchange_weak(head, head + 1, ...)) {\n    // 失败：其他生产者抢先，重新加载 head 再试\n}\n```\n\n在 4 核竞争下，CAS 失败重试的平均次数随竞争线程数线性增长。SPSC 的 Push 始终是 **恒定 5 步操作**。\n\n## 7. 精确的内存序选择\n\n内存序是无锁编程中最容易出错的部分。多数开发者为求安全使用 `memory_order_seq_cst`（顺序一致性），但这在 ARM 上代价高昂。\n\n### 7.1 ARM 内存模型背景\n\nARM 是 **弱序（weakly-ordered）** 架构。CPU 可能：\n\n1. 将**存储操作（store）重排到后续加载操作（load）之前**\n2. 将**多个存储操作之间重排**\n3. 将**多个加载操作之间重排**\n\nx86 是 **TSO（Total Store Order）** 架构，仅允许 store-load 重排。因此 x86 上很多无锁代码「碰巧正确」，但移植到 ARM 后出 bug。重排序的硬件根因 (Store Buffer、Invalidation Queue、MESI 协议) 以及 ARM DMB/DSB/ISB 三条屏障指令的精确语义，详见 [内存屏障的硬件原理](../memory_barrier_hardware/)。\n\n不同内存序在 ARM 上的硬件指令：\n\n| 内存序 | ARM 指令 | 开销 |\n|--------|----------|------|\n| `relaxed` | 普通 load/store | 0 额外开销 |\n| `acquire` | load + `DMB ISHLD` (ARMv8) 或 `LDAPR`/`LDAR` | 约 10-40 周期 |\n| `release` | `DMB ISH` + store (ARMv8) 或 `STLR` | 约 10-40 周期 |\n| `seq_cst` | `DMB ISH` + load/store + `DMB ISH` | 约 20-80 周期 |\n\n### 7.2 本实现的内存序选择\n\n每个原子操作的内存序都经过精确推敲：\n\n**生产者读自己的 `head_`：`relaxed`**\n\n```cpp\nconst IndexT current_head = head_.value.load(std::memory_order_relaxed);\n```\n\n`head_` 只有生产者自己会写。读自己上次写的值，不需要跨线程同步。\n\n**生产者读对方的 `tail_`：`acquire`**\n\n```cpp\nconst IndexT current_tail = tail_.value.load(AcquireOrder());\n```\n\n消费者 Pop 后会 `release` 更新 `tail_`。生产者用 `acquire` 读取，形成 **release-acquire 配对**，保证生产者看到消费者释放的最新 `tail_` 值。语义：「我看到 tail 至少推进到了这里，这些位置是安全可写的」。\n\n**生产者更新 `head_`：`release`**\n\n```cpp\nhead_.value.store(current_head + 1, ReleaseOrder());\n```\n\n`release` 保证**之前的数据写入（`data_buff_[...] = data`）不会被 CPU 重排到 `head_` 更新之后**。消费者用 `acquire` 读取 `head_` 时，保证能看到完整的数据。这是正确性的核心：如果数据写入被重排到 `head_` 更新之后，消费者可能读到未初始化的旧数据。\n\n### 7.3 为什么不用 `seq_cst`\n\n`seq_cst` 提供全局全序，但 SPSC 不需要。SPSC 的同步关系是线性的：\n\n```\nProducer: write data -> release head  -(同步)-> acquire head -> read data :Consumer\nConsumer: read data  -> release tail  -(同步)-> acquire tail -> check space :Producer\n```\n\n只有两对 release-acquire 关系，不需要第三方观察者看到全局一致的顺序。`seq_cst` 在 ARM 上每次操作多一个 `DMB` 屏障，代价约 **2x**。\n\n### 7.4 冗余屏障修正\n\n原始 jnk0le/Ring-Buffer 实现中有一个冗余：\n\n```cpp\n// 原始代码（jnk0le）\natomic_thread_fence(std::memory_order_release);    // 显式屏障\nhead_.store(current_head + 1, std::memory_order_relaxed);  // relaxed store\n```\n\n`atomic_thread_fence(release)` + `relaxed store` 在语义上等价于 `release store`，但在 ARM 上可能生成两条指令（`DMB ISH` + `STR`），而 `store(release)` 在 ARMv8 上可以生成单条 `STLR` 指令。\n\n修正后：\n\n```cpp\n// 修正代码（liudegui/ringbuffer）\nhead_.value.store(current_head + 1, ReleaseOrder());  // 单条 STLR\n```\n\n这是一个微优化，但体现了「**理解硬件指令映射**」的重要性。\n\n## 8. FakeTSO 单核模式\n\n### 8.1 原理\n\n在单核 MCU（如 Cortex-M4）上，只有一个 CPU 核心，**不存在跨核缓存一致性问题**。所有的 DMB（Data Memory Barrier）指令都是多余的。\n\n但 ISR（中断服务程序）和主循环之间仍然需要防止**编译器重排**。C++ 的 `std::atomic` 即使用 `relaxed` 内存序，也能防止编译器对原子操作的重排。\n\n```cpp\nstatic constexpr std::memory_order AcquireOrder() noexcept {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_acquire;\n}\n\nstatic constexpr std::memory_order ReleaseOrder() noexcept {\n    return FakeTSO ? std::memory_order_relaxed : std::memory_order_release;\n}\n```\n\n当 `FakeTSO = true` 时，所有 acquire/release 降级为 relaxed。ARM 编译器对 relaxed 原子操作生成普通的 `LDR`/`STR` 指令，**不插入任何 DMB 屏障**。\n\n### 8.2 为什么叫 FakeTSO\n\nTSO（Total Store Order）是 x86 的内存模型，在 TSO 下 acquire-load 和 release-store 不需要额外屏障（硬件保证）。`FakeTSO` 的含义是「**假装我们运行在 TSO 架构上**」——在单核 MCU 上这是安全的，因为没有第二个 CPU 核心能观察到重排。\n\n### 8.3 安全边界\n\n`FakeTSO = true` 的前提条件：\n\n1. **只有一个 CPU 核心**（或所有参与线程都 pinned 到同一核心）\n2. 生产者是 ISR，消费者是主循环（或反之）\n3. **没有 DMA 设备直接读写 ring buffer**（DMA 有自己的内存视图，需要显式同步）\n\n违反这些条件使用 `FakeTSO = true` 是 **未定义行为**。\n\n### 8.4 实际效果\n\n在 Cortex-M4 (100 MHz) 上，DMB 指令延迟约 3-5 个时钟周期。每次 Push/Pop 有两个原子操作（一个 load + 一个 store），FakeTSO 省下约 **6-10 个时钟周期/操作**。对于 10 kHz 采样率，每秒节省 60,000-100,000 个周期。这在 MCU 上是可观的。\n\n## 9. 批量 memcpy 操作\n\n### 9.1 为什么需要批量\n\n单元素 Push/Pop 每次操作都执行：\n\n1. 一次 `relaxed load`（读自己的索引）\n2. 一次 `acquire load`（读对方的索引）\n3. 一次数据拷贝\n4. 一次 `release store`（更新自己的索引）\n\n第 2 步的 acquire load 和第 4 步的 release store 涉及内存屏障。当需要传输 1000 个元素时，逐个操作需要 1000 次屏障。\n\n批量操作将 **N 个元素用一次 acquire load 和一次 release store 包裹**：\n\n```cpp\nstd::size_t PushBatchCore(const T* buf, std::size_t count) {\n    std::size_t written = 0;\n    IndexT current_head = head_.value.load(std::memory_order_relaxed);\n\n    while (written < count) {\n        const IndexT current_tail = tail_.value.load(AcquireOrder());  // 一次 acquire\n        const IndexT space = BufferSize - (current_head - current_tail);\n\n        if (space == 0) break;\n\n        const std::size_t to_write = std::min(count - written,\n                                               static_cast<std::size_t>(space));\n        // 处理环形回绕：可能需要两段 memcpy\n        const std::size_t head_offset = current_head & kMask;\n        const std::size_t first_part = std::min(to_write, BufferSize - head_offset);\n\n        std::memcpy(&data_buff_[head_offset], buf + written,\n                    first_part * sizeof(T));\n        if (to_write > first_part) {\n            std::memcpy(&data_buff_[0], buf + written + first_part,\n                        (to_write - first_part) * sizeof(T));\n        }\n\n        written += to_write;\n        current_head += static_cast<IndexT>(to_write);\n        head_.value.store(current_head, ReleaseOrder());  // 一次 release\n    }\n    return written;\n}\n```\n\n### 9.2 环形回绕的两段 memcpy\n\n当写入跨越数组末尾时，需要分两段拷贝：\n\n```\ndata_buff_:\n+---+---+---+---+---+---+---+---+\n| . | . | X | X | X | . | . | . |\n+---+---+---+---+---+---+---+---+\n  0   1   2   3   4   5   6   7\n\nhead_ = 5, 要写入 5 个元素:\n\n第一段: memcpy(&data_buff_[5], buf, 3 * sizeof(T))  // 位置 5,6,7\n第二段: memcpy(&data_buff_[0], buf+3, 2 * sizeof(T)) // 位置 0,1\n```\n\n`memcpy` 比逐元素赋值高效得多，因为：\n\n1. 编译器可以展开为 NEON/SVE SIMD 指令（ARM 128/256 位宽加载/存储）\n2. 大块 memcpy 触发 CPU 的硬件预取器（prefetcher），提升缓存命中率\n3. 连续内存访问对 CPU 流水线友好\n\n### 9.3 trivially_copyable 约束\n\n```cpp\nstatic_assert(std::is_trivially_copyable<T>::value,\n              \"Type T must be trivially copyable.\");\n```\n\n`memcpy` 只对 `trivially_copyable` 类型安全。如果 `T` 有自定义拷贝构造函数、析构函数或虚函数表，`memcpy` 会绕过这些逻辑，导致未定义行为。\n\n这个约束也与嵌入式设计哲学一致：**热路径上的数据类型应该是 POD-like 的**，不应携带复杂的生命周期管理。\n\n## 10. ProducerClear 所有权修正\n\n### 10.1 原始实现的 bug\n\njnk0le/Ring-Buffer 原始实现中，`ProducerClear()` 修改 `tail_`：\n\n```cpp\n// 原始代码（jnk0le）-- 有 bug\nvoid producerClear() {\n    tail.store(head.load(relaxed), relaxed);  // 生产者修改 tail_!\n}\n```\n\n这违反了 SPSC 的核心约定：**`tail_` 由消费者拥有，只有消费者可以写入**。如果生产者和消费者同时操作（生产者调用 `producerClear`，消费者正在 `Pop`），两个线程同时写 `tail_`，产生数据竞争（data race），属于未定义行为。\n\n### 10.2 修正方案\n\n```cpp\n// 修正代码（liudegui/ringbuffer）\nvoid ProducerClear() noexcept {\n    // Producer owns head_. Read tail and set head to match it.\n    head_.value.store(tail_.value.load(std::memory_order_relaxed),\n                      std::memory_order_relaxed);\n}\n```\n\n生产者只修改自己拥有的 `head_`，将其设为当前 `tail_` 值。效果一样（`head == tail` 意味着队列为空），但不违反所有权约定。\n\n对称地，`ConsumerClear()` 只修改 `tail_`：\n\n```cpp\nvoid ConsumerClear() noexcept {\n    tail_.value.store(head_.value.load(std::memory_order_relaxed),\n                      std::memory_order_relaxed);\n}\n```\n\n### 10.3 为什么用 relaxed\n\n`ProducerClear()` 和 `ConsumerClear()` 都用 `relaxed` 是安全的，因为：\n\n1. Clear 操作本身是一种「重置」，不需要与对方同步具体数据内容\n2. Clear 之后的下一次 Push/Pop 会用 acquire/release 重新建立同步关系\n3. Clear 通常在系统初始化或错误恢复路径调用，不在热路径\n\n## 11. PushFromCallback -- 延迟构造\n\n```cpp\ntemplate <typename Callable>\nbool PushFromCallback(Callable&& callback) {\n    const IndexT current_head = head_.value.load(std::memory_order_relaxed);\n    const IndexT current_tail = tail_.value.load(AcquireOrder());\n\n    if ((current_head - current_tail) == BufferSize) {\n        return false;  // 满了，callback 不会被调用\n    }\n\n    data_buff_[current_head & kMask] = callback();  // 有空间才构造\n    head_.value.store(current_head + 1, ReleaseOrder());\n    return true;\n}\n```\n\n为什么不直接 `Push(expensive_construct())`？\n\n如果队列已满，`Push` 返回 false，但 `expensive_construct()` **已经被调用并构造了对象**，白白浪费了计算。`PushFromCallback` 先检查空间，只在确认有空间时才调用 callback 构造数据。\n\n典型场景：\n\n```cpp\nrb.PushFromCallback([&]() -> LogEntry {\n    // 这个构造涉及 snprintf 格式化，开销约 1us\n    return LogEntry{timestamp(), format_message(...)};\n});\n```\n\n如果队列满了（日志积压），格式化操作完全跳过，节省 CPU 时间。\n\n回调类型是模板参数 `Callable`，支持 lambda、`std::function`、函数指针，编译器可以内联 lambda，零间接调用开销。\n\n## 12. 数据布局与缓存友好性\n\n### 12.1 完整内存布局\n\n```\nAddress   Content              Size    Cache Line\n0x00      head_.value          8B      \\\n0x08      head_.padding        56B      > Cache Line 0 (64B)\n                                       /\n0x40      tail_.value          8B      \\\n0x48      tail_.padding        56B      > Cache Line 1 (64B)\n                                       /\n0x80      data_buff_[0]        sizeof(T) * BufferSize\n          ...                           > Cache Line 2 ~ N\n          data_buff_[N-1]\n```\n\n三个成员分别位于不同的缓存行组：\n\n- **生产者热数据**：`head_` + `data_buff_[head & mask]`\n- **消费者热数据**：`tail_` + `data_buff_[tail & mask]`\n- **生产者偶尔读**：`tail_`（检查空间）\n- **消费者偶尔读**：`head_`（检查数据）\n\n### 12.2 数组的缓存行为\n\n环形缓冲区的顺序访问模式对 CPU 预取器非常友好。生产者和消费者都是按索引单调递增访问 `data_buff_`，CPU 硬件预取器会提前加载下一条缓存行。\n\n对比链表：节点在堆上随机分配，指针跳转导致缓存 miss。环形缓冲区的数组布局保证了 **空间局部性（spatial locality）**。\n\n## 13. 设计决策汇总\n\n| 决策 | 为什么 | 硬件原理 |\n|------|--------|----------|\n| SPSC 而非 MPMC | 消除 CAS 竞争，wait-free | 无写-写竞争 = 无重试 |\n| `alignas(64)` 填充 | 消除 false sharing | MESI 协议按缓存行粒度同步 |\n| 2 的幂 + 位掩码 | 替代取模，单周期执行 | ARM 无硬件除法或延迟高 |\n| 索引不回绕 | 减少一次取模操作 | 无符号溢出是 well-defined |\n| `relaxed` 读自己 | 无需同步，只有自己写 | 省去 DMB 屏障 |\n| `acquire`/`release` 配对 | 最小必要同步 | ARM LDAR/STLR 单指令 |\n| 不用 `seq_cst` | SPSC 不需要全局全序 | 省去额外 DMB |\n| FakeTSO | 单核 MCU 省去所有屏障 | 单核无缓存一致性问题 |\n| `memcpy` 批量操作 | 摊薄屏障开销，触发 SIMD | 连续内存 + 硬件预取 |\n| `trivially_copyable` 约束 | memcpy 安全性前提 | 无构造/析构副作用 |\n| ProducerClear 改 `head_` | 修正所有权违反 | 消除 data race UB |\n| 去掉冗余 fence | fence+relaxed = release store | ARMv8 STLR 单指令 |\n| 可配置 IndexT | MCU RAM 节省 | 小类型减少原子操作宽度 |\n| 模板 Callable | 内联 lambda，零间接调用 | 编译器去虚化 |\n\n## 14. 从 MPMC 到 SPSC 的性能差距\n\n基于笔者之前 CSDN 文章中的 `LockFreeRingQueue`（MPMC CAS）和本项目 `spsc::Ringbuffer` 的对比：\n\n| 维度 | MPMC CAS 队列 | SPSC Ringbuffer |\n|------|---------------|-----------------|\n| 入队最坏延迟 | O(N)（N = 竞争线程数） | O(1)（wait-free） |\n| 内存屏障 | `acq_rel` CAS（ARM: LDAXR+STLXR 循环） | acquire load + release store |\n| 缓存行为 | `head_` 被多核乒乓 | `head_` 仅一核修改 |\n| 数据拷贝 | 逐元素赋值 | `memcpy` 批量 |\n| 适用场景 | 多个生产者/消费者 | 严格一对一 |\n\n**选择原则**：如果你的场景是严格的单生产者单消费者（绝大多数嵌入式数据通道），使用 SPSC。MPMC 的通用性是以性能为代价的。\n\n## 15. 在实际项目中的应用\n\n`spsc::Ringbuffer` 在以下项目中被复用：\n\n- **[newosp](https://github.com/DeguiLiu/newosp)**：`spsc_ringbuffer.hpp` 模块，用于日志系统和传感器数据管道\n- **[mccc-bus](https://gitee.com/liudegui/mccc-bus)**：MPSC 消息总线内部的单生产者路径\n\n无锁异步日志系统中的典型用法：\n\n```cpp\n// 日志线程 (生产者)\nspsc::Ringbuffer<LogEntry, 4096> log_ring;\n\nvoid LogWrite(const char* msg) {\n    log_ring.PushFromCallback([&]() -> LogEntry {\n        return LogEntry{Now(), msg, strlen(msg)};\n    });\n}\n\n// 写盘线程 (消费者)\nvoid LogFlush() {\n    LogEntry batch[64];\n    std::size_t n = log_ring.PopBatch(batch, 64);\n    for (std::size_t i = 0; i < n; ++i) {\n        write(fd, batch[i].buf, batch[i].len);\n    }\n}\n```\n\n## 16. 总结\n\n`spsc::Ringbuffer` 的设计哲学可以概括为一句话：**只为确定的场景付出最小的代价**。\n\n它不试图支持多生产者多消费者（那是 MPMC 队列的职责），不试图支持非平凡类型（那是有锁队列的领域），不试图在所有架构上使用同一种内存序（那是 `seq_cst` 的懒惰）。通过缩窄适用范围，在 SPSC 这个特定领域做到了 wait-free、零冗余屏障、缓存友好、批量高效。\n\n每一个设计决策都对应一个具体的硬件现象或性能瓶颈：缓存行对齐对应 false sharing、位掩码对应 ARM 除法开销、FakeTSO 对应单核 MCU 无 DMA 屏障、memcpy 对应 SIMD 加速。**没有「因为教科书说要这样」的设计，只有「因为硬件是这样工作的」的选择**。\n",
      "ctime": "1771552621",
      "mtime": "1771552621",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/tcp_ringbuffer_short_write.md": {
    "err_no": 0,
    "data": {
      "id": "7607620065857519666",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "TCP 非阻塞发送的 Short Write 问题: 环形缓冲区 + epoll 事件驱动方案",
      "brief_content": "非阻塞 TCP 发送的 short write 问题在高吞吐嵌入式场景下不可回避。本文从一个 CSDN 环形缓冲方案出发，逐项分析其 5 个工程缺陷 (非 2 幂、无界索引、内存泄漏、部分发送丢失、E",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [C++编程：利用环形缓冲区优化 TCP 发送流程，避免 Short Write 问题](https://blog.csdn.net/stallion5632/article/details/143668586)\n>\n> 前置阅读: [Linux编程：解析 EAGAIN 错误 Resource temporarily unavailable](https://blog.csdn.net/stallion5632/article/details/142407679)\n>\n> 相关: [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) | [ARM-Linux 网络性能优化](../arm_linux_network_optimization/)\n\n---\n\n## 1. 问题域: Short Write 与 EAGAIN\n\n### 1.1 什么是 TCP Short Write\n\n非阻塞模式下调用 `send()` / `write()`，内核 TCP 发送缓冲区空间不足时，系统调用只写入**部分字节**并返回实际写入数，`errno` 置为 `EAGAIN` / `EWOULDBLOCK`。这就是 short write。\n\n```\n应用层: send(fd, buf, 4096)\n        ↓ 内核 TCP 发送缓冲区只剩 1500 字节\n        返回 1500 (而非 4096)\n        剩余 2596 字节需要应用层自行处理\n```\n\n阻塞模式下 `send()` 会等待直到全部写完，但阻塞会导致线程挂起，在 epoll 事件循环中不可接受。\n\n### 1.2 EAGAIN: 不是错误，是\"稍后重试\"\n\nEAGAIN (errno 11) 是 POSIX 标准定义的瞬态错误码，表示\"资源暂时不可用\"。在非阻塞 I/O 中，它的含义是:\n\n- **send() 返回 -1, errno=EAGAIN**: 内核 TCP 发送缓冲区已满，一个字节也写不进去。不是连接错误，稍后重试可能成功。\n- **send() 返回 N (0 < N < len)**: 写入了部分字节 (short write)。不一定触发 EAGAIN，但后续 send 可能触发。\n\n关键区分:\n\n| 返回值 | errno | 含义 | 处理方式 |\n|--------|-------|------|----------|\n| N > 0 | - | 成功写入 N 字节 | 推进指针，继续写剩余 |\n| -1 | EAGAIN / EWOULDBLOCK | 内核缓冲满 | 等待 EPOLLOUT 后重试 |\n| -1 | EINTR | 被信号中断 | 立即重试 |\n| -1 | EPIPE / ECONNRESET | 连接已断 | 关闭连接 |\n| 0 | - | 对端关闭 | 关闭连接 |\n\n一个常见的错误是把 EAGAIN 当作致命错误直接断开连接 -- 这会导致在网络拥塞或接收端处理缓慢时产生不必要的连接断开。\n\n### 1.3 正确的处理策略\n\n1. **同步重试 (简单场景)**: 循环调用 `send()`，遇到 EAGAIN 时 `yield()` + 重试，超过上限则报告失败。适合低频场景。\n2. **用户态发送缓冲 + EPOLLOUT (高吞吐场景)**: 数据先写入环形缓冲区，由 `EPOLLOUT` 事件驱动异步刷写。不阻塞调用线程。\n\n本文重点讨论方案 2。\n\n---\n\n## 2. 原始方案分析\n\n原文实现了一个 `LockFreeBytesBuffer` (SPSC 字节环形缓冲) + `SocketContext` (epoll 事件驱动)。核心思路正确，但代码存在 5 个工程问题。\n\n### 2.1 原始代码 (关键部分)\n\n```cpp\nclass LockFreeBytesBuffer {\n public:\n  static const std::size_t kBufferSize = 10240U;\n\n  bool append(const char* data, std::size_t length) noexcept {\n    const std::size_t current_write = writer_index_.load(std::memory_order_relaxed);\n    const std::size_t current_read = reader_index_.load(std::memory_order_acquire);\n    const std::size_t free_space =\n        (current_read + kBufferSize - current_write - 1U) % kBufferSize;\n    if (length > free_space) return false;\n\n    const std::size_t pos = current_write % kBufferSize;\n    const std::size_t first_part = std::min(length, kBufferSize - pos);\n    std::memcpy(&buffer_[pos], data, first_part);\n    std::memcpy(&buffer_[0], data + first_part, length - first_part);\n    writer_index_.store(current_write + length, std::memory_order_release);\n    return true;\n  }\n\n  std::size_t beginRead(const char** target) noexcept {\n    const std::size_t current_read = reader_index_.load(std::memory_order_relaxed);\n    const std::size_t current_write = writer_index_.load(std::memory_order_acquire);\n    const std::size_t available = (current_write - current_read) % kBufferSize;\n    if (available == 0U) return 0U;\n\n    const std::size_t pos = current_read % kBufferSize;\n    *target = &buffer_[pos];\n    return std::min(available, kBufferSize - pos);\n  }\n\n  void endRead(std::size_t length) noexcept {\n    const std::size_t current_read = reader_index_.load(std::memory_order_relaxed);\n    reader_index_.store(current_read + length, std::memory_order_release);\n  }\n\n private:\n  char buffer_[kBufferSize];\n  std::atomic<std::size_t> reader_index_{0};\n  std::atomic<std::size_t> writer_index_{0};\n};\n```\n\n### 2.2 问题 1: 缓冲区大小不是 2 的幂\n\n```cpp\nstatic const std::size_t kBufferSize = 10240U;  // 不是 2 的幂\n\nconst std::size_t pos = current_write % kBufferSize;  // 除法取模\n```\n\n10240 不是 2 的幂，`% 10240` 编译器无法优化为位掩码 `& (N-1)`，在 ARM Cortex-A53 上一次除法需要 ~20 个时钟周期，位与只需 1 个。\n\n每次 `append()` 和 `beginRead()` 各有 2 次取模，单次 I/O 操作多出 ~60 ns 的无谓开销。\n\n**修正**: 缓冲区大小用 2 的幂，取模改为位与:\n\n```cpp\nstatic constexpr std::size_t kBufferSize = 8192U;  // 2^13\nstatic constexpr std::size_t kMask = kBufferSize - 1U;\n\nconst std::size_t pos = current_write & kMask;  // 1 条 AND 指令\n```\n\n### 2.3 问题 2: 无界索引 + 非 2 幂 = 溢出隐患\n\n`writer_index_` 和 `reader_index_` 是无界递增的 `size_t`。如果 `kBufferSize` 是 2 的幂，无符号溢出后 `(write - read)` 的差值仍然正确 (利用无符号算术的回绕性质)。但 `kBufferSize = 10240` 下:\n\n```cpp\nstd::size_t available = (current_write - current_read) % kBufferSize;\n```\n\n当 `write - read` 接近 `SIZE_MAX` 时，`% 10240` 的结果不等于实际有效数据量。虽然在实践中 `size_t` 的回绕周期极长 (64-bit 下约 1.8 x 10^19)，但设计上不应依赖此假设。\n\n**修正**: 使用 2 的幂后，索引差值天然正确:\n\n```cpp\n// 2 的幂下，无符号差值 & kMask 始终正确\nstd::size_t available = (current_write - current_read);  // 无需 % 或 &\n// available 直接表示有效数据量，因为 write 永远 >= read\n```\n\n### 2.4 问题 3: 测试程序内存泄漏\n\n```cpp\n// 原始代码: unique_ptr 创建后未存储\nstd::unique_ptr<SocketContext> client =\n    std::make_unique<SocketContext>(epoll_fd, client_fd);\n\nev.data.ptr = client.get();\n// client 在此作用域结束后析构，data.ptr 变成悬空指针\n```\n\n`unique_ptr` 在栈上创建，离开 `if` 块后立即析构，`epoll_event.data.ptr` 指向已释放内存。后续 `EPOLLOUT` 事件触发时解引用这个悬空指针，行为未定义。\n\n此外，`addFd()` 在构造函数中已经 `EPOLL_CTL_ADD` 了一次，`main()` 中又加了一次，造成重复注册。\n\n### 2.5 问题 4: `doSend` 不处理部分发送\n\n```cpp\nint doSend() {\n  const char* pdata = nullptr;\n  std::size_t data_size = buffer_.beginRead(&pdata);\n  if (data_size == 0) return 0;\n\n  int send_size = send(sock_fd_, pdata, static_cast<int>(data_size), MSG_DONTWAIT);\n  if (send_size > 0) {\n    buffer_.endRead(static_cast<std::size_t>(send_size));\n  }\n  return send_size;\n}\n```\n\n`send()` 可能只发送了 `data_size` 的一部分 (short write)。此时 `endRead(send_size)` 正确推进了读指针，但**没有重新注册 `EPOLLOUT`** 来触发下一次刷写。在 EPOLLET (边缘触发) 模式下，如果不重新 MOD 事件，剩余数据将永远不会被发送。\n\nLT (水平触发) 模式下问题较轻，因为只要发送缓冲区可写，`EPOLLOUT` 会持续触发。但原文使用 `EPOLLONESHOT`，每次事件后必须重新注册。\n\n**修正**: `doSend()` 返回后检查缓冲区是否还有数据，有则重新注册 `EPOLLOUT`:\n\n```cpp\nint doSend() {\n  // ... send logic ...\n  if (send_size > 0) {\n    buffer_.endRead(static_cast<std::size_t>(send_size));\n  }\n  // 缓冲区非空，继续注册 EPOLLOUT\n  if (buffer_.available() > 0) {\n    modifyEvent(true, true);  // EPOLLIN + EPOLLOUT\n  } else {\n    modifyEvent(true, false);  // 只保留 EPOLLIN\n  }\n  return send_size;\n}\n```\n\n### 2.6 问题 5: EAGAIN 处理不完整\n\n```cpp\nif (send_size == -1 && errno != EAGAIN) {\n  fprintf(stderr, \"send failed, error: %s\\n\", strerror(errno));\n}\n```\n\n两个问题:\n- 缺少 `EWOULDBLOCK` 检查 (POSIX 允许 `EAGAIN != EWOULDBLOCK`，虽然 Linux 上相等)\n- `EINTR` (被信号中断) 也应当重试，而非静默忽略\n\n---\n\n## 3. 工程级改进方案\n\n### 3.1 SendBuffer: 2 的幂字节环形缓冲\n\n```cpp\n/// @brief SPSC 字节环形缓冲区，用于 TCP 非阻塞发送缓冲\n/// @tparam SizeLog2 缓冲区大小的 log2 值 (默认 13 = 8KB)\ntemplate <uint32_t SizeLog2 = 13>\nclass SendBuffer {\n public:\n  static constexpr uint32_t kSize = 1U << SizeLog2;\n  static constexpr uint32_t kMask = kSize - 1U;\n\n  /// @brief 写入数据到缓冲区 (生产者线程调用)\n  /// @return 实际写入的字节数 (可能小于 len，表示缓冲区满)\n  uint32_t Write(const uint8_t* data, uint32_t len) noexcept {\n    const uint32_t w = write_idx_.load(std::memory_order_relaxed);\n    const uint32_t r = read_idx_.load(std::memory_order_acquire);\n    const uint32_t free = kSize - (w - r);  // 无符号差值在 2 的幂下天然正确\n    const uint32_t to_write = (len < free) ? len : free;\n    if (to_write == 0) return 0;\n\n    const uint32_t pos = w & kMask;\n    const uint32_t first = (kSize - pos < to_write) ? (kSize - pos) : to_write;\n    std::memcpy(&buf_[pos], data, first);\n    if (first < to_write) {\n      std::memcpy(&buf_[0], data + first, to_write - first);\n    }\n    write_idx_.store(w + to_write, std::memory_order_release);\n    return to_write;\n  }\n\n  /// @brief 获取可读数据的连续区间指针 (消费者线程调用)\n  /// @param[out] ptr 指向缓冲区内数据起始位置 (零拷贝)\n  /// @return 连续可读字节数 (不跨环形边界)\n  uint32_t Peek(const uint8_t** ptr) noexcept {\n    const uint32_t r = read_idx_.load(std::memory_order_relaxed);\n    const uint32_t w = write_idx_.load(std::memory_order_acquire);\n    const uint32_t avail = w - r;\n    if (avail == 0) return 0;\n\n    const uint32_t pos = r & kMask;\n    *ptr = &buf_[pos];\n    const uint32_t contig = kSize - pos;\n    return (avail < contig) ? avail : contig;\n  }\n\n  /// @brief 消费者确认已读取 len 字节\n  void Consume(uint32_t len) noexcept {\n    read_idx_.fetch_add(len, std::memory_order_release);\n  }\n\n  /// @brief 查询缓冲区内待发送数据量\n  uint32_t Pending() const noexcept {\n    return write_idx_.load(std::memory_order_acquire)\n         - read_idx_.load(std::memory_order_relaxed);\n  }\n\n  bool IsEmpty() const noexcept { return Pending() == 0; }\n\n private:\n  alignas(64) std::atomic<uint32_t> write_idx_{0};\n  alignas(64) std::atomic<uint32_t> read_idx_{0};\n  alignas(64) uint8_t buf_[kSize]{};\n};\n```\n\n与原始 `LockFreeBytesBuffer` 的设计差异:\n\n| 设计点 | 原始方案 | 改进方案 |\n|--------|---------|---------|\n| 缓冲区大小 | 10240 (非 2 幂) | `1 << SizeLog2` (编译期保证) |\n| 索引取模 | `% kBufferSize` (除法) | `& kMask` (1 条指令) |\n| 可用空间计算 | `(r + N - w - 1) % N` | `N - (w - r)` (无符号差值) |\n| 缓存行对齐 | 无 | `alignas(64)` 消除伪共享 |\n| API 设计 | `beginRead`/`endRead` 分离 | `Peek`/`Consume` (更明确语义) |\n| 索引类型 | `size_t` (8 字节) | `uint32_t` (4 字节, 嵌入式友好) |\n\n### 3.2 AsyncSocket: 事件驱动异步发送\n\n```cpp\n/// @brief 非阻塞 TCP socket，内置发送缓冲区\nclass AsyncSocket {\n public:\n  AsyncSocket(int epoll_fd, int sock_fd) noexcept\n      : epoll_fd_(epoll_fd), fd_(sock_fd) {\n    // 设置非阻塞\n    int flags = ::fcntl(fd_, F_GETFL, 0);\n    ::fcntl(fd_, F_SETFL, flags | O_NONBLOCK);\n  }\n\n  ~AsyncSocket() {\n    if (fd_ >= 0) {\n      ::epoll_ctl(epoll_fd_, EPOLL_CTL_DEL, fd_, nullptr);\n      ::close(fd_);\n    }\n  }\n\n  /// @brief 异步发送: 数据先入缓冲区，由 EPOLLOUT 驱动实际发送\n  /// @return 实际入队的字节数 (< len 表示缓冲区满，应用层需处理背压)\n  uint32_t AsyncSend(const uint8_t* data, uint32_t len) noexcept {\n    uint32_t written = send_buf_.Write(data, len);\n    if (written > 0 && !epollout_armed_) {\n      ArmEpollout();\n    }\n    return written;\n  }\n\n  /// @brief EPOLLOUT 事件回调: 将缓冲区数据刷入内核\n  /// @return >0 实际发送字节数, 0 缓冲区空, <0 连接错误\n  int FlushSendBuffer() noexcept {\n    int total_sent = 0;\n    for (;;) {\n      const uint8_t* ptr = nullptr;\n      uint32_t avail = send_buf_.Peek(&ptr);\n      if (avail == 0) break;\n\n      ssize_t n = ::send(fd_, ptr, avail, MSG_DONTWAIT | MSG_NOSIGNAL);\n      if (n > 0) {\n        send_buf_.Consume(static_cast<uint32_t>(n));\n        total_sent += static_cast<int>(n);\n        continue;  // 尝试继续发送 (边界跨回环可能还有数据)\n      }\n      if (n < 0) {\n        if (errno == EAGAIN || errno == EWOULDBLOCK) {\n          break;  // 内核缓冲区满，等下一次 EPOLLOUT\n        }\n        if (errno == EINTR) continue;  // 被信号中断，重试\n        return -1;  // 真正的错误 (EPIPE, ECONNRESET 等)\n      }\n      // n == 0: 对端关闭\n      return -1;\n    }\n\n    // 更新 epoll 注册状态\n    if (send_buf_.IsEmpty()) {\n      DisarmEpollout();\n    }\n    return total_sent;\n  }\n\n private:\n  void ArmEpollout() noexcept {\n    struct epoll_event ev{};\n    ev.data.ptr = this;\n    ev.events = EPOLLIN | EPOLLOUT | EPOLLET;\n    ::epoll_ctl(epoll_fd_, EPOLL_CTL_MOD, fd_, &ev);\n    epollout_armed_ = true;\n  }\n\n  void DisarmEpollout() noexcept {\n    struct epoll_event ev{};\n    ev.data.ptr = this;\n    ev.events = EPOLLIN | EPOLLET;\n    ::epoll_ctl(epoll_fd_, EPOLL_CTL_MOD, fd_, &ev);\n    epollout_armed_ = false;\n  }\n\n  int epoll_fd_;\n  int fd_;\n  SendBuffer<13> send_buf_;       // 8 KB 发送缓冲\n  bool epollout_armed_ = false;\n};\n```\n\n关键设计:\n\n1. **EPOLLOUT 按需注册**: 只在缓冲区有数据时注册 `EPOLLOUT`，避免空转唤醒\n2. **FlushSendBuffer 循环刷写**: 一次 `EPOLLOUT` 事件尽量多地发送数据 (EPOLLET 要求)\n3. **EAGAIN/EINTR 正确处理**: `EAGAIN` 等待下次事件，`EINTR` 立即重试，其他错误断开\n4. **背压感知**: `AsyncSend()` 返回实际入队字节数，应用层可据此控制生产速率\n\n### 3.3 事件循环集成\n\n```cpp\n// epoll 事件循环\nstruct epoll_event events[64];\nint n = ::epoll_wait(epoll_fd, events, 64, -1);\n\nfor (int i = 0; i < n; ++i) {\n  auto* sock = static_cast<AsyncSocket*>(events[i].data.ptr);\n\n  if (events[i].events & (EPOLLERR | EPOLLHUP)) {\n    // 连接错误或对端挂断\n    delete sock;\n    continue;\n  }\n  if (events[i].events & EPOLLIN) {\n    // 读取数据...\n    sock->OnReadable();\n  }\n  if (events[i].events & EPOLLOUT) {\n    int ret = sock->FlushSendBuffer();\n    if (ret < 0) {\n      // 发送失败，关闭连接\n      delete sock;\n      continue;\n    }\n  }\n}\n```\n\n对比原始方案缺失的错误处理:\n- `EPOLLERR` / `EPOLLHUP` 事件现在被正确检测\n- 连接关闭时清理资源 (原始方案的 `unique_ptr` 生命周期管理有缺陷)\n\n### 3.4 数据流时序\n\n```\n生产者线程                      I/O 线程 (epoll)\n    |                               |\n    | AsyncSend(data, 4096)         |\n    |   → Write 4096B to SendBuffer |\n    |   → ArmEpollout()            |\n    |                               |\n    |                          EPOLLOUT 触发\n    |                               |\n    |                          FlushSendBuffer()\n    |                            → Peek() 获取连续区间\n    |                            → send(fd, ptr, avail)\n    |                            → 内核接受 1500B (short write)\n    |                            → Consume(1500)\n    |                            → send(fd, ptr, avail) 再次尝试\n    |                            → EAGAIN (内核缓冲满)\n    |                            → 等待下一次 EPOLLOUT\n    |                               |\n    |                          EPOLLOUT 再次触发\n    |                            → 发送剩余 2596B\n    |                            → 缓冲区空\n    |                            → DisarmEpollout()\n```\n\n---\n\n## 4. 与 newosp 基础设施的对比\n\nnewosp 的 `SpscRingbuffer<T, N>` 和本文的 `SendBuffer` 解决不同层面的问题:\n\n### 4.1 SpscRingbuffer: 类型化元素队列\n\n```cpp\n// newosp: 传递结构化帧 (类型安全)\nusing RecvRing = osp::SpscRingbuffer<RecvFrameSlot, 32>;\n\nRecvFrameSlot slot;\nslot.header = ...;\nstd::memcpy(slot.payload, data, len);\nring.Push(slot);  // 整帧入队\n```\n\n- **用途**: 接收线程 → 处理线程的帧传递\n- **元素**: 固定大小结构体 (`RecvFrameSlot` ~4KB)\n- **操作粒度**: 整帧 Push/Pop\n\n### 4.2 SendBuffer: 字节流缓冲\n\n```cpp\n// 本文: 字节流发送缓冲 (面向 TCP)\nSendBuffer<13> buf;\n\nbuf.Write(header_bytes, 14);   // 帧头\nbuf.Write(payload, 4096);      // 载荷\n// 由 EPOLLOUT 驱动 Peek() + send() + Consume()\n```\n\n- **用途**: 应用层 → TCP 发送的字节流暂存\n- **元素**: 原始字节 (uint8_t)\n- **操作粒度**: 可变长度字节块\n\n### 4.3 核心共性\n\n两者共享相同的底层设计原则:\n\n| 设计原则 | SpscRingbuffer | SendBuffer |\n|---------|----------------|------------|\n| 2 的幂大小 + 位掩码 | `static_assert(IsPowerOf2)` | `1 << SizeLog2` |\n| 无界递增索引 | `head_`/`tail_` 无符号递增 | `write_idx_`/`read_idx_` |\n| acquire-release 配对 | `AcquireOrder()`/`ReleaseOrder()` | `acquire`/`release` |\n| 缓存行对齐消除伪共享 | `alignas(kCacheLineSize)` | `alignas(64)` |\n| SPSC 约束 (不可多线程写) | 文档约定 + API 分离 | 同上 |\n| 零堆分配 | 栈上 `std::array` | 栈上 `uint8_t[]` |\n\n### 4.4 newosp transport 的 short write 处理\n\nnewosp `transport.hpp` 中的 `SendAll()` 处理 TCP short write。v0.4.1 新增了 EAGAIN 区分:\n\n```cpp\n// newosp v0.4.1 transport.hpp SendAll():\nwhile (remaining > 0) {\n  auto r = socket_.Send(ptr, remaining);\n  if (!r.has_value()) {\n    if (r.get_error() == SocketError::kWouldBlock) {\n      // EAGAIN: 有限重试 (yield + 最多 16 次)\n      if (++eagain_count > kMaxEagainRetries) {\n        return TransportError::kWouldBlock;  // 不断开连接\n      }\n      std::this_thread::yield();\n      continue;\n    }\n    // 致命错误 (EPIPE, ECONNRESET)\n    connected_ = false;\n    return TransportError::kSendFailed;\n  }\n  ptr += sent;\n  remaining -= sent;\n  eagain_count = 0;  // 有进展则重置\n}\n```\n\n这是**同步有限重试**方案 -- 比 v0.4.0 的直接判定失败改进了对瞬态 EAGAIN 的容忍度，且 EAGAIN 重试耗尽后返回 `kWouldBlock` 而不断开连接，允许调用方决策是否重试。\n\n对于 newosp 的目标场景 (同机 shm_transport 优先，TCP 仅作远程备选)，同步方案是合理的选择。高吞吐 TCP 场景应引入本文的 `SendBuffer` + EPOLLOUT 异步方案。\n\n---\n\n## 5. 内存序细节\n\n### 5.1 为什么 Write 侧 load 自己的 write_idx 用 relaxed\n\n```cpp\nconst uint32_t w = write_idx_.load(std::memory_order_relaxed);  // 只有自己写\nconst uint32_t r = read_idx_.load(std::memory_order_acquire);   // 对方写，需 acquire\n```\n\nSPSC 模型中，`write_idx_` 只由生产者线程修改，`read_idx_` 只由消费者线程修改。加载自己拥有的索引不需要同步 (值一定是上次 store 的值)，加载对方的索引需要 acquire 来保证看到对方的最新值以及相关的数据写入。\n\n### 5.2 store 用 release 的含义\n\n```cpp\nwrite_idx_.store(w + to_write, std::memory_order_release);\n```\n\nrelease 保证: 在 store 之前的所有 `memcpy`(数据写入) 对另一个线程的 acquire load 可见。这是 SPSC 无锁正确性的核心 -- 消费者 acquire load 到新的 write_idx 后，数据一定已经就位。\n\n### 5.3 ARM 上的实际代价\n\nARM (非 TSO 架构) 上:\n- `relaxed` load/store: 普通 `ldr`/`str` 指令\n- `acquire` load: `ldar` 指令 (ARM v8) 或 `ldr` + `dmb ishld` (ARM v7)\n- `release` store: `stlr` 指令 (ARM v8) 或 `dmb ish` + `str` (ARM v7)\n\n每次 `Write()` 只有 1 次 acquire + 1 次 release，开销可控。这也是 newosp SpscRingbuffer 提供 `FakeTSO` 模式的原因 -- 单核 MCU 上所有 acquire/release 可降级为 relaxed + compiler fence，进一步消除 barrier 开销。\n\n---\n\n## 6. 总结\n\n1. **TCP short write 在非阻塞 + EPOLLET 模式下必须处理**。正确方案是用户态发送缓冲 + EPOLLOUT 事件驱动刷写，而非阻塞重试。\n\n2. **字节环形缓冲的工程要求**: 2 的幂位掩码 (非除法取模)、无界递增无符号索引、精确 acquire-release 内存序、缓存行对齐消除伪共享。这些要求与结构化 SPSC 队列完全一致。\n\n3. **EPOLLOUT 管理关键**: 按需注册 (有数据时 arm，空时 disarm)，EPOLLET 模式下一次事件循环内尽量多发送，区分 EAGAIN (等待) / EINTR (重试) / 其他 (断开)。\n\n4. **同步 vs 异步 short write 处理**: 同步方案 (循环 `send()` 直到写完) 适合低吞吐场景，实现简单但阻塞调用线程; 异步方案 (缓冲 + EPOLLOUT) 适合高吞吐场景，不阻塞但需要管理缓冲区生命周期和背压。\n\n---\n\n## 参考\n\n- [newosp SpscRingbuffer](https://github.com/DeguiLiu/newosp) -- C++17 header-only SPSC 无锁环形缓冲\n- [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- 12 项设计决策详解\n- [ARM-Linux 网络性能优化](../arm_linux_network_optimization/) -- 内核协议栈调优\n- Linux man page: epoll(7), send(2)\n",
      "ctime": "1771552624",
      "mtime": "1771552624",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "performance/unix_domain_socket_realtime.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853766666",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "Unix Domain Socket 实时性优化: 嵌入式 IPC 全链路调优",
      "brief_content": "面向嵌入式 ARM-Linux 平台的 Unix Domain Socket 实时性优化系统指南。从 UDS 内核数据路径出发，覆盖 socket 类型选择（STREAM/DGRAM/SEQPACKE",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [如何优化 Linux 中 Domain Socket 的线程间通信实时性](https://blog.csdn.net/stallion5632/article/details/143735726)\n>\n> 参考:\n> - [unix(7) - Linux manual page](https://man7.org/linux/man-pages/man7/unix.7.html)\n> - [Linux Kernel: Unix Domain Sockets](https://docs.kernel.org/networking/af_unix.html)\n> - [Beej's Guide to Unix IPC](https://beej.us/guide/bgipc/)\n> - [LWN: Rethinking the design of io_uring](https://lwn.net/Articles/879724/)\n> - newosp socket 实现: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) -- `include/osp/socket.hpp`\n\n## 1. UDS 内核数据路径\n\nUnix Domain Socket（UDS）是 Linux 上同主机进程间通信最成熟的机制。与 TCP loopback 相比，UDS 绕过了整个网络协议栈（IP 路由、TCP 拥塞控制、校验和计算），数据在内核中直接从发送进程的缓冲区拷贝到接收进程的缓冲区。\n\n```\n发送进程                            接收进程\n   |                                  |\n   | send(fd, buf, len)               |\n   |   用户空间 -> 内核空间 (拷贝 1)    |\n   v                                  |\n+----------------------------------+  |\n|  内核 sk_buff (发送端 socket)      |  |\n|  直接链接到接收端 socket 队列       |  |\n+----------------------------------+  |\n   |                                  |\n   | (无 IP/TCP 处理、无路由查找)      |\n   |                                  v\n   |                            recv(fd, buf, len)\n   |                              内核空间 -> 用户空间 (拷贝 2)\n```\n\n关键特征：\n\n- **两次拷贝**：用户空间 -> 内核 -> 用户空间（对比 TCP loopback 也是两次，但 UDS 无协议栈处理开销）\n- **无网络栈开销**：无 IP 头构造/解析、无 TCP 拥塞窗口、无校验和\n- **本地安全**：可通过文件权限和 `SO_PEERCRED` 进行身份验证\n\n实测性能（newosp 基准测试，ARM-Linux）：\n\n| 传输方式 | 延迟 | 吞吐量 (1KB 消息) |\n|----------|------|------------------|\n| Unix Domain Socket | 15.8 us | 1,641 MB/s |\n| TCP Loopback | 44.7 us | 512 MB/s |\n| **UDS 优势** | **2.8x** | **3.2x** |\n\n优化 UDS 的核心目标是：**减少每次传输的系统调用次数、减少数据拷贝次数、减少调度延迟**。\n\n## 2. Socket 类型选择\n\nUDS 支持三种 socket 类型，选择直接影响性能和编程模型。\n\n### 2.1 三种类型对比\n\n| 类型 | 语义 | 消息边界 | 连接 | 适用场景 |\n|------|------|----------|------|----------|\n| `SOCK_STREAM` | 字节流 | 无（需自行分帧） | 面向连接 | 大数据量、持久连接 |\n| `SOCK_DGRAM` | 数据报 | 有（每个 sendto 一个消息） | 无连接 | 小消息、多对一 |\n| `SOCK_SEQPACKET` | 有序数据报 | 有（每个 send 一个消息） | 面向连接 | 帧协议、工业控制 |\n\n### 2.2 SOCK_SEQPACKET -- 被忽视的选项\n\n`SOCK_SEQPACKET` 结合了 `SOCK_STREAM` 的可靠有序传输和 `SOCK_DGRAM` 的消息边界保持。**对于嵌入式协议通信，这通常是最优选择**。\n\n```cpp\n// 创建 SEQPACKET 类型的 UDS\nint fd = socket(AF_UNIX, SOCK_SEQPACKET, 0);\n```\n\n为什么 `SOCK_SEQPACKET` 更适合嵌入式：\n\n1. **无需分帧层**：`SOCK_STREAM` 是字节流，一次 `send(100 bytes)` 可能被拆成多次 `recv()`。应用层必须实现长度前缀或定界符分帧。`SOCK_SEQPACKET` 保证每次 `send()` 对应一次完整的 `recv()`，省去分帧代码。\n\n2. **零拷贝语义更清晰**：每个消息是原子的，不存在半包问题，消费者不需要缓冲拼接。\n\n3. **天然适配工业协议**：Modbus RTU、CANopen、自定义控制指令都是固定长度或长度前缀的帧，直接映射到 `SOCK_SEQPACKET` 的消息语义。\n\n```cpp\n// SOCK_STREAM: 需要自行分帧\nstruct FrameHeader {\n    uint32_t length;\n};\n// 发送端: send(header) + send(payload)\n// 接收端: recv(header) + 循环 recv(payload, remaining)\n\n// SOCK_SEQPACKET: 消息自带边界\n// 发送端: send(frame, frame_size) -- 原子操作\n// 接收端: recv(buf, max_size) -- 一次收到完整帧\n```\n\n**限制**：`SOCK_SEQPACKET` 的单次消息大小受 `SO_SNDBUF` 限制（默认约 200 KB），超大数据仍需 `SOCK_STREAM`。\n\n## 3. 抽象命名空间\n\n### 3.1 文件系统路径的问题\n\n传统 UDS 通过文件系统路径标识：\n\n```cpp\nstruct sockaddr_un addr;\naddr.sun_family = AF_UNIX;\nstrncpy(addr.sun_path, \"/tmp/my_socket\", sizeof(addr.sun_path) - 1);\n```\n\n这在嵌入式系统中存在几个问题：\n\n1. **残留文件**：进程异常退出后，socket 文件残留在文件系统，下次 `bind()` 失败（`EADDRINUSE`）。需要先 `unlink()` 清理。\n2. **文件系统依赖**：只读文件系统（squashfs rootfs）或 tmpfs 挂载点变化时，路径不可用。\n3. **路径长度限制**：`sun_path` 最大 108 字节（含 null 终止符），深层目录路径可能超限。\n4. **权限管理**：需要确保 socket 文件的目录权限正确。\n\n### 3.2 抽象命名空间\n\nLinux 特有的抽象命名空间（Abstract Namespace）通过 `sun_path[0] = '\\0'` 标识，socket 名称不映射到文件系统：\n\n```cpp\nstruct sockaddr_un addr;\nmemset(&addr, 0, sizeof(addr));\naddr.sun_family = AF_UNIX;\n// 第一个字节为 \\0，后续为抽象名称\nconst char* name = \"\\0my_embedded_ipc\";\nmemcpy(addr.sun_path, name, 17);  // 包含前导 \\0\n\n// bind 时指定精确长度\nsocklen_t len = offsetof(struct sockaddr_un, sun_path) + 17;\nbind(fd, (struct sockaddr*)&addr, len);\n```\n\n优势：\n\n| 维度 | 文件路径 | 抽象命名空间 |\n|------|----------|------------|\n| 残留清理 | 需要手动 `unlink()` | 自动释放（所有 fd 关闭后） |\n| 文件系统依赖 | 需要可写目录 | 无文件系统依赖 |\n| 安全 | 文件权限控制 | 网络命名空间隔离 |\n| 可移植性 | POSIX 标准 | Linux 特有 |\n\n**嵌入式建议**：如果目标平台仅为 Linux（不需要移植到 QNX/VxWorks），优先使用抽象命名空间。它消除了文件管理的所有复杂性。\n\n**ARM 注意事项**：抽象命名空间 socket 在网络命名空间（`CLONE_NEWNET`）间隔离。如果嵌入式系统使用容器（如 LXC/Docker），确保通信进程在同一网络命名空间中。\n\n## 4. epoll 边缘触发的正确实现\n\n原文提到了 epoll 边缘触发（ET），但示例中的实现存在**关键遗漏**。\n\n### 4.1 边缘触发的陷阱\n\nET 模式在状态**变化**时只通知一次。如果一次 `read()` 没有读完缓冲区中的所有数据，epoll 不会再次通知，数据会滞留在内核缓冲区中，直到有**新数据到达**触发新的状态变化。\n\n**原文代码的问题**：\n\n```cpp\n// 原文: 只读一次\nssize_t nread = read(event.data.fd, buf, sizeof(buf));\n```\n\n如果发送端一次发了 10 KB，接收端 `buf` 只有 1 KB，第一次 `read()` 读到 1 KB 后返回。如果没有新数据到达，剩余 9 KB 会一直停滞。\n\n### 4.2 正确的 ET 读取模式\n\n```cpp\nvoid HandleReadET(int fd) {\n    char buf[4096];\n    while (true) {\n        ssize_t n = read(fd, buf, sizeof(buf));\n        if (n > 0) {\n            ProcessData(buf, n);\n            continue;\n        }\n        if (n == 0) {\n            // 对端关闭\n            close(fd);\n            break;\n        }\n        // n == -1\n        if (errno == EAGAIN || errno == EWOULDBLOCK) {\n            // 缓冲区已空，正常退出循环\n            break;\n        }\n        if (errno == EINTR) {\n            continue;  // 被信号中断，重试\n        }\n        // 真正的错误\n        perror(\"read\");\n        close(fd);\n        break;\n    }\n}\n```\n\n**核心规则**：ET 模式下，每次事件触发必须**循环读到 `EAGAIN`**，确保缓冲区完全排空。\n\n### 4.3 ET 的 accept 也需要循环\n\n同理，监听 socket 在 ET 模式下也需要循环 `accept()` 直到 `EAGAIN`：\n\n```cpp\nvoid HandleAcceptET(int listen_fd, int epoll_fd) {\n    while (true) {\n        int conn_fd = accept4(listen_fd, nullptr, nullptr,\n                              SOCK_NONBLOCK | SOCK_CLOEXEC);\n        if (conn_fd < 0) {\n            if (errno == EAGAIN || errno == EWOULDBLOCK) {\n                break;  // 所有挂起连接已处理\n            }\n            if (errno == EINTR) {\n                continue;\n            }\n            perror(\"accept4\");\n            break;\n        }\n        // 注册新连接到 epoll\n        struct epoll_event ev;\n        ev.events = EPOLLIN | EPOLLET;\n        ev.data.fd = conn_fd;\n        epoll_ctl(epoll_fd, EPOLL_CTL_ADD, conn_fd, &ev);\n    }\n}\n```\n\n注意使用 `accept4()` 而非 `accept()`：`accept4()` 可以原子地设置 `SOCK_NONBLOCK` 和 `SOCK_CLOEXEC`，避免额外的 `fcntl()` 系统调用。\n\n### 4.4 EPOLLONESHOT -- 多线程安全\n\n如果多个工作线程共享一个 epoll 实例，ET 模式下同一个 fd 的事件可能被多个线程同时拿到。使用 `EPOLLONESHOT` 确保每次只有一个线程处理：\n\n```cpp\nev.events = EPOLLIN | EPOLLET | EPOLLONESHOT;\n```\n\n处理完成后需要重新 arm：\n\n```cpp\nepoll_ctl(epoll_fd, EPOLL_CTL_MOD, fd, &ev);\n```\n\n## 5. 实时调度与 CPU 隔离\n\n### 5.1 SCHED_FIFO 优先级选择\n\n原文使用 `sched_priority = 99`，这是**不推荐的**。\n\nLinux 的 SCHED_FIFO 优先级范围是 1-99（数字越大优先级越高）。内核自身的关键线程（如 `migration/N`、`watchdog/N`）通常运行在优先级 99。将应用线程设为 99 可能抢占内核线程，导致系统不稳定。\n\n**嵌入式推荐实践**：\n\n```cpp\n// 优先级规划\n// 99: 内核线程保留 (migration, watchdog)\n// 90: 硬实时控制 (电机控制, 安全回路)\n// 80: 软实时通信 (IPC 收发线程)\n// 70: 数据处理 (传感器融合)\n// 1-50: 非关键实时任务\n\nstruct sched_param param;\nparam.sched_priority = 80;  // 通信线程\nif (sched_setscheduler(0, SCHED_FIFO, &param) != 0) {\n    perror(\"sched_setscheduler\");\n}\n```\n\n### 5.2 CPU 隔离 -- isolcpus\n\n仅绑定 CPU 不够。默认情况下，内核调度器仍会将其他任务放到该 CPU 上。通过内核启动参数 `isolcpus` 将核心从通用调度器中移除：\n\n```bash\n# 内核启动参数: 隔离 CPU 2 和 3\nisolcpus=2,3 nohz_full=2,3 rcu_nocbs=2,3\n```\n\n| 参数 | 作用 |\n|------|------|\n| `isolcpus=2,3` | 从调度器移除，只有显式绑定的任务才会运行 |\n| `nohz_full=2,3` | 关闭定时器中断（adaptive-tick），减少调度噪声 |\n| `rcu_nocbs=2,3` | RCU 回调卸载到其他核，避免 RCU grace period 延迟 |\n\n然后将 IPC 线程绑定到隔离的核心：\n\n```cpp\ncpu_set_t cpuset;\nCPU_ZERO(&cpuset);\nCPU_SET(2, &cpuset);  // 绑定到隔离的 CPU 2\nsched_setaffinity(0, sizeof(cpuset), &cpuset);\n```\n\n### 5.3 mlockall -- 消除缺页延迟\n\n```cpp\n#include <sys/mman.h>\n\n// 锁定当前和未来的所有内存页\nif (mlockall(MCL_CURRENT | MCL_FUTURE) != 0) {\n    perror(\"mlockall\");\n}\n```\n\n防止实时线程的栈或堆内存被换出到 swap，消除缺页中断引入的毫秒级延迟。\n\n**ARM 注意事项**：嵌入式系统 RAM 有限，`MCL_FUTURE` 会锁定后续所有 `mmap` 和堆分配。确保进程的内存用量在可控范围内，否则可能耗尽物理内存导致 OOM。\n\n## 6. fd 传递与零拷贝\n\nUDS 独有的能力是通过 `sendmsg`/`recvmsg` 的辅助数据（ancillary data）传递文件描述符。这是实现**真正零拷贝 IPC** 的基础。\n\n### 6.1 基本 fd 传递\n\n```cpp\n// 发送端: 通过 UDS 传递一个 fd\nvoid SendFd(int uds_fd, int target_fd) {\n    struct msghdr msg = {};\n    struct iovec iov;\n    char dummy = 'F';\n    iov.iov_base = &dummy;\n    iov.iov_len = 1;\n    msg.msg_iov = &iov;\n    msg.msg_iovlen = 1;\n\n    // 构造 CMSG 携带 fd\n    char cmsg_buf[CMSG_SPACE(sizeof(int))];\n    msg.msg_control = cmsg_buf;\n    msg.msg_controllen = sizeof(cmsg_buf);\n\n    struct cmsghdr* cmsg = CMSG_FIRSTHDR(&msg);\n    cmsg->cmsg_level = SOL_SOCKET;\n    cmsg->cmsg_type = SCM_RIGHTS;\n    cmsg->cmsg_len = CMSG_LEN(sizeof(int));\n    memcpy(CMSG_DATA(cmsg), &target_fd, sizeof(int));\n\n    sendmsg(uds_fd, &msg, 0);\n}\n\n// 接收端: 收到 fd 后可直接 mmap\nint RecvFd(int uds_fd) {\n    struct msghdr msg = {};\n    struct iovec iov;\n    char dummy;\n    iov.iov_base = &dummy;\n    iov.iov_len = 1;\n    msg.msg_iov = &iov;\n    msg.msg_iovlen = 1;\n\n    char cmsg_buf[CMSG_SPACE(sizeof(int))];\n    msg.msg_control = cmsg_buf;\n    msg.msg_controllen = sizeof(cmsg_buf);\n\n    recvmsg(uds_fd, &msg, 0);\n\n    struct cmsghdr* cmsg = CMSG_FIRSTHDR(&msg);\n    int received_fd;\n    memcpy(&received_fd, CMSG_DATA(cmsg), sizeof(int));\n    return received_fd;\n}\n```\n\n### 6.2 memfd_create + fd 传递 -- 大数据零拷贝\n\n对于大块数据（图像帧、点云、音频缓冲），传统 `send()`/`recv()` 需要两次拷贝。使用 `memfd_create` 创建匿名共享内存，通过 UDS 传递 fd，接收端直接 `mmap` 访问，实现**零拷贝**：\n\n```cpp\n#include <sys/mman.h>\n\n// 发送端\nvoid SendLargeData(int uds_fd, const void* data, size_t size) {\n    // 1. 创建匿名内存 fd\n    int memfd = memfd_create(\"ipc_frame\", MFD_CLOEXEC);\n    ftruncate(memfd, size);\n\n    // 2. 映射并写入数据\n    void* ptr = mmap(nullptr, size, PROT_READ | PROT_WRITE,\n                     MAP_SHARED, memfd, 0);\n    memcpy(ptr, data, size);  // 仅一次拷贝: 用户空间 -> 共享内存\n    munmap(ptr, size);\n\n    // 3. 通过 UDS 传递 fd + 元数据\n    struct FrameHeader hdr = { .size = size };\n    // sendmsg: 携带 hdr 数据 + memfd 作为辅助数据\n    SendFdWithData(uds_fd, memfd, &hdr, sizeof(hdr));\n    close(memfd);  // 发送端关闭自己的引用\n}\n\n// 接收端\nvoid RecvLargeData(int uds_fd) {\n    struct FrameHeader hdr;\n    int memfd = RecvFdWithData(uds_fd, &hdr, sizeof(hdr));\n\n    // 直接 mmap，零拷贝访问\n    void* ptr = mmap(nullptr, hdr.size, PROT_READ,\n                     MAP_SHARED, memfd, 0);\n    ProcessFrame(ptr, hdr.size);  // 直接读取，无拷贝\n    munmap(ptr, hdr.size);\n    close(memfd);\n}\n```\n\n数据路径对比：\n\n```\n传统 send/recv:\n  发送进程 buf -> [拷贝1] -> 内核 sk_buff -> [拷贝2] -> 接收进程 buf\n\nmemfd + fd 传递:\n  发送进程 buf -> [拷贝1] -> 共享内存 (memfd)\n  接收进程 mmap(memfd) -> 直接访问  [零拷贝]\n```\n\n大数据场景下节省了一次内核-用户空间拷贝。\n\n**适用场景**：激光雷达点云帧（数百 KB ~ 数 MB）、摄像头图像帧、大型配置文件传输。\n\n**ARM 注意事项**：`mmap` 在 ARM 上默认 cacheable，但跨进程写入后需要确保缓存一致性。内核会在 `mmap(MAP_SHARED)` 的页上维护一致性，但频繁的 `mmap/munmap` 有 TLB flush 开销。对于高频传输（> 1 kHz），建议预分配固定的 memfd 池循环使用。\n\n## 7. eventfd -- 轻量级通知\n\n### 7.1 UDS 通知的开销\n\n如果 IPC 场景是「生产者写入共享内存，通知消费者读取」，使用 UDS 传输通知消息本身有不必要的开销：需要构造/解析消息、经过 socket 缓冲区拷贝。\n\n`eventfd` 是一个 8 字节的信号量文件描述符，专为轻量级通知设计：\n\n```cpp\n#include <sys/eventfd.h>\n\n// 创建 eventfd (初始值 0, 信号量模式)\nint efd = eventfd(0, EFD_NONBLOCK | EFD_SEMAPHORE);\n\n// 生产者: 写入 1 表示 \"有新数据\"\nuint64_t val = 1;\nwrite(efd, &val, sizeof(val));\n\n// 消费者: 读取值 (信号量模式下每次减 1)\nuint64_t count;\nread(efd, &count, sizeof(count));\n```\n\n`eventfd` 可以注册到 `epoll`，与 UDS fd 统一管理：\n\n```cpp\nstruct epoll_event ev;\nev.events = EPOLLIN | EPOLLET;\nev.data.fd = efd;\nepoll_ctl(epoll_fd, EPOLL_CTL_ADD, efd, &ev);\n```\n\n### 7.2 eventfd + 共享内存模式\n\n对于超低延迟场景，推荐「共享内存 + eventfd 通知」架构：\n\n```\n生产者                     消费者\n   |                         |\n   | 写入共享内存 (零拷贝)     |\n   | write(eventfd, 1)       |\n   |                         | epoll_wait 或 read(eventfd)\n   |                         | 读取共享内存 (零拷贝)\n```\n\n这种模式下数据传输零拷贝，通知路径仅有 8 字节 `write`/`read`。延迟可以低至 **1-5 us**（ARM Cortex-A7 实测）。\n\n## 8. sendmsg/recvmsg 与 scatter-gather I/O\n\n### 8.1 iovec 避免内存拷贝\n\n传统发送方式需要先将头部和载荷拼接到连续缓冲区：\n\n```cpp\n// 低效: 需要拼接到连续缓冲区\nchar buf[sizeof(Header) + payload_len];\nmemcpy(buf, &header, sizeof(Header));\nmemcpy(buf + sizeof(Header), payload, payload_len);\nsend(fd, buf, sizeof(buf), 0);\n```\n\n`sendmsg` 的 `iovec` 支持 scatter-gather，直接从多个不连续缓冲区发送：\n\n```cpp\nstruct iovec iov[2];\niov[0].iov_base = &header;\niov[0].iov_len = sizeof(Header);\niov[1].iov_base = payload;\niov[1].iov_len = payload_len;\n\nstruct msghdr msg = {};\nmsg.msg_iov = iov;\nmsg.msg_iovlen = 2;\n\nsendmsg(fd, &msg, MSG_NOSIGNAL);\n```\n\n省去了一次 `memcpy` 拼接操作，头部和载荷可以来自不同的内存区域。\n\n### 8.2 recvmmsg 批量接收\n\n`recvmmsg` 一次系统调用接收多个消息，减少系统调用次数：\n\n```cpp\n#define BATCH 16\nstruct mmsghdr msgs[BATCH];\nstruct iovec iovecs[BATCH];\nchar bufs[BATCH][1024];\n\nfor (int i = 0; i < BATCH; ++i) {\n    iovecs[i].iov_base = bufs[i];\n    iovecs[i].iov_len = sizeof(bufs[i]);\n    msgs[i].msg_hdr.msg_iov = &iovecs[i];\n    msgs[i].msg_hdr.msg_iovlen = 1;\n}\n\nint n = recvmmsg(fd, msgs, BATCH, MSG_DONTWAIT, nullptr);\nfor (int i = 0; i < n; ++i) {\n    ProcessMessage(bufs[i], msgs[i].msg_len);\n}\n```\n\n**ARM 系统调用开销**：ARM 的 `svc` 指令陷入内核的开销（约 1-3 us）高于 x86 的 `syscall`（约 0.2-0.5 us）。批量操作在 ARM 上的收益更显著。\n\n## 9. 内核缓冲区调优\n\n### 9.1 SO_SNDBUF / SO_RCVBUF\n\nUDS 的内核缓冲区大小直接影响突发流量的容忍能力。默认值通常为 212992 字节（约 208 KB）。\n\n```cpp\n// 查询默认值\nint bufsize;\nsocklen_t len = sizeof(bufsize);\ngetsockopt(fd, SOL_SOCKET, SO_RCVBUF, &bufsize, &len);\n// Linux 返回值是实际分配的 2 倍（内核会翻倍）\n\n// 设置更大的缓冲区\nint desired = 1024 * 1024;  // 1 MB\nsetsockopt(fd, SOL_SOCKET, SO_RCVBUF, &desired, sizeof(desired));\nsetsockopt(fd, SOL_SOCKET, SO_SNDBUF, &desired, sizeof(desired));\n```\n\n**上限控制**：\n\n```bash\n# 查看/设置系统级最大值\nsysctl net.core.rmem_max          # 接收缓冲区上限\nsysctl net.core.wmem_max          # 发送缓冲区上限\n\n# 嵌入式系统建议值（根据 RAM 调整）\nsysctl -w net.core.rmem_max=4194304   # 4 MB\nsysctl -w net.core.wmem_max=4194304   # 4 MB\n```\n\n**ARM 嵌入式注意**：每个 UDS 连接的缓冲区占用物理内存。如果系统有 50 个活跃 UDS 连接，每个 1 MB 缓冲区，总占用 50 MB。256 MB RAM 的设备需要谨慎设置。\n\n### 9.2 SO_SNDBUF = 0 的低延迟技巧\n\n对于延迟敏感的小消息场景，可以将发送缓冲区设为最小值：\n\n```cpp\nint bufsize = 1;  // 内核会设为允许的最小值\nsetsockopt(fd, SOL_SOCKET, SO_SNDBUF, &bufsize, sizeof(bufsize));\n```\n\n效果：`send()` 在接收端缓冲区满时立即返回 `EAGAIN`，而不是在发送端缓冲区中排队。这迫使应用层立即感知背压，有助于控制端到端延迟。\n\n## 10. io_uring 异步路径\n\n### 10.1 传统路径的系统调用开销\n\n传统的 epoll + `read`/`write` 路径每次 I/O 需要两个系统调用：\n\n```\nepoll_wait()  -> 返回就绪 fd 列表    (系统调用 1)\nread(fd)      -> 读取数据             (系统调用 2)\n```\n\n`io_uring`（Linux 5.1+）通过共享内存 ring buffer 实现**真正的异步 I/O**，减少系统调用：\n\n```\n提交请求: 写入 SQE 到 submission queue (用户空间操作，无系统调用)\n收割结果: 读取 CQE 从 completion queue (用户空间操作，无系统调用)\n(仅在队列空时需要 io_uring_enter() 系统调用)\n```\n\n### 10.2 UDS + io_uring\n\n```cpp\n#include <liburing.h>\n\nstruct io_uring ring;\nio_uring_queue_init(256, &ring, 0);\n\n// 提交异步 recv 请求\nstruct io_uring_sqe* sqe = io_uring_get_sqe(&ring);\nio_uring_prep_recv(sqe, uds_fd, buf, buf_size, 0);\nio_uring_sqe_set_data(sqe, user_context);\nio_uring_submit(&ring);\n\n// 等待完成\nstruct io_uring_cqe* cqe;\nio_uring_wait_cqe(&ring, &cqe);\nint bytes_read = cqe->res;\nvoid* ctx = io_uring_cqe_get_data(cqe);\nio_uring_cqe_seen(&ring, cqe);\n```\n\n**ARM 兼容性**：io_uring 在 Linux 5.1+ 的 ARM64 上完全支持。但部分嵌入式 Linux 发行版（如 Buildroot/Yocto 构建的 4.x 内核）不支持。检查内核版本：\n\n```bash\nuname -r  # 需要 >= 5.1\n```\n\n**收益评估**：io_uring 对高频小消息场景（> 100K msg/s）有显著收益。对于低频控制指令（< 1 kHz），epoll 已经足够，引入 io_uring 增加了复杂度但收益有限。\n\n## 11. RAII 与资源管理\n\n原文的示例代码使用裸 fd 和手动 `close()`，在错误路径上容易泄漏资源。嵌入式系统的 fd 数量有限（通常 1024 或更少），泄漏会导致系统级故障。\n\n### 11.1 RAII 封装\n\n```cpp\nclass UnixSocket {\npublic:\n    static UnixSocket Create() {\n        int fd = ::socket(AF_UNIX, SOCK_STREAM | SOCK_CLOEXEC, 0);\n        return UnixSocket(fd);\n    }\n\n    ~UnixSocket() { Close(); }\n\n    // Move-only: 防止 fd 被拷贝后 double-close\n    UnixSocket(UnixSocket&& other) noexcept : fd_(other.fd_) {\n        other.fd_ = -1;\n    }\n    UnixSocket& operator=(UnixSocket&& other) noexcept {\n        if (this != &other) {\n            Close();\n            fd_ = other.fd_;\n            other.fd_ = -1;\n        }\n        return *this;\n    }\n\n    UnixSocket(const UnixSocket&) = delete;\n    UnixSocket& operator=(const UnixSocket&) = delete;\n\n    void Close() noexcept {\n        if (fd_ >= 0) {\n            ::close(fd_);\n            fd_ = -1;\n        }\n    }\n\n    int Fd() const noexcept { return fd_; }\n    bool Valid() const noexcept { return fd_ >= 0; }\n\nprivate:\n    explicit UnixSocket(int fd) : fd_(fd) {}\n    int fd_ = -1;\n};\n```\n\n关键设计：\n\n- **`SOCK_CLOEXEC`**：`fork` + `exec` 时自动关闭 fd，防止子进程继承不需要的 socket\n- **Move-only**：`delete` 拷贝构造/赋值，防止 double-close\n- **幂等 Close**：多次调用安全，析构器可以放心调用\n\n### 11.2 Listener 的 socket 文件清理\n\n```cpp\nclass UnixListener {\npublic:\n    bool Bind(const char* path) {\n        // 清理残留 socket 文件\n        ::unlink(path);\n\n        struct sockaddr_un addr;\n        memset(&addr, 0, sizeof(addr));\n        addr.sun_family = AF_UNIX;\n        strncpy(addr.sun_path, path, sizeof(addr.sun_path) - 1);\n\n        if (::bind(fd_, (struct sockaddr*)&addr, sizeof(addr)) != 0) {\n            return false;\n        }\n        // 保存路径用于析构时清理\n        path_len_ = strlen(path);\n        memcpy(path_, path, path_len_ + 1);\n        return true;\n    }\n\n    ~UnixListener() {\n        Close();\n        // 清理 socket 文件\n        if (path_len_ > 0) {\n            ::unlink(path_);\n        }\n    }\n\nprivate:\n    char path_[108] = {};\n    size_t path_len_ = 0;\n};\n```\n\n析构时自动 `unlink` socket 文件，避免残留。\n\n## 12. UDS vs 替代方案选择矩阵\n\n| 维度 | UDS STREAM | UDS SEQPACKET | 共享内存 + eventfd | pipe | TCP loopback |\n|------|-----------|---------------|-------------------|------|-------------|\n| 延迟 | 15-20 us | 15-20 us | 1-5 us | 10-15 us | 40-50 us |\n| 吞吐量 | 高 | 高 | 极高 | 中 | 中 |\n| 消息边界 | 无 | 有 | 自定义 | 无 | 无 |\n| fd 传递 | 支持 | 支持 | 不支持 | 不支持 | 不支持 |\n| 多对一 | 需 accept | 需 accept | 需同步原语 | 不支持 | 需 accept |\n| 安全认证 | SO_PEERCRED | SO_PEERCRED | 文件权限 | 进程关系 | 无 |\n| 可移植性 | POSIX | Linux | POSIX | POSIX | POSIX |\n| 复杂度 | 低 | 低 | 高 | 极低 | 中 |\n\n**嵌入式选择建议**：\n\n- **帧协议通信（控制指令、传感器数据帧）**：`SOCK_SEQPACKET`\n- **大块数据传输（图像、点云）**：共享内存 + eventfd（或 memfd + fd 传递）\n- **简单父子进程通信**：pipe\n- **需要远程扩展能力**：TCP（便于后期从本地迁移到网络）\n\n## 13. newosp 的 UDS 实现评析\n\n[newosp](https://github.com/DeguiLiu/newosp) 的 `socket.hpp` 中包含了 `UnixAddress`、`UnixSocket`、`UnixListener` 三个类。以下是其设计优劣分析：\n\n### 13.1 做得好的方面\n\n| 设计 | 实现 | 评价 |\n|------|------|------|\n| RAII | Move-only，析构自动 `close()` | 杜绝 fd 泄漏 |\n| 路径校验 | `strlen >= sizeof(sun_path)` 检查 | 防止缓冲区溢出 |\n| 错误处理 | `expected<T, SocketError>` 返回值 | 无异常，嵌入式友好 |\n| 幂等关闭 | `if (fd_ >= 0)` 检查后 close | 防止 double-close |\n| 残留清理 | `Bind()` 前 `unlink()` | 避免 EADDRINUSE |\n| MSG_NOSIGNAL | `Send()` 使用此标志 | 防止 SIGPIPE 崩溃 |\n| 移动语义 | 自赋值检查 + 源 fd 置 -1 | 正确无误 |\n| 传输自动选择 | `TransportFactory` 优先 UDS > SHM > TCP | 本地优先最快路径 |\n\n### 13.2 可改进的方面\n\n| 问题 | 详情 | 建议 |\n|------|------|------|\n| socket 文件未自动删除 | `~UnixListener()` 只关闭 fd，不 `unlink` 文件 | 保存路径，析构时 `unlink` |\n| 仅 SOCK_STREAM | 不支持 SOCK_SEQPACKET | 添加模板参数或工厂方法 |\n| 无抽象命名空间 | 仅文件路径模式 | 添加 `FromAbstract(name)` 工厂 |\n| NetworkNode 未集成 UDS | `NetworkNode` 仅使用 `TcpSocket` | 添加 `UnixTransport` 并行实现 |\n| 无 fd 传递 API | 不支持 `SCM_RIGHTS` | 添加 `SendFd`/`RecvFd` 方法 |\n\n## 14. 完整优化配置模板\n\n```bash\n#!/bin/bash\n# ARM-Linux UDS Real-time Tuning Script\n\n# --- CPU 隔离 (需要在内核启动参数中配置 isolcpus=2,3) ---\n# 确认隔离生效\ncat /sys/devices/system/cpu/isolated\n\n# --- 实时调度 ---\n# 通信进程: SCHED_FIFO 优先级 80, 绑定到 CPU 2\nchrt -f 80 taskset -c 2 ./ipc_server\n\n# --- 内核缓冲区 ---\nsysctl -w net.core.rmem_max=4194304    # 4 MB\nsysctl -w net.core.wmem_max=4194304    # 4 MB\nsysctl -w net.core.rmem_default=262144 # 256 KB\n\n# --- 禁用不需要的内核模块 ---\nsysctl -w net.ipv6.conf.all.disable_ipv6=1\n\n# --- 内存锁定 ---\n# 确保 /etc/security/limits.conf 中设置:\n# your_user  -  memlock  unlimited\n\necho \"UDS tuning applied\"\n```\n\n## 15. 总结\n\nUnix Domain Socket 的实时性优化是一个多维度的工程问题。按收益从高到低排列：\n\n**高收益优化**（建议优先实施）：\n\n1. **选择正确的 socket 类型**：帧协议用 `SOCK_SEQPACKET` 省去分帧层\n2. **epoll ET 正确实现**：循环读到 `EAGAIN`，不遗漏数据\n3. **SCHED_FIFO + CPU 隔离 + mlockall**：消除调度抖动\n4. **RAII 资源管理**：Move-only fd 封装，杜绝泄漏\n\n**中等收益优化**（按需评估）：\n\n5. **抽象命名空间**：消除文件系统依赖和残留问题\n6. **sendmsg/iovec**：避免头部+载荷的拼接拷贝\n7. **内核缓冲区调优**：按设备 RAM 和突发流量设置\n\n**高级优化**（大数据/超低延迟场景）：\n\n8. **memfd_create + fd 传递**：大块数据零拷贝\n9. **eventfd + 共享内存**：通知路径仅 8 字节，数据路径零拷贝\n10. **io_uring**：高频场景减少系统调用\n",
      "ctime": "1771552627",
      "mtime": "1771552627",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/behavior_tree_tick_mechanism.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038519334",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "行为树 Tick 机制深度解析: 从原理到 bt-cpp 实践",
      "brief_content": "行为树的 Tick 心跳机制将复杂任务编排抽象为一棵可组合的静态规则树，通过 RUNNING 状态实现协作式并发。本文从 Tick 原理出发，以 bt-cpp (C++14 header-only) ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "行为树 (Behavior Tree, BT) 不是游戏引擎的专属技术。在嵌入式设备启动流程、工业控制任务编排、机器人行为规划等单核系统场景中，行为树的 Tick 心跳机制提供了一种结构化的协作式并发方案: 无需多线程，无需操作系统调度器，只靠主循环的周期性 tick 调用就能实现 I/O 并发和复杂决策逻辑。\n\n本文以 [bt-cpp](https://gitee.com/liudegui/bt-cpp) (C++14 header-only 行为树库) 为主线，从 Tick 机制原理出发，逐步展开节点遍历语义、异步模式、性能特征和工程实践。\n\n> 相关文章:\n> - [C 语言层次状态机框架: 从过程驱动到数据驱动](../c_hsm_data_driven_framework/) -- HSM 与 BT 互补的架构基础\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- newosp 中 HSM + BT 的实际集成\n\n## 1. Tick 机制核心原理\n\n### 1.1 什么是 Tick\n\nTick 是行为树的\"心跳\"。每次 tick 代表一次从根节点开始的完整树遍历: 根据节点类型和子节点返回状态，决定下一步执行哪个分支。\n\n```mermaid\nsequenceDiagram\n    participant Main as 主循环\n    participant BT as 行为树\n    participant Leaf as 叶子节点\n\n    Main->>BT: tree.Tick()\n    BT->>Leaf: 遍历并执行节点\n    Leaf-->>BT: return RUNNING\n    BT-->>Main: return RUNNING\n    Note over Main: 等待下一个 tick 周期\n\n    Main->>BT: tree.Tick()\n    BT->>Leaf: 从上次中断处继续\n    Leaf-->>BT: return SUCCESS\n    BT-->>Main: return SUCCESS\n    Note over Main: 任务完成\n```\n\nbt-cpp 中的 tick 入口:\n\n```cpp\n// BehaviorTree<Context>::Tick()\nStatus Tick() noexcept {\n    ++tick_count_;\n    last_status_ = root_->Tick(context_);\n    return last_status_;\n}\n```\n\n每次 `Tick()` 递增计数器，从根节点开始递归遍历。返回值决定整棵树的执行状态。\n\n### 1.2 四种状态\n\n```cpp\nenum class Status : uint8_t {\n    kSuccess = 0,  // 执行成功\n    kFailure = 1,  // 执行失败\n    kRunning = 2,  // 仍在执行 (异步操作的关键)\n    kError   = 3   // 配置错误\n};\n```\n\n`RUNNING` 是行为树区别于普通 if-else 的核心: 叶子节点返回 `RUNNING` 表示\"我还没完成，下次 tick 再来问我\"。树会保存当前进度，下次 tick 从中断处恢复，而非从头开始。\n\n### 1.3 六种节点类型\n\n| 类型 | 分类 | 语义 | 等价逻辑 |\n|------|------|------|----------|\n| Action | 叶子 | 执行具体操作 | 函数调用 |\n| Condition | 叶子 | 检查条件 (不应返回 RUNNING) | if 判断 |\n| Sequence | 组合 | 全部子节点成功才成功 | AND + 短路求值 |\n| Selector | 组合 | 第一个成功的子节点即可 | OR + 短路求值 |\n| Parallel | 组合 | 每帧 tick 所有子节点 | 协作式并发 |\n| Inverter | 装饰 | 反转 SUCCESS/FAILURE | NOT |\n\n## 2. bt-cpp 库设计\n\n[bt-cpp](https://gitee.com/liudegui/bt-cpp) 是一个 C++14 header-only 行为树库 (单文件 `bt/behavior_tree.hpp`，约 960 行)，面向嵌入式系统设计。核心设计原则:\n\n- **模板化类型安全上下文**: `Node<Context>` 消除 `void*` 类型转换\n- **固定容量内联子节点数组**: 无外部生命周期依赖\n- **可配置回调类型**: 函数指针 (默认) 或 `std::function` (宏开关)\n- **缓存友好内存布局**: 热数据字段前置\n- **兼容 `-fno-exceptions -fno-rtti`**\n\n### 2.1 类型安全上下文 vs void*\n\nC 语言行为树的传统做法是 `void* user_data` + `void* blackboard`，需要手动类型转换:\n\n```c\n// C 风格: 运行时类型转换, 编译器无法检查\nstatic bt_status_t action_load(bt_node_t *self) {\n    file_ctx_t *ctx = (file_ctx_t *)self->user_data;  // 不安全\n    // ...\n}\n```\n\nbt-cpp 用模板参数替代:\n\n```cpp\n// C++14: 编译期类型安全, 无需转换\nstruct DeviceContext {\n    bool system_ok = true;\n    bool config_loaded = false;\n    int total_operations = 0;\n};\n\nbt::Node<DeviceContext> node(\"Check\");\nnode.set_type(bt::NodeType::kCondition)\n    .set_tick([](DeviceContext& ctx) {\n        return ctx.system_ok ? bt::Status::kSuccess\n                             : bt::Status::kFailure;\n    });\n```\n\n`static_assert` 在编译期阻止传入指针类型:\n\n```cpp\nstatic_assert(!std::is_pointer<Context>::value,\n              \"Context must not be a pointer type; use the pointed-to type\");\n```\n\n### 2.2 双模式回调\n\nbt-cpp 支持两种回调模式，通过宏在编译期选择:\n\n```cpp\n// 默认模式: 函数指针 (零堆分配, 确定性延迟)\nusing TickFn = Status(*)(Context&);\n\n// 可选模式: std::function (支持 lambda 捕获, 定义 BT_USE_STD_FUNCTION)\nusing TickFn = std::function<Status(Context&)>;\n```\n\n**函数指针模式**适合嵌入式场景: 零间接开销，节点状态存放在 Context 而非 lambda 捕获。**std::function 模式**适合应用层: 支持有状态 lambda，API 更灵活。\n\n```cpp\n// 函数指针模式: 状态放 Context, tick 函数是普通函数\nstatic bt::Status ReadFlashTick(AsyncContext& ctx) {\n    if (!ctx.flash_started) {\n        ctx.flash_future = std::async(std::launch::async, SimFlashRead, 256);\n        ctx.flash_started = true;\n        return bt::Status::kRunning;\n    }\n    // ...\n}\n\n// std::function 模式: 状态可以用 lambda 捕获\nint progress = 0;\nbt::factory::MakeAction(node, [&progress](DeviceContext& c) {\n    ++progress;\n    return (progress >= 3) ? bt::Status::kSuccess : bt::Status::kRunning;\n});\n```\n\n### 2.3 缓存友好的节点布局\n\nbt-cpp 的 `Node` 类将高频访问字段置于结构体前部:\n\n```\nNode<Context> 内存布局 (热数据前置):\n+00: type_              (uint8_t,  1B)  -- 每次 tick 访问\n+01: status_            (uint8_t,  1B)  -- 每次 tick 访问\n+02: children_count_    (uint16_t, 2B)  -- 每次 tick 访问\n+04: current_child_     (uint16_t, 2B)  -- Sequence/Selector 用\n+06: success_policy_    (uint8_t,  1B)\n+08: child_done_bits_   (uint32_t, 4B)  -- Parallel 位图\n+12: child_success_bits_(uint32_t, 4B)  -- Parallel 位图\n+16: tick_              (指针, 8B)      -- 叶子节点回调\n+24: on_enter_          (指针, 8B)      -- 生命周期回调\n+32: on_exit_           (指针, 8B)      -- 生命周期回调\n+40: children_[]        (指针数组)      -- 固定容量内联\n+xx: name_              (const char*)   -- 冷数据, 仅调试用\n```\n\ntype, status, children_count 这些每次 tick 都会访问的字段集中在前 16 字节，对 CPU 指令缓存友好。name 作为冷数据放在最后。\n\n### 2.4 构建时校验\n\nbt-cpp 提供 `Validate()` 和 `ValidateTree()` 在首次 tick 前检查树结构:\n\n```cpp\nenum class ValidateError : uint8_t {\n    kNone = 0,              // 无错误\n    kLeafMissingTick,       // 叶子节点缺少 tick 回调\n    kInverterNotOneChild,   // Inverter 必须恰好 1 个子节点\n    kParallelExceedsBitmap, // Parallel 子节点超过 32 (位图宽度)\n    kChildrenExceedMax,     // 子节点数超过 BT_MAX_CHILDREN\n    kNullChild              // 子节点数组中有空指针\n};\n\n// 构建后一次性验证, 运行时零开销\nbt::BehaviorTree<Context> tree(root, ctx);\nbt::ValidateError err = tree.ValidateTree();\nif (err != bt::ValidateError::kNone) {\n    std::printf(\"Validation failed: %s\\n\", bt::ValidateErrorToString(err));\n}\n```\n\n这些检查在构建时运行一次，热路径零开销。\n\n### 2.5 流式 API 与工厂辅助函数\n\nbt-cpp 提供两种节点配置风格:\n\n**流式 API** (链式调用):\n\n```cpp\nbt::Node<Ctx> node(\"Name\");\nnode.set_type(bt::NodeType::kAction)\n    .set_tick(MyTickFn)\n    .set_on_enter(MyEnterFn)\n    .set_on_exit(MyExitFn);\n```\n\n**工厂辅助函数** (一行配置):\n\n```cpp\nbt::Node<Ctx> node(\"Name\");\nbt::factory::MakeAction(node, MyTickFn);\nbt::factory::MakeCondition(node, MyCheckFn);\nbt::factory::MakeSequence(node, children, count);\nbt::factory::MakeParallel(node, children, count, bt::ParallelPolicy::kRequireAll);\nbt::factory::MakeInverter(node, child);\n```\n\n## 3. 节点遍历语义\n\n### 3.1 Sequence: 全部成功才成功\n\nSequence 节点按顺序执行子节点，遇到失败或 RUNNING 立即返回。关键: `current_child_` 字段保存执行进度，下次 tick 从上次中断处恢复。\n\n```cpp\n// bt-cpp TickSequence 核心逻辑 (简化)\nStatus TickSequence(Context& ctx) noexcept {\n    if (status_ != Status::kRunning) {\n        current_child_ = 0;       // 首次进入, 从第一个子节点开始\n        CallEnter(ctx);\n    }\n\n    for (uint16_t i = current_child_; i < children_count_; ++i) {\n        Status child_status = children_[i]->Tick(ctx);\n\n        if (child_status == Status::kRunning) {\n            current_child_ = i;   // 保存进度, 下次从这里继续\n            status_ = Status::kRunning;\n            return Status::kRunning;\n        }\n\n        if (child_status != Status::kSuccess) {\n            status_ = child_status;\n            CallExit(ctx);\n            return child_status;  // 子节点失败, Sequence 失败\n        }\n    }\n\n    status_ = Status::kSuccess;   // 全部子节点成功\n    CallExit(ctx);\n    return Status::kSuccess;\n}\n```\n\n`current_child_` 递增的过程就是 Sequence \"看起来在动态推进\"的本质。实际上树结构完全是静态的，\"动态\"只是状态保存的视觉效果。\n\n### 3.2 Selector: 第一个成功即可\n\nSelector 是 Sequence 的对偶: 依次尝试子节点，第一个成功就返回成功。适合实现 fallback 逻辑。\n\n```\nSelector (尝试多种方案)\n+-- TryPrimary  (Condition: 检查主路径是否可行)\n+-- DoFallback  (Action: 主路径不可行时的降级方案)\n```\n\n### 3.3 Parallel: 协作式并发的核心\n\nPARALLEL 节点是行为树实现协作式并发的关键。它在每次 tick 中遍历所有子节点，用 `uint32_t` 位图跟踪完成状态:\n\n```cpp\n// bt-cpp TickParallel 核心逻辑 (简化)\nStatus TickParallel(Context& ctx) noexcept {\n    if (status_ != Status::kRunning) {\n        child_done_bits_ = 0;      // 首次进入, 重置位图\n        child_success_bits_ = 0;\n        CallEnter(ctx);\n    }\n\n    uint16_t running_count = 0, success_count = 0, failure_count = 0;\n\n    for (uint16_t i = 0; i < children_count_; ++i) {\n        const uint32_t bit_mask = (static_cast<uint32_t>(1) << i);\n\n        // O(1) 跳过已完成的子节点\n        if ((child_done_bits_ & bit_mask) != 0U) {\n            if ((child_success_bits_ & bit_mask) != 0U) ++success_count;\n            else ++failure_count;\n            continue;\n        }\n\n        Status child_status = children_[i]->Tick(ctx);\n\n        if (child_status == Status::kRunning) {\n            ++running_count;\n        } else if (child_status == Status::kSuccess) {\n            child_done_bits_ |= bit_mask;       // 标记完成\n            child_success_bits_ |= bit_mask;     // 标记成功\n            ++success_count;\n        } else {\n            child_done_bits_ |= bit_mask;        // 标记完成\n            ++failure_count;\n        }\n    }\n\n    // 根据策略判定\n    if (success_policy_ == ParallelPolicy::kRequireAll) {\n        if (failure_count > 0) return Status::kFailure;\n        if (running_count > 0) return Status::kRunning;\n        return Status::kSuccess;\n    } else {  // kRequireOne\n        if (success_count > 0) return Status::kSuccess;\n        if (running_count > 0) return Status::kRunning;\n        return Status::kFailure;\n    }\n}\n```\n\n三个关键设计:\n\n1. **零内存分配**: `child_done_bits_` 和 `child_success_bits_` 是 `uint32_t` 位图，内嵌在节点结构体中\n2. **O(1) 跳过**: 已完成的子节点通过位测试快速跳过，不会重复 tick\n3. **双策略**: `kRequireAll` (全部成功才成功) 和 `kRequireOne` (一个成功即可)\n\n位图宽度 32 位意味着单个 Parallel 节点最多支持 32 个子节点。`ValidateTree()` 会在构建时检查这个约束。\n\n### 3.4 Inverter: 装饰器模式\n\nInverter 将子节点的 SUCCESS 反转为 FAILURE，FAILURE 反转为 SUCCESS。RUNNING 和 ERROR 透传。\n\n```\nInverter(NoErrorCheck)\n+-- CheckError (Condition, 返回 FAILURE 表示无错误)\n=> Inverter 将 FAILURE 转为 SUCCESS, 意思是\"无错误=通过\"\n```\n\n## 4. RUNNING 状态与异步操作\n\n### 4.1 RUNNING: 协作式多任务的关键\n\n`RUNNING` 状态让行为树天然支持非阻塞操作。叶子节点返回 `RUNNING` 时，树保存当前进度; 下次 tick 自动从中断处恢复，期间主循环可以执行其他工作。\n\n对比传统阻塞方式:\n\n```cpp\n// 阻塞方式: CPU 在等待 I/O 时空闲\nvoid load_all_blocking() {\n    read_flash();    // 阻塞 150ms, CPU 大部分时间空闲\n    read_sensor();   // 阻塞 80ms\n    load_network();  // 阻塞 200ms\n    // 总耗时: 430ms (串行)\n}\n\n// 行为树 RUNNING 方式: Parallel 节点同时驱动三个 I/O\n// Tick 1: 三个 Action 各自提交 I/O -> 返回 RUNNING\n// Tick 2: 轮询各自的 future -> sensor 完成, 其他仍 RUNNING\n// Tick 3: flash 完成\n// Tick 4: network 完成 -> Parallel 返回 SUCCESS\n// 总耗时: ~200ms (受最慢的 I/O 限制, 而非三者之和)\n```\n\n### 4.2 异步 I/O 模式: std::async + std::future\n\nbt-cpp 的 `async_example.cpp` 演示了标准异步模式: 首次 tick 提交 I/O 任务到后台线程，后续 tick 非阻塞轮询 `std::future`:\n\n```cpp\n// 异步状态存放在类型安全的 Context 中\nstruct AsyncContext {\n    std::future<std::string> flash_future;\n    bool flash_started = false;\n    std::string flash_data;\n    // ... 其他节点的异步状态\n};\n\n// 异步 Action 的 tick 函数 (函数指针模式, 无 lambda 捕获)\nstatic bt::Status ReadFlashTick(AsyncContext& ctx) {\n    // 首次 tick: 提交 I/O 任务到后台线程\n    if (!ctx.flash_started) {\n        ctx.flash_future = std::async(std::launch::async, SimFlashRead, 256);\n        ctx.flash_started = true;\n        return bt::Status::kRunning;  // 告诉树: 我还没完成\n    }\n\n    // 后续 tick: 非阻塞轮询\n    if (ctx.flash_future.wait_for(std::chrono::seconds(0)) ==\n        std::future_status::ready) {\n        ctx.flash_data = ctx.flash_future.get();\n        return bt::Status::kSuccess;  // I/O 完成\n    }\n\n    return bt::Status::kRunning;      // 继续等待\n}\n```\n\n这个模式的关键: `wait_for(std::chrono::seconds(0))` 是非阻塞的，如果 future 未就绪则立即返回，不会挂起主线程。\n\n### 4.3 完整异步树示例\n\n以下树结构演示了 Parallel + Selector 组合处理多路异步 I/O 和 fallback 逻辑 (来自 bt-cpp `async_example.cpp`):\n\n```\nRoot (Sequence)\n+-- CheckSystem    (Condition, 同步)\n+-- ParallelIO     (Parallel, RequireAll)\n|   +-- ReadFlash  (Action, async 150ms)\n|   +-- ReadSensor (Action, async 80ms)\n|   +-- LoadNetwork(Action, async 200ms, 可能失败)\n+-- ProcessResults (Selector)\n    +-- ProcessAll     (Condition: 三路数据都加载成功?)\n    +-- ProcessPartial (Action: 降级处理, 只用 flash + sensor)\n```\n\n构建和运行:\n\n```cpp\nAsyncContext ctx;\n\n// 构建节点\nbt::Node<AsyncContext> check_sys(\"CheckSystem\");\ncheck_sys.set_type(bt::NodeType::kCondition).set_tick(CheckSystemTick);\n\nbt::Node<AsyncContext> read_flash(\"ReadFlash\");\nread_flash.set_type(bt::NodeType::kAction).set_tick(ReadFlashTick);\n\nbt::Node<AsyncContext> read_sensor(\"ReadSensor\");\nread_sensor.set_type(bt::NodeType::kAction).set_tick(ReadSensorTick);\n\nbt::Node<AsyncContext> load_net(\"LoadNetwork\");\nload_net.set_type(bt::NodeType::kAction).set_tick(LoadNetworkTick);\n\n// Parallel: 三路 I/O 并发\nbt::Node<AsyncContext> parallel_io(\"ParallelIO\");\nparallel_io.set_type(bt::NodeType::kParallel)\n    .AddChild(read_flash)\n    .AddChild(read_sensor)\n    .AddChild(load_net)\n    .set_parallel_policy(bt::ParallelPolicy::kRequireAll);\n\n// Selector: 优先全量处理, 失败则降级\nbt::Node<AsyncContext> process(\"ProcessResults\");\nprocess.set_type(bt::NodeType::kSelector)\n    .AddChild(process_all)\n    .AddChild(process_partial);\n\n// Root\nbt::Node<AsyncContext> root(\"Root\");\nroot.set_type(bt::NodeType::kSequence)\n    .AddChild(check_sys)\n    .AddChild(parallel_io)\n    .AddChild(process);\n\n// 验证 + 运行\nbt::BehaviorTree<AsyncContext> tree(root, ctx);\nbt::ValidateError err = tree.ValidateTree();\n\nbt::Status result = bt::Status::kRunning;\nwhile (result == bt::Status::kRunning) {\n    result = tree.Tick();\n    if (result == bt::Status::kRunning) {\n        std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    }\n}\n```\n\n当 `LoadNetwork` 失败时，`ProcessResults` Selector 会跳过 `ProcessAll` (返回 FAILURE)，自动执行 `ProcessPartial` 降级方案。整棵树不需要任何手动错误处理代码。\n\n## 5. 设备启动流程: bt-cpp 实战\n\n以下示例来自 bt-cpp 的 `bt_example.cpp`，模拟嵌入式设备启动序列:\n\n```\nRoot (Sequence)\n+-- SystemCheck      (Condition: 系统自检)\n+-- ParallelLoad     (Parallel, RequireAll)\n|   +-- LoadConfig   (Action: 加载配置, 3 个 tick 完成)\n|   +-- LoadCalib    (Action: 加载校准, 2 个 tick 完成)\n+-- InitModules      (Sequence)\n|   +-- Inverter     (装饰器)\n|   |   +-- CheckError (Condition: FAILURE=无错误, 经 Inverter 转为 SUCCESS)\n|   +-- InitISP      (Action: 初始化 ISP)\n+-- StartPreview     (Action: 启动预览)\n```\n\nContext 作为类型安全的共享黑板:\n\n```cpp\nstruct DeviceContext {\n    bool system_ok = true;\n    bool config_loaded = false;\n    bool calib_loaded = false;\n    bool isp_initialized = false;\n    bool preview_started = false;\n    int total_operations = 0;\n};\n```\n\n使用工厂辅助函数配置节点:\n\n```cpp\nDeviceContext ctx;\n\n// 条件节点\nbt::Node<DeviceContext> sys_check(\"SystemCheck\");\nbt::factory::MakeCondition(sys_check, [](DeviceContext& c) {\n    return c.system_ok ? bt::Status::kSuccess : bt::Status::kFailure;\n});\n\n// 异步 Action (3 个 tick 完成, 用 lambda 捕获局部进度)\nint config_progress = 0;\nbt::Node<DeviceContext> load_config(\"LoadConfig\");\nbt::factory::MakeAction(load_config,\n    [&config_progress](DeviceContext& c) {\n        ++config_progress;\n        if (config_progress >= 3) {\n            c.config_loaded = true;\n            ++c.total_operations;\n            return bt::Status::kSuccess;\n        }\n        return bt::Status::kRunning;\n    });\n\n// 生命周期回调\nload_config\n    .set_on_enter([](DeviceContext&) { std::printf(\"[Enter] LoadConfig\\n\"); })\n    .set_on_exit([](DeviceContext&)  { std::printf(\"[Exit]  LoadConfig\\n\"); });\n\n// Parallel: 配置和校准并发加载\nbt::Node<DeviceContext> parallel_load(\"ParallelLoad\");\nbt::Node<DeviceContext>* par_children[] = {&load_config, &load_calib};\nbt::factory::MakeParallel(parallel_load, par_children, 2,\n                           bt::ParallelPolicy::kRequireAll);\n\n// Inverter: 将 CheckError 的 FAILURE (无错误) 转为 SUCCESS\nbt::Node<DeviceContext> inverter(\"NoErrorCheck\");\nbt::factory::MakeInverter(inverter, check_error);\n```\n\n运行结果 (3 次 tick 完成启动):\n\n```\n--- Tick 1 ---\n    [Condition] SystemCheck: PASS\n  >> ParallelLoad: begin\n    [Enter] LoadConfig started\n    [Action] LoadConfig: progress 1/3    (RUNNING)\n    [Enter] LoadCalib started\n    [Action] LoadCalib: progress 1/2     (RUNNING)\n  -> Tree status: RUNNING\n\n--- Tick 2 ---\n    [Action] LoadConfig: progress 2/3    (RUNNING)\n    [Action] LoadCalib: progress 2/2     (SUCCESS)\n    [Exit]  LoadCalib finished\n  -> Tree status: RUNNING\n\n--- Tick 3 ---\n    [Action] LoadConfig: progress 3/3    (SUCCESS)\n    [Exit]  LoadConfig finished\n  << ParallelLoad: done\n    [Condition] CheckError: no errors found (FAILURE -> Inverter -> SUCCESS)\n    [Action] InitISP\n    [Action] StartPreview\n  -> Tree status: SUCCESS\n```\n\nParallel 节点在 Tick 1 同时启动 LoadConfig 和 LoadCalib。LoadCalib 在 Tick 2 完成 (2 个 tick)，LoadConfig 在 Tick 3 完成 (3 个 tick)。整个并行加载阶段耗时等于最慢的子任务 (3 tick)，而非两者之和 (5 tick)。\n\n## 6. 行为树的静态本质\n\n### 6.1 静态规则树，非动态 AI\n\n行为树的\"动态\"是一种误解。树结构在构建时固定，运行时不会创建或销毁节点。所谓的\"动态推进\"只是 `current_child_` 索引在递增:\n\n```\nTick 1: current_child_=0, 执行子节点 0\nTick 2: current_child_=1, 执行子节点 1  (子节点 0 已完成)\nTick 3: current_child_=2, 执行子节点 2  (子节点 0,1 已完成)\n```\n\nbt-cpp 的子节点存储是固定容量内联数组，不依赖外部分配:\n\n```cpp\n// 固定容量, 编译期可配置 (默认 8)\nstatic constexpr uint16_t kMaxChildren = static_cast<uint16_t>(BT_MAX_CHILDREN);\nNode* children_[kMaxChildren];  // 内联在节点结构体内\n```\n\n### 6.2 行为树 = if-else 的结构化替代\n\n5 步以内的线性流程用 if-else 更直接。当流程包含并行分支、条件降级、异步等待时，行为树的结构化优势才体现出来:\n\n```cpp\n// if-else: 无法表达并行加载\nif (check() && load_config() && load_calib() && init() && start()) {\n    return OK;\n}\n// 问题: load_config 和 load_calib 只能串行执行\n\n// 行为树: 并行加载是一等公民\nRoot (Sequence)\n+-- Check\n+-- Parallel(RequireAll)     // 自然表达并行\n|   +-- LoadConfig\n|   +-- LoadCalib\n+-- Init\n+-- Start\n```\n\n## 7. 性能特征\n\n### 7.1 框架开销量化\n\n以下数据来自 bt-cpp 的 `benchmark_example.cpp`，每个场景运行 100,000 次迭代 (含 1,000 次 warmup)，叶子节点执行极简操作 (递增计数器) 以隔离框架开销:\n\n| 场景 | avg (ns) | p50 (ns) | p99 (ns) | 说明 |\n|------|----------|----------|----------|------|\n| Flat Sequence (8 actions) | 130 | -- | 222 | 最佳顺序分发 |\n| Deep Nesting (5 levels) | 78 | -- | 136 | 嵌套深度影响 |\n| Parallel (4 children) | 75 | -- | 131 | 位图跟踪开销 |\n| Selector early exit (1/8) | 58 | -- | 106 | 短路求值收益 |\n| Realistic tree (8 nodes) | 97 | -- | 174 | 混合节点类型 |\n| Hand-written if-else | 30 | -- | 36 | 基准对照 |\n\n*数据来源: bt-cpp `examples/benchmark_example.cpp`，x86-64 平台。ARM 平台性能特征类似。*\n\n关键结论:\n\n- 一次完整树 tick 开销在**百纳秒量级** (8 节点混合树 ~97ns avg)\n- BT 相对手写 if-else 约 **4 倍开销** (130ns vs 30ns)\n- 在 20Hz tick 频率 (50ms 间隔) 下，框架开销占 tick 预算 **< 0.001%**\n- Selector 短路求值有效减少不必要的节点遍历\n\n### 7.2 性能有利面与代价\n\n**有利:**\n\n- 短路求值: Sequence/Selector 遇到终止条件立即返回\n- 顺序遍历: 对 CPU 指令缓存友好 (对比 FSM 的间接跳转表)\n- 函数指针模式零间接开销\n- 固定容量子节点数组，无动态内存分配\n\n**代价:**\n\n- 每帧从根节点开始遍历 (FSM 直接从当前状态开始)\n- Parallel 节点每帧 tick 所有未完成子节点\n\n这些代价在百纳秒级别，对绝大多数嵌入式 tick 频率 (10-100Hz) 可忽略不计。\n\n## 8. 行为树 vs 状态机: 选型与互补\n\n### 8.1 选型对比\n\n| 维度 | 行为树 | 状态机 (FSM/HSM) |\n|------|--------|-----------------|\n| 状态爆炸 | 节点线性增长 | N 状态 x M 事件 = O(NM) 转换 |\n| 可组合性 | 强，子树可复用 | 弱，状态间强耦合 |\n| 并发行为 | Parallel 节点原生支持 | 需要并行状态域 |\n| 异步操作 | RUNNING 一等公民 | 需要额外\"等待\"状态 |\n| 事件驱动 | 不擅长 | 天然适合 |\n| 状态循环 | 不适合 | 天然适合 |\n\n### 8.2 BT + HSM 互补架构\n\nbt-cpp 推荐的工程实践: HSM 管理系统级状态转换，BT 管理运行态内的复杂决策和任务编排。\n\n```\nHSM (系统级状态管理)              BT (运行态内的决策)\n+-- Init                          Root (Sequence)\n+-- Running  ----BT 驱动--->      +-- CheckSensors\n+-- Error                         +-- Parallel(I/O)\n+-- Shutdown                      +-- Selector(Fallback)\n```\n\n- **HSM** 处理状态转换有严格协议约束的场景 (初始化->运行->错误->关机)\n- **BT** 处理运行态内的任务编排、并发 I/O、条件降级\n\n这种分层避免了两种架构各自的弱点: BT 不擅长循环状态转换，HSM 不擅长并发任务编排。\n\n相关项目:\n- [bt-cpp](https://gitee.com/liudegui/bt-cpp) -- C++14 行为树库 (header-only, MIT)\n- [bt_simulation](https://gitee.com/liudegui/bt_simulation) -- C 语言版本 (含嵌入式设备模拟)\n- [hsm-cpp](https://gitee.com/liudegui/hsm-cpp) -- C++14 层次状态机库\n\n### 8.3 不适合行为树的场景\n\n- 状态转换有严格协议约束 (通信协议栈) -- 用 HSM\n- 纯事件驱动、无需周期性轮询 -- FSM 更高效\n- 决策分支少 (< 5 个行为) -- if-else 更简单直接\n\n## 9. 工程实践要点\n\n### 9.1 关键: Action 节点必须非阻塞\n\n行为树协作式并发的前提是每个叶子节点快速返回。阻塞调用会打破整棵树的并发能力:\n\n```cpp\n// 错误: 阻塞等待, 主循环挂起\nstatic bt::Status BadAction(Context& ctx) {\n    auto data = blocking_read(fd);  // 阻塞 100ms, 其他节点无法执行\n    return bt::Status::kSuccess;\n}\n\n// 正确: 非阻塞, 返回 RUNNING\nstatic bt::Status GoodAction(Context& ctx) {\n    if (!ctx.started) {\n        ctx.future = std::async(std::launch::async, blocking_read, fd);\n        ctx.started = true;\n        return bt::Status::kRunning;  // 立即返回, 不阻塞\n    }\n    if (ctx.future.wait_for(std::chrono::seconds(0)) ==\n        std::future_status::ready) {\n        ctx.data = ctx.future.get();\n        return bt::Status::kSuccess;\n    }\n    return bt::Status::kRunning;\n}\n```\n\n### 9.2 主循环驱动模式\n\n最简单的 tick 驱动方式: 主循环 + 固定间隔:\n\n```cpp\nbt::BehaviorTree<Context> tree(root, ctx);\n\nbt::Status result = bt::Status::kRunning;\nwhile (result == bt::Status::kRunning) {\n    result = tree.Tick();\n    if (result == bt::Status::kRunning) {\n        std::this_thread::sleep_for(std::chrono::milliseconds(50));  // 20Hz\n    }\n}\n```\n\n在 RTOS 环境中，`sleep_for` 替换为 `rt_thread_mdelay()` 或定时器回调。\n\n### 9.3 超时保护\n\n长时间 RUNNING 的任务需要超时机制:\n\n```cpp\nauto start = std::chrono::steady_clock::now();\nbt::Status result = bt::Status::kRunning;\n\nwhile (result == bt::Status::kRunning) {\n    result = tree.Tick();\n    auto elapsed = std::chrono::steady_clock::now() - start;\n    if (elapsed > std::chrono::seconds(10)) {\n        // 超时处理\n        break;\n    }\n    if (result == bt::Status::kRunning) {\n        std::this_thread::sleep_for(std::chrono::milliseconds(50));\n    }\n}\n```\n\n### 9.4 线程池替代 std::async\n\n`std::async` 每次创建新线程，对高频任务提交有开销。bt-cpp 的 `threadpool_example.cpp` 演示了用固定线程池替代:\n\n```cpp\nstruct PoolContext {\n    std::unique_ptr<ThreadPool> pool;  // 2 个 worker 线程\n    std::future<std::string> config_future;\n    bool config_started = false;\n    // ...\n    PoolContext() : pool(std::unique_ptr<ThreadPool>(new ThreadPool(2))) {}\n};\n\nstatic bt::Status LoadConfigTick(PoolContext& ctx) {\n    if (!ctx.config_started) {\n        ctx.config_future = ctx.pool->enqueue(SimLoadConfig);  // 提交到线程池\n        ctx.config_started = true;\n        return bt::Status::kRunning;\n    }\n    // 后续 tick: 同样用 wait_for(0s) 非阻塞轮询\n    // ...\n}\n```\n\n线程池方案的优势: 线程创建一次复用多次，资源使用有上限 (bounded concurrency)。\n\n## 10. 从 C 到 C++14 的演进\n\nbt-cpp 的 C 语言前身 [bt_simulation](https://gitee.com/liudegui/bt_simulation) 面向资源极度受限的 MCU (几十 KB RAM)。bt-cpp 保留了 C 版本的核心设计 (节点结构、位图跟踪、状态保存)，在 C++14 层面做了类型安全和易用性提升:\n\n| 设计点 | C 版本 (bt_simulation) | C++14 版本 (bt-cpp) |\n|--------|----------------------|---------------------|\n| 上下文传递 | `void* user_data` + `void* blackboard` | 模板 `Context` 参数 |\n| 节点数据 | 函数指针 + `void*` | Lambda 捕获或 Context 成员 |\n| 子节点存储 | 外部指针数组 (生命周期需用户管理) | 固定容量内联数组 (无外部依赖) |\n| 回调类型 | 函数指针 | 函数指针 (默认) / `std::function` (宏开关) |\n| 节点配置 | `BT_INIT_ACTION()` 宏 | 流式 API + 工厂辅助函数 |\n| 编译器提示 | 无 | `BT_LIKELY` / `BT_UNLIKELY` / `BT_HOT` |\n| 构建时校验 | 无 | `Validate()` / `ValidateTree()` + `static_assert` |\n\n两者共享相同的 Tick 语义和节点遍历逻辑。选择依据:\n\n- **MCU / 裸机 / 纯 C 环境**: 使用 bt_simulation\n- **ARM-Linux / 嵌入式 C++ 环境**: 使用 bt-cpp\n\n## 总结\n\n行为树 Tick 机制的价值在于用**可忽略的运行时开销换取显著的架构清晰度**:\n\n1. **Tick 心跳**: 每次 tick 从根节点遍历，节点通过 RUNNING 保存进度，实现协作式并发\n2. **静态规则树**: 结构编译时固定，\"动态\"只是状态保存的视觉效果\n3. **PARALLEL 位图**: 零分配、O(1) 跳过已完成子节点，单核系统上实现 I/O 并发\n4. **百纳秒开销**: 8 节点混合树 tick 约 97ns，对 20Hz 主循环占比 < 0.001%\n5. **BT + HSM 互补**: BT 管任务编排和并发调度，HSM 管系统级状态转换\n\n选型决策:\n\n```\n任务编排 (启动/初始化/多步流程)  -> 行为树\n状态转换 (运行/暂停/错误/恢复)   -> 状态机\n单核 I/O 并发                    -> 行为树 Parallel + RUNNING\n决策分支少 (< 5 步线性)          -> if-else\n```\n",
      "ctime": "1771552630",
      "mtime": "1771552630",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/clang_tidy_embedded_cpp17.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038535718",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "Clang-Tidy 嵌入式 C++17 实战: 从配置到 CI 集成的完整指南",
      "brief_content": "将两篇 clang-tidy 基础教程整合并扩展为面向嵌入式 C++17 的完整实战指南。涵盖针对 -fno-exceptions/-fno-rtti 场景的精选 check 集合、嵌入式专属 che",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原始教程: [Clang-Tidy 完整配置与 CMake 集成](https://blog.csdn.net/stallion5632/article/details/139545885) | [多进程 shell 脚本加速](https://blog.csdn.net/stallion5632/article/details/140122323)\n>\n> 目标平台: ARM-Linux (Cortex-A53/A72) | C++17, `-fno-exceptions -fno-rtti`\n>\n> 官方文档: [Clang-Tidy Checks List](https://clang.llvm.org/extra/clang-tidy/checks/list.html)\n\n---\n\n## 1. 为什么嵌入式项目需要 clang-tidy\n\ncpplint 和 clang-format 解决的是**风格**问题 (命名、缩进、include 排序)，而 clang-tidy 解决的是**语义**问题:\n\n| 工具 | 分析层级 | 能力 |\n|------|---------|------|\n| clang-format | 词法 (token) | 缩进、空格、换行 |\n| cpplint | 正则匹配 | 命名规范、头文件 guard、include 排序 |\n| **clang-tidy** | **AST (抽象语法树)** | 空指针解引用、窄化转换、use-after-move、线程安全 |\n\n嵌入式 C++17 项目 (如 newosp) 常用 `-fno-exceptions -fno-rtti` 编译，这意味着:\n- 运行时类型检查缺失，类型错误更难发现\n- 异常路径被截断，错误处理依赖返回值检查\n- `reinterpret_cast`、`placement new` 等底层操作更多\n\n这些场景恰好是 clang-tidy 的 bugprone、cppcoreguidelines、performance 系列 check 的发力点。\n\n---\n\n## 2. 安装\n\n推荐使用 LLVM 官方脚本安装最新版 (当前 18):\n\n```bash\nwget https://apt.llvm.org/llvm.sh\nchmod +x llvm.sh\nsudo ./llvm.sh 18\n\n# 验证\nclang-tidy-18 --version\n```\n\n`apt-get install clang-tidy` 安装的版本通常较旧，缺少 C++17 相关 check (如 `modernize-use-structured-binding`、`bugprone-unchecked-optional-access`)。\n\n---\n\n## 3. 嵌入式 C++17 专用 .clang-tidy 配置\n\n原始教程的配置面向 C++11 桌面项目。以下是针对嵌入式 C++17 重新设计的配置:\n\n```yaml\n---\n# 嵌入式 C++17 clang-tidy 配置\n# 目标: ARM-Linux, -fno-exceptions -fno-rtti, header-only 库\n\nChecks: >\n  -*,\n  bugprone-*,\n  -bugprone-easily-swappable-parameters,\n  -bugprone-exception-escape,\n  -bugprone-unhandled-exception-at-new,\n  cert-*,\n  -cert-err60-cpp,\n  clang-analyzer-core.*,\n  clang-analyzer-cplusplus.*,\n  clang-analyzer-deadcode.*,\n  concurrency-mt-unsafe,\n  cppcoreguidelines-init-variables,\n  cppcoreguidelines-misleading-capture-default-by-value,\n  cppcoreguidelines-narrowing-conversions,\n  cppcoreguidelines-no-malloc,\n  cppcoreguidelines-prefer-member-initializer,\n  cppcoreguidelines-pro-type-cstyle-cast,\n  cppcoreguidelines-pro-type-member-init,\n  cppcoreguidelines-slicing,\n  cppcoreguidelines-special-member-functions,\n  google-build-using-namespace,\n  google-explicit-constructor,\n  google-readability-casting,\n  misc-const-correctness,\n  misc-redundant-expression,\n  misc-static-assert,\n  misc-unconventional-assign-operator,\n  misc-unused-parameters,\n  modernize-deprecated-headers,\n  modernize-loop-convert,\n  modernize-redundant-void-arg,\n  modernize-use-bool-literals,\n  modernize-use-default-member-init,\n  modernize-use-emplace,\n  modernize-use-equals-default,\n  modernize-use-equals-delete,\n  modernize-use-nodiscard,\n  modernize-use-noexcept,\n  modernize-use-nullptr,\n  modernize-use-override,\n  modernize-use-using,\n  performance-*,\n  -performance-avoid-endl,\n  readability-braces-around-statements,\n  readability-container-size-empty,\n  readability-else-after-return,\n  readability-identifier-naming,\n  readability-implicit-bool-conversion,\n  readability-make-member-function-const,\n  readability-misleading-indentation,\n  readability-non-const-parameter,\n  readability-redundant-control-flow,\n  readability-simplify-boolean-expr,\n  readability-static-accessed-through-instance\n\n# 仅检查项目头文件，排除第三方和系统头文件\nHeaderFilterRegex: '(include/osp/|include/mccc/|src/)'\n\n# 严格模式: 将以下 check 升级为编译错误\nWarningsAsErrors: >\n  bugprone-use-after-move,\n  bugprone-dangling-handle,\n  bugprone-infinite-loop,\n  cppcoreguidelines-no-malloc,\n  performance-move-const-arg\n\nFormatStyle: file\n\nCheckOptions:\n  # --- 命名规范 (Google Style) ---\n  - key: readability-identifier-naming.NamespaceCase\n    value: lower_case\n  - key: readability-identifier-naming.ClassCase\n    value: CamelCase\n  - key: readability-identifier-naming.StructCase\n    value: CamelCase\n  - key: readability-identifier-naming.EnumCase\n    value: CamelCase\n  - key: readability-identifier-naming.EnumConstantCase\n    value: CamelCase\n  - key: readability-identifier-naming.EnumConstantPrefix\n    value: k\n  - key: readability-identifier-naming.FunctionCase\n    value: CamelCase\n  - key: readability-identifier-naming.MethodCase\n    value: CamelCase\n  - key: readability-identifier-naming.ParameterCase\n    value: lower_case\n  - key: readability-identifier-naming.LocalVariableCase\n    value: lower_case\n  - key: readability-identifier-naming.MemberCase\n    value: lower_case\n  - key: readability-identifier-naming.MemberSuffix\n    value: _\n  - key: readability-identifier-naming.ConstantCase\n    value: CamelCase\n  - key: readability-identifier-naming.ConstantPrefix\n    value: k\n  - key: readability-identifier-naming.TemplateParameterCase\n    value: CamelCase\n  - key: readability-identifier-naming.TypeAliasCase\n    value: CamelCase\n  - key: readability-identifier-naming.MacroDefinitionCase\n    value: UPPER_CASE\n\n  # --- 嵌入式专属调优 ---\n  - key: cppcoreguidelines-special-member-functions.AllowSoleDefaultDtor\n    value: 'true'\n  - key: modernize-use-noexcept.ReplacementString\n    value: 'noexcept'\n  - key: performance-move-const-arg.CheckTriviallyCopyableMove\n    value: 'true'\n  - key: readability-function-size.LineThreshold\n    value: '200'\n  - key: readability-function-cognitive-complexity.Threshold\n    value: '40'\n  - key: bugprone-narrowing-conversions.WarnOnIntegerNarrowingConversion\n    value: 'true'\n  - key: bugprone-narrowing-conversions.WarnOnFloatingPointNarrowingConversion\n    value: 'true'\n  - key: misc-const-correctness.WarnPointersAsValues\n    value: 'true'\n...\n```\n\n### 3.1 配置设计原则\n\n**原则 1: 先禁全部 (`-*`)，再精选启用**\n\n原始教程和本文都采用 `-*` 起手。理由: clang-tidy 有 500+ check，全部启用会产生大量噪声。嵌入式项目需要精选与目标平台相关的 check。\n\n**原则 2: 禁用异常相关 check**\n\n`-fno-exceptions` 项目中，以下 check 会产生误报:\n- `bugprone-exception-escape`: 检测异常泄漏，但异常已禁用\n- `bugprone-unhandled-exception-at-new`: 检测 new 的异常，但使用 placement new\n- `cert-err60-cpp`: 检测异常类拷贝构造，无异常场景不适用\n\n**原则 3: HeaderFilterRegex 必须配置**\n\n```yaml\nHeaderFilterRegex: '(include/osp/|include/mccc/|src/)'\n```\n\n不配置此项 (或设为空)，clang-tidy **只检查源文件，跳过头文件中的警告**。对于 header-only 库这意味着大部分代码不会被检查。设为 `.*` 则会检查系统头文件和第三方库 (Catch2、sockpp 等)，产生大量不可修复的噪声。\n\n**原则 4: WarningsAsErrors 精选致命级 check**\n\n只将确定是 bug 的 check 升级为错误 (阻断 CI):\n- `bugprone-use-after-move`: 移动后使用，100% 是 bug\n- `bugprone-dangling-handle`: 悬挂引用\n- `cppcoreguidelines-no-malloc`: 嵌入式项目禁止裸 malloc\n\n### 3.2 嵌入式高价值 check 详解\n\n#### bugprone 系列 (bug 检测)\n\n| check | 说明 | 嵌入式价值 |\n|-------|------|-----------|\n| `bugprone-use-after-move` | 检测 `std::move` 后继续使用对象 | 高: 无异常下 UB 难以调试 |\n| `bugprone-narrowing-conversions` | `uint32_t → uint16_t` 隐式截断 | 高: 嵌入式常用固定宽度类型 |\n| `bugprone-infinite-loop` | 检测死循环 | 高: RTOS 任务中死循环影响看门狗 |\n| `bugprone-sizeof-expression` | `sizeof(ptr)` vs `sizeof(*ptr)` | 高: DMA 缓冲区大小计算 |\n| `bugprone-signal-handler` | signal handler 中调用非异步安全函数 | 高: ARM-Linux 信号处理 |\n| `bugprone-misplaced-widening-cast` | 宽化转换位置错误 | 高: 32-bit ARM 上整数溢出 |\n\n#### concurrency 系列 (并发安全)\n\n| check | 说明 | 嵌入式价值 |\n|-------|------|-----------|\n| `concurrency-mt-unsafe` | 检测多线程不安全函数 (strtok, rand, localtime) | 高: 嵌入式多线程/中断环境 |\n\n这个 check 在原始教程中缺失，但对嵌入式极其重要。`strtok`、`rand`、`asctime` 等函数使用静态内部缓冲区，在多线程环境中会产生数据竞争。\n\n#### performance 系列\n\n| check | 说明 | 嵌入式价值 |\n|-------|------|-----------|\n| `performance-move-const-arg` | 对 trivially-copyable 类型使用 std::move 无效 | 高: 避免误导性代码 |\n| `performance-unnecessary-value-param` | 大对象按值传参应改为 const& | 高: 栈空间有限 |\n| `performance-noexcept-move-constructor` | 移动构造函数缺少 noexcept | 高: 影响 std::vector 扩容策略 |\n| `performance-trivially-destructible` | 有 trivial 析构但未利用 | 中: 影响 memcpy 优化路径 |\n\n#### modernize 系列 (针对 C++17 精选)\n\n```\nmodernize-use-structured-binding   # auto [a, b] = pair (C++17)\nmodernize-use-nodiscard            # [[nodiscard]] 标注返回值必须检查\nmodernize-use-default-member-init  # int x{0} 替代构造函数初始化列表\n```\n\n注意: `modernize-use-trailing-return-type` (建议 `auto f() -> int`) 在嵌入式团队中争议较大，建议不启用。\n\n---\n\n## 4. CMake 集成\n\n### 4.1 CMAKE_CXX_CLANG_TIDY (推荐)\n\nCMake 3.6+ 原生支持将 clang-tidy 嵌入编译过程:\n\n```cmake\ncmake_minimum_required(VERSION 3.14)\nproject(MyEmbeddedProject LANGUAGES CXX)\n\nset(CMAKE_CXX_STANDARD 17)\nset(CMAKE_EXPORT_COMPILE_COMMANDS ON)\n\n# 可选: 只在 Debug 构建或指定选项时启用\noption(ENABLE_CLANG_TIDY \"Enable clang-tidy static analysis\" OFF)\n\nif(ENABLE_CLANG_TIDY)\n  find_program(CLANG_TIDY_EXE NAMES clang-tidy-18 clang-tidy)\n  if(CLANG_TIDY_EXE)\n    # 使用项目根目录的 .clang-tidy 配置\n    set(CMAKE_CXX_CLANG_TIDY\n      \"${CLANG_TIDY_EXE}\"\n      \"--config-file=${CMAKE_SOURCE_DIR}/.clang-tidy\"\n    )\n    message(STATUS \"clang-tidy enabled: ${CLANG_TIDY_EXE}\")\n  else()\n    message(WARNING \"clang-tidy not found, static analysis disabled\")\n  endif()\nendif()\n\n# 库目标\nadd_library(mylib INTERFACE)\ntarget_include_directories(mylib INTERFACE include/)\n```\n\n使用:\n\n```bash\n# 普通构建 (无 clang-tidy)\ncmake -B build && cmake --build build\n\n# 启用 clang-tidy 的构建 (每个源文件编译时自动检查)\ncmake -B build -DENABLE_CLANG_TIDY=ON && cmake --build build\n```\n\n**优势**: 每个 `.cpp` 文件编译时自动运行 clang-tidy，增量编译只检查修改的文件。无需手动指定文件列表。\n\n**注意**: `CMAKE_CXX_CLANG_TIDY` 只在 **编译源文件时** 触发。header-only 库如果没有 `.cpp` 文件，需要通过测试文件间接触发检查。\n\n### 4.2 自定义 target (适合 CI)\n\n```cmake\n# 查找所有项目源文件 (排除第三方)\nfile(GLOB_RECURSE PROJECT_SOURCES\n  ${CMAKE_SOURCE_DIR}/src/*.cpp\n  ${CMAKE_SOURCE_DIR}/tests/*.cpp\n  ${CMAKE_SOURCE_DIR}/examples/*.cpp\n)\n\n# 独立的 clang-tidy target\nadd_custom_target(clang-tidy\n  COMMAND ${CLANG_TIDY_EXE}\n    -p ${CMAKE_BINARY_DIR}\n    --config-file=${CMAKE_SOURCE_DIR}/.clang-tidy\n    ${PROJECT_SOURCES}\n  COMMENT \"Running clang-tidy on project sources\"\n  VERBATIM\n)\n```\n\n```bash\ncmake --build build --target clang-tidy\n```\n\n---\n\n## 5. 并行执行: run-clang-tidy 与 GNU parallel\n\n### 5.1 run-clang-tidy (LLVM 官方)\n\nLLVM 提供的 `run-clang-tidy` 脚本内置并行支持:\n\n```bash\n# -j: 并行线程数 (默认 CPU 核数)\n# -p: compile_commands.json 目录\n# -config-file: 配置文件路径\nrun-clang-tidy-18 -j$(nproc) -p build -config-file=.clang-tidy\n```\n\n这是最简单的并行方案，但输出格式不易定制。\n\n### 5.2 GNU parallel + 过滤脚本\n\n原始教程提供了 GNU parallel 方案。以下是优化后的版本:\n\n```bash\n#!/bin/bash\nset -euo pipefail\n\nSOURCE_DIR=\"${1:?Usage: $0 <source_dir> [build_dir]}\"\nBUILD_DIR=\"${2:-build}\"\n\n# 验证\n[[ -d \"$SOURCE_DIR\" ]] || { echo \"Error: $SOURCE_DIR not found\"; exit 1; }\n[[ -f \"$BUILD_DIR/compile_commands.json\" ]] || {\n  echo \"Error: compile_commands.json not found in $BUILD_DIR\"\n  echo \"Run: cmake -B $BUILD_DIR -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\"\n  exit 1\n}\n\nCLANG_TIDY=\"clang-tidy-18\"\nCONFIG_FILE=\"$(pwd)/.clang-tidy\"\nFAIL_DIR=$(mktemp -d)\ntrap \"rm -rf $FAIL_DIR\" EXIT\n\n# 过滤函数: 去除系统头文件和无用警告\nfilter_output() {\n  awk '\n    /^[0-9]+ warnings? generated/ { next }\n    /^Suppressed [0-9]+ warnings/ { next }\n    /^Use -header-filter=/ { next }\n    /^Use -system-headers/ { next }\n    { print }\n  '\n}\nexport -f filter_output\n\n# 查找源文件 (排除第三方)\nfind \"$SOURCE_DIR\" -type f \\( -name '*.cpp' -o -name '*.cc' \\) \\\n  ! -path '*/third_party/*' ! -path '*/_deps/*' \\\n  | parallel -j\"$(nproc)\" --halt soon,fail=1 --linebuffer \\\n    \"$CLANG_TIDY {} -p '$BUILD_DIR' --config-file='$CONFIG_FILE' \\\n     --warnings-as-errors='bugprone-use-after-move,bugprone-dangling-handle' \\\n     2>&1 | filter_output \\\n     || touch '$FAIL_DIR/failed_{#}'\"\n\n# 检查结果\nif compgen -G \"$FAIL_DIR/failed_*\" > /dev/null; then\n  echo \"clang-tidy detected issues.\"\n  exit 1\nfi\necho \"clang-tidy: all checks passed.\"\n```\n\n改进点:\n\n| 原始版本 | 优化版本 |\n|---------|---------|\n| `set -e` | `set -euo pipefail` (更严格的错误处理) |\n| 手动指定 `-j4` | `-j$(nproc)` (自动匹配核数) |\n| 失败文件留在 build 目录 | `mktemp -d` + `trap` 自动清理 |\n| 无文件排除 | `! -path '*/third_party/*'` 排除第三方 |\n| `--no-notice` (已废弃) | 移除 |\n| 无 `--halt` | `--halt soon,fail=1` 首个错误后尽快停止 |\n\n---\n\n## 6. NOLINT: 精确抑制误报\n\n### 6.1 行级抑制\n\n```cpp\n// 抑制单行的特定 check\nauto* raw = reinterpret_cast<uint8_t*>(buffer);  // NOLINT(cppcoreguidelines-pro-type-reinterpret-cast)\n\n// 抑制单行所有 check (谨慎使用)\nvoid* ctx = static_cast<void*>(this);  // NOLINT\n```\n\n### 6.2 下一行抑制\n\n```cpp\n// NOLINTNEXTLINE(bugprone-narrowing-conversions)\nuint16_t len = static_cast<uint16_t>(total_size);\n```\n\n### 6.3 区间抑制\n\n```cpp\n// NOLINTBEGIN(cppcoreguidelines-pro-type-reinterpret-cast)\nauto* hdr = reinterpret_cast<FrameHeader*>(buf);\nauto* payload = reinterpret_cast<uint8_t*>(buf + sizeof(FrameHeader));\nauto* crc = reinterpret_cast<uint16_t*>(buf + total - 2);\n// NOLINTEND(cppcoreguidelines-pro-type-reinterpret-cast)\n```\n\n### 6.4 嵌入式常见的合理抑制场景\n\n```cpp\n// 1. 硬件寄存器地址映射 (必须 reinterpret_cast)\nauto* gpio = reinterpret_cast<volatile GpioRegs*>(0x40020000);  // NOLINT(cppcoreguidelines-pro-type-reinterpret-cast,performance-no-int-to-ptr)\n\n// 2. placement new (不是堆分配)\n::new (&storage_) T(std::forward<Args>(args)...);  // NOLINT(cppcoreguidelines-owning-memory)\n\n// 3. POSIX 回调 void* context (C 接口兼容)\nauto* self = static_cast<Pipeline*>(ctx);  // NOLINT(cppcoreguidelines-pro-type-static-cast-downcast)\n\n// 4. 位操作 (有意的窄化)\n// NOLINTNEXTLINE(bugprone-narrowing-conversions)\nuint8_t crc_lo = static_cast<uint8_t>(crc16 & 0xFF);\n```\n\n---\n\n## 7. GitHub Actions CI 集成\n\n```yaml\nname: Static Analysis\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  clang-tidy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Install LLVM 18\n        run: |\n          wget https://apt.llvm.org/llvm.sh\n          chmod +x llvm.sh\n          sudo ./llvm.sh 18\n          sudo apt-get install -y clang-tidy-18\n\n      - name: Generate compile_commands.json\n        run: cmake -B build -DCMAKE_EXPORT_COMPILE_COMMANDS=ON\n\n      - name: Run clang-tidy\n        run: |\n          run-clang-tidy-18 -j$(nproc) -p build \\\n            -config-file=.clang-tidy \\\n            'tests/.*\\.cpp' 'examples/.*\\.cpp'\n\n  clang-format:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Check formatting\n        run: |\n          find include/ tests/ examples/ -name '*.hpp' -o -name '*.cpp' \\\n            | xargs clang-format-18 --dry-run --Werror\n\n  cpplint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install cpplint\n        run: pip install cpplint\n      - name: Run cpplint\n        run: |\n          cpplint --recursive --quiet \\\n            --filter=-legal/copyright,-build/header_guard \\\n            include/ tests/\n```\n\n三层质量门禁:\n1. **clang-format**: 格式一致性 (词法级)\n2. **cpplint**: 命名规范、头文件规则 (正则级)\n3. **clang-tidy**: bug 检测、性能分析、现代化建议 (AST 级)\n\n---\n\n## 8. check 分类速查表\n\n### 8.1 嵌入式必选 (建议所有项目启用)\n\n| 分类 | check | 说明 |\n|------|-------|------|\n| 安全 | `bugprone-use-after-move` | 移动后使用 |\n| 安全 | `bugprone-dangling-handle` | 悬挂引用/指针 |\n| 安全 | `bugprone-sizeof-expression` | sizeof 误用 |\n| 安全 | `bugprone-signal-handler` | 信号处理安全 |\n| 安全 | `concurrency-mt-unsafe` | 多线程不安全函数 |\n| 类型 | `bugprone-narrowing-conversions` | 窄化转换 |\n| 类型 | `cppcoreguidelines-pro-type-cstyle-cast` | C 风格转换 |\n| 内存 | `cppcoreguidelines-no-malloc` | 禁止裸 malloc |\n| 内存 | `bugprone-infinite-loop` | 死循环 (看门狗友好) |\n| 分析 | `clang-analyzer-core.*` | 空指针、内存泄漏 |\n| 分析 | `clang-analyzer-cplusplus.*` | 对象生命周期 |\n\n### 8.2 C++17 现代化 (建议新项目启用)\n\n| check | 说明 | 自动修复 |\n|-------|------|---------|\n| `modernize-use-nullptr` | NULL/0 → nullptr | Y |\n| `modernize-use-override` | 添加 override | Y |\n| `modernize-use-equals-default` | 默认构造 = default | Y |\n| `modernize-use-emplace` | push_back → emplace_back | Y |\n| `modernize-use-nodiscard` | 添加 [[nodiscard]] | Y |\n| `modernize-use-using` | typedef → using | Y |\n| `modernize-deprecated-headers` | stdio.h → cstdio | Y |\n| `modernize-loop-convert` | C 风格循环 → range-for | Y |\n| `modernize-use-default-member-init` | 类内默认初始化 | Y |\n\n### 8.3 争议较大 / 建议不启用\n\n| check | 原因 |\n|-------|------|\n| `modernize-use-trailing-return-type` | `auto f() -> int` 团队接受度低 |\n| `readability-magic-numbers` | 嵌入式中寄存器地址和协议常量太多 |\n| `cppcoreguidelines-avoid-do-while` | do-while 在协议解析中有合理用途 |\n| `cppcoreguidelines-pro-bounds-pointer-arithmetic` | 嵌入式必须操作 buffer 指针 |\n| `bugprone-easily-swappable-parameters` | 误报率极高 |\n| `readability-identifier-length` | 循环变量 `i`、`j` 是合理的 |\n\n---\n\n## 9. 与 cpplint 的分工\n\n两个工具有部分重叠，但定位不同:\n\n| 检查项 | cpplint | clang-tidy | 推荐 |\n|--------|---------|-----------|------|\n| 命名规范 | `readability/naming` | `readability-identifier-naming` | 二选一 |\n| include 排序 | `build/include_order` | (无) | cpplint |\n| 头文件 guard | `build/header_guard` | (无) | cpplint |\n| C 风格转换 | `readability/casting` | `google-readability-casting` | clang-tidy (更精确) |\n| 窄化转换 | (无) | `bugprone-narrowing-conversions` | clang-tidy |\n| 空指针检测 | (无) | `clang-analyzer-core.NullDereference` | clang-tidy |\n| use-after-move | (无) | `bugprone-use-after-move` | clang-tidy |\n\n推荐策略: cpplint 负责风格 (include、命名、注释)，clang-tidy 负责语义 (bug、性能、现代化)。两者在 CI 中并行运行。\n\n---\n\n## 10. 总结\n\n| 步骤 | 内容 |\n|------|------|\n| 1. 配置 | `.clang-tidy` 精选 check，禁用异常相关，配置 HeaderFilterRegex |\n| 2. 本地 | `cmake -DENABLE_CLANG_TIDY=ON` 编译时自动检查 |\n| 3. 批量 | `run-clang-tidy-18 -j$(nproc)` 全量扫描 |\n| 4. CI | GitHub Actions 三层门禁 (format + cpllint + tidy) |\n| 5. 抑制 | `NOLINT(check-name)` 精确标注，禁止裸 NOLINT |\n\n---\n\n## 参考\n\n- [Clang-Tidy 官方文档](https://clang.llvm.org/extra/clang-tidy/)\n- [Clang-Tidy Checks 完整列表](https://clang.llvm.org/extra/clang-tidy/checks/list.html)\n- [Clang-Tidy 配置与 CMake 集成](https://blog.csdn.net/stallion5632/article/details/139545885) -- 原始教程 1\n- [多进程 shell 脚本加速 clang-tidy](https://blog.csdn.net/stallion5632/article/details/140122323) -- 原始教程 2\n- [CMake CMAKE_CXX_CLANG_TIDY 文档](https://cmake.org/cmake/help/latest/variable/CMAKE_LANG_CLANG_TIDY.html)\n- [LLVM Discussion Forums](https://forums.llvm.org/)\n- [C++ Core Guidelines](https://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines)\n- [CERT C++ Coding Standard](https://wiki.sei.cmu.edu/confluence/display/cplusplus)\n",
      "ctime": "1771552633",
      "mtime": "1771552633",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/cpp14_pluggable_log_library_design.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469702190",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "轻量级 C++14 日志库设计: 可插拔后端与零依赖架构",
      "brief_content": "在嵌入式 ARM Linux 项目中，基于 Boost.Log 的日志方案因临时对象创建、std::regex 解析和动态链接依赖而成为性能瓶颈。本文以 loghelper 的重构为例，将其改造为 C",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 在嵌入式 ARM Linux 项目中，日志系统是最基础的基础设施之一。然而许多项目仍在使用基于 Boost.Log 的重量级方案，每条日志创建临时对象、使用 std::regex 解析占位符、依赖动态链接库。本文以一个真实项目 loghelper 的重构为例，详细阐述如何将其改造为 C++14 header-only 架构，支持 spdlog/zlog/fallback 三后端编译期切换，实现 10-100x 的性能提升。\n\n## 1. 旧版架构的问题分析\n\n### 1.1 临时对象模式的性能陷阱\n\n旧版 loghelper 采用经典的\"构造-析构\"日志模式:\n\n```cpp\n// 旧版: 每次 LOG 宏创建临时 LogHelper 对象\n#define LOG(X) RockLog::LogHelper(X, __FILENAME__, __FUNCTION__, __LINE__)\n\n// 使用时\nLOG(kInfo) << \"value=\" << 42;\n```\n\n这个看似优雅的设计隐藏了严重的性能问题:\n\n1. 每次调用创建 `LogHelper` 临时对象，构造函数中检查 `isInit()` 并可能触发初始化\n2. `operator<<` 将数据写入 `std::stringstream _ss` 成员 -- 堆分配\n3. 析构函数中执行实际的日志输出 -- 又一次 `std::ostringstream` 格式化\n4. 成员变量包含 `std::string _funcName`, `std::string _fileName`, `std::string _tag` -- 三次堆分配\n\n单条日志的堆分配次数: 至少 4 次 (stringstream + 3 个 string)。\n\n### 1.2 std::regex 的灾难性开销\n\n旧版的 `AMS_*` 宏使用 `std::regex` 分割 `{}` 占位符:\n\n```cpp\n// 旧版: 每条日志都编译正则表达式\nauto vf = split(format, std::string(\"\\\\{\\\\}\"));\n// split 内部: std::basic_regex<E> re{delim};\n```\n\n`std::regex` 的构造开销在微秒级别，对于一个期望纳秒级延迟的日志系统来说，这是不可接受的。\n\n### 1.3 头文件中的全局状态\n\n```cpp\n// 旧版 logger.hpp -- ODR 违规\nnamespace logger {\n    std::mutex mtx;  // 全局 mutex 在头文件中定义\n    thread_local std::string loggerTag;\n    static std::map<std::string, ...> channel_map;\n}\n```\n\n这些定义在头文件中的全局变量，如果被多个翻译单元包含，会导致 ODR (One Definition Rule) 违规，在链接时产生未定义行为。\n\n### 1.4 量化: 旧版单条日志开销\n\n| 操作 | 预估耗时 |\n|------|---------|\n| LogHelper 构造 (3x string copy) | ~200 ns |\n| stringstream 格式化 | ~500 ns |\n| Boost.Log 分发 (mutex + channel lookup) | ~2,000 ns |\n| AMS_* regex 分割 | ~5,000 ns |\n| 总计 | ~5,000-8,000 ns |\n\n## 2. 新架构设计\n\n### 2.1 设计目标\n\n- C++14 标准，GCC/Clang 兼容\n- Header-only，单文件 `loghelper.hpp`\n- 零临时对象，零堆分配 (热路径)\n- 编译期后端切换，编译期日志级别过滤\n- 保持 API 向后兼容\n\n### 2.2 架构总览\n\n```\nloghelper.hpp\n├── LogConfig          -- 配置 (char 数组, 非 std::string)\n├── detail::ParseIniFile -- 内置 INI 解析器 (~60 行)\n├── fallback::Backend  -- 零依赖 stderr 输出\n├── spdlog_backend::Backend -- spdlog 适配\n├── zlog_backend::Backend   -- zlog 适配\n├── LogEngine          -- 统一初始化门面\n├── detail::LogDispatch -- 核心分发 (variadic, printf-style)\n└── 宏层\n    ├── LOG_*          -- 基础日志\n    ├── LOG_TAG_*      -- 带 channel tag\n    ├── LOG_*_IF       -- 条件日志\n    ├── LOG_PERF_*     -- 性能测量\n    └── AMS_*          -- fmt-style (仅 spdlog)\n```\n\n### 2.3 编译期后端选择\n\n```cpp\n// CMake 传入或用户定义\n#define LOGHELPER_BACKEND_SPDLOG   1\n#define LOGHELPER_BACKEND_ZLOG     2\n#define LOGHELPER_BACKEND_FALLBACK 3\n\n#ifndef LOGHELPER_BACKEND\n#define LOGHELPER_BACKEND LOGHELPER_BACKEND_SPDLOG\n#endif\n\n// 类型别名在编译期确定\n#if LOGHELPER_BACKEND == LOGHELPER_BACKEND_SPDLOG\nusing ActiveBackend = spdlog_backend::Backend;\n#elif LOGHELPER_BACKEND == LOGHELPER_BACKEND_ZLOG\nusing ActiveBackend = zlog_backend::Backend;\n#else\nusing ActiveBackend = fallback::Backend;\n#endif\n```\n\n这种模式的优势: 编译器在编译期就确定了具体的后端类型，所有后端方法调用都可以被内联，不存在虚函数开销。\n\n## 3. 关键实现细节\n\n### 3.1 零临时对象的日志分发\n\n新版的核心分发函数使用 C variadic arguments，直接在栈上格式化:\n\n```cpp\ninline void LogDispatch(Level lv, const char* tag, const char* file,\n                        int32_t line, const char* func,\n                        const char* fmt, ...) noexcept {\n  if (!LogEngine::IsInited()) LogEngine::Init();\n\n  va_list args;\n  va_start(args, fmt);\n  // 直接调用后端，后端内部使用栈缓冲区\n  ActiveBackend::Instance().Log(lv, tag, file, line, func, fmt, args);\n  va_end(args);\n}\n```\n\n后端的 `Log()` 方法:\n\n```cpp\nvoid Log(Level lv, const char* tag, const char* file,\n         int32_t line, const char* func,\n         const char* fmt, va_list args) noexcept {\n  if (lv < cfg_.console_level) return;  // 运行时过滤: 1 次比较\n\n  char msg[2048];                        // 栈缓冲区, 零堆分配\n  std::vsnprintf(msg, sizeof(msg), fmt, args);\n  // ... 输出 ...\n}\n```\n\n对比旧版: 零 `new`，零 `std::string`，零 `std::stringstream`。\n\n### 3.2 编译期日志级别过滤\n\n```cpp\n#define LOGHELPER_COMPILE_LEVEL LOGHELPER_LEVEL_INFO\n\n// 低于 INFO 的宏直接展开为空操作\n#if LOGHELPER_COMPILE_LEVEL <= LOGHELPER_LEVEL_DEBUG\n#define LOG_DEBUG(fmt, ...) \\\n  loghelper::detail::LogDispatch(loghelper::kDebug, ...)\n#else\n#define LOG_DEBUG(fmt, ...) ((void)0)  // 编译器完全消除\n#endif\n```\n\n当 `LOGHELPER_COMPILE_LEVEL` 设为 `LOGHELPER_LEVEL_INFO` 时，所有 `LOG_TRACE` 和 `LOG_DEBUG` 调用在预处理阶段就被替换为 `((void)0)`，编译器会完全消除这些代码，包括参数求值。这是真正的零开销。\n\n### 3.3 syslog.h 宏名冲突处理\n\nspdlog 的 syslog_sink 会引入 `<sys/syslog.h>`，其中定义了 `LOG_DEBUG`、`LOG_INFO` 等宏，与我们的日志宏冲突。解决方案:\n\n```cpp\n#include \"spdlog/sinks/syslog_sink.h\"\n// 立即 undef 系统宏\n#ifdef LOG_DEBUG\n#undef LOG_DEBUG\n#endif\n#ifdef LOG_INFO\n#undef LOG_INFO\n#endif\n```\n\n这个处理必须在 include spdlog 之后、定义我们的宏之前完成。\n\n### 3.4 内置 INI 解析器\n\n旧版依赖 `boost::property_tree::ini_parser`，新版内置了一个约 60 行的轻量解析器:\n\n```cpp\ninline bool ParseIniFile(const char* path, LogConfig& cfg) noexcept {\n  std::FILE* f = std::fopen(path, \"r\");\n  if (!f) return false;\n\n  char line[512];\n  while (std::fgets(line, static_cast<int>(sizeof(line)), f)) {\n    TrimInPlace(line);\n    if (line[0] == '\\0' || line[0] == '#' || line[0] == ';' ||\n        line[0] == '[') continue;\n    char* eq = std::strchr(line, '=');\n    if (!eq) continue;\n    *eq = '\\0';\n    // ... key-value 匹配 ...\n  }\n  std::fclose(f);\n  return true;\n}\n```\n\n特点:\n- 纯 C I/O (`fopen/fgets/fclose`)，无 `std::ifstream`\n- 支持 `#` 和 `;` 注释，支持 section header `[...]`\n- 同时兼容新旧配置键名 (`ConsoleLevel` / `ConsoleLogLevel`)\n\n### 3.5 LogConfig 的设计选择\n\n```cpp\nstruct LogConfig {\n  Level   console_level    = kInfo;\n  Level   file_level       = kDebug;\n  int32_t file_max_size_mb = 100;\n  char    file_path[256]   = \"logs/app\";   // char 数组, 非 std::string\n  char    syslog_addr[64]  = \"\";\n  bool    enable_console   = true;\n  bool    enable_file      = true;\n  bool    enable_syslog    = false;\n};\n```\n\n使用 `char[]` 而非 `std::string` 的原因:\n- 避免堆分配\n- 可以安全地跨线程传递 (trivially copyable)\n- 配置路径长度有明确上限 (256 字节足够)\n\n## 4. 后端对比\n\n### 4.1 三后端特性矩阵\n\n| 特性 | spdlog | zlog | fallback |\n|------|--------|------|----------|\n| 语言 | C++11 | Pure C | C++14 |\n| 获取方式 | FetchContent | 系统安装 | 内置 |\n| 文件轮转 | 内置 | 内置 | 无 |\n| Syslog | 内置 | 内置 | 无 |\n| 彩色输出 | 内置 | 无 | 无 |\n| fmt 格式化 | `{}` 占位符 | printf | printf |\n| 外部依赖 | 0 (bundled fmt) | libzlog.so | 0 |\n\n### 4.2 性能基准 (x86_64, GCC 13.3, -O3)\n\n| 测试项 | fallback | spdlog |\n|--------|----------|--------|\n| 单线程 avg | 38 ns | 315 ns |\n| 单线程吞吐 | 26.3M msg/s | 3.2M msg/s |\n| 4 线程吞吐 | 200M msg/s | 7.1M msg/s |\n| 带 Tag 日志 | 39 ns | 296 ns |\n\nfallback 后端在 sink 关闭时仅执行一次级别比较即 return，因此延迟极低。spdlog 后端即使 sink 级别为 OFF，仍会执行 `vsnprintf` 格式化，因此基础开销约 250-315ns。\n\n### 4.3 选型建议\n\n- 通用 Linux 应用: spdlog (文件轮转 + syslog + 彩色输出)\n- 嵌入式极简场景: fallback (零依赖，仅 stderr)\n- 高性能 C 项目: zlog (纯 C，配置文件驱动)\n- 热路径日志: 编译期过滤 (`LOGHELPER_COMPILE_LEVEL`)\n\n## 5. CMake 集成\n\n```cmake\n# spdlog 后端 (默认, FetchContent 自动获取)\ncmake .. -DLOGHELPER_BACKEND=spdlog\n\n# fallback 后端 (零依赖)\ncmake .. -DLOGHELPER_BACKEND=fallback\n\n# zlog 后端 (需系统安装 libzlog)\ncmake .. -DLOGHELPER_BACKEND=zlog\n```\n\nCMake 通过 `target_compile_definitions` 传递后端 ID:\n\n```cmake\nif(LOGHELPER_BACKEND STREQUAL \"spdlog\")\n  set(LOGHELPER_BACKEND_ID 1)\nelseif(LOGHELPER_BACKEND STREQUAL \"zlog\")\n  set(LOGHELPER_BACKEND_ID 2)\nelse()\n  set(LOGHELPER_BACKEND_ID 3)\nendif()\n\ntarget_compile_definitions(loghelper INTERFACE\n  LOGHELPER_BACKEND=${LOGHELPER_BACKEND_ID}\n)\n```\n\n## 6. 与旧版对比总结\n\n| 维度 | 旧版 (Boost.Log) | 新版 (loghelper.hpp) |\n|------|-----------------|---------------------|\n| 形式 | 动态库 (.so) | Header-only |\n| 依赖 | Boost.Log + Filesystem + PropertyTree | 可选 spdlog / 零依赖 |\n| 标准 | C++11 (实际用了 C++14 特性) | C++14 |\n| 每条日志堆分配 | 4+ 次 | 0 次 |\n| 单条延迟 | ~5,000-8,000 ns | 38-315 ns |\n| 编译期过滤 | 无 | 支持 (零开销) |\n| 线程安全 | 全局 mutex + TLS | 后端内部处理 |\n| 配置解析 | Boost.PropertyTree | 内置 INI (~60 行) |\n| AMS 占位符 | std::regex | fmt 库 (spdlog) |\n| 性能提升 | - | 10-100x |\n\n## 7. 经验总结\n\n1. 日志系统的热路径禁止堆分配 -- `vsnprintf` + 栈缓冲区是最优解\n2. 编译期过滤优于运行时过滤 -- 宏展开为 `((void)0)` 是真正的零开销\n3. 后端可插拔设计用编译期类型别名实现 -- 比虚函数 + 工厂模式更高效\n4. `std::regex` 不适合任何性能敏感场景 -- 构造开销在微秒级\n5. 头文件中不要定义全局变量 -- 使用 `inline` 函数内的 `static` 局部变量\n6. INI 解析不需要重量级库 -- 60 行 C 代码足够\n\n项目地址:\n- Gitee: https://gitee.com/liudegui/loghelper\n- GitHub: https://github.com/DeguiLiu/loghelper\n",
      "ctime": "1771552637",
      "mtime": "1771552637",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/cpp17_claims_in_newosp.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651636270",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "newosp 源码中的 C++17 实践: 8 项能力的工程落地",
      "brief_content": "从 newosp v0.4.3 (43 headers, 1153 tests) 源码中提炼 C++17 能力的实际工程运用。每项附具体代码位置、设计决策和 C 语言对比，展示工业嵌入式库如何将语言特",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 源码仓库: [newosp](https://github.com/DeguiLiu/newosp) | 本文代码引用基于 newosp v0.4.3 (43 headers, 1153 tests)\n\n> 筛选标准: 只保留 C11 在语言层面**无法实现**的能力。\n> 边界检查、SBO 回调、ARM 内存序、cache line 对齐、`-fno-exceptions` 等 C 均可做到，已移除。\n\n> 姊妹篇: [C11 做不到的事: 10 项 C++17 语言级不可替代能力]({{< ref \"cpp17_what_c_cannot_do\" >}}) -- 语言层面的系统性对比与完整代码示例。\n\n---\n\n## 1. 编译期类型成员校验 -- bus.hpp\n\nC 的 `void*` 不携带类型信息，编译器无法验证传入类型是否属于合法集合。\n\n`include/osp/bus.hpp:376-385`:\n\n```cpp\ntemplate <typename T, typename... Types>\nstruct VariantIndex<T, std::variant<Types...>> {\n  static constexpr size_t value =\n      detail::VariantIndexImpl<T, 0, std::variant<Types...>>::value;\n  static_assert(value != static_cast<size_t>(-1),\n                \"Type not found in PayloadVariant\");\n};\n```\n\n`include/osp/bus.hpp:500-505` -- `Subscribe` 调用点验证:\n\n```cpp\ntemplate <typename T, typename Func>\nSubscriptionHandle Subscribe(Func&& func) noexcept {\n  constexpr size_t type_idx = VariantIndex<T, PayloadVariant>::value;\n  static_assert(type_idx < OSP_BUS_MAX_MESSAGE_TYPES,\n                \"Type index exceeds OSP_BUS_MAX_MESSAGE_TYPES\");\n```\n\n**工程决策**: `VariantIndex` 在模板实例化时递归展开，将\"类型是否在合法集合中\"从运行时 tag 校验提升为编译期硬错误。C 的 `subscribe(bus, GPS_TAG, handler)` 中 tag 写错不会产生编译错误。\n\n---\n\n## 2. 穷举式类型分发 -- bus.hpp\n\nC 的 `switch (msg->tag)` 缺少 `case` 只产生 `-Wswitch` 警告。\n\n`include/osp/bus.hpp:84-90`:\n\n```cpp\ntemplate <class... Ts>\nstruct overloaded : Ts... {\n  using Ts::operator()...;\n};\ntemplate <class... Ts>\noverloaded(Ts...) -> overloaded<Ts...>;\n```\n\n**工程决策**: `overloaded` + `std::visit` 的组合使新增消息类型时，所有未更新的处理点编译失败而非运行时丢消息。对于工业嵌入式系统，\"编译不过\"远好于\"部署后丢数据\"。\n\n---\n\n## 3. 强类型别名 -- vocabulary.hpp\n\nC 的 `typedef uint32_t TimerId` 和 `typedef uint32_t NodeId` 是同一类型。\n\n`include/osp/vocabulary.hpp:739-763`:\n\n```cpp\ntemplate <typename T, typename Tag>\nclass NewType final {\n public:\n  constexpr explicit NewType(T val) noexcept : val_(val) {}\n  constexpr T value() const noexcept { return val_; }\n  constexpr bool operator==(NewType rhs) const noexcept { return val_ == rhs.val_; }\n  constexpr bool operator!=(NewType rhs) const noexcept { return val_ != rhs.val_; }\n private:\n  T val_;\n};\n\nusing TimerTaskId = NewType<uint32_t, TimerTaskIdTag>;\nusing SessionId   = NewType<uint32_t, SessionIdTag>;\n```\n\n**工程决策**: `TimerTaskId id; SessionId sid = id;` 编译失败。在 newosp 中，节点 ID、定时器 ID、会话 ID 均使用 `NewType` 包装。零运行时开销 -- `sizeof(NewType<uint32_t, Tag>) == sizeof(uint32_t)`，编译器直接传寄存器。\n\n---\n\n## 4. if constexpr -- spsc_ringbuffer.hpp / config.hpp / fault_collector.hpp\n\nC 的 `#ifdef` 只能基于宏开关，无法检测类型属性。\n\n**(a) `include/osp/spsc_ringbuffer.hpp:144-157`** -- 根据 T 是否 trivially copyable 选择路径:\n\n```cpp\nif constexpr (kTriviallyCopyable) {\n  std::memcpy(&data_buff_[head_offset], buf + written, first_part * sizeof(T));\n} else {\n  for (size_t i = 0; i < to_write; ++i) {\n    data_buff_[(head_offset + i) & kMask] = buf[written + i];\n  }\n}\n```\n\n同一文件 184 行 (Pop)、210 行 (PopBatch) 使用相同模式。\n\n**(b) `include/osp/config.hpp:534-560`** -- 编译期递归展开多后端分派:\n\n```cpp\ntemplate <typename First, typename... Rest>\nexpected<void, ConfigError> DispatchFile(const char* path, ConfigFormat format) {\n  if (First::kFormat == format)\n    return ConfigParser<First>::ParseFile(*this, path);\n  if constexpr (sizeof...(Rest) > 0)\n    return DispatchFile<Rest...>(path, format);\n  return expected<void, ConfigError>::error(ConfigError::kFormatNotSupported);\n}\n```\n\n**(c) `include/osp/fault_collector.hpp:580`** -- 根据回调返回类型选择控制流:\n\n```cpp\nif constexpr (std::is_same_v<decltype(fn(recent_ring_[idx])), bool>) {\n  if (!fn(recent_ring_[idx])) { break; }\n} else {\n  fn(recent_ring_[idx]);\n}\n```\n\n**工程决策**: 三处 `if constexpr` 的共同特征 -- 在同一个函数模板中，根据类型属性生成不同代码路径，编译后只保留命中分支。C 的 `#ifdef` 无法区分 `SensorData` 是否 trivially copyable，必须由程序员手动选择拷贝方式。\n\n---\n\n## 5. constexpr 函数 -- bus.hpp / app.hpp\n\nC 的 `const` 不是编译期常量合同。C 没有\"函数必须在编译期求值\"的语言机制。\n\n`include/osp/bus.hpp:70-78`:\n\n```cpp\nconstexpr uint32_t Fnv1a32(const char* str) noexcept {\n  if (str == nullptr) return 0;\n  uint32_t hash = 2166136261u;\n  while (*str) {\n    hash ^= static_cast<uint32_t>(*str++);\n    hash *= 16777619u;\n  }\n  return hash;\n}\n```\n\n`include/osp/app.hpp:80`:\n\n```cpp\nconstexpr uint32_t MakeIID(uint16_t app_id, uint16_t ins_id) noexcept {\n  return (static_cast<uint32_t>(app_id) << 16) | static_cast<uint32_t>(ins_id);\n}\n```\n\n**工程决策**: `Fnv1a32` 用于 topic 路由，编译期将字符串 `\"sensor/imu\"` 折叠为立即数，运行时零开销。`MakeIID` 将 app_id/ins_id 编码为 32 位实例标识符，同样在编译期完成。C 可以用宏做 `MAKE_IID`，但无法在宏中写 while 循环实现哈希函数。\n\n---\n\n## 6. 模板实例化 -- spsc_ringbuffer.hpp / bus.hpp\n\nC 的 `void* + size_t` 传参让编译器丢失常量信息，`index % depth` 变成运行时除法。\n\n`include/osp/spsc_ringbuffer.hpp:74-86`:\n\n```cpp\ntemplate <typename T, size_t BufferSize = 16, bool FakeTSO = false, typename IndexT = size_t>\nclass SpscRingbuffer {\n  static_assert(BufferSize != 0, \"Buffer size cannot be zero.\");\n  static_assert((BufferSize & (BufferSize - 1)) == 0, \"Buffer size must be a power of 2.\");\n  static_assert(sizeof(IndexT) <= sizeof(size_t), \"Index type size must not exceed size_t.\");\n  static_assert(std::is_unsigned<IndexT>::value, \"Index type must be unsigned.\");\n```\n\n`include/osp/bus.hpp:406-420`:\n\n```cpp\nstatic constexpr uint32_t kQueueDepth = static_cast<uint32_t>(OSP_BUS_QUEUE_DEPTH);\nstatic constexpr uint32_t kBufferMask = kQueueDepth - 1;\n\nstatic_assert((kQueueDepth & (kQueueDepth - 1)) == 0,\n              \"Queue depth must be power of 2\");\n```\n\n**工程决策**: `SpscRingbuffer<SensorData, 256>` 和 `SpscRingbuffer<MotorCmd, 64>` 是不同类型，编译器为每个实例化独立优化 -- `& (256-1)` 编译为单条 AND 立即数指令。C11 的 `_Static_assert` 只能断言整型常量表达式，无法断言类型属性 (`is_unsigned`、`is_trivially_copyable`)。\n\n---\n\n## 7. RAII -- vocabulary.hpp / node.hpp / shm_transport.hpp\n\n标准 C 没有析构函数。`goto cleanup` 是手动操作，漏一条路径就泄漏。\n\n`include/osp/vocabulary.hpp:774-801`:\n\n```cpp\nclass ScopeGuard final {\n public:\n  explicit ScopeGuard(FixedFunction<void()> cleanup) noexcept\n      : cleanup_(static_cast<FixedFunction<void()>&&>(cleanup)), active_(true) {}\n  ~ScopeGuard() {\n    if (active_ && cleanup_) { cleanup_(); }\n  }\n  void release() noexcept { active_ = false; }\n};\n```\n\n`include/osp/node.hpp:177` -- Node 析构自动清理全部订阅:\n\n```cpp\n~Node() noexcept { Stop(); }\n```\n\n`include/osp/shm_transport.hpp:98` -- SharedMemorySegment 析构自动 `munmap` + `shm_unlink`。\n\n**工程决策**: newosp 中 RAII 的三层应用 -- (1) `ScopeGuard` 用于临时资源的确定性清理; (2) `Node` 析构自动取消所有订阅，防止悬空回调; (3) `SharedMemorySegment` 析构自动释放共享内存。编译器保证 `return`、异常、作用域结束等所有退出路径均调用析构函数。\n\n---\n\n## 8. Fold Expression + CRTP -- worker_pool.hpp / static_node.hpp\n\nC 没有可变参数模板，也缺少零开销的编译期多态机制。\n\n`include/osp/worker_pool.hpp:519-522` -- 参数包自动展开:\n\n```cpp\ntemplate <typename... Types>\nvoid SubscribeAllImpl(std::variant<Types...>* /*tag*/) noexcept {\n  (MaybeSubscribe<Types>(), ...);\n}\n```\n\n`include/osp/static_node.hpp` -- CRTP 零 vtable 编译期多态:\n\n```cpp\ntemplate <typename Derived>\nstruct NodeBase {\n  void Process() {\n    static_cast<Derived*>(this)->DoProcess();  // 编译期解析，可内联\n  }\n};\n// DoProcess() 直接内联到调用点，零间接跳转\n```\n\n**工程决策**: Fold Expression 一行代码为 variant 中每个类型调用 `MaybeSubscribe`，C 需要手动枚举或 X-Macro 生成。CRTP 让 `StaticNode` 的 handler 在编译期绑定，避免 `virtual` 的间接调用开销和 vtable 内存占用 -- 在 ARM Cortex-A 上，消除一次虚函数调用可节省约 10-20 个周期 (cache miss 时更多)。\n\n---\n\n## 总结\n\n| # | 能力 | C 的局限 | newosp 实现位置 |\n|---|------|---------|----------------|\n| 1 | 编译期类型成员校验 | `void*` 无类型信息 | `bus.hpp:376-385` |\n| 2 | 穷举式类型分发 | `switch` 缺 `case` 仅警告 | `bus.hpp:84-90` |\n| 3 | 强类型别名 | `typedef` 是别名非新类型 | `vocabulary.hpp:739-763` |\n| 4 | 基于类型属性的分支消除 | 无 type trait，无 `if constexpr` | `spsc_ringbuffer.hpp:144` |\n| 5 | 保证编译期求值的函数 | `const` 非编译期合同 | `bus.hpp:70-78` |\n| 6 | 参数化专用代码生成 | `void* + size_t` 丢失常量 | `spsc_ringbuffer.hpp:74-86` |\n| 7 | 自动资源清理 | 无析构函数 | `vocabulary.hpp:774-801` |\n| 8 | 参数包展开 + CRTP | 无可变参数模板，函数指针不可内联 | `worker_pool.hpp:519-522` |\n\n这些能力并非孤立使用。以 `AsyncBus` 为例，一次 `Publish` 调用链涉及: 模板实例化生成专用队列代码 (第 6 项) -> `VariantIndex` 编译期校验消息类型 (第 1 项) -> `constexpr` 计算 topic hash (第 5 项) -> `if constexpr` 按类型选择拷贝策略 (第 4 项) -> RAII 保证 envelope 资源自动释放 (第 7 项)。五项能力在同一条热路径上协同工作，形成编译期到运行时的完整安全链。\n",
      "ctime": "1771552640",
      "mtime": "1771552640",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/cyberrt_datavisitor_mccc_rewrite.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357876762",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "基于无锁消息总线的观察者模式: 零堆分配、单线程消费",
      "brief_content": "基于无锁 MPSC 消息总线，实现嵌入式场景下的数据分发架构。提供两种方案: Component 动态订阅版和 StaticComponent 零开销编译期分发版。单文件 ~100 行，零堆分配，单 ",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 数据分发 (一个数据源，多个订阅者) 是嵌入式系统中的常见需求。本文基于无锁 MPSC 消息总线，提供两种实现方案: 支持运行时动态增删订阅者的 Component 版，以及追求零开销的 StaticComponent 编译期分发版。单文件 ~100 行，零堆分配，单 worker 线程。完整代码: [data-visitor-dispatcher](https://gitee.com/liudegui/data-visitor-dispatcher)。\n\n## 1. 数据分发架构\n\n数据分发的核心模型: 数据源 (Receiver) 产生消息，分发器 (Bus) 路由到多个订阅者 (Visitor)，每个订阅者独立处理。\n\n```\nReceiver (数据源)\n    │\n    ▼\nAsyncBus (无锁 MPSC Ring Buffer)\n    │\n    ├──▶ LoggingVisitor   (记录日志)\n    ├──▶ ProcessingVisitor (数据处理)\n    └──▶ ...更多订阅者\n```\n\n核心设计决策:\n\n| 决策 | 方案 | 原因 |\n|------|------|------|\n| 并发同步 | lock-free CAS (MPSC) | 多生产者无锁并发发布，避免 mutex 串行化 |\n| 消息存储 | Ring Buffer 嵌入 | 定长、零堆分配、内置背压 |\n| 线程模型 | 单 worker 线程 | `ProcessBatch()` 一次遍历处理所有消息，线程数 O(1) |\n| 字符串 | `FixedString<N>` 栈缓冲 | 替代 `std::string`，消除热路径堆分配 |\n| 类型路由 | `std::variant` + `Subscribe<T>` | 编译期类型安全，订阅者只收指定类型 |\n| 回调存储 | `FixedFunction` SBO | 替代 `std::function`，零堆分配 |\n| 生命周期 | `weak_ptr` 自动取消订阅 | `shared_ptr` release 即注销，无需手动管理 |\n\n提供两种实现版本:\n\n| 版本 | 订阅方式 | 分发机制 | 适用场景 |\n|------|----------|----------|----------|\n| Component 版 | 运行时动态 | `FixedFunction` SBO 回调 | 需要动态增删订阅者 |\n| StaticComponent 版 | 编译期固定 | CRTP `Handle()` 内联 | 订阅者集合固定，追求零开销 |\n\n## 2. 消息类型定义\n\n```cpp\nstruct SensorData {\n  int32_t id;\n  mccc::FixedString<64> content;  // 64 字节栈上固定缓冲，零堆分配\n\n  SensorData() noexcept : id(0) {}\n  SensorData(int32_t id_, const char* msg) noexcept\n      : id(id_), content(mccc::TruncateToCapacity, msg) {}\n};\n\nusing DemoPayload = std::variant<SensorData>;\nusing DemoBus = mccc::AsyncBus<DemoPayload>;\nusing DemoComponent = mccc::Component<DemoPayload>;\n```\n\n`FixedString<64>` 在栈上预分配 64 字节，超过容量时截断 (`TruncateToCapacity` 策略)，不抛异常，不触发堆分配。\n\n## 3. Component 版: 动态订阅\n\n### 3.1 订阅者定义\n\n```cpp\nclass LoggingVisitor : public DemoComponent {\n public:\n  static std::shared_ptr<LoggingVisitor> Create() noexcept {\n    std::shared_ptr<LoggingVisitor> ptr(new LoggingVisitor());\n    ptr->Init();\n    return ptr;\n  }\n\n private:\n  LoggingVisitor() = default;\n\n  void Init() noexcept {\n    InitializeComponent();\n    SubscribeSimple<SensorData>(\n        [](const SensorData& data, const mccc::MessageHeader& hdr) noexcept {\n          LOG_INFO(\"[LoggingVisitor] msg_id=%lu id=%d content=\\\"%s\\\"\",\n                   hdr.msg_id, data.id, data.content.c_str());\n        });\n  }\n};\n```\n\n`SubscribeSimple<SensorData>` 在编译期绑定消息类型，只接收 `SensorData`。回调存储在 `FixedFunction` SBO 缓冲中，零堆分配。\n\n### 3.2 数据源与消费\n\n```cpp\nclass Receiver {\n public:\n  explicit Receiver(uint32_t sender_id) noexcept : sender_id_(sender_id) {}\n\n  void ReceiveMessage(int32_t id, const char* content) noexcept {\n    SensorData data(id, content);\n    DemoBus::Instance().Publish(std::move(data), sender_id_);\n  }\n\n private:\n  uint32_t sender_id_;\n};\n```\n\n单 worker 线程处理所有消息:\n\n```cpp\nstd::thread worker([&stop_worker]() noexcept {\n  while (!stop_worker.load(std::memory_order_acquire)) {\n    uint32_t processed = DemoBus::Instance().ProcessBatch();\n    if (processed == 0U) {\n      std::this_thread::sleep_for(std::chrono::microseconds(100));\n    }\n  }\n});\n```\n\n### 3.3 动态增删订阅者\n\n```cpp\nauto logger = LoggingVisitor::Create();\nauto processor = ProcessingVisitor::Create();\n\nreceiver.ReceiveMessage(1, \"Hello\");      // 两个 visitor 都收到\nreceiver.ReceiveMessage(2, \"World\");      // 两个 visitor 都收到\n\nlogger.reset();                           // shared_ptr release → 自动取消订阅\n\nreceiver.ReceiveMessage(3, \"After\");      // 只有 processor 收到\n```\n\n`shared_ptr` release 时，Component 内部的 `weak_ptr` 检测到失效，自动跳过该订阅者的回调。\n\n### 3.4 运行输出\n\n```\n=== Receiving message #1 ===\n[LoggingVisitor] msg_id=1 id=1 content=\"Hello, CyberRT!\"\n[ProcessingVisitor] msg_id=1 id=1 length=15\n=== Receiving message #2 ===\n[LoggingVisitor] msg_id=2 id=2 content=\"Another data packet.\"\n[ProcessingVisitor] msg_id=2 id=2 length=20\n\n=== Removing LoggingVisitor ===\n=== Receiving message #3 ===\n[ProcessingVisitor] msg_id=3 id=3 length=27\n\nStatistics:\n  Published: 3  Processed: 3  Dropped: 0\n```\n\n## 4. StaticComponent 版: 零开销编译期分发\n\n### 4.1 CRTP 订阅者\n\n```cpp\nclass LoggingVisitor\n    : public mccc::StaticComponent<LoggingVisitor, DemoPayload> {\n public:\n  void Handle(const SensorData& data) noexcept {\n    LOG_INFO(\"[LoggingVisitor] id=%d content=\\\"%s\\\"\",\n             data.id, data.content.c_str());\n  }\n};\n\nclass ProcessingVisitor\n    : public mccc::StaticComponent<ProcessingVisitor, DemoPayload> {\n public:\n  void Handle(const SensorData& data) noexcept {\n    LOG_INFO(\"[ProcessingVisitor] id=%d length=%u\",\n             data.id, data.content.size());\n  }\n};\n```\n\n`Handle()` 方法在编译期被 CRTP 基类检测和绑定，无虚函数、无间接调用。\n\n### 4.2 CombinedVisitor: 单次遍历多路分发\n\n```cpp\ntemplate <typename... Visitors>\nclass CombinedVisitor {\n public:\n  explicit CombinedVisitor(Visitors&... visitors) noexcept\n      : visitors_(visitors...) {}\n\n  template <typename T>\n  void operator()(const T& data) noexcept {\n    DispatchAll<T>(data, std::index_sequence_for<Visitors...>{});\n  }\n\n private:\n  template <typename T, size_t... Is>\n  void DispatchAll(const T& data, std::index_sequence<Is...>) noexcept {\n    (std::get<Is>(visitors_).get().Handle(data), ...);  // fold expression 展开\n  }\n\n  std::tuple<std::reference_wrapper<Visitors>...> visitors_;\n};\n```\n\nfold expression `(... , ...)` 在编译期将所有 visitor 的 `Handle()` 调用展开为顺序执行，编译器可以完全内联。\n\n### 4.3 使用\n\n```cpp\n// 栈分配，零 shared_ptr，零堆分配\nLoggingVisitor logger;\nProcessingVisitor processor;\nCombinedVisitor combined(logger, processor);\n\n// 单次 Ring Buffer 遍历，分发到所有 visitor\nstd::thread worker([&stop_worker, &combined]() noexcept {\n  while (!stop_worker.load(std::memory_order_acquire)) {\n    uint32_t processed = DemoBus::Instance().ProcessBatchWith(combined);\n    if (processed == 0U) {\n      std::this_thread::sleep_for(std::chrono::microseconds(100));\n    }\n  }\n});\n```\n\n## 5. 两种方案选型\n\n**Component 版** -- 需要运行时灵活性:\n- 订阅者集合在运行期动态变化\n- 需要 `shared_ptr` 生命周期管理\n- 组件可能被多个模块引用\n\n**StaticComponent 版** -- 追求极致性能:\n- 订阅者集合在编译期确定\n- 嵌入式实时系统，对延迟敏感\n- Handler 调用需要被编译器内联\n\n| 维度 | Component 版 | StaticComponent 版 |\n|------|-------------|-------------------|\n| 代码量 | ~110 行 / 1 文件 | ~95 行 / 1 文件 |\n| 堆分配 (每条消息) | 0 次 | 0 次 |\n| 线程数 | 2 (worker + main) | 2 (worker + main) |\n| 动态增删订阅者 | 支持 | 不支持 |\n| 间接调用 | `FixedFunction` (SBO，非堆) | 无 (可内联) |\n| 订阅者存储 | `shared_ptr` 堆分配 | 栈分配 |\n\n对于大多数嵌入式应用，StaticComponent 版是更好的选择。只有在确实需要动态增删订阅者时才使用 Component 版。\n\n## 6. 相关资源\n\n- 完整代码: [data-visitor-dispatcher](https://gitee.com/liudegui/data-visitor-dispatcher) (MIT License)\n- 消息总线: [mccc-bus](https://gitee.com/liudegui/mccc-bus) -- C++17 header-only 无锁消息总线\n- 基础设施库: [newosp](https://github.com/DeguiLiu/newosp) -- 工业级嵌入式 C++17 库 (基于 mccc-bus)\n- [无锁消息总线设计与实现](/posts/practice/mccc_bus_cpp17_practice/)\n- [嵌入式系统中的编译期分发](/posts/pattern/compile_time_dispatch_optimization/)\n",
      "ctime": "1771552643",
      "mtime": "1771552643",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/dbpp_cpp14_database_modernization.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651652654",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "数据库抽象层的 C++14 重写: 从手动内存管理到 RAII",
      "brief_content": "以 dbpp 对 DatabaseLayer 的现代化重写为案例，系统展示如何将一个 C++03 风格的数据库封装库改造为符合 MISRA C++ 标准的 C++14 实现。涵盖 RAII 资源管理、",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "将一个能跑的 C++03 项目重写为 C++14，投入是否值得？当原始代码中同时存在裸 new/delete、const_cast 模拟移动语义、全局静态变量、sprintf 缓冲区溢出这四类问题时，答案是明确的: 重写的收益不在于新功能，而在于消除这些定时炸弹。\n\n本文以 [dbpp](https://gitee.com/liudegui/dbpp) 对 [DatabaseLayer](https://gitee.com/liudegui/DatabaseLayer) 的现代化重写为案例，逐一展示 C++14 如何系统性地解决 C++03 遗留问题。\n\n## 1. 原始代码问题诊断\n\nDatabaseLayer 是一个 SQLite3 + MySQL 的统一数据库操作封装，功能完整，但代码风格停留在 C++03 时代。以下是按严重程度排列的问题清单:\n\n| 问题 | 位置 | 严重程度 | 风险 |\n|------|------|----------|------|\n| 裸 new/delete | Exception, ResultSet, Statement 中 `new std::string`, `new vector` | 高 | 内存泄漏 |\n| const_cast 模拟移动语义 | 所有拷贝构造和赋值运算符 | 高 | 未定义行为 |\n| 全局静态变量 | `s_DBName`, `s_nValue`, `s_dwValue` | 高 | 线程不安全 |\n| sprintf 缓冲区溢出 | `tableExists`, `createDB`, `dropDB` 中的 `char[256]` | 中 | 安全漏洞 |\n| `#undef NULL` / `#define NULL 0` | 宏污染全局命名空间 | 中 | 编译问题 |\n| 内嵌 sqlite3.c 源码 (7386 行) | 维护负担 | 低 | 版本过时 |\n| 虚基类 + `#ifdef` typedef | 设计层面 | 低 | 架构缺陷 |\n\n下面逐一分析每个问题的本质和解决方案。\n\n## 2. 裸 new/delete -> RAII\n\n### 2.1 问题: 资源泄漏风险\n\n```cpp\n// DatabaseLayer 原始代码: 裸 new，析构路径不完整\nclass CppMySQLException {\n    CppMySQLException(const char* msg)\n        : message_(new std::string(msg)) {}  // 裸 new\n\n    ~CppMySQLException() { delete message_; }  // 需要手动 delete\n\n    // 拷贝构造中有 new，但如果 new 抛异常? -> 泄漏\n};\n\nclass CppMySQLResultSet {\n    CppMySQLResultSet()\n        : pszData_(new std::vector<...>()) {}   // 裸 new\n\n    // 如果构造函数中后续操作抛异常，pszData_ 泄漏\n};\n```\n\n每个 `new` 都是一个潜在的泄漏点。如果异常路径没有覆盖到，或者中间有 return，资源就丢失了。\n\n### 2.2 解决: RAII 管理所有数据库资源\n\ndbpp 的每个类持有一个数据库资源，析构函数自动释放:\n\n```cpp\n// dbpp: RAII 管理 sqlite3* 连接\nclass Sqlite3Db {\n public:\n    Sqlite3Db() = default;\n    ~Sqlite3Db() { Close(); }  // 析构自动 close\n\n    Error Open(const char* path) {\n        Close();  // 先释放旧连接 (幂等)\n        int32_t rc = sqlite3_open(path, &db_);\n        if (rc != SQLITE_OK) {\n            Error err = Error::Make(ErrorCode::kError,\n                                    db_ ? sqlite3_errmsg(db_) : \"open failed\");\n            if (db_ != nullptr) {\n                sqlite3_close(db_);\n                db_ = nullptr;\n            }\n            return err;\n        }\n        return Error::Ok();\n    }\n\n    void Close() {\n        if (db_ != nullptr) {\n            sqlite3_close(db_);\n            db_ = nullptr;\n        }\n    }\n\n private:\n    sqlite3* db_ = nullptr;  // 唯一资源\n};\n```\n\n四个类各自管理一种资源:\n\n| 类 | 持有资源 | 获取方式 | 释放方式 |\n|----|----------|----------|----------|\n| `Sqlite3Db` | `sqlite3*` | `sqlite3_open()` | `sqlite3_close()` |\n| `Sqlite3Query` | `sqlite3_stmt*` | `sqlite3_prepare_v2()` + `sqlite3_step()` | `sqlite3_finalize()` |\n| `Sqlite3ResultSet` | `char**` | `sqlite3_get_table()` | `sqlite3_free_table()` |\n| `Sqlite3Statement` | `sqlite3_stmt*` | `sqlite3_prepare_v2()` | `sqlite3_finalize()` |\n\nRAII 保证: 无论正常退出还是异常退出，资源一定被释放。零手动 delete。\n\n## 3. const_cast hack -> Move 语义\n\n### 3.1 问题: const_cast 模拟移动\n\nDatabaseLayer 中最危险的模式: 用 `const_cast` 在拷贝构造函数中修改源对象，模拟 C++11 的移动语义:\n\n```cpp\n// DatabaseLayer 原始代码: const_cast hack\nclass CppSQLite3Query {\n    CppSQLite3Query(const CppSQLite3Query& rQuery) {\n        // 拷贝构造却修改源对象 -> 违反 const 契约\n        mpStmt = rQuery.mpStmt;\n        const_cast<CppSQLite3Query&>(rQuery).mpStmt = 0;  // 偷走资源\n\n        mbEof = rQuery.mbEof;\n        const_cast<CppSQLite3Query&>(rQuery).mbEof = true;  // 修改源对象\n    }\n};\n```\n\n这段代码做的事情和 C++11 移动语义完全一样 (转移资源所有权)，但手段是错误的:\n\n- 违反 `const` 契约 (声明接受 `const&` 却修改了源对象)\n- C++ 标准中 `const_cast` 去除底层 const 后修改对象是**未定义行为**\n- 编译器可能基于 const 假设做优化，导致不可预测的结果\n\n### 3.2 解决: move-only 语义\n\ndbpp 用标准 C++11 移动语义替代:\n\n```cpp\n// dbpp: 标准移动语义\nclass Sqlite3Query {\n public:\n    // 禁止拷贝\n    Sqlite3Query(const Sqlite3Query&) = delete;\n    Sqlite3Query& operator=(const Sqlite3Query&) = delete;\n\n    // 移动构造: 转移所有权\n    Sqlite3Query(Sqlite3Query&& other) noexcept\n        : db_(other.db_),\n          stmt_(other.stmt_),\n          eof_(other.eof_),\n          num_fields_(other.num_fields_) {\n        other.db_ = nullptr;\n        other.stmt_ = nullptr;     // 源对象资源清零\n        other.eof_ = true;\n        other.num_fields_ = 0;\n    }\n\n    // 移动赋值: 先释放自己的资源，再接管\n    Sqlite3Query& operator=(Sqlite3Query&& other) noexcept {\n        if (this != &other) {\n            Finalize();            // 释放当前资源\n            db_ = other.db_;\n            stmt_ = other.stmt_;\n            eof_ = other.eof_;\n            num_fields_ = other.num_fields_;\n            other.db_ = nullptr;   // 源对象清零\n            other.stmt_ = nullptr;\n            other.eof_ = true;\n            other.num_fields_ = 0;\n        }\n        return *this;\n    }\n};\n```\n\n关键区别:\n\n| 维度 | const_cast hack | move 语义 |\n|------|----------------|-----------|\n| 接口声明 | `(const T&)` 接受 const 引用 | `(T&&)` 接受右值引用 |\n| 语义 | 声称拷贝，实际移动 | 明确声明移动 |\n| 调用方感知 | 不知道源对象被修改 | `std::move()` 显式转移所有权 |\n| 编译器保证 | 无 (UB) | 标准行为 |\n\n使用方式对比:\n\n```cpp\n// DatabaseLayer: 看起来是拷贝，实际源对象被清空 (惊吓)\nCppSQLite3Query q1 = db.execQuery(\"SELECT * FROM emp;\");\nCppSQLite3Query q2 = q1;  // q1 被偷走资源，但代码看不出来\n\n// dbpp: 移动语义，所有权转移显式可见\nauto q1 = db.ExecQuery(\"SELECT * FROM emp;\");\nauto q2 = std::move(q1);  // 明确: q1 不再持有资源\n// Sqlite3Query q3 = q1;  // 编译错误: 拷贝被禁止\n```\n\n## 4. throw 异常 -> Error 结构体\n\n### 4.1 问题: 异常与嵌入式不兼容\n\nDatabaseLayer 大量使用 `throw`:\n\n```cpp\n// DatabaseLayer: throw 异常\nvoid CppSQLite3DB::execDML(const char* szSQL) {\n    char* szError = 0;\n    int nRet = sqlite3_exec(mpDB, szSQL, 0, 0, &szError);\n    if (nRet != SQLITE_OK) {\n        throw CppSQLite3Exception(nRet, szError);  // throw\n    }\n}\n```\n\n嵌入式 C++ 项目通常使用 `-fno-exceptions` 编译 (减少二进制大小，消除 unwind 表开销)。throw 在这种环境下直接导致编译失败。\n\n### 4.2 解决: Error 结构体 + 输出参数\n\ndbpp 用 `Error` 结构体替代异常:\n\n```cpp\n// 错误码: enum class，固定宽度\nenum class ErrorCode : int32_t {\n    kOk = 0,\n    kError = -1,\n    kNotOpen = -2,\n    kBusy = -3,\n    kConstraint = -5,\n    kNullParam = -9,\n    // ...\n};\n\n// 错误信息: 错误码 + 固定大小消息缓冲区 (无堆分配)\nstruct Error {\n    static constexpr uint32_t kMaxMessageLen = 256;\n\n    ErrorCode code = ErrorCode::kOk;\n    char message[kMaxMessageLen] = {};\n\n    bool ok() const { return code == ErrorCode::kOk; }\n    explicit operator bool() const { return ok(); }\n\n    static Error Ok() { return Error{}; }\n    static Error Make(ErrorCode c, const char* msg = nullptr) {\n        Error e;\n        e.Set(c, msg);\n        return e;\n    }\n};\n```\n\nAPI 中通过可选的 `Error*` 输出参数报告错误:\n\n```cpp\n// dbpp: 错误通过输出参数返回 (可选)\nint32_t ExecDml(const char* sql, Error* out_error = nullptr) {\n    if (db_ == nullptr) {\n        if (out_error != nullptr) {\n            out_error->Set(ErrorCode::kNotOpen, \"Database not open\");\n        }\n        return -1;\n    }\n\n    char* errmsg = nullptr;\n    int32_t rc = sqlite3_exec(db_, sql, nullptr, nullptr, &errmsg);\n    if (rc == SQLITE_OK) {\n        return sqlite3_changes(db_);\n    }\n\n    if (out_error != nullptr) {\n        out_error->Set(ErrorCode::kError,\n                       errmsg ? errmsg : sqlite3_errmsg(db_));\n    }\n    if (errmsg != nullptr) { sqlite3_free(errmsg); }\n    return -1;\n}\n```\n\n调用方可以选择是否处理错误:\n\n```cpp\n// 忽略错误 (简单场景)\ndb.ExecDml(\"INSERT INTO emp VALUES(1, 'Alice');\");\n\n// 检查错误\ndbpp::Error err;\ndb.ExecDml(\"INVALID SQL\", &err);\nif (!err.ok()) {\n    std::printf(\"error %d: %s\\n\", static_cast<int>(err.code), err.message);\n}\n```\n\n设计要点:\n\n- `Error` 是值类型，栈分配，无堆内存\n- 消息缓冲区固定 256 字节，用 `snprintf` 填充 (无溢出)\n- `out_error` 参数默认 nullptr，不关心错误时可以省略\n- 兼容 `-fno-exceptions`\n\n## 5. 全局状态 -> 零全局状态\n\n### 5.1 问题: 全局静态变量\n\nDatabaseLayer 中有全局静态变量用于临时数据:\n\n```cpp\n// DatabaseLayer: 全局静态变量 (线程不安全)\nstatic char s_DBName[512];    // 全局共享\nstatic int  s_nValue;         // 多线程访问 -> 数据竞争\nstatic DWORD s_dwValue;\n```\n\n多线程环境下，两个线程同时操作不同的数据库连接会互相覆盖全局缓冲区。\n\n### 5.2 解决: 状态全部在实例中\n\ndbpp 没有任何全局变量或静态成员变量:\n\n```cpp\n// dbpp: 每个连接独立，零全局状态\nclass Sqlite3Db {\n private:\n    sqlite3* db_ = nullptr;  // 所有状态在实例中\n};\n\nclass Sqlite3Query {\n private:\n    sqlite3* db_ = nullptr;\n    sqlite3_stmt* stmt_ = nullptr;\n    bool eof_ = true;\n    int32_t num_fields_ = 0;\n    // 无全局变量、无 static 成员\n};\n```\n\n每个 `Sqlite3Db` 实例独立持有自己的连接，多个实例可以在不同线程中安全使用。\n\n## 6. sprintf -> snprintf\n\n```cpp\n// DatabaseLayer: sprintf 缓冲区溢出风险\nchar szSQL[256];\nsprintf(szSQL, \"SELECT count(*) FROM sqlite_master \"\n        \"WHERE type='table' AND name='%s'\", szTable);\n// 如果 szTable 超过 ~200 字符 -> 缓冲区溢出\n\n// dbpp: snprintf 安全写入\nchar sql[256];\nstd::snprintf(sql, sizeof(sql),\n    \"SELECT count(*) FROM sqlite_master \"\n    \"WHERE type='table' AND name='%s'\", table);\n// sizeof(sql) 限制写入长度，不会溢出\n```\n\n## 7. 架构简化: 去掉虚基类\n\n### 7.1 问题: 虚基类 + #ifdef\n\nDatabaseLayer 用虚基类 `DatabaseLayer` 定义统一接口，然后通过 `#ifdef` 选择实现:\n\n```cpp\n// DatabaseLayer: 虚基类 + typedef 切换\nclass DatabaseLayer {\n    virtual int execDML(const char* sql) = 0;    // 虚函数开销\n    virtual ResultSet execQuery(const char* sql) = 0;\n};\n\n#ifdef USE_MYSQL\n    typedef CppMySQLDB DatabaseImpl;\n#else\n    typedef CppSQLite3DB DatabaseImpl;\n#endif\n```\n\n这种设计同时承担了两种开销: 虚函数调用的运行时开销，和 `#ifdef` 切换的编译时复杂度。而且无法在运行时切换后端。\n\n### 7.2 解决: 具体类直接使用\n\ndbpp 直接提供 `Sqlite3Db` 具体类:\n\n```cpp\n// dbpp: 直接使用具体类，无虚函数\ndbpp::Sqlite3Db db;\ndb.Open(\":memory:\");\ndb.ExecDml(\"CREATE TABLE emp(empno INTEGER, empname TEXT);\");\nauto q = db.ExecQuery(\"SELECT * FROM emp;\");\n```\n\n如果未来需要多后端，可以通过模板参数化实现编译期多态:\n\n```cpp\n// 未来扩展方向: 模板参数化 (编译期多态, 零虚函数开销)\ntemplate <typename Backend>\nclass Database {\n    Backend backend_;\n public:\n    auto ExecQuery(const char* sql) { return backend_.ExecQuery(sql); }\n};\n\nusing SqliteDb = Database<Sqlite3Backend>;\nusing MysqlDb = Database<MysqlBackend>;\n```\n\n## 8. 完整使用示例\n\n### 8.1 基本 CRUD\n\n```cpp\n#include \"dbpp/sqlite3_db.hpp\"\n\nint main() {\n    dbpp::Sqlite3Db db;\n    db.Open(\":memory:\");\n\n    // CREATE\n    db.ExecDml(\"CREATE TABLE emp(empno INTEGER, empname TEXT);\");\n\n    // INSERT\n    db.ExecDml(\"INSERT INTO emp VALUES(1, 'Alice');\");\n    db.ExecDml(\"INSERT INTO emp VALUES(2, 'Bob');\");\n\n    // SELECT (前向遍历)\n    auto q = db.ExecQuery(\"SELECT * FROM emp ORDER BY empno;\");\n    while (!q.Eof()) {\n        std::printf(\"empno=%d empname=%s\\n\",\n                    q.GetInt(0), q.GetString(1));\n        q.NextRow();\n    }\n    q.Finalize();\n\n    // COUNT\n    int32_t count = db.ExecScalar(\"SELECT count(*) FROM emp;\");\n    std::printf(\"total: %d\\n\", count);\n\n    // UPDATE / DELETE\n    int32_t updated = db.ExecDml(\"UPDATE emp SET empname='Boss' WHERE empno=1;\");\n    int32_t deleted = db.ExecDml(\"DELETE FROM emp WHERE empno > 5;\");\n\n    return 0;  // db 析构自动 close\n}\n```\n\n### 8.2 预编译语句 + 事务\n\n```cpp\ndbpp::Sqlite3Db db;\ndb.Open(\":memory:\");\ndb.ExecDml(\"CREATE TABLE emp(empno INTEGER, empname TEXT);\");\n\n// 事务 + 预编译语句批量插入\ndb.BeginTransaction();\n\nauto stmt = db.CompileStatement(\"INSERT INTO emp VALUES(?, ?);\");\nfor (int32_t i = 0; i < 100; ++i) {\n    char name[32];\n    std::snprintf(name, sizeof(name), \"Emp%02d\", i);\n    stmt.Bind(1, i);         // 1-based 参数索引\n    stmt.Bind(2, name);\n    stmt.ExecDml();\n    stmt.Reset();             // 重置绑定，复用语句\n}\nstmt.Finalize();\n\ndb.Commit();  // 或 db.Rollback()\n```\n\n### 8.3 随机访问结果集\n\n```cpp\n// GetResultSet: 全量加载到内存，支持 SeekRow() 随机访问\nauto rs = db.GetResultSet(\"SELECT * FROM emp ORDER BY empno;\");\n\n// 反向遍历\nfor (int32_t i = static_cast<int32_t>(rs.NumRows()) - 1; i >= 0; --i) {\n    rs.SeekRow(static_cast<uint32_t>(i));\n    std::printf(\"%s | %s\\n\", rs.FieldValue(0), rs.FieldValue(1));\n}\nrs.Finalize();\n```\n\n### 8.4 Query vs ResultSet 选择\n\n| 维度 | Sqlite3Query (前向) | Sqlite3ResultSet (随机) |\n|------|--------------------|-----------------------|\n| 内存 | 按需读取 (低) | 全量加载 (高) |\n| 访问模式 | 只能前向 Eof()/NextRow() | 支持 SeekRow() 随机访问 |\n| 底层 API | `sqlite3_step()` | `sqlite3_get_table()` |\n| 适用场景 | 流式处理大结果集 | 需要随机访问或多次遍历 |\n\n## 9. 改造总结\n\n### 9.1 前后对比\n\n| 维度 | DatabaseLayer (C++03) | dbpp (C++14) |\n|------|----------------------|--------------|\n| 资源管理 | 裸 new/delete | RAII + 析构自动释放 |\n| 拷贝语义 | const_cast hack (UB) | 禁止拷贝，仅移动 |\n| 错误处理 | throw 异常 | Error 结构体 (无异常) |\n| 线程安全 | 全局 static 变量 | 零全局状态 |\n| 缓冲区 | sprintf | snprintf |\n| 后端切换 | 虚基类 + #ifdef | 具体类 (模板扩展预留) |\n| 依赖管理 | 内嵌 7386 行 sqlite3.c | bundled amalgamation + FetchContent |\n| 测试 | CppUnit | Catch2 v3 (51 cases, ASan+UBSan) |\n| CI | 无 | GitHub Actions (Linux + macOS) |\n| 代码规范 | 无 | MISRA C++ / Google Style |\n\n### 9.2 可复用的改造模式\n\n这次改造中应用的模式适用于任何 C++03 -> C++14 迁移:\n\n1. **裸指针 -> RAII**: 每个类管理恰好一种资源，析构函数负责释放\n2. **const_cast -> move**: 禁止拷贝 (`= delete`)，实现移动构造和移动赋值\n3. **throw -> Error 结构体**: 固定大小值类型，通过输出参数返回，兼容 `-fno-exceptions`\n4. **全局 static -> 实例成员**: 所有状态都在对象实例中，零全局变量\n5. **sprintf -> snprintf**: 所有格式化输出使用安全版本\n6. **内嵌源码 -> FetchContent**: 让 CMake 管理依赖版本\n\n### 9.3 项目信息\n\n- 仓库: [GitHub](https://github.com/DeguiLiu/dbpp) | [Gitee](https://gitee.com/liudegui/dbpp)\n- 原始项目: [DatabaseLayer](https://gitee.com/liudegui/DatabaseLayer)\n- 设计文档: [docs/design_zh.md](https://gitee.com/liudegui/dbpp/blob/master/docs/design_zh.md)\n- 许可证: MIT\n",
      "ctime": "1771552646",
      "mtime": "1771552646",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/embedded_config_serialization.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651669038",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式配置序列化选型: struct/TLV/nanopb/capnproto 对比",
      "brief_content": "嵌入式设备的配置数据需要在 Flash/NvM 与内存之间可靠存取。本文从最简的裸 struct memcpy 出发，逐级递进到自定义 TLV、nanopb (Protocol Buffers C 实",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 参考文章:\n>\n> - [嵌入式配置数据持久化方案对比 -- 自定义 TLV vs nanopb](https://blog.csdn.net/stallion5632/article/details/150866044)\n>\n> nanopb 官方: [github.com/nanopb/nanopb](https://github.com/nanopb/nanopb) |\n> c-capnproto 仓库: [github.com/opensourcerouting/c-capnproto](https://github.com/opensourcerouting/c-capnproto)\n\n## 1. 背景与决策\n\n我们的设备启动时间敏感，配置加载后频繁随机读取各模块参数，最终选了 c-capnproto。这个决策并非拍脑袋，而是在裸 struct、自定义 TLV、nanopb 三种方案逐一评估后得出的结论。本文将完整呈现这个评估过程，让读者带着结论去理解对比。\n\n嵌入式设备 (激光雷达、工业传感器、边缘网关) 的配置数据 (设备参数、校准值、用户设置) 需要持久化到 Flash/NvM，启动时加载回内存。这看似简单的需求，面临三个核心挑战:\n\n| 挑战 | 说明 | 典型场景 |\n|------|------|---------|\n| **格式可演进** | 配置字段随固件升级增删，新旧固件需互相解析 | OTA 后旧配置不能丢失 |\n| **数据完整性** | Flash 写入可能被断电中断，需防止配置损坏 | 工业现场意外断电 |\n| **资源高效** | 在有限 ROM/RAM 下，序列化开销要小 | Cortex-M 系列 MCU |\n\n四档方案形成清晰的递进关系:\n\n```\n裸 struct ──→ 自定义 TLV ──→ nanopb ──→ c-capnproto\n最简基线      轻量自描述      声明式演进    零拷贝随机访问\n零版本兼容    手动兼容        自动兼容      自动兼容\n```\n\n## 2. 裸 struct: 最简基线\n\n大多数嵌入式团队的第一反应: 直接 `memcpy(struct)` + CRC + version 字段。这是最简方案，也是理解后续方案价值的参照物。\n\n### 2.1 实现方式\n\n```c\ntypedef struct __attribute__((packed)) {\n    uint16_t version;           // 格式版本号\n    char     device_id[32];     // 设备标识\n    uint32_t scan_rate_hz;      // 采样率\n    uint8_t  filter_mode;       // 滤波模式\n    uint8_t  log_level;         // 日志等级\n    float    noise_threshold;   // 噪声阈值\n    uint32_t crc32;             // 校验 (必须放最后)\n} device_config_t;\n\n// 写入 Flash\nbool config_save(const device_config_t *cfg) {\n    device_config_t tmp = *cfg;\n    tmp.crc32 = crc32_calc(&tmp, offsetof(device_config_t, crc32));\n    return flash_write(CONFIG_ADDR, &tmp, sizeof(tmp));\n}\n\n// 从 Flash 加载\nbool config_load(device_config_t *cfg) {\n    flash_read(CONFIG_ADDR, cfg, sizeof(*cfg));\n    return crc32_calc(cfg, offsetof(device_config_t, crc32)) == cfg->crc32;\n}\n```\n\n### 2.2 优缺点分析\n\n**优点:**\n\n- **极简**: 代码量最少 (~20 行)，零依赖，零学习成本\n- **性能最优**: 读写均为单次 memcpy，无任何解析开销\n- **内存开销最小**: 结构体本身即为存储格式，无额外缓冲区\n\n**缺点:**\n\n- **零版本兼容**: struct 布局变化 (增删字段、调整顺序) 直接导致旧数据不可读。version 字段只能做\"全有或全无\"判断\n- **编译器依赖**: padding、对齐规则由编译器和平台决定。`__attribute__((packed))` 可消除 padding，但在部分架构上引发非对齐访问惩罚\n- **跨平台不可移植**: 不同编译器/架构生成不同布局，大小端差异需手动处理\n- **无增量兼容**: 新固件无法解析旧格式中缺失的字段，旧固件无法跳过新格式中多出的字段\n\n```c\n// 版本升级的困境: 新增一个字段就要废弃全部旧数据\n// V1\ntypedef struct __attribute__((packed)) {\n    uint16_t version;       // = 1\n    uint32_t scan_rate_hz;\n    uint32_t crc32;\n} config_v1_t;\n\n// V2: 新增 laser_power，布局完全不同\ntypedef struct __attribute__((packed)) {\n    uint16_t version;       // = 2\n    uint32_t scan_rate_hz;\n    uint8_t  laser_power;   // 新增\n    uint32_t crc32;\n} config_v2_t;\n\n// 升级时必须: 检测 version → 按旧格式解析 → 手动迁移 → 写回新格式\n// 每增加一个版本，迁移代码就多一条分支\n```\n\n裸 struct 适合字段固定、永不变更的场景 (如硬件寄存器映射)。一旦配置需要跨版本演进，就需要自描述格式 -- 这正是 TLV 的起点。\n\n## 3. 自定义 TLV: 轻量与直接\n\n### 3.1 数据格式\n\nTLV (Type-Length-Value) 是最原始的自描述格式。每个数据块由类型标识、长度、实际数据三部分组成:\n\n```\n+--------+--------+------------------+\n| Type   | Length | Value (payload)  |\n| 2 bytes| 2 bytes| Length bytes      |\n+--------+--------+------------------+\n```\n\nTLV 块可以嵌套，构建树状结构:\n\n```\n+------------------+------------------+\n|      全局配置头 (CRC, Ver, Len)     |\n+------------------+------------------+\n| Type(Mod_A) | Len(24) | Payload_A   |\n+------------------+------------------+\n| Type(Mod_B) | Len(128)| Payload_B   |\n+------------------+------------------+\n                   |\n                   +-----------------------------------+\n                   | Type(Sub_B1) | Len(4) | Payload   |\n                   +-----------------------------------+\n                   | Type(Sub_B2) | Len(16)| Payload   |\n                   +-----------------------------------+\n                   | Type(Sub_X)  | Len(96)| Payload   | <-- 旧固件不认识，跳过\n                   +-----------------------------------+\n```\n\n### 3.2 实现核心\n\nTLV 头结构和解析器:\n\n```c\ntypedef struct {\n    uint16_t type;\n    uint16_t length;\n} tlv_header_t;\n\n// TLV 解析器: 遍历 buffer，按 type 分发\nbool tlv_parse(const uint8_t *buf, size_t total_len,\n               tlv_handler_t *handlers, size_t handler_count) {\n    size_t offset = 0;\n    while (offset + sizeof(tlv_header_t) <= total_len) {\n        const tlv_header_t *hdr = (const tlv_header_t *)(buf + offset);\n\n        // 边界检查\n        if (offset + sizeof(tlv_header_t) + hdr->length > total_len) {\n            return false;  // 数据截断\n        }\n\n        const uint8_t *value = buf + offset + sizeof(tlv_header_t);\n        bool handled = false;\n\n        for (size_t i = 0; i < handler_count; i++) {\n            if (handlers[i].type == hdr->type) {\n                handlers[i].parse(value, hdr->length, handlers[i].dst);\n                handled = true;\n                break;\n            }\n        }\n\n        if (!handled) {\n            // 未知类型: 跳过 (向前兼容的关键)\n            LOG_W(\"Unknown TLV type: 0x%04X, skip %u bytes\",\n                  hdr->type, hdr->length);\n        }\n\n        offset += sizeof(tlv_header_t) + hdr->length;\n    }\n    return true;\n}\n```\n\n序列化同样直接:\n\n```c\nsize_t tlv_write(uint8_t *buf, size_t buf_size,\n                 uint16_t type, const void *value, uint16_t length) {\n    size_t total = sizeof(tlv_header_t) + length;\n    if (total > buf_size) { return 0; }\n\n    tlv_header_t hdr = { .type = type, .length = length };\n    memcpy(buf, &hdr, sizeof(hdr));\n    memcpy(buf + sizeof(hdr), value, length);\n    return total;\n}\n```\n\n### 3.3 优缺点分析\n\n**优点:**\n\n- **零依赖**: 代码量极小 (~200 行)，不引入任何第三方库\n- **CPU 开销低**: 反序列化基于指针偏移 + memcpy，无需复杂解析\n- **向前兼容**: 跳过未知 type 字段即可，不会因新增字段导致旧固件崩溃\n- **支持嵌套**: TLV 天然支持递归嵌套，可构建模块化配置\n\n**缺点:**\n\n- **维护成本高 (命令式开发)**: 每新增一个字段需手动修改**三处代码** -- 枚举定义、解析逻辑、序列化逻辑\n- **无编译期类型检查**: memcpy 不会验证字段类型和长度匹配，错误只能在运行时发现\n- **原地更新的局限性**: 字段长度变化时原地更新失效，会覆盖后续数据\n- **缺少默认值机制**: 旧数据中不存在的新字段，需要手动填充默认值\n\n```c\n// 每次新增字段都需要修改三处:\n// 1. 枚举定义\nenum cfg_type { TYPE_GAIN_MODE, TYPE_SCENE_MODE, TYPE_LASER_POWER /* 新增 */ };\n// 2. 解析逻辑\ncase TYPE_LASER_POWER:\n    memcpy(&config.laser_power, ptr, sizeof(uint32_t));\n    break;\n// 3. 序列化逻辑\ntlv_write(buf, buf_size, TYPE_LASER_POWER,\n          &config.laser_power, sizeof(uint32_t));\n```\n\n## 4. nanopb: 声明式演进与紧凑编码\n\n### 4.1 核心理念\n\n[nanopb](https://github.com/nanopb/nanopb) 是 Protocol Buffers 的 C 语言实现，专为嵌入式系统设计。核心理念: **用 `.proto` 文件声明配置结构，工具自动生成编解码代码**。开发者只需维护 schema，不需要手写解析逻辑。\n\n```bash\n# 声明式开发流程\n# 1. 编写 .proto 文件 (schema)\n# 2. 工具自动生成编解码代码\nprotoc --nanopb_out=. config.proto\n# 产出: config.pb.c, config.pb.h\n# 3. 嵌入式代码调用 pb_encode / pb_decode\n```\n\n### 4.2 Schema 定义\n\n```protobuf\nsyntax = \"proto2\";  // nanopb 推荐使用 proto2 (支持 required/optional/default)\nimport \"nanopb.proto\";\n\n// 全局选项: 限制最大消息大小，防止内存溢出\noption (nanopb_fileopt).max_size = 512;\n\nmessage LidarConfig {\n    // required: 必须存在，缺失则解码失败\n    required string device_id = 1 [(nanopb).max_size = 32];\n    required uint32 scan_rate_hz = 2;\n\n    // optional: 可选，可缺省，旧固件不认识的新字段会被自动忽略\n    optional bool enable_filtering = 3 [default = true];\n    optional uint32 log_level = 4 [default = 2];\n\n    // 嵌套消息: 结构化管理子模块配置\n    message AlgorithmParams {\n        required float noise_threshold = 1;\n        optional bool enable_outlier_removal = 2 [default = true];\n    }\n    optional AlgorithmParams alg_params = 5;\n}\n```\n\nnanopb 的关键 `.proto` 选项:\n\n| 选项 | 作用 | 示例 |\n|------|------|------|\n| `(nanopb).max_size` | 限制 string/bytes 最大长度 | `[(nanopb).max_size = 32]` |\n| `(nanopb).max_count` | 限制 repeated 字段最大数量 | `[(nanopb).max_count = 10]` |\n| `(nanopb_fileopt).max_size` | 限制整个消息最大编码大小 | `option (nanopb_fileopt).max_size = 512;` |\n| `(nanopb).type` | 指定字段类型 (FT_STATIC/FT_CALLBACK) | `[(nanopb).type = FT_STATIC]` |\n\n### 4.3 编解码使用\n\nnanopb 生成的代码提供静态结构体和流式编解码 API:\n\n```c\n#include \"config.pb.h\"\n\n// === 编码 (序列化) ===\nLidarConfig config = LidarConfig_init_default;  // 所有字段初始化为默认值\nstrcpy(config.device_id, \"LIDAR-001\");\nconfig.scan_rate_hz = 200;\nconfig.enable_filtering = true;\nconfig.has_alg_params = true;  // 标记 optional 嵌套消息存在\nconfig.alg_params.noise_threshold = 0.05f;\n\nuint8_t buffer[512];\npb_ostream_t stream = pb_ostream_from_buffer(buffer, sizeof(buffer));\nbool ok = pb_encode(&stream, LidarConfig_fields, &config);\nsize_t encoded_size = stream.bytes_written;\n// encoded_size 通常远小于 sizeof(LidarConfig)，varint 编码紧凑\n\n// === 解码 (反序列化) ===\nLidarConfig loaded = LidarConfig_init_default;  // 先填充默认值\npb_istream_t istream = pb_istream_from_buffer(buffer, encoded_size);\nok = pb_decode(&istream, LidarConfig_fields, &loaded);\n\n// 访问解码后的字段\nprintf(\"scan_rate = %u\\n\", loaded.scan_rate_hz);\nprintf(\"filtering = %d\\n\", loaded.enable_filtering);\n```\n\n**关键细节**: `LidarConfig_init_default` 宏会将所有 optional 字段初始化为 `.proto` 中定义的默认值。解码旧数据时，旧数据中不存在的新字段保持默认值 -- 这是向前兼容的核心机制。\n\n### 4.4 静态分配 vs 回调分配\n\nnanopb 提供两种内存策略:\n\n```protobuf\n// 静态分配 (默认): 字段直接嵌入结构体，编译期确定大小\nrequired string device_id = 1 [(nanopb).max_size = 32];\n// 生成: char device_id[32];\n\n// 回调分配: 通过回调函数逐块处理，适合大数据或流式处理\noptional bytes firmware_chunk = 10 [(nanopb).type = FT_CALLBACK];\n// 生成: pb_callback_t firmware_chunk;\n```\n\n| 策略 | 内存模型 | 适用场景 |\n|------|---------|---------|\n| FT_STATIC (默认) | 编译期固定大小，零 malloc | 配置参数、小型消息 |\n| FT_CALLBACK | 回调式逐块处理 | 大文件传输、流式数据 |\n\n嵌入式配置持久化场景推荐全部使用 FT_STATIC，编译期即可确定内存占用。\n\n### 4.5 varint 编码: 紧凑的秘密\n\nProtocol Buffers 的核心编码是 varint (变长整数):\n\n```\n值        varint 编码      字节数\n0         0x00             1\n127       0x7F             1\n128       0x80 0x01        2\n300       0xAC 0x02        2\n16383     0xFF 0x7F        2\n16384     0x80 0x80 0x01   3\n```\n\n每个字段的编码格式: `[field_number << 3 | wire_type] [varint length/value] [data]`\n\n**与 c-capnproto 固定布局的关键对比**:\n\n```\n// 同一个 struct { uint8_t a; uint32_t b; uint16_t c; }\n\nc-capnproto 存储: 8 字节 (固定，64-bit 对齐)\n+--------+--------+--------+--------+\n| a(1B)  | pad(1B)| c(2B)  | b(4B)  |\n+--------+--------+--------+--------+\n\nnanopb 存储 (a=1, b=100, c=50): 6 字节 (变长)\n+------+------+------+\n|08 01 |10 64 |18 32 |\n+------+------+------+\n a=1    b=100  c=50\n\nnanopb 存储 (a=0, b=0, c=0): 0 字节 (全默认，不编码)\n```\n\n当大量字段保持默认值时 (嵌入式配置的常态)，nanopb 的编码体积可以远小于 c-capnproto。\n\n### 4.6 优缺点分析\n\n**优点:**\n\n- **声明式演进**: 新增字段只需修改 `.proto` 一行，工具自动生成编解码代码\n- **自动版本兼容**: 旧固件忽略未知字段，新固件为缺失字段填充默认值\n- **varint 紧凑编码**: 小值和默认值占用极少空间，文件体积小\n- **跨语言生态**: `.proto` 文件可生成 C/C++/Python/Go/Java 等多语言解析器\n- **ROM 开销小**: nanopb 库本身约 4KB ROM，适合资源受限 MCU\n- **基本安全检查**: 解码时检查字段长度，防止缓冲区溢出\n\n**缺点:**\n\n- **需要完整解码**: 读取任何字段前，必须将整个消息解码到 C 结构体中 (非零拷贝)\n- **整体重写**: 更新配置需要完整编码后写回 (不支持原地修改)\n- **工具链依赖**: 需要 PC 端 protoc 编译器 + nanopb 插件，增加构建复杂度\n- **解码性能低于 TLV**: 需要解析 varint 和 wire type，比纯 memcpy 慢\n- **proto2 vs proto3 选择**: nanopb 推荐 proto2 (支持 required/default)，与主流 proto3 存在差异\n\n## 5. c-capnproto: 零拷贝与固定布局\n\n### 5.1 核心理念\n\n[c-capnproto](https://github.com/opensourcerouting/c-capnproto) 是 Cap'n Proto 的纯 C (C99) 实现。核心理念: **数据在内存中的布局即为最终存储格式 (wire format)**。读取时通过编译期确定的偏移量直接访问字段，跳过了\"解析 -> 拷贝 -> 构建结构体\"步骤。\n\n```bash\n# 声明式开发流程 (类似 nanopb)\ncapnp compile -oc config.capnp\n# 产出: config.capnp.c, config.capnp.h (纯 C，无 C++ 依赖)\n```\n\n> **注意**: capnp 编译器 (capnpc-c) 本身是 C++ 程序，仅在 PC 端运行。生成的代码是纯 C，可直接在 MCU 上编译。\n\n### 5.2 Schema 定义与生成代码\n\n```capnp\n@0xf4b7a151b72a445d;\n\nstruct DeviceConfig {\n  deviceId @0 :Text;\n  sampleRate @1 :UInt32 = 100;      # 采样率，默认 100\n  filterMode @2 :UInt8 = 0;         # 滤波模式\n\n  struct AlgorithmParams {\n    noiseThreshold @0 :Float32 = 0.1;\n    enableOutlierRemoval @1 :Bool = true;\n  }\n  algorithmParams @3 :AlgorithmParams;\n\n  # 新增字段只需在此处声明，自动兼容\n  logLevel @4 :UInt32 = 2;\n}\n```\n\n编译器生成的 C 代码包含结构体定义和读写函数:\n\n```c\n// config.capnp.h (生成代码)\ntypedef struct { capn_ptr p; } DeviceConfig_ptr;\n\nstruct DeviceConfig {\n    uint32_t sampleRate;\n    uint8_t  filterMode;\n    uint32_t logLevel;\n    capn_text deviceId;\n    AlgorithmParams_ptr algorithmParams;\n};\n\n// 生成的 API: 创建、读取、写入\nDeviceConfig_ptr new_DeviceConfig(struct capn_segment *s);\nvoid read_DeviceConfig(struct DeviceConfig *s, DeviceConfig_ptr p);\nvoid write_DeviceConfig(const struct DeviceConfig *s, DeviceConfig_ptr p);\n```\n\n读写函数内部通过 `capn_read8/16/32/64` 直接从 buffer 偏移位置读取，结合 XOR 默认值解码 (见 5.5 节)。\n\n### 5.3 字段 ID 机制与版本兼容\n\nCap'n Proto 使用**显式字段 ID** (`@0`, `@1`, ...) 替代隐式字段顺序:\n\n**ID 管理原则:**\n\n- **唯一性**: 同一 struct 内 ID 必须唯一\n- **稳定性**: 一旦分配，ID 永不改变、永不重用\n- **可跳跃**: 支持非连续 ID，便于后续插入新字段\n- **类型不可变**: 不支持改变已有字段的类型 (如 UInt8 -> UInt16)\n\n**向后兼容 (旧程序读新数据):**\n\n```c\n// 旧程序只知道 @0 和 @1 字段\n// @4 的 logLevel 字段存在于数据中，但旧程序不访问它，不受影响\nstruct DeviceConfig cfg;\nread_DeviceConfig(&cfg, root);\nuint32_t rate = cfg.sampleRate;  // 正常读取\n```\n\n**向前兼容 (新程序读旧数据):**\n\n```c\n// 新程序读取旧数据时，@4 字段在数据中不存在\n// read_DeviceConfig 内部访问时，XOR 零值返回 schema 中定义的默认值 2\nstruct DeviceConfig cfg;\nread_DeviceConfig(&cfg, root);\nuint32_t level = cfg.logLevel;  // 返回默认值 2\n```\n\n### 5.4 零拷贝读取: 固定布局与指针头\n\nCap'n Proto 的 struct 在内存中被分为 **data section** (存放基本类型) 和 **pointer section** (存放引用类型如 Text、List、子 struct)。所有字段在 data section 中的偏移量在编译期确定。\n\n```\nDeviceConfig 在 buffer 中的布局 (8 字节对齐):\n+----------------------------------------------------------+\n| Data Section (基本类型字段)                                |\n| Byte 0-3: sampleRate (UInt32)                            |\n| Byte 4:   filterMode (UInt8)                             |\n| Byte 5-7: padding                                        |\n| Byte 8-11: logLevel (UInt32)                             |\n| Byte 12-15: padding                                      |\n+----------------------------------------------------------+\n| Pointer Section (引用类型字段)                             |\n| Byte 16-23: deviceId 指针头 (8 字节)                      |\n| Byte 24-31: algorithmParams 指针头 (8 字节)               |\n+----------------------------------------------------------+\n```\n\n指针是 Cap'n Proto 实现动态数据和版本兼容的核心机制。每个指针固定 8 字节:\n\n```c\n// 指针头位域布局\nunion wire_pointer_t {\n    uint64_t raw;\n    struct {\n        uint64_t type   : 2;   // 0=struct, 1=list, 2=far pointer\n        uint64_t offset : 30;  // 相对偏移 (单位: 8 字节)\n        uint64_t extra  : 32;  // struct: data/pointer size; list: count\n    } __attribute__((packed));\n};\n```\n\n**跳过未知字段的工作原理**: 当旧固件遇到新版本数据中多出的字段时，虽然不理解其业务含义，但可以解析指针头的 `type`、`offset` 和 `extra`，精确计算出该字段占用的总字节数，从而安全跳过。这使得旧固件能向前兼容新配置文件。\n\n### 5.5 XOR 默认值编码\n\nCap'n Proto 的默认值机制: **字段值在存储时与默认值做 XOR**。\n\n```c\n// 假设 schema 中 sampleRate 的默认值为 100\n// 存储时: stored = actual_value XOR 100\n// 读取时: actual = stored XOR 100\n//\n// 当 actual_value == 100 时: stored = 100 XOR 100 = 0   (零存储)\n// 当 actual_value == 200 时: stored = 200 XOR 100 = 172\n// 当数据缺失 (全零) 时: actual = 0 XOR 100 = 100       (自动返回默认值)\n```\n\n设计优势:\n\n- 零值存储 = 默认配置，无需特殊处理\n- 向前兼容: 新程序读旧数据，缺失字段自动返回默认值\n- 无额外空间开销: 不需要 presence bit 或 optional 标记\n\n### 5.6 内存模型与读取模式\n\nc-capnproto 使用 **arena 分配** 而非逐个 malloc:\n\n```c\n// 静态分配方式: 预分配 segment buffer\nstatic uint8_t seg_buf[1024] __attribute__((aligned(8)));\n\nstruct capn ctx;\nstruct capn_segment seg;\nmemset(seg_buf, 0, sizeof(seg_buf));  // 必须零初始化 (XOR 编码要求)\ncapn_init_malloc(&ctx);\ncapn_append_segment(&ctx, &seg, seg_buf, sizeof(seg_buf));\n```\n\n根据 Flash 访问速度和系统资源，可选择两种读取模式:\n\n```c\n// 模式一: 零拷贝 (Flash 支持字节级随机访问时推荐)\nvoid config_read_zero_copy(const uint8_t *flash_data, size_t size) {\n    struct capn ctx;\n    capn_init_mem(&ctx, flash_data, size, 0);  // 直接使用 Flash 数据\n\n    DeviceConfig_ptr root;\n    root.p = capn_getp(capn_root(&ctx), 0, 0);\n\n    struct DeviceConfig cfg;\n    read_DeviceConfig(&cfg, root);  // 从 buffer 直接读取\n    printf(\"sampleRate = %u\\n\", cfg.sampleRate);\n    capn_free(&ctx);\n}\n\n// 模式二: 全拷贝 (Flash 访问较慢时，先拷贝到 RAM)\nvoid config_read_with_copy(const uint8_t *flash_data, size_t size) {\n    uint8_t *ram_buf = malloc(size);\n    memcpy(ram_buf, flash_data, size);\n\n    struct capn ctx;\n    capn_init_mem(&ctx, ram_buf, size, 0);\n    // ... 后续同零拷贝模式 ...\n    capn_free(&ctx);\n    free(ram_buf);\n}\n```\n\n### 5.7 更新机制\n\nCap'n Proto 是 **write-once, read-many** 设计。Builder 用于一次性构建消息，不支持原地修改:\n\n```c\n// 更新流程: 旧 Reader -> 新 Builder -> 写回 Flash\nstruct capn old_ctx, new_ctx;\n// ... 从 Flash 加载旧数据到 old_ctx ...\n\ncapn_init_malloc(&new_ctx);\nstruct capn_segment *new_seg = capn_append_segment(&new_ctx, ...);\nDeviceConfig_ptr new_root = new_DeviceConfig(new_seg);\n\n// 复制旧值 + 修改目标字段\nstruct DeviceConfig old_cfg, new_cfg;\nread_DeviceConfig(&old_cfg, old_root);\nnew_cfg = old_cfg;                   // 复制所有旧值\nnew_cfg.sampleRate = 200;            // 修改目标字段\nwrite_DeviceConfig(&new_cfg, new_root);\n```\n\n### 5.8 优缺点分析\n\n**优点:**\n\n- **零拷贝读取**: 从 Flash/buffer 直接指针偏移访问字段，O(1) 随机访问\n- **声明式演进**: 修改 .capnp 一行，工具自动处理兼容性\n- **XOR 默认值**: 优雅的缺省机制，无额外空间开销\n- **编译期类型检查**: 生成的访问函数有明确的类型签名\n- **纯 C 实现**: 生成代码无 C++ 依赖，可直接在 MCU 上编译\n\n**缺点:**\n\n- **文件体积偏大**: 固定布局为所有字段预留空间 (64-bit 对齐)，即使未设置也占空间\n- **整体重写**: write-once 设计，更新配置需要 Reader -> Builder -> 写回全量数据\n- **内存短暂翻倍**: 更新时同时持有旧数据和新 Builder\n- **不检查输入边界**: 生成的代码假定输入可信，需在外部添加 CRC 校验\n- **零初始化要求**: 所有 segment buffer 必须零初始化，否则 XOR 编码会读出错误值\n\n## 6. 四方案横向对比\n\n### 6.1 核心特性对比\n\n| 维度 | 裸 struct | 自定义 TLV | nanopb | c-capnproto |\n|------|----------|-----------|--------|-------------|\n| **代码量** | ~20 行 | ~200 行手写 | 库 (~4KB) + 生成代码 | 生成代码 + capn.c |\n| **外部依赖** | 无 | 无 | PC 端 protoc + 插件 | PC 端 capnp 编译器 |\n| **新增字段** | 改 struct + 迁移 | 手动修改 3 处 | 修改 .proto 1 行 | 修改 .capnp 1 行 |\n| **类型安全** | 有 (C 编译器) | 无 (memcpy) | 编译期结构体检查 | 编译期类型检查 |\n| **版本兼容** | **无** | 手动 (跳过未知 type) | 自动 (字段号 + 默认值) | 自动 (字段 ID + XOR) |\n| **读取性能** | **memcpy 最快** | memcpy + switch | 流式解码 (需拷贝) | 零拷贝 O(1) 访问 |\n| **随机访问** | O(1) 直接偏移 | 遍历查找 O(n) | 需完整解码后访问 | **O(1) 直接偏移** |\n| **更新方式** | 整体重写 | 原地更新 | 整体重写 (encode) | 整体重写 (Builder) |\n| **文件体积** | sizeof(struct) | 紧凑 | **紧凑 (varint)** | 偏大 (64-bit 对齐) |\n| **字节序** | 平台相关 | 需手动处理 | varint 天然跨平台 | 小端 + flip 转换 |\n| **输入安全** | 需 CRC 外部校验 | 需自行校验 | 有基本长度检查 | 不检查边界 |\n| **跨语言** | 无 | 无 | **.proto 多语言生成** | .capnp 多语言 |\n\n### 6.2 资源开销对比\n\n| 资源 | 裸 struct | 自定义 TLV | nanopb | c-capnproto |\n|------|----------|-----------|--------|-------------|\n| ROM 占用 | 极小 | < 1 KB | ~4 KB (库) + 生成代码 | 生成代码 + capn.c (~2 KB) |\n| RAM (读取) | sizeof(struct) | sizeof(config_t) | sizeof(config_t) | **零额外** (直接读 buffer) |\n| RAM (更新) | sizeof(struct) | sizeof(config_t) | sizeof(config_t) + 编码 buffer | **2x** (旧 Reader + 新 Builder) |\n| 文件大小 (10 字段，半数默认) | ~60 B | ~80 B | ~40 B | ~120 B |\n\n### 6.3 读取路径对比\n\n```\n裸 struct:\n  Flash -> memcpy -> 直接使用结构体\n                     ↑ 最快，但零兼容\n\n自定义 TLV:\n  Flash -> 读取到 RAM -> 遍历 TLV 块 -> switch/case -> memcpy 到结构体\n                                                        ↑ 需要遍历查找\n\nnanopb:\n  Flash -> 读取到 RAM -> pb_decode() -> 逐字段解码 varint -> 填充结构体\n                                                              ↑ 完整解码\n\nc-capnproto:\n  Flash -> 读取到 RAM (或直接访问) -> 指针偏移 -> 读取字段\n                                                  ↑ 零拷贝，O(1)\n```\n\n### 6.4 整体重写并非性能瓶颈\n\n评估 TLV 原地更新与 nanopb/c-capnproto 整体重写的性能差异时，需要理解 Flash 的物理特性:\n\n- **读取**: 按字节或字进行，速度极快\n- **写入**: 只能将 1 变为 0，不能将 0 变为 1\n- **擦除**: 将整个扇区 (通常 4KB) 恢复为全 1，是唯一能将 0 变回 1 的操作\n\n这意味着**即使只修改一个字节，只要需要将 0 变为 1**，就必须: 读取整个扇区到 RAM -> 修改目标字节 -> 擦除整个扇区 -> 将整个扇区写回。\n\n| 对比维度 | TLV 原地更新 | nanopb/c-capnproto 整体重写 |\n|---------|-------------|---------------------------|\n| 理论写入量 | 极少 (单个字段) | 整个文件 |\n| 实际写入量 | **至少一个扇区 (4KB)** | 整个文件 (通常 < 4KB) |\n| 单点更新 | 读-擦-写一个扇区 | 读-擦-写整个文件 |\n| 多点更新 | 读-擦-写**多个**扇区 | 读-擦-写整个文件 **(一次)** |\n| 原子性 | 难以实现，易产生中间态 | 可结合双区存储保证原子性 |\n\n**关键结论**: 当配置文件小于一个扇区 (4KB，绝大多数嵌入式配置的情况) 时，TLV 的原地更新和整体重写在 Flash 层面的实际开销相同 -- 都是读-擦-写一个扇区。当需要更新分散在多个扇区的字段时，整体重写反而更高效。TLV 的\"原地更新\"优势仅存在于理论上。\n\n这一事实支持 c-capnproto 的选型: 既然 Flash 层面开销相同，那么整体重写带来的简洁性、原子性和版本兼容性就是净收益。\n\n### 6.5 存储鲁棒性\n\n无论使用哪种序列化方案，配置写入 Flash 时都需要解决断电保护问题。通用做法:\n\n- **CRC-32 校验**: 在序列化数据前添加配置头 (magic + version + flags + length + crc32)。加载时先验证 magic 和 CRC，任一不匹配则拒绝使用。c-capnproto 生成的代码不做边界检查，CRC 校验是防止损坏数据被错误解析的最后防线\n- **双区存储 (Dual-bank)**: 新配置写入备用 Bank，CRC 校验通过后切换 active 标记。写入中断电时，另一个 Bank 数据完好。c-capnproto 和 nanopb 的整体重写模式天然适配双区存储\n\n## 7. 版本演进实践\n\n假设需要在配置中新增一个控制激光功率的 `laser_power` 字段。四种方案的修改量和兼容性行为:\n\n### 7.1 裸 struct: 版本号 + 迁移代码\n\n```c\n// V1\ntypedef struct __attribute__((packed)) {\n    uint16_t version;  // = 1\n    uint32_t scan_rate_hz;\n    uint32_t crc32;\n} config_v1_t;\n\n// V2: 新增 laser_power\ntypedef struct __attribute__((packed)) {\n    uint16_t version;  // = 2\n    uint32_t scan_rate_hz;\n    uint8_t  laser_power;  // 新增\n    uint32_t crc32;\n} config_v2_t;\n\n// 加载时需手动迁移\nbool config_load(config_v2_t *cfg) {\n    uint16_t ver;\n    flash_read(CONFIG_ADDR, &ver, sizeof(ver));\n    if (ver == 1) {\n        config_v1_t old;\n        flash_read(CONFIG_ADDR, &old, sizeof(old));\n        cfg->version = 2;\n        cfg->scan_rate_hz = old.scan_rate_hz;\n        cfg->laser_power = 100;  // 手动填默认值\n        config_save(cfg);        // 迁移后写回\n    } else if (ver == 2) {\n        flash_read(CONFIG_ADDR, cfg, sizeof(*cfg));\n    }\n    return true;\n}\n```\n\n每增加一个版本，迁移代码就多一条 `if` 分支。版本积累后维护成本线性增长。\n\n### 7.2 TLV: 手动修改三处\n\n```c\n// 1. 枚举定义 -- 新增\nenum cfg_type { /* ... */ TYPE_LASER_POWER };\n\n// 2. 结构体 -- 新增\ntypedef struct {\n    /* ... */\n    uint8_t laser_power;\n} user_cfg_t;\n\n// 3. 解析函数 -- 新增 case\ncase TYPE_LASER_POWER:\n    memcpy(&config.laser_power, ptr, sizeof(uint8_t));\n    break;\n\n// 4. 序列化函数 -- 新增\ntlv_write(buf, buf_size, TYPE_LASER_POWER,\n          &config.laser_power, sizeof(uint8_t));\n```\n\n兼容性: 新固件可解析旧文件 (手动填默认值)。旧固件遇到新字段会跳过。\n\n### 7.3 nanopb: 修改 .proto 一行\n\n```protobuf\noptional uint32 laser_power = 6 [default = 100];\n```\n\n重新运行 `protoc --nanopb_out=. config.proto`，编解码代码自动更新。\n\n兼容性:\n\n- **新固件读旧数据**: `laser_power` 在旧数据中不存在，`pb_decode` 自动填充默认值 100\n- **旧固件读新数据**: 旧固件不认识字段号 6，自动忽略该字段\n\n### 7.4 c-capnproto: 修改 .capnp 一行\n\n```capnp\nlaserPower @5 :UInt32 = 100;\n```\n\n重新运行 `capnp compile -oc config.capnp`，访问器代码自动更新。\n\n兼容性:\n\n- **新固件读旧数据**: @5 字段在旧数据中不存在，XOR 零值返回默认值 100\n- **旧固件读新数据**: 旧程序不访问 @5 字段，不受影响\n\n### 7.5 演进对比\n\n| 操作 | 裸 struct | TLV | nanopb | c-capnproto |\n|------|----------|-----|--------|-------------|\n| Schema 修改 | 改 struct 定义 | 无 schema | 1 行 | 1 行 |\n| 代码修改 | struct + 迁移函数 | 3-4 处手动 | **0 (自动生成)** | **0 (自动生成)** |\n| 编译期检查 | 有 (C 类型系统) | 无 | 有 (结构体类型) | 有 (访问器签名) |\n| 默认值处理 | 手动逐版本迁移 | 手动 | 自动 (init_default) | 自动 (XOR) |\n| 向后兼容 | 无 (旧数据不可读) | 手动 (跳过) | **自动** | **自动** |\n| 向前兼容 | 无 | 手动 (跳过) | **自动** | **自动** |\n| 人为出错概率 | 高 | 高 | 低 | 低 |\n\n## 8. 总结与选型建议\n\n| 决策点 | 推荐方案 |\n|--------|----------|\n| 配置字段固定、永不变更 | **裸 struct** -- 最简最快 |\n| 配置简单 (< 10 字段)、偶尔变更 | **自定义 TLV** -- 零依赖 |\n| 配置复杂、迭代频繁、多端共享 | **nanopb** -- varint 紧凑 + 跨语言 |\n| 配置加载后频繁随机访问字段 | **c-capnproto** -- 零拷贝 O(1) |\n| 断电保护 | CRC-32 + 双区存储 (四者通用) |\n| 数据来源不可信 | nanopb (有基本校验) + 外部 CRC |\n| 频繁写入场景 | LittleFS 等磨损均衡文件系统 |\n| 长期可维护性 | **nanopb** 或 **c-capnproto** -- 声明式演进 |\n\n四种方案各有定位:\n\n- **裸 struct**: 零开销基线。适合字段固定、永不变更的场景。一旦需要版本兼容，代价急剧上升。\n- **自定义 TLV**: 零依赖的轻量方案。适合字段少且稳定的简单配置。维护成本随字段数量线性增长。\n- **nanopb**: 声明式演进 + varint 紧凑编码 + 跨语言生态。是综合推荐方案 -- 维护成本最低、protobuf 生态最成熟。\n- **c-capnproto**: 零拷贝读取 + O(1) 随机访问。在\"加载一次、频繁读取\"的场景有独特性能优势。Flash 扇区擦除特性决定了整体重写并非性能瓶颈，这使得 c-capnproto 的 write-once 设计不构成实际劣势。\n\n## 参考资料\n\n1. [嵌入式配置数据持久化方案对比 -- 自定义 TLV vs nanopb](https://blog.csdn.net/stallion5632/article/details/150866044)\n2. [nanopb 官方文档](https://jpa.kapsi.fi/nanopb/)\n3. [nanopb GitHub](https://github.com/nanopb/nanopb)\n4. [c-capnproto GitHub](https://github.com/opensourcerouting/c-capnproto)\n5. [Cap'n Proto 官方文档](https://capnproto.org/)\n6. [Protocol Buffers Language Guide](https://protobuf.dev/programming-guides/proto2/)\n",
      "ctime": "1771552650",
      "mtime": "1771552650",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/ewss_embedded_websocket_server.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357893146",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "EWSS: 面向嵌入式 Linux 的轻量级 WebSocket 服务器",
      "brief_content": "从 Simple-WebSocket-Server 重构而来，去掉 ASIO 依赖，用 poll Reactor + 固定 RingBuffer + 状态机实现一个 67KB 二进制、12KB/连接、",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 背景\n\n嵌入式 Linux 设备（激光雷达、机器人控制器、边缘网关）经常需要一个 WebSocket 接口，用于调试面板、远程配置、实时数据推送。现有方案要么太重（Boost.ASIO 体系，二进制 2MB+），要么太简陋（裸 socket 手写帧解析，缺乏状态管理）。\n\n[Simple-WebSocket-Server](https://gitlab.com/eidheim/Simple-WebSocket-Server) 是一个广泛使用的 C++ WebSocket 库，功能完整、接口简洁。但它依赖 ASIO（或 Boost.ASIO），使用 `std::shared_ptr`、`std::ostream`、动态 `std::string` 做帧编码，每条消息都有堆分配。对桌面/服务器场景这不是问题，但在内存受限、要求确定性延迟的嵌入式平台上，这些开销不可接受。\n\n[EWSS](https://github.com/DeguiLiu/ewss)（Embedded WebSocket Server）是对 Simple-WebSocket-Server 的嵌入式重构：去掉 ASIO 依赖，用 `poll()` 单线程 Reactor 替代多线程模型，用固定大小 RingBuffer 替代动态缓冲区，用状态机替代隐式的 ASIO handler 链。目标是在 67KB 二进制、12KB/连接的资源预算内，提供完整的 RFC 6455 WebSocket 协议支持。\n\n项目地址: [https://github.com/DeguiLiu/ewss](https://github.com/DeguiLiu/ewss)\n\n## 架构概览\n\n```\nServer (poll Reactor)\n  |\n  +-- Connection #1 ─┐\n  +-- Connection #2  ├─ 每个连接:\n  +-- Connection #N ─┘\n        RxBuffer (RingBuffer<4096>)\n            | readv 零拷贝接收\n        StateOps (函数指针表)\n            | on_message 回调\n        Application\n            | send()\n        TxBuffer (RingBuffer<8192>)\n            | writev 零拷贝发送\n        TCP Socket (sockpp)\n```\n\n核心设计决策：\n\n- 单线程 Reactor: `poll()` 事件循环，无锁、无上下文切换、Cache 友好\n- 固定内存: 编译期确定的 RingBuffer 大小，运行时零堆分配\n- 状态机驱动: 4 状态 StateOps 函数指针表（Handshaking/Open/Closing/Closed），编译期常量零分配\n- 零拷贝 I/O: `readv` 直接读入 RingBuffer，`writev` 直接从 RingBuffer 发送\n\n## 为什么去掉 ASIO\n\n不是 ASIO 不好，而是嵌入式场景的约束不同。\n\n| 维度 | ASIO 方案 | EWSS 方案 |\n|------|-----------|-----------|\n| 二进制体积 | ~2 MB (含 ASIO 模板实例化) | 67 KB (stripped) |\n| 每连接内存 | 动态，取决于消息大小 | 固定 12 KB (4KB RX + 8KB TX) |\n| 热路径堆分配 | 每消息 `make_shared<SendStream>` | 零 |\n| 线程模型 | 多线程 + strand 序列化 | 单线程，无锁 |\n| 依赖 | Boost.ASIO 或 standalone ASIO | sockpp (仅 TCP 封装) |\n| 异常处理 | 必须开启 | 可选 (`-fno-exceptions`) |\n\n在 ARM Cortex-A 平台上，2MB 二进制意味着更多的 I-Cache miss；动态内存分配意味着不确定的延迟毛刺；多线程意味着锁竞争和上下文切换开销。对于 64 连接以内的嵌入式场景，单线程 `poll()` Reactor 是更合适的选择。\n\n## 核心模块详解\n\n### RingBuffer: 固定内存的循环缓冲\n\nRingBuffer 是整个系统的数据通道。每个连接有两个：RxBuffer (4KB) 接收数据，TxBuffer (8KB) 发送数据。\n\n```cpp\ntemplate <typename T, size_t Size>\nclass alignas(64) RingBuffer {\n public:\n  static constexpr size_t kCapacity = Size;\n\n  bool push(const T* data, size_t len);     // 写入数据\n  size_t peek(T* data, size_t max_len) const; // 读取不移除\n  void advance(size_t len);                  // 消费数据\n\n  // 零拷贝 I/O 接口\n  size_t fill_iovec(struct iovec* iov, size_t max_iov) const;       // writev 发送\n  size_t fill_iovec_write(struct iovec* iov, size_t max_iov) const; // readv 接收\n  void commit_write(size_t len);                                     // readv 后提交\n\n private:\n  alignas(64) std::array<T, kCapacity> buffer_{};\n  size_t read_idx_ = 0;\n  size_t write_idx_ = 0;\n  size_t count_ = 0;\n};\n```\n\n关键设计点：\n\n- `alignas(64)` 缓存行对齐，避免 false sharing\n- `fill_iovec_write` + `commit_write` 配合 `readv`，内核直接写入 RingBuffer 的可写区域，省去一次 `memcpy`\n- `fill_iovec` 配合 `writev`，从 RingBuffer 的读侧直接发送，同样零拷贝\n- 环形缓冲区可能跨越数组边界，`fill_iovec` 返回 1 或 2 个 iovec 段处理 wrap-around\n\n为什么不用 `std::vector` 或 `std::string`？因为它们会在数据增长时 `realloc`，产生不确定延迟和内存碎片。RingBuffer 的所有操作都是 O(1)，内存占用在编译期确定。\n\n### 零拷贝接收路径\n\n传统做法是先 `recv` 到临时缓冲区，再 `memcpy` 到应用缓冲区。EWSS 用 `readv` 直接读入 RingBuffer：\n\n```cpp\nexpected<void, ErrorCode> Connection::handle_read() {\n  struct iovec iov[2];\n  size_t iov_count = rx_buffer_.fill_iovec_write(iov, 2);\n  if (iov_count == 0) {\n    return expected<void, ErrorCode>::error(ErrorCode::kBufferFull);\n  }\n\n  ssize_t n = ::readv(socket_.handle(), iov, static_cast<int>(iov_count));\n  if (n > 0) {\n    rx_buffer_.commit_write(static_cast<size_t>(n));\n    ops_->on_data(*this);\n    return expected<void, ErrorCode>::success();\n  }\n  // ... 错误处理\n}\n```\n\n`fill_iovec_write` 返回 RingBuffer 写侧的 1-2 个连续内存段（处理 wrap-around），`readv` 一次系统调用直接填充，`commit_write` 更新写指针。整个路径零 `memcpy`。\n\n发送路径同理，`fill_iovec` 返回读侧的连续段，`writev` 一次系统调用发送：\n\n```cpp\nexpected<void, ErrorCode> Connection::handle_write_vectored() {\n  struct iovec iov[2];\n  size_t iov_count = tx_buffer_.fill_iovec(iov, 2);\n  if (iov_count == 0) return expected<void, ErrorCode>::success();\n\n  ssize_t n = ::writev(socket_.handle(), iov, static_cast<int>(iov_count));\n  if (n > 0) {\n    tx_buffer_.advance(static_cast<size_t>(n));\n  }\n  // ...\n}\n```\n\n### 协议状态机\n\nWebSocket 连接有 4 个状态，每个状态是一个 `StateOps` 函数指针表：\n\n```\nHandshaking ──(握手成功)──> Open ──(Close 帧)──> Closing ──> Closed\n     |                       |                                  ^\n     +──(超时/错误)──────────+──────(错误)──────────────────────+\n```\n\n```cpp\n// Function pointer types for state operations\nusing StateDataHandler = expected<void, ErrorCode> (*)(Connection& conn);\nusing StateSendHandler = expected<void, ErrorCode> (*)(Connection& conn, std::string_view payload);\nusing StateCloseHandler = expected<void, ErrorCode> (*)(Connection& conn, uint16_t code);\n\nstruct StateOps {\n  ConnectionState state;\n  StateDataHandler on_data;\n  StateSendHandler on_send;\n  StateCloseHandler on_close;\n};\n\n// Compile-time constant state tables (zero allocation, zero virtual)\ninline const StateOps kHandshakeOps = { ConnectionState::kHandshaking, ... };\ninline const StateOps kOpenOps      = { ConnectionState::kOpen, ... };\ninline const StateOps kClosingOps   = { ConnectionState::kClosing, ... };\ninline const StateOps kClosedOps    = { ConnectionState::kClosed, ... };\n```\n\n状态转换通过指针切换实现，不需要 `new`/`delete`，也没有 virtual 开销：\n\n```cpp\nvoid Connection::transition_to_state(ConnectionState state) {\n  switch (state) {\n    case ConnectionState::kOpen:\n      ops_ = &kOpenOps;\n      if (on_open) on_open(shared_from_this());\n      break;\n    case ConnectionState::kClosed:\n      ops_ = &kClosedOps;\n      if (on_close) on_close(shared_from_this(), true);\n      break;\n    // ...\n  }\n}\n```\n\n每个状态只处理自己关心的事件。`kHandshakeOps.on_data` 解析 HTTP Upgrade 请求，`kOpenOps.on_data` 解析 WebSocket 帧，`kClosingOps.on_data` 等待对端 Close 帧。职责清晰，不会出现 if-else 嵌套的状态混乱。\n\n### 帧编码: 栈上完成\n\nWebSocket 帧头最大 14 字节（2 字节基础 + 8 字节扩展长度 + 4 字节掩码）。EWSS 在栈上编码，直接写入 TxBuffer：\n\n```cpp\nvoid Connection::write_frame(std::string_view payload, ws::OpCode opcode) {\n  uint8_t header_buf[14];  // 栈上分配\n  size_t header_len = ws::encode_frame_header(\n      header_buf, opcode, payload.size(), false);\n\n  tx_buffer_.push(header_buf, header_len);\n  if (!payload.empty()) {\n    tx_buffer_.push(\n        reinterpret_cast<const uint8_t*>(payload.data()), payload.size());\n  }\n}\n```\n\n对比 Simple-WebSocket-Server 的做法：\n\n```cpp\n// Simple-WebSocket-Server: 每次发送都堆分配\nauto send_stream = make_shared<SendStream>();\n*send_stream << message_str;  // std::ostream 格式化\nconnection->send(send_stream, callback);\n```\n\n一个是 14 字节栈缓冲 + RingBuffer push，一个是 `shared_ptr` + `ostream` + 堆分配。在嵌入式热路径上，差距是数量级的。\n\n### Server: poll Reactor\n\nServer 的主循环是经典的 Reactor 模式：\n\n```cpp\nvoid Server::run() {\n  while (is_running_) {\n    // 1. 构建 pollfd 数组（预分配，零堆分配）\n    poll_fds_[0] = {server_sock_, POLLIN, 0};\n    for (uint32_t i = 0; i < connections_.size(); ++i) {\n      short events = POLLIN;\n      if (connections_[i]->has_data_to_send()) events |= POLLOUT;\n      poll_fds_[i + 1] = {connections_[i]->get_fd(), events, 0};\n    }\n\n    // 2. poll 等待事件\n    int ret = ::poll(poll_fds_.data(), nfds, poll_timeout_ms_);\n\n    // 3. 处理新连接（含过载保护）\n    if (poll_fds_[0].revents & POLLIN) {\n      if (stats_.is_overloaded(max_connections_)) {\n        // Accept and immediately close to drain kernel backlog\n        int reject_sock = accept(server_sock_, ...);\n        if (reject_sock >= 0) ::close(reject_sock);\n      } else {\n        accept_connection();\n      }\n    }\n\n    // 4. 处理客户端 I/O\n    for (size_t i = 1; i < nfds; ++i) {\n      handle_connection_io(connections_[i - 1], poll_fds_[i]);\n    }\n\n    // 5. 清理已关闭连接（swap-and-pop）\n    remove_closed_connections();\n  }\n}\n```\n\n几个细节：\n\n- `poll_fds_` 是 `std::array<pollfd, 65>`，编译期固定，不需要每轮 `new`\n- `connections_` 是 `FixedVector<ConnPtr, 64>`，栈上分配，swap-and-pop 移除\n- 过载保护：活跃连接超过 90% 容量时，accept 后立即 close，避免资源耗尽\n- 性能监控：原子计数器跟踪 poll 延迟、连接数、错误数\n\n### 词汇类型: 从 newosp 移植\n\nEWSS 的基础类型（`expected`、`optional`、`FixedVector`、`FixedString`、`FixedFunction`、`ScopeGuard`）来自 [newosp](https://github.com/DeguiLiu/newosp) 库，全部栈分配、零堆开销：\n\n| 类型 | 替代 | 用途 |\n|------|------|------|\n| `expected<V, E>` | 异常 / errno | 类型安全错误处理 |\n| `FixedVector<T, N>` | `std::vector` | 连接列表 (N=64) |\n| `FixedFunction<Sig, Cap>` | `std::function` | SBO 回调 |\n| `ScopeGuard` | 手动 cleanup | RAII 资源释放 |\n\n这些类型兼容 `-fno-exceptions -fno-rtti`，适合嵌入式编译配置。\n\n## 性能实测\n\n测试环境：x86-64 Linux (虚拟化)，GCC 13.3.0 -O2 Release，loopback TCP。EWSS 目标平台是 ARM-Linux 嵌入式，x86-64 结果作为基线参考。\n\n### 单客户端吞吐量 (10,000 消息)\n\n| 载荷大小 | 吞吐量 (msg/s) | P50 (us) | P99 (us) |\n|----------|----------------|----------|----------|\n| 8 B      | 27,344         | 35.5     | 55.9     |\n| 64 B     | 27,446         | 35.5     | 54.6     |\n| 128 B    | 26,830         | 36.1     | 58.9     |\n| 512 B    | 25,462         | 37.7     | 61.0     |\n| 1024 B   | 22,084         | 42.5     | 73.8     |\n\n小载荷（8-128B）吞吐量稳定在 ~27K msg/s，说明瓶颈在系统调用开销而非数据拷贝。1KB 载荷下降到 22K msg/s，符合预期。\n\n### 多客户端吞吐量 (64B 载荷)\n\n| 客户端数 | 总吞吐量 (msg/s) | P50 (us) | P99 (us) |\n|----------|------------------|----------|----------|\n| 1        | 27,446           | 35.5     | 54.6     |\n| 4        | 66,731           | 57.8     | 84.9     |\n| 8        | 67,856           | 102.6    | 167.2    |\n\n4 客户端时总吞吐量达到 ~67K msg/s，接近单线程 poll Reactor 的上限。8 客户端时吞吐量不再增长，P99 延迟上升到 167us，这是单线程模型的固有限制——所有连接共享一个事件循环。\n\n### 资源占用\n\n| 指标 | 值 |\n|------|-----|\n| 二进制大小 (stripped) | 67 KB |\n| 库类型 | Header-only (单文件 ~1720 行) |\n| 每连接内存 | ~12 KB (4KB RX + 8KB TX RingBuffer) |\n| 热路径堆分配 | 0 |\n| 最大连接数 (编译期) | 64 |\n\n67KB 二进制 vs Simple-WebSocket-Server 的 ~2MB，差 30 倍。EWSS 是 header-only 单文件库（~1720 行），无需编译静态库。体积差距主要来自 ASIO 的模板实例化和异常处理代码。\n\n### 架构维度对比\n\n| 维度 | EWSS | Simple-WebSocket-Server |\n|------|------|------------------------|\n| I/O 模型 | poll() 单线程 Reactor | ASIO 多线程 |\n| 内存模型 | 固定 RingBuffer (12KB/conn) | 动态 std::string + shared_ptr |\n| 热路径分配 | 零 | 每消息堆分配 |\n| 帧编码 | 栈缓冲 (14B max) | std::ostream + shared_ptr\\<SendStream\\> |\n| 状态机 | StateOps 函数指针表 (零分配, 零 virtual) | 隐式 ASIO handler 链 |\n| Socket I/O | readv/writev 零拷贝 | ASIO async_read/async_write |\n| 依赖 | sockpp (仅 TCP) | Boost.ASIO 或 standalone ASIO |\n| 二进制大小 (stripped) | 67 KB | ~2 MB |\n| TLS 支持 | 可选 mbedTLS | OpenSSL |\n| 目标平台 | ARM-Linux 嵌入式 | 桌面/服务器 |\n| C++ 标准 | C++17 | C++11/14 |\n| 异常处理 | 可选 (-fno-exceptions) | 必须 |\n\nEWSS 在单线程场景下的吞吐量（~27K msg/s 单客户端，~67K msg/s 多客户端）与 Simple-WebSocket-Server 处于同一量级，但资源占用差距显著：67KB vs 2MB 二进制，12KB vs 动态内存每连接，P50 35us / P99 55us 的确定性延迟 vs 受 GC 和堆分配影响的不确定延迟。\n\nSimple-WebSocket-Server 的优势在多核扩展：4 线程池可以线性提升吞吐量，而 EWSS 的单线程模型在 4-8 客户端后就触及上限。这正是两者的设计定位差异——EWSS 优化的是资源受限场景下的确定性，而非吞吐量天花板。\n\n## 设计权衡\n\nEWSS 为嵌入式约束做了明确的取舍：\n\n| 取舍 | EWSS 选择 | 代价 |\n|------|-----------|------|\n| 最大连接数 | 64 (编译期固定) | 不能动态扩展 |\n| 线程模型 | 单线程 | CPU 密集型任务会阻塞所有连接 |\n| 缓冲区大小 | 固定 4KB RX / 8KB TX | 大消息需要分片 |\n| poll vs epoll | poll() | POSIX 可移植，但 O(n) 扫描 |\n| 内存模型 | 全部预分配 | 固定容量，不能按需增长 |\n\n这些取舍在嵌入式场景下是合理的：64 连接足够覆盖调试面板、配置接口、数据推送等典型用途；单线程避免了锁竞争；固定内存消除了碎片化风险。\n\n对于需要数千并发连接和多核扩展的桌面/服务器场景，Simple-WebSocket-Server（或类似 ASIO 方案）仍然是更好的选择。\n\n## Simple-WebSocket-Server 的优势\n\n公平起见，列出 EWSS 做不到而 Simple-WebSocket-Server 能做的：\n\n- 多线程扩展：ASIO 线程池可利用多核\n- 动态缓冲区：处理任意大小的消息\n- 成熟生态：ASIO 集成、OpenSSL TLS\n- URL 路由：正则表达式端点路由\n- 客户端库：内置 WebSocket 客户端\n\n## 测试覆盖\n\nEWSS 目前有 7 个测试套件，119 个测试用例，307 个断言：\n\n- 单元测试：Base64、SHA1、帧解析、RingBuffer、连接状态机、对象池\n- 集成测试：13 个端到端测试（握手、echo、批量消息、二进制、Ping/Pong、关闭、统计、回调）\n- Sanitizer：ASan + UBSan 全部通过\n\n集成测试使用原始 POSIX socket 实现的 WebSocket 客户端，覆盖了从 TCP 连接到 WebSocket 帧收发的完整链路，对标 Simple-WebSocket-Server 的 `io_test.cpp`。\n\n## 快速上手\n\n```bash\ngit clone https://github.com/DeguiLiu/ewss.git\ncd ewss\ncmake -B build -DCMAKE_BUILD_TYPE=Release\ncmake --build build -j\n```\n\n最小 echo 服务器：\n\n```cpp\n#include \"ewss.hpp\"\n\nint main() {\n  ewss::Server server(8080);\n\n  ewss::TcpTuning tuning;\n  tuning.tcp_nodelay = true;\n  server.set_tcp_tuning(tuning);\n\n  server.on_message = [](const auto& conn, std::string_view msg) {\n    conn->send(msg);  // Echo back\n  };\n\n  server.run();\n}\n```\n\n## 设计文档\n\n完整的架构设计、数据流、状态机、回压控制、超时管理等详细设计，参见 [EWSS 设计文档](https://github.com/DeguiLiu/ewss/blob/master/docs/design_zh.md)。\n\n## 适用场景\n\nEWSS 适合这些场景：\n\n- 嵌入式 Linux 设备的 WebSocket 调试/配置接口\n- 资源受限环境（ARM Cortex-A，内存 < 64MB）\n- 对延迟确定性有要求，不能容忍堆分配毛刺\n- 连接数少（< 64），不需要多核扩展\n- 需要最小二进制体积（67KB vs 2MB）\n\n如果你的场景是高并发服务器、需要 TLS、需要 URL 路由，Simple-WebSocket-Server 或其他 ASIO 方案更合适。\n\n项目地址: [https://github.com/DeguiLiu/ewss](https://github.com/DeguiLiu/ewss)\n\n---\n\n> 本文介绍的 EWSS 库基于 MIT 协议开源。\n",
      "ctime": "1771552653",
      "mtime": "1771552653",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/fccu_cpp_software_fault_collector.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853783050",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "fccu-cpp: C++17 Header-Only 软件故障收集器",
      "brief_content": "fccu-cpp 是一个 C++17 header-only 软件 FCCU 组件，复用 newosp 成熟设计模式，基于外部 SPSC ringbuffer 和两层 HSM 构建，零堆分配、裸机友好",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> **仓库**: [fccu-cpp](https://github.com/DeguiLiu/fccu-cpp) |\n> **设计模式来源**: [newosp](https://github.com/DeguiLiu/newosp) fault_collector.hpp\n>\n> **相关文章**: [QPC 事件驱动与活动对象模式](../qpc_active_object_hsm/) |\n> [C 语言 HSM 数据驱动框架](../../pattern/c_hsm_data_driven_framework/) |\n> [mccc 无锁 MPSC 设计](../../performance/mccc_lockfree_mpsc_design/) |\n> [SPSC 环形缓冲设计](../../performance/spsc_ringbuffer_design/)\n\n## 背景\n\n### 什么是 FCCU\n\nFCCU (Fault Collection and Control Unit) 是汽车/工业 MCU 中常见的硬件模块，典型如 NXP S32K3 和 Infineon AURIX TC3xx 系列中的 FCCU 外设。其核心职责:\n\n- 统一收集全系统故障信号 (软件异常、硬件中断、看门狗超时)\n- 按优先级分类缓存、状态维护\n- 根据故障属性自动采取后处理措施 (恢复、降级、关停)\n- 提供故障快照与诊断查询接口\n\n在没有硬件 FCCU 的平台 (通用 ARM-Linux、RTOS、裸机 MCU) 上，用软件实现同等机制是工业嵌入式系统的常见需求。\n\n### 为什么需要软件 FCCU\n\n工业设备 (激光雷达、机器人控制器、边缘网关) 和汽车 ECU 面对的故障场景高度相似:\n\n| 场景 | 故障源 | 处理策略 |\n|------|--------|---------|\n| 传感器掉线 | I2C/SPI 通信超时 | 降级运行 |\n| 电压异常 | ADC 采样越界 | 紧急关停 |\n| 通信丢包 | 序列号跳变 | 重试/升级 |\n| 看门狗超时 | 任务死锁 | 系统复位 |\n| 温度过高 | 热传感器报警 | 降频/关闭负载 |\n\n这些场景的共性需求: 故障去重、优先级排队、Hook 后处理、状态追踪、统计诊断。fccu-cpp 将这些需求封装为一个零依赖的 header-only 组件。\n\n## fccu-cpp 设计\n\nfccu-cpp 的目标: header-only、零堆分配、裸机友好 (无 std::thread)，复用 newosp 中久经测试的设计模式。\n\n### 设计特性\n\n| 特性 | 实现方式 |\n|------|---------|\n| Header-only | 仅 `#include \"fccu/fccu.hpp\"` |\n| 零堆分配 | 所有存储栈/静态分配 |\n| 裸机友好 | 无 `std::thread`，无 OS 依赖 |\n| 编译期配置 | 模板参数: MaxFaults, QueueDepth, QueueLevels, MaxPerFaultHsm |\n| SPSC 线程模型 | 单生产者上报，单消费者处理 |\n| 形式化状态管理 | 两层 HSM，杜绝非法状态组合 |\n| 准入控制 | 4 级阈值，防止低优先级淹没关键故障 |\n\n### 架构全景\n\n```\n                      +---------------------------------------+\n                      |       FaultCollector<Config>           |\n                      |                                       |\n  ReportFault() --->  |  FaultTable    GlobalHsm              |\n                      |  (array)       Idle/Active/            |\n                      |                Degraded/Shutdown       |\n                      |                                       |\n                      |  FaultQueueSet                         |\n                      |  spsc::Ringbuffer per level            |\n                      |  + priority admission control          |\n                      |                                       |\n  ProcessFaults() --> |  HookAction dispatch                   |\n                      |  Handled/Escalate/Defer/Shutdown       |\n                      |                                       |\n                      |  Per-Fault HSM (optional, <=8)         |\n                      |  Dormant->Detected->Active->Cleared    |\n                      |                                       |\n                      |  Atomic bitmap + Stats + Recent ring   |\n                      +-------+---------------+---------------+\n                              |               |\n                       mccc AsyncBus    ztask Scheduler\n                       (optional)       (optional)\n```\n\n### 组件复用关系\n\nfccu-cpp 不重复造轮子，而是组合已有组件:\n\n| 组件 | 仓库 | 在 fccu-cpp 中的角色 |\n|------|------|---------------------|\n| ringbuffer | [DeguiLiu/ringbuffer](https://github.com/DeguiLiu/ringbuffer) | SPSC 队列基础设施 |\n| hsm-cpp | [liudegui/hsm-cpp](https://gitee.com/liudegui/hsm-cpp) | 全局 + Per-Fault 状态机 |\n| mccc | [DeguiLiu/mccc](https://github.com/DeguiLiu/mccc) | 可选故障通知总线 |\n| ztask-cpp | [DeguiLiu/ztask-cpp](https://github.com/DeguiLiu/ztask-cpp) | 可选周期调度 |\n| newosp | [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) | 设计模式来源 (不作为运行时依赖) |\n\n所有依赖通过 CMake FetchContent 自动拉取。\n\n## 关键设计模式\n\nfccu-cpp 从 newosp `fault_collector.hpp` 复用了多个经过 979 条测试验证的模式，并做了裸机适配。\n\n### 1. 优先级准入控制\n\n队列越满，对低优先级越严格:\n\n```cpp\n// fault_queue_set.hpp\ntemplate <typename T, uint32_t Levels = 4U, uint32_t LevelSize = 32U>\nclass FaultQueueSet {\n  static constexpr uint32_t kLowThreshold = (LevelSize * 60U) / 100U;\n  static constexpr uint32_t kMediumThreshold = (LevelSize * 80U) / 100U;\n  static constexpr uint32_t kHighThreshold = (LevelSize * 99U) / 100U;\n\n  bool PushWithAdmission(uint8_t level, const T& item) noexcept {\n    auto current_size = queues_[level].size();\n    uint32_t threshold = LevelSize;\n    switch (level) {\n      case 1U: threshold = kHighThreshold; break;   // High: < 99%\n      case 2U: threshold = kMediumThreshold; break;  // Medium: < 80%\n      case 3U: threshold = kLowThreshold; break;     // Low: < 60%\n      default: break;                                 // Critical: always\n    }\n    if (current_size >= threshold) { return false; }\n    return queues_[level].push(item);\n  }\n};\n```\n\n队列满 60% 时先丢 Low，满 80% 时再丢 Medium，满 99% 时丢 High，Critical 只在物理满时才丢弃。\n\n### 2. 原子位图\n\n`fetch_or` / `fetch_and` + `PopCount64()` 实现高效的活跃故障追踪:\n\n```cpp\n// fccu.hpp\nstatic constexpr uint32_t kBitmapWords = (MaxFaults + 63U) / 64U;\nstd::array<std::atomic<uint64_t>, kBitmapWords> active_bitmap_{};\n\nvoid SetFaultActive(uint16_t fault_index) noexcept {\n  uint32_t word_idx = fault_index / 64U;\n  uint32_t bit_idx = fault_index % 64U;\n  active_bitmap_[word_idx].fetch_or(1ULL << bit_idx, std::memory_order_relaxed);\n}\n\nuint32_t ActiveFaultCount() const noexcept {\n  uint32_t count = 0U;\n  for (uint32_t i = 0U; i < kBitmapWords; ++i) {\n    count += PopCount64(active_bitmap_[i].load(std::memory_order_relaxed));\n  }\n  return count;\n}\n```\n\n256 个故障点只需 4 个 `uint64_t` 字 (32 字节)，`PopCount64` 在 ARMv8 上编译为单条 `cnt` 指令。\n\n### 3. HookAction 四路分发\n\n每个故障可注册回调，返回处理动作:\n\n```cpp\nenum class HookAction : uint8_t {\n  kHandled = 0U,   // 已处理，清除故障活跃位\n  kEscalate = 1U,  // 升级到更高优先级，重新入队\n  kDefer = 2U,     // 保持活跃，稍后处理\n  kShutdown = 3U   // 请求系统关停\n};\n```\n\n`enum class` 保证编译期穷举检查，避免遗漏分支。Escalate 会将故障以更高优先级重新入队，实现故障自动升级。\n\n### 4. FaultReporter 注入点\n\n将故障上报能力注入到子模块，实现编译防火墙:\n\n```cpp\nstruct FaultReporter {\n  FaultReportFn fn = nullptr;\n  void* ctx = nullptr;\n\n  void Report(uint16_t fault_index, uint32_t detail = 0U,\n              FaultPriority priority = FaultPriority::kMedium) const noexcept {\n    if (fn != nullptr) { fn(fault_index, detail, priority, ctx); }\n  }\n};\n\n// 子模块只持有 FaultReporter，不依赖 FaultCollector 头文件\nauto reporter = collector.GetReporter();\nreporter.Report(0U, 0xBEEF, fccu::FaultPriority::kMedium);\n```\n\n16 字节 POD，零间接调用开销。子模块无需 `#include \"fccu/fccu.hpp\"`，只需前向声明 `FaultReporter`。\n\n## 两层 HSM 设计\n\nfccu-cpp 使用 [hsm-cpp](https://gitee.com/liudegui/hsm-cpp) 实现形式化的层次状态机，杜绝非法状态组合。\n\n### 全局 FCCU 状态机\n\n管理整个 FCCU 子系统的运行态:\n\n```\n       FaultReported        CriticalDetected\nIdle ──────────────> Active ───────────────> Degraded\n  ^                    |                        |\n  |    AllCleared      |      DegradeRecovered  |\n  +<───────────────────+<───────────────────────+\n                       |\n                       | ShutdownReq\n                       v\n                    Shutdown\n```\n\n状态语义:\n- **Idle**: 无活跃故障，系统正常\n- **Active**: 有非关键故障在处理\n- **Degraded**: 检测到 Critical 级故障，限制功能\n- **Shutdown**: 收到关停请求，停止故障处理\n\n### Per-Fault 状态机\n\n管理单个关键故障的生命周期 (最多 8 个):\n\n```\n          Detected        Confirmed         RecoveryStart\nDormant ─────────> Detected ──────> Active ─────────────> Recovering\n   ^                                                          |\n   |                          ClearFault                      | RecoveryDone\n   +<──────────────────────── Cleared <───────────────────────+\n```\n\nPer-Fault HSM 的关键设计:\n- `Confirmed` 转换有 guard 条件: `occurrence_count >= threshold`\n- 阈值可配: 抖动频繁的信号设置高阈值 (如温度传感器 threshold=5)\n- 可选绑定: 只对关键故障启用，节省内存\n\n```cpp\n// 绑定 Per-Fault HSM (可选)\ncollector.BindFaultHsm(0U, 3U);  // fault_index=0, threshold=3\n// 连续检测到 3 次后才从 Detected -> Active\n```\n\n## 代码示例\n\n### 基本使用\n\n```cpp\n#include \"fccu/fccu.hpp\"\n\n// 创建收集器: 16 个最大故障点, 8 深队列, 4 个优先级\nfccu::FaultCollector<16, 8, 4> collector;\n\n// 注册故障点\ncollector.RegisterFault(0, 0x1001);  // 温度传感器\ncollector.RegisterFault(1, 0x1002);  // 电压监控\n\n// 注册 Hook\ncollector.RegisterHook(0, [](const fccu::FaultEvent& e, void*) -> fccu::HookAction {\n    printf(\"Fault 0x%04x: detail=0x%x, count=%u\\n\",\n           e.fault_code, e.detail, e.occurrence_count);\n    return fccu::HookAction::kHandled;\n});\n\n// 设置关停回调\ncollector.SetShutdownCallback([](void*) {\n    printf(\"EMERGENCY SHUTDOWN!\\n\");\n});\n\n// 上报故障 (生产者侧)\ncollector.ReportFault(0, 0xDEAD, fccu::FaultPriority::kCritical);\n\n// 处理故障 (消费者侧, 在主循环或 ztask 回调中)\ncollector.ProcessFaults();\n\n// 查询状态\nprintf(\"Active faults: %u\\n\", collector.ActiveFaultCount());\nprintf(\"HSM state: %s\\n\", collector.GetGlobalHsm().IsIdle() ? \"Idle\" : \"Active\");\n```\n\n### mccc 总线集成\n\n故障处理时自动通过消息总线广播通知:\n\n```cpp\n#include \"fccu/fccu.hpp\"\n#include \"mccc/message_bus.hpp\"\n\nstruct FaultNotification {\n  uint16_t fault_index;\n  uint32_t fault_code;\n  uint32_t detail;\n  uint8_t priority;\n};\n\nusing BusPayload = std::variant<FaultNotification>;\nusing Bus = mccc::AsyncBus<BusPayload>;\n\n// 订阅故障通知\nBus& bus = Bus::Instance();\nbus.Subscribe<FaultNotification>([](const Bus::EnvelopeType& env) {\n    if (auto* msg = std::get_if<FaultNotification>(&env.payload)) {\n        printf(\"Bus: fault 0x%04x pri=%u\\n\", msg->fault_code, msg->priority);\n    }\n});\n\n// 设置 FCCU 的总线通知回调\ncollector.SetBusNotifier([](const fccu::FaultEvent& event, void* ctx) {\n    auto* bus = static_cast<Bus*>(ctx);\n    FaultNotification msg{event.fault_index, event.fault_code,\n                          event.detail, static_cast<uint8_t>(event.priority)};\n    bus->Publish(BusPayload{msg}, 0U);\n}, &bus);\n```\n\n### ztask 周期调度\n\n无需手动调用 ProcessFaults()，交给协作式调度器:\n\n```cpp\n#include \"fccu/fccu.hpp\"\n#include \"ztask/task_scheduler.hpp\"\n\nfccu::FaultCollector<16, 8, 4> collector;\nztask::TaskScheduler<8> scheduler;\n\n// 注册周期任务: 每 10ms 处理一次故障队列\nscheduler.Bind(\"fccu_proc\", 10, [](void* ctx) {\n    static_cast<decltype(&collector)>(ctx)->ProcessFaults();\n}, &collector);\n\n// 主循环\nwhile (!collector.IsShutdownRequested()) {\n    scheduler.Tick();\n}\n```\n\n## 测试覆盖\n\nfccu-cpp 包含 38 个 Catch2 测试用例，覆盖:\n\n| 测试类别 | 数量 | 覆盖内容 |\n|---------|------|---------|\n| 注册 | 4 | 正常/重复/越界/Hook 前置检查 |\n| 上报与处理 | 4 | 基本流程/未注册/越界/多优先级 |\n| HookAction | 5 | Handled/Defer/Escalate/Shutdown/Default |\n| 准入控制 | 2 | 低优先级丢弃/Critical 始终准入 |\n| 统计 | 2 | 计数准确性/重置 |\n| 全局 HSM | 4 | 初始状态/转换/恢复/关停 |\n| Per-Fault HSM | 3 | 绑定/槽位限制/完整生命周期 |\n| 清除 | 2 | 单个/全部 |\n| 溢出 | 1 | 回调触发 |\n| 背压 | 1 | 初始等级 |\n| FaultReporter | 2 | 注入点/空指针安全 |\n| 近期故障环 | 1 | 遍历顺序 |\n| 队列独立 | 4 | Push/Pop/优先级序/准入/越界 |\n\n所有测试在 ASan + UBSan 下通过。\n\n## 与 newosp FaultCollector 的关系\n\nfccu-cpp 与 newosp `fault_collector.hpp` 共享设计模式，但定位不同:\n\n| 维度 | newosp FaultCollector | fccu-cpp |\n|------|----------------------|----------|\n| 定位 | 内置模块，服务 newosp 生态 | 独立库，可单独引用 |\n| 队列 | 内置 MPSC CAS 队列 | 外部 ringbuffer (SPSC) |\n| 消费者 | std::thread + condition_variable | 外部调用 ProcessFaults() |\n| 状态管理 | atomic bool | hsm-cpp 两层 HSM |\n| 通知 | 无 | mccc AsyncBus (可选) |\n| 平台 | Linux (依赖 std::thread) | 裸机友好 (无 OS 依赖) |\n\n选择建议:\n- **已使用 newosp 生态**: 直接使用 newosp 内置的 FaultCollector\n- **裸机/RTOS 项目**: 使用 fccu-cpp\n- **需要形式化状态管理**: 使用 fccu-cpp (HSM 保证状态合法性)\n- **多生产者场景**: 使用 newosp (MPSC 队列) 或 fccu-cpp + mccc 前端\n\n## 构建与验证\n\n```bash\n# 基本构建\ncmake -B build -DCMAKE_BUILD_TYPE=Debug\ncmake --build build -j\n\n# 运行测试\ncd build && ctest --output-on-failure\n\n# ASan + UBSan 验证\ncmake -B build -DCMAKE_BUILD_TYPE=Debug \\\n  -DCMAKE_CXX_FLAGS=\"-fsanitize=address,undefined -fno-omit-frame-pointer\"\ncmake --build build -j && ctest --output-on-failure\n\n# 中国大陆加速\ncmake -B build -DFCCU_GITHUB_MIRROR=\"https://ghfast.top/\"\n```\n\n## 总结\n\nfccu-cpp 的核心设计原则:\n\n- **统一收集**: 全系统故障通过 `ReportFault()` 统一入口上报\n- **优先级分流**: 4 级 SPSC 队列 + 准入控制，关键故障不被淹没\n- **Hook 后处理**: Handled/Escalate/Defer/Shutdown 四路分发，灵活可扩展\n- **形式化状态管理**: 两层 HSM 杜绝非法状态组合\n- **零堆分配**: 模板参数化编译期配置，所有存储栈/静态分配\n- **可选集成**: mccc 总线通知和 ztask 周期调度按需引入，不引入不付开销\n",
      "ctime": "1771552656",
      "mtime": "1771552656",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/lmdb_embedded_linux_zero_copy.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651701806",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "LMDB 在嵌入式 Linux 上的实践: 零拷贝读取与内存映射 I/O",
      "brief_content": "LMDB 是基于 B+ 树 + mmap 的嵌入式 KV 数据库，编译产物 < 50KB，零拷贝读取，CoW 断电安全。本文从嵌入式 Linux 视角评估 LMDB 的适用场景（标定数据、设备配置、O",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 1. 结论前置\n\nLMDB (Lightning Memory-Mapped Database) 在嵌入式 Linux 中的定位：**读密集、崩溃安全的 KV 持久化存储**，用于替代以下传统方案：\n\n| 传统方案 | 问题 | LMDB 改进 |\n|----------|------|-----------|\n| 裸文件 (fwrite JSON/INI/bin) | 写到一半断电 = 数据损坏 | CoW 原子写，断电不损坏 |\n| 自定义二进制格式 | 每个项目重新造轮子，难以维护 | 标准 KV API，20 个函数 |\n| SQLite | 300KB+ 体积，SQL 解析开销 | 50KB 体积，直接字节访问 |\n| /etc 配置文件 + fsync | 需要 rename 原子替换技巧 | 内置事务，应用层无需关心 |\n\n**一句话决策规则**：写入频率 < 10 次/秒、单条数据 < 4KB、总量 < 100MB 的持久化 KV 数据，LMDB 是嵌入式 Linux 上的优选。\n\n**典型适用场景**：\n\n- 传感器标定数据（IMU 零偏、相机内参、温度补偿系数）\n- 设备配置参数（网络配置、功能开关、阈值表）\n- OTA 固件元数据（版本号、回滚状态、分区标记）\n\n**明确不适用场景**：\n\n| 场景 | 原因 | 推荐替代 |\n|------|------|---------|\n| 运行日志 | 高频追加 + 只增不删 + 写放大 | 直接写文件 + logrotate |\n| 时序传感器数据 | 单写者瓶颈，写入吞吐不足 | LevelDB / 文件追加 |\n| 频繁更新的大对象 (> 1MB) | CoW 写放大严重 (更新 1MB = 重写 256 页) | 文件系统直存 |\n| 需要 SQL 查询 | 纯 KV，无查询引擎 | SQLite |\n\n> 注意：一次写入、反复读取的大 blob（模型文件、字库）仍然适合 LMDB，零拷贝 mmap 读性能优秀。不适合的是频繁更新的大对象。\n\n---\n\n## 2. 概述\n\n### 2.1 嵌入式 Linux 适用性分析\n\n**平台硬性要求**：\n\n- **MMU**：LMDB 依赖 mmap 系统调用，必须有内存管理单元。Cortex-A 系列（运行 Linux）满足，Cortex-M（无 MMU 裸机）不可用\n- **POSIX 文件系统**：需要 mmap、msync、flock 语义。ext4、F2FS、UBIFS 均可\n- **虚拟地址空间**：32-bit ARM 上数据库上限约 1-2GB（需预留用户空间给应用程序）；64-bit 无此限制\n\n**资源占用**：\n\n| 指标 | 数值 | 说明 |\n|------|------|------|\n| 编译体积 | < 50KB | 单个 C 文件 (lmdb.c + lmdb.h)，交叉编译友好 |\n| 运行时 RAM | 由 OS 管理 | 无独立 buffer pool，数据通过 page cache 按需加载 |\n| 外部依赖 | 零 | 纯 POSIX API，无第三方库 |\n| 守护进程 | 无 | 嵌入式库，链接到应用进程 |\n\n对于资源受限的嵌入式 Linux 设备（128MB RAM、256MB Flash 的网关），LMDB 的资源开销几乎可以忽略。\n\n### 2.2 适合存储的数据类型\n\n#### 传感器标定数据\n\n标定数据是 LMDB 最匹配的场景之一：出厂或现场校准时写入（极低频），运行时高频读取，断电绝不能丢。\n\n```\n写入频率: 极低 (出厂标定 / 现场校准)\n数据量: KB ~ 几十 KB\n读取频率: 高 (启动加载, 运行时查表)\n可靠性: 丢失标定数据 = 设备报废或返厂\n```\n\n典型存储内容：\n\n- IMU 陀螺仪零偏矩阵 (3x3 float, 36 字节)\n- 相机内参/外参 (焦距、畸变系数等)\n- 激光雷达角度校正表 (数百 ~ 数千个校正值)\n- ADC 增益偏移量、温度补偿多项式系数\n\n```c\n// 写入标定数据 (出厂标定工位, 一次性操作)\ntypedef struct {\n    float gyro_bias[3];\n    float accel_bias[3];\n    float cross_coupling[9];\n} ImuCalibration;\n\nImuCalibration calib = { /* 标定结果 */ };\nMDB_val key = { .mv_size = 10, .mv_data = \"imu_calib\" };\nMDB_val val = { .mv_size = sizeof(calib), .mv_data = &calib };\nmdb_put(txn, dbi, &key, &val, 0);\n\n// 读取标定数据 (设备启动时, 零拷贝)\nMDB_val result;\nmdb_get(txn, dbi, &key, &result);\nconst ImuCalibration *p = (const ImuCalibration *)result.mv_data;\n// p 直接指向 mmap 区域, 无 memcpy\n```\n\n#### 设备配置参数\n\n替代传统的 `/etc/device.conf` + `fsync` 方案：\n\n- 网络配置（IP、网关、DNS、NTP 服务器）\n- 功能开关（调试模式、日志级别、传感器使能位）\n- 业务阈值表（报警阈值、滤波参数、采样率）\n\nLMDB 的优势：配置项以 KV 对存储，修改单个配置项是原子操作，不会出现 JSON/INI 文件写到一半断电导致配置全部丢失的问题。\n\n#### OTA / 固件元数据\n\nA/B 分区升级的关键状态数据：\n\n```\n\"fw_current_version\"  → \"2.1.3\"\n\"fw_rollback_version\" → \"2.0.8\"\n\"fw_update_state\"     → COMMITTED / PENDING / ROLLBACK\n\"fw_partition_active\" → \"A\"\n\"fw_md5_a\"            → <16 bytes binary>\n\"fw_md5_b\"            → <16 bytes binary>\n```\n\nCoW 事务保证：版本号和分区标记在同一个事务中原子更新，中途断电回滚到更新前的一致状态，不会出现\"分区标记切换了但版本号没更新\"的情况。\n\n### 2.3 竞品对比：LMDB vs SQLite\n\nSQLite 是嵌入式数据库领域的事实标准，也是 LMDB 最常被比较的方案：\n\n| 维度 | LMDB | SQLite |\n|------|------|--------|\n| 数据模型 | 有序 KV（字节数组） | 关系型（SQL 表） |\n| 编译体积 | ~50KB | ~300KB+ |\n| 读性能 | 零拷贝 mmap，微秒级 | SQL 解析 + B-tree 查找 + memcpy |\n| 写性能 | 中（单写者） | 中-高（WAL 模式并发写） |\n| 并发 | 多读者零锁 + 单写者 | WAL 模式多读者 + 单写者 |\n| 多进程 | 原生支持 | WAL 模式支持 |\n| 崩溃安全 | CoW（天然安全，无恢复流程） | Journal / WAL（需要 recovery） |\n| 查询能力 | 前缀扫描、范围遍历 | 完整 SQL（JOIN、聚合、索引） |\n| API 复杂度 | ~20 个函数 | ~200+ 个函数 |\n| 维护状态 | OpenLDAP 团队，核心维护者 1 人 | Hwaci 公司，商业支持，20+ 年 |\n| 测试覆盖 | 社区测试 + fuzz | 100% MC/DC 覆盖率，数十亿设备验证 |\n\n**选型建议**：\n\n- **只需 KV 存取**（配置、标定、状态快照）→ LMDB：更轻量、读更快、API 更简单\n- **需要结构化查询**（关联查询、条件过滤、聚合统计）→ SQLite：完整 SQL 能力\n- **两者都可以时** → 看团队熟悉度；SQLite 生态更大，文档资料更丰富\n\n### 2.4 工业级代码质量评估\n\n| 维度 | 评估 |\n|------|------|\n| 代码规模 | 约 1.1 万行 C（单文件），一个工程师可完整审计 |\n| 代码标准 | 纯 C99，Valgrind clean，无未定义行为 |\n| 维护方 | OpenLDAP 项目（Howard Chu），持续维护超过 12 年 |\n| 生产部署 | OpenLDAP（全球网络设备）、Monero（区块链）、Caffe（ML）、HyperLedger |\n| 安全记录 | CVE 极少，已知问题均已修复 |\n\n**与 SQLite 工业级标准的差距**：SQLite 拥有航空级测试覆盖（100% MC/DC）和数十亿设备部署验证。LMDB 在形式化验证和测试完备性上不如 SQLite，但代码量仅为其 1/10，核心数据结构（CoW B+ 树）的正确性比 WAL + Journal 更容易推理和审计。\n\n**需关注的风险**：\n\n- 核心维护者单一（Howard Chu），bus factor = 1（但代码量小，社区可接管）\n- 无商业级付费支持\n- 磁盘满、mmap 失败等异常路径的处理不如 SQLite 细致，应用层需做防御性检查\n\n### 2.5 不适合的场景、使用方法与原因\n\n#### 运行日志\n\n```\n特征: 高频追加 (100~10000 条/秒), 只增不删, 定期清理\n```\n\nLMDB 不适合的原因：\n\n1. **单写者锁**：全局一把写锁，高频写入串行化\n2. **CoW 写放大**：每条日志写入触发 B+ 树根到叶路径的页拷贝（3-4 个 4KB 页）\n3. **空间不归还**：删除旧日志后，释放的页只能内部复用（freelist），文件不缩小\n\n**推荐方案**：直接追加写文件（`fwrite` + 定期 `fsync`），配合 `logrotate` 按大小/时间轮转。需要索引查询时用 LevelDB（LSM-tree 对顺序写友好，自动 compaction 回收空间）。\n\n#### 时序传感器原始数据\n\n```\n特征: 高频采样 (1kHz~100kHz), 连续写入, 偶尔批量读取\n```\n\n单写者吞吐成为瓶颈。推荐直接写二进制文件（固定长度记录，按时间戳文件名切分），或使用 LevelDB 按时间戳键存储。\n\n#### 频繁更新的大对象\n\n```\n特征: 单条 Value > 1MB, 反复覆写\n```\n\n更新 1MB Value = CoW 重写约 256 个 4KB 页，写放大严重。推荐文件系统直存（rename 原子替换），LMDB 只存元数据（版本号、路径、MD5）。\n\n> **例外**：一次写入、反复读取的大 blob（AI 模型 < 10MB、字库、固件镜像）仍然适合 LMDB。零拷贝 mmap 读取性能优秀，且 CoW 事务保证模型与元数据原子更新。模型 > 10MB 时推荐文件存模型 + LMDB 存元数据的混合方案。\n\n### 2.6 加密方案\n\nLMDB 不提供内置加密，数据以明文存储在 mmap 文件中。\n\n| 方案 | 实现方式 | 适用场景 |\n|------|---------|---------|\n| **无加密** | 直接使用 | 标定数据、设备配置等非敏感数据（最常见） |\n| **文件系统加密** | dm-crypt / LUKS | 整盘加密，对 LMDB 透明，零拷贝仍有效 |\n| **应用层加密** | 写入前 AES 加密 Value | 仅少量字段需加密（token、密钥索引） |\n\n**嵌入式场景推荐策略**：\n\n- 多数场景下标定数据和设备配置不属于高敏感数据，**无需加密**\n- 需要整机数据保护时（防设备被盗后数据泄露），使用 **dm-crypt 全盘加密**，对应用代码零侵入\n- 仅个别字段敏感（设备证书、认证 token）时，**应用层加密**该字段后再存入 LMDB，避免全盘加密的性能开销\n\n> 注意：应用层加密会破坏零拷贝优势——读出后需 memcpy + 解密。仅对必要字段加密，不要对所有 KV 加密。\n\n---\n\n## 3. 架构原理\n\n### 3.1 核心机制：B+ 树 + mmap + Copy-on-Write\n\nLMDB 的架构可以用三个关键词概括：\n\n```\n                 +------------------+\n                 |    应用进程       |\n                 | mdb_get/mdb_put  |\n                 +--------+---------+\n                          |\n                 +--------v---------+\n                 |   B+ 树索引      |  有序键查找, O(log N)\n                 |   (3-4 层深度)   |\n                 +--------+---------+\n                          |\n                 +--------v---------+\n                 |   mmap 内存映射   |  零拷贝: 读操作返回 mmap 指针\n                 |   (OS page cache)|  无独立 buffer pool\n                 +--------+---------+\n                          |\n                 +--------v---------+\n                 |   Copy-on-Write  |  写时复制: 修改页 → 写新页 → 原子切根\n                 |   (崩溃安全)     |  断电安全: 旧根未被覆盖\n                 +------------------+\n```\n\n**B+ 树**：所有键有序存储在 B+ 树中。典型深度 3-4 层，一次查找 = 3-4 次页访问。支持精确查找、前缀扫描、范围遍历。\n\n**mmap**：整个数据库文件通过 `mmap` 映射到进程虚拟地址空间。读操作（`mdb_get`）返回指向映射区域的指针，无 `memcpy`，这就是\"零拷贝\"的含义。内存管理完全交给 OS page cache，无需应用层调优。\n\n**Copy-on-Write**：这是 LMDB 崩溃安全的核心。写操作不修改现有页，而是：\n\n1. 复制要修改的页（从叶到根的路径）\n2. 在新页上做修改\n3. 最后原子写入新的根页指针\n\n### 3.2 MVCC 并发模型\n\n```\n   写者 (全局唯一)              读者 A              读者 B\n        |                        |                    |\n   +----v----+              +----v----+          +----v----+\n   | 新 B+ 树 |              | 旧 B+ 树 |          | 旧 B+ 树 |\n   | (写入中) |              | (快照 1) |          | (快照 2) |\n   +---------+              +---------+          +---------+\n        |                        |                    |\n   +----v----------------------------------------------------+\n   |                    mmap 共享内存                          |\n   |          (多个版本的页共存, 旧页在无读者引用后回收)        |\n   +----------------------------------------------------------+\n```\n\n- **多读者零锁**：每个读事务看到数据库的一个一致性快照（MVCC），读者之间完全无竞争，无锁、无等待\n- **单写者**：同一时刻只有一个写者可以持有写锁。写操作不阻塞读者，读者也不阻塞写者\n- **多进程安全**：mmap 文件 + 进程间共享 lock.mdb，原生支持多进程并发读\n\n### 3.3 崩溃安全：CoW vs WAL/Journal\n\n传统数据库（SQLite）的崩溃安全依赖 WAL (Write-Ahead Log) 或 Journal：先写日志 → 再改数据 → 崩溃时重放日志恢复。这涉及日志管理、checkpoint、recovery 流程。\n\nLMDB 的 CoW 机制更简单：\n\n```\n写入流程:\n  1. 分配新页, 复制修改路径\n  2. 在新页上写入数据\n  3. fsync (数据落盘)\n  4. 原子更新根指针 (meta page, 交替写两个 meta page)\n  5. fsync (根指针落盘)\n\n断电场景:\n  - 步骤 1-3 中断: 旧根指针未改, 指向旧数据, 完全一致\n  - 步骤 4 中断: meta page 有校验和, 损坏的 meta 被忽略, 回退到上一个有效 meta\n  - 步骤 5 后: 新数据完整可见\n\n结果: 任何时刻断电, 数据库都处于某个完整事务的一致状态, 无需 recovery\n```\n\n这对嵌入式场景的意义：设备掉电后重启，打开 LMDB 数据库即可直接使用，无需扫描日志、无需 recovery 流程、无需等待——启动时间可预测。\n\n### 3.4 存储结构\n\nLMDB 数据库由两个文件组成：\n\n| 文件 | 内容 | 大小 |\n|------|------|------|\n| `data.mdb` | 所有数据 (B+ 树页 + meta page + freelist) | 由 `map_size` 预分配上限 |\n| `lock.mdb` | 读者注册表 + 写锁 (共享内存) | 固定大小，通常 8KB |\n\n`data.mdb` 的页布局：\n\n```\n+------------------+\n| Meta Page 0      |  根指针、事务 ID、DB 统计 (交替更新)\n+------------------+\n| Meta Page 1      |  备份 meta page\n+------------------+\n| B+ 树内部节点页   |  有序键索引\n+------------------+\n| B+ 树叶子节点页   |  实际 KV 数据\n+------------------+\n| Freelist 页      |  已删除数据释放的页 (内部复用)\n+------------------+\n| 未使用空间        |  map_size 预留的增长空间\n+------------------+\n```\n\n页大小默认为 OS 页大小（ARM-Linux 通常 4KB）。`map_size` 是数据库的最大容量上限，需在打开时指定。实际磁盘占用按需增长，但文件一旦增长不会自动缩小（freelist 内部复用）。\n\n---\n\n## 4. 跨平台与 Python 工具链\n\n### 4.1 数据库文件跨平台兼容性\n\nLMDB 数据库文件可以在不同平台之间直接拷贝使用，前提是**字节序一致**：\n\n| 源平台 | 目标平台 | 兼容性 |\n|--------|---------|--------|\n| ARM-Linux (小端) | Windows x86/x64 (小端) | 兼容，直接拷贝 |\n| ARM-Linux (小端) | Linux x86_64 (小端) | 兼容，直接拷贝 |\n| 小端 | 大端 | 不兼容 |\n\n当前主流 ARM (Cortex-A) 和 x86 均为小端，跨平台问题在实际中基本不存在。\n\n应用层数据（Value 中的 struct 二进制）需确保两端使用相同的序列化布局。推荐使用固定宽度类型 + 显式小端序：\n\n```c\n// 跨平台安全的标定数据格式\n#pragma pack(push, 1)\ntypedef struct {\n    uint32_t version;      // 格式版本号\n    float    gyro_bias[3]; // IEEE 754 float, 小端\n    float    accel_bias[3];\n    uint32_t crc32;        // 校验和\n} ImuCalibrationV1;\n#pragma pack(pop)\n```\n\n### 4.2 Python lmdb 库\n\n```bash\npip install lmdb\n```\n\n#### 写入标定数据\n\n```python\nimport lmdb\nimport struct\n\n# 打开数据库 (若不存在则创建)\nenv = lmdb.open('/path/to/calib_db', map_size=1 * 1024 * 1024)  # 1MB 足够\n\n# 写入 IMU 标定数据\nwith env.begin(write=True) as txn:\n    # struct 二进制格式: version(u32) + gyro_bias(3f) + accel_bias(3f) + crc(u32)\n    calib = struct.pack('<I3f3fI',\n        1,                          # version\n        0.00123, -0.00045, 0.00067, # gyro_bias\n        0.015, -0.008, 9.7923,      # accel_bias\n        0x00000000)                  # crc32 (示例)\n    txn.put(b'imu_calib_v1', calib)\n\n    # 也可以存 JSON 字符串 (牺牲零拷贝, 换取可读性)\n    import json\n    config = json.dumps({\"ip\": \"192.168.1.100\", \"mask\": \"255.255.255.0\"})\n    txn.put(b'network_config', config.encode())\n```\n\n#### 读取与遍历\n\n```python\n# 读取单个键\nwith env.begin() as txn:\n    raw = txn.get(b'imu_calib_v1')\n    if raw:\n        values = struct.unpack('<I3f3fI', raw)\n        print(f\"Version: {values[0]}\")\n        print(f\"Gyro bias: {values[1]:.5f}, {values[2]:.5f}, {values[3]:.5f}\")\n        print(f\"Accel bias: {values[4]:.4f}, {values[5]:.4f}, {values[6]:.4f}\")\n\n# 遍历所有键值对\nwith env.begin() as txn:\n    cursor = txn.cursor()\n    for key, value in cursor:\n        print(f\"{key.decode():20s} -> {len(value)} bytes\")\n\n# 查看数据库统计信息\nwith env.begin() as txn:\n    stat = txn.stat()\n    print(f\"Entries: {stat['entries']}, Depth: {stat['depth']}, Page size: {stat['psize']}\")\n```\n\n#### 批量导入/导出（标定工位常用）\n\n```python\ndef export_all(db_path, output_file):\n    \"\"\"导出数据库所有内容为 JSON (标定数据备份)\"\"\"\n    import json, base64\n    env = lmdb.open(db_path, readonly=True)\n    data = {}\n    with env.begin() as txn:\n        cursor = txn.cursor()\n        for key, value in cursor:\n            try:\n                data[key.decode()] = value.decode()  # 尝试文本\n            except UnicodeDecodeError:\n                data[key.decode()] = base64.b64encode(value).decode()  # 二进制 base64\n    with open(output_file, 'w') as f:\n        json.dump(data, f, indent=2)\n\ndef import_from_json(db_path, input_file):\n    \"\"\"从 JSON 导入 (工厂批量标定)\"\"\"\n    import json, base64\n    env = lmdb.open(db_path, map_size=10 * 1024 * 1024)\n    with open(input_file) as f:\n        data = json.load(f)\n    with env.begin(write=True) as txn:\n        for key, value in data.items():\n            txn.put(key.encode(), value.encode())\n```\n\n### 4.3 C API 核心用法\n\n```c\n#include \"lmdb.h\"\n\nint main(void) {\n    MDB_env *env;\n    MDB_dbi dbi;\n    MDB_txn *txn;\n\n    /* 1. 创建并打开环境 */\n    mdb_env_create(&env);\n    mdb_env_set_mapsize(env, 1UL * 1024 * 1024);  /* 1MB */\n    mdb_env_open(env, \"/data/calib_db\", 0, 0664);\n\n    /* 2. 写入 */\n    mdb_txn_begin(env, NULL, 0, &txn);\n    mdb_dbi_open(txn, NULL, 0, &dbi);\n\n    float gyro_bias[3] = {0.00123f, -0.00045f, 0.00067f};\n    MDB_val key = {10, \"gyro_bias\"};\n    MDB_val val = {sizeof(gyro_bias), gyro_bias};\n    mdb_put(txn, dbi, &key, &val, 0);\n    mdb_txn_commit(txn);  /* 原子提交 */\n\n    /* 3. 读取 (零拷贝) */\n    mdb_txn_begin(env, NULL, MDB_RDONLY, &txn);\n    MDB_val result;\n    mdb_get(txn, dbi, &key, &result);\n    const float *p = (const float *)result.mv_data;\n    /* p 直接指向 mmap 区域, 无 memcpy */\n    printf(\"Gyro bias: %.5f, %.5f, %.5f\\n\", p[0], p[1], p[2]);\n    mdb_txn_abort(txn);  /* 只读事务用 abort 释放 */\n\n    /* 4. 关闭 */\n    mdb_dbi_close(env, dbi);\n    mdb_env_close(env);\n    return 0;\n}\n```\n\n编译（交叉编译示例）：\n\n```bash\n# 获取 LMDB 源码 (仅需 lmdb.h + mdb.c + midl.h + midl.c)\n# 与应用代码一起编译, 无需单独构建库\narm-linux-gnueabihf-gcc -O2 -o calib_tool main.c mdb.c midl.c -lpthread\n```\n\n### 4.4 典型工作流：工厂标定工位\n\n```\n  工厂标定工位 (Windows/Linux PC)          嵌入式设备 (ARM-Linux)\n  ================================         =========================\n\n  1. Python 脚本驱动标定流程\n     采集传感器原始数据\n     计算标定参数\n              |\n  2. Python lmdb 写入 data.mdb\n     txn.put(b'imu_calib', struct.pack(...))\n     txn.put(b'cam_intrinsic', struct.pack(...))\n     txn.put(b'device_sn', b'SN20260217001')\n              |\n  3. 通过 SCP/USB/串口 传输\n     data.mdb ─────────────────────> /data/calib_db/data.mdb\n              |                                |\n              |                      4. 设备启动时 C 代码加载\n              |                         mdb_env_open(env, \"/data/calib_db\", ...)\n              |                         mdb_get(txn, dbi, &key, &result)\n              |                         // 零拷贝读取, 微秒级加载\n              |                                |\n  5. 读回验证 (可选)                   6. 运行时使用标定数据\n     scp 拷贝回 PC                       const float *bias = result.mv_data;\n     Python 读取验证校验和                 apply_calibration(bias);\n```\n\n这个工作流的优势：PC 端和设备端使用同一个数据库格式（同为小端），无需定义和维护自定义的导入/导出协议，Python 和 C 通过标准 LMDB API 对接。\n",
      "ctime": "1771552660",
      "mtime": "1771552660",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/mccc_bus_api_reference.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853799434",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "MCCC 消息总线 API 全参考: 类型、接口与配置",
      "brief_content": "MCCC (Message-Centric Component Communication) 消息总线的完整 API 参考，涵盖 FixedString/FixedVector 容器、MessageE",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> **MCCC** (Message-Centric Component Communication) — 面向安全关键嵌入式系统的 Lock-free MPSC 消息总线\n\n## 目录\n\n- [核心概念](#核心概念)\n- [mccc.hpp — 核心定义](#mccchpp--核心定义)\n  - [FixedString\\<N\\>](#fixedstringn)\n  - [FixedVector\\<T, N\\>](#fixedvectort-n)\n  - [MessagePriority](#messagepriority)\n  - [MessageHeader](#messageheader)\n  - [MessageEnvelope\\<PayloadVariant\\>](#messageenvelopepayloadvariant)\n  - [make_overloaded](#make_overloaded)\n  - [FixedFunction\\<Sig, Capacity\\>](#fixedfunctionsig-capacity)\n- [mccc.hpp — 消息总线](#mccchpp--消息总线)\n  - [AsyncBus\\<PayloadVariant\\>](#asyncbuspayloadvariant)\n  - [发布 API](#发布-api)\n  - [订阅 API](#订阅-api)\n  - [处理 API](#处理-api)\n  - [队列状态 API](#队列状态-api)\n  - [性能模式](#性能模式)\n  - [统计信息](#统计信息)\n  - [错误处理](#错误处理)\n- [component.hpp — 组件基类](#componenthpp--组件基类)\n  - [Component\\<PayloadVariant\\>](#componentpayloadvariant)\n- [static_component.hpp — CRTP 零开销组件](#static_componenthpp--crtp-零开销组件)\n- [编译期配置宏](#编译期配置宏)\n- [完整示例](#完整示例)\n\n---\n\n## 核心概念\n\nMCCC 是一个 **Header-only** 的 C++17 消息总线库，核心设计：\n\n| 概念 | 说明 |\n|------|------|\n| **PayloadVariant** | 用户定义的 `std::variant<...>` 消息类型集合 |\n| **AsyncBus** | 单例消息总线，内部使用 Lock-free Ring Buffer |\n| **MessageEnvelope** | 消息信封 = 消息头（ID、时间戳、优先级）+ 载荷 |\n| **Component** | 可选基类，提供安全的订阅生命周期管理 |\n\n**典型用法**:\n\n```cpp\n// 1. 定义消息类型\nstruct SensorData { float temperature; };\nstruct MotorCmd   { int32_t speed; };\n\n// 2. 组合为 variant\nusing MyPayload = std::variant<SensorData, MotorCmd>;\nusing MyBus = mccc::AsyncBus<MyPayload>;\n\n// 3. 订阅\nMyBus::Instance().Subscribe<SensorData>([](const auto& env) {\n    const auto* data = std::get_if<SensorData>(&env.payload);\n    if (data) { /* 处理 */ }\n});\n\n// 4. 发布\nMyBus::Instance().Publish(SensorData{25.5f}, /*sender_id=*/1);\n\n// 5. 消费（需要显式调用）\nMyBus::Instance().ProcessBatch();\n```\n\n---\n\n## mccc.hpp — 核心定义\n\n### FixedString\\<N\\>\n\n栈上固定容量字符串，零堆分配。灵感来源于 iceoryx `iox::string<N>`。\n\n```cpp\ntemplate <uint32_t Capacity>\nclass FixedString;\n```\n\n**模板参数**:\n- `Capacity` — 最大字符数（不含 null 终止符），必须 > 0\n\n#### 构造函数\n\n| 签名 | 说明 |\n|------|------|\n| `FixedString()` | 默认构造，空字符串 |\n| `FixedString(const char (&str)[N])` | 从字符串字面量构造（编译期检查长度） |\n| `FixedString(TruncateToCapacity_t, const char* str)` | 从 C 字符串构造，超长截断 |\n| `FixedString(TruncateToCapacity_t, const char* str, uint32_t count)` | 指定长度构造，超长截断 |\n| `FixedString(TruncateToCapacity_t, const std::string& str)` | 从 std::string 构造，超长截断 |\n\n**截断标记**:\n\n```cpp\n// TruncateToCapacity 强制调用者显式承认可能的数据丢失\nmccc::FixedString<8> name(mccc::TruncateToCapacity, \"very long string\");\n// name == \"very lon\"（被截断到 8 字符）\n```\n\n#### 成员函数\n\n| 方法 | 返回类型 | 说明 |\n|------|---------|------|\n| `c_str()` | `const char*` | 返回 null 终止的 C 字符串 |\n| `size()` | `uint32_t` | 当前字符串长度 |\n| `capacity()` | `uint32_t` | 最大容量（静态） |\n| `empty()` | `bool` | 是否为空 |\n| `clear()` | `void` | 清空字符串 |\n| `assign(TruncateToCapacity_t, const char*)` | `FixedString&` | 截断赋值 |\n| `operator==(const FixedString<M>&)` | `bool` | 比较相等 |\n| `operator!=(const FixedString<M>&)` | `bool` | 比较不等 |\n| `operator==(const char (&)[N])` | `bool` | 与字符串字面量比较 |\n\n---\n\n### FixedVector\\<T, N\\>\n\n栈上固定容量容器，零堆分配。\n\n```cpp\ntemplate <typename T, uint32_t Capacity>\nclass FixedVector;\n```\n\n**模板参数**:\n- `T` — 元素类型\n- `Capacity` — 最大元素数，必须 > 0\n\n#### 成员类型\n\n| 类型 | 定义 |\n|------|------|\n| `value_type` | `T` |\n| `size_type` | `uint32_t` |\n| `iterator` | `T*` |\n| `const_iterator` | `const T*` |\n\n#### 构造 / 析构\n\n| 签名 | 说明 |\n|------|------|\n| `FixedVector()` | 默认构造，空容器 |\n| `~FixedVector()` | 析构，销毁所有元素 |\n| `FixedVector(const FixedVector&)` | 拷贝构造 |\n| `FixedVector(FixedVector&&)` | 移动构造 |\n\n#### 容量\n\n| 方法 | 返回类型 | 说明 |\n|------|---------|------|\n| `empty()` | `bool` | 是否为空 |\n| `size()` | `uint32_t` | 当前元素数 |\n| `capacity()` | `uint32_t` | 最大容量（静态） |\n| `full()` | `bool` | 是否已满 |\n\n#### 修改器\n\n| 方法 | 返回类型 | 说明 |\n|------|---------|------|\n| `push_back(const T&)` | `bool` | 拷贝添加，满时返回 false |\n| `push_back(T&&)` | `bool` | 移动添加，满时返回 false |\n| `emplace_back(Args&&...)` | `bool` | 原地构造，满时返回 false |\n| `pop_back()` | `bool` | 移除末尾元素，空时返回 false |\n| `erase_unordered(uint32_t index)` | `bool` | 无序删除（用最后元素填充），越界返回 false |\n| `clear()` | `void` | 清空所有元素 |\n\n#### 元素访问\n\n| 方法 | 说明 |\n|------|------|\n| `operator[](uint32_t)` | 无边界检查访问 |\n| `front()` / `back()` | 首/尾元素 |\n| `data()` | 底层数组指针 |\n| `begin()` / `end()` | 迭代器 |\n\n---\n\n### MessagePriority\n\n消息优先级，用于背压准入控制。\n\n```cpp\nenum class MessagePriority : uint8_t {\n    LOW    = 0U,   // 队列 >= 60% 满时拒绝\n    MEDIUM = 1U,   // 队列 >= 80% 满时拒绝\n    HIGH   = 2U    // 队列 >= 99% 满时拒绝\n};\n```\n\n**准入阈值**:\n\n```\n队列深度 ─────────────────────────────────────────────────────→ 100%\n          │                    │                │         │\n          0%                  60%              80%       99%\n          │← LOW/MED/HIGH →│← MED/HIGH →│← HIGH →│← 全拒 →│\n```\n\n---\n\n### MessageHeader\n\n消息头，用于追踪和调试。\n\n```cpp\nstruct MessageHeader {\n    uint64_t        msg_id;        // 全局递增 ID\n    uint64_t        timestamp_us;  // 微秒时间戳 (steady_clock)\n    uint32_t        sender_id;     // 发送者标识\n    MessagePriority priority;      // 消息优先级\n};\n```\n\n---\n\n### MessageEnvelope\\<PayloadVariant\\>\n\n消息信封，值类型，直接内嵌在 Ring Buffer 中。\n\n```cpp\ntemplate <typename PayloadVariant>\nstruct MessageEnvelope {\n    MessageHeader  header;\n    PayloadVariant payload;\n};\n```\n\n---\n\n### make_overloaded\n\nC++14 兼容的 `std::visit` 辅助工具（替代 C++17 的类模板推导指南）。\n\n```cpp\ntemplate <class... Ts>\noverloaded<Ts...> make_overloaded(Ts... ts);\n```\n\n**用法**:\n\n```cpp\nusing MyPayload = std::variant<SensorData, MotorCmd>;\nMyPayload msg = SensorData{25.0f};\n\nstd::visit(mccc::make_overloaded(\n    [](const SensorData& s) { /* 处理传感器数据 */ },\n    [](const MotorCmd& m)   { /* 处理电机命令 */ }\n), msg);\n```\n\n---\n\n### FixedFunction\\<Sig, Capacity\\>\n\n栈上固定容量类型擦除 callable，替代 `std::function`。零堆分配，`static_assert` 超容量编译失败。\n\n```cpp\ntemplate <typename Signature, uint32_t Capacity = 48U>\nclass FixedFunction;\n```\n\n**模板参数**:\n- `Signature` — 函数签名，如 `void(int)`, `int(float, float)`\n- `Capacity` — 内联存储字节数（默认 48），callable 超过此大小编译失败\n\n#### 构造函数\n\n| 签名 | 说明 |\n|------|------|\n| `FixedFunction()` | 默认构造，空状态 |\n| `FixedFunction(nullptr_t)` | 空状态 |\n| `FixedFunction(F&& f)` | 从 callable 构造（`static_assert(sizeof(F) <= Capacity)`） |\n| `FixedFunction(FixedFunction&&)` | 移动构造 |\n\n#### 成员函数\n\n| 方法 | 说明 |\n|------|------|\n| `operator bool()` | 是否持有 callable |\n| `operator()(Args...)` | 调用（空时返回 `R{}`） |\n| `operator=(FixedFunction&&)` | 移动赋值 |\n| `operator=(nullptr_t)` | 清空 |\n\n**与 std::function 对比**:\n\n| 特性 | `std::function` | `FixedFunction<Sig, 48>` |\n|------|:---:|:---:|\n| 堆分配 | 可能 (>16B) | **永不** |\n| 超容量行为 | 运行时 malloc | **编译期报错** |\n| 异常路径 | 有 | **无** |\n\n---\n\n## mccc.hpp — 消息总线\n\n### AsyncBus\\<PayloadVariant\\>\n\nLock-free MPSC 消息总线，单例模式。\n\n```cpp\ntemplate <typename PayloadVariant>\nclass AsyncBus;\n```\n\n**模板参数**:\n- `PayloadVariant` — `std::variant<...>`，用户定义的消息类型集合\n\n#### 获取实例\n\n```cpp\nstatic AsyncBus& Instance() noexcept;\n```\n\n每个 `PayloadVariant` 类型有独立的单例实例。\n\n---\n\n### 发布 API\n\n#### Publish\n\n默认优先级（MEDIUM）发布消息。\n\n```cpp\nbool Publish(PayloadVariant&& payload, uint32_t sender_id) noexcept;\n```\n\n| 参数 | 类型 | 说明 |\n|------|------|------|\n| `payload` | `PayloadVariant&&` | 消息载荷（右值引用，零拷贝入队） |\n| `sender_id` | `uint32_t` | 发送者标识 |\n\n**返回值**: `true` 入队成功，`false` 队列满或被准入控制拒绝\n\n#### PublishWithPriority\n\n指定优先级发布消息。\n\n```cpp\nbool PublishWithPriority(PayloadVariant&& payload, uint32_t sender_id,\n                         MessagePriority priority) noexcept;\n```\n\n#### PublishFast\n\n使用外部提供的时间戳发布（避免 `steady_clock::now()` 调用开销）。\n\n```cpp\nbool PublishFast(PayloadVariant&& payload, uint32_t sender_id,\n                 uint64_t timestamp_us) noexcept;\n```\n\n---\n\n### 订阅 API\n\n#### Subscribe\n\n注册类型化的消息回调。\n\n```cpp\ntemplate <typename T, typename Func>\nSubscriptionHandle Subscribe(Func&& func);\n```\n\n| 参数 | 说明 |\n|------|------|\n| `T` | 要订阅的消息类型（必须是 `PayloadVariant` 的成员类型） |\n| `func` | 回调函数，签名 `void(const MessageEnvelope<PayloadVariant>&)` |\n\n**返回值**: `SubscriptionHandle`，用于后续取消订阅。如果回调槽位已满，返回无效 handle（`callback_id == -1`）。\n\n**注意**: 回调在 `ProcessBatch()` 的调用线程中执行。\n\n```cpp\nauto handle = bus.Subscribe<SensorData>([](const auto& env) {\n    const auto* data = std::get_if<SensorData>(&env.payload);\n    if (data) {\n        printf(\"温度: %.1f\\n\", data->temperature);\n    }\n});\n```\n\n#### Unsubscribe\n\n取消订阅。\n\n```cpp\nbool Unsubscribe(const SubscriptionHandle& handle) noexcept;\n```\n\n**返回值**: `true` 成功取消，`false` handle 无效或已被取消\n\n---\n\n### 处理 API\n\n#### ProcessBatch\n\n从 Ring Buffer 中消费并分发消息（单消费者调用）。\n\n```cpp\nuint32_t ProcessBatch() noexcept;\n```\n\n**返回值**: 本次处理的消息数（最多 `BATCH_PROCESS_SIZE = 1024` 条）\n\n**使用模式**:\n\n```cpp\n// 方式 1: 专用消费者线程\nstd::thread consumer([&bus, &running]() {\n    while (running) {\n        bus.ProcessBatch();\n    }\n});\n\n// 方式 2: 主循环轮询\nwhile (true) {\n    bus.ProcessBatch();\n    // ... 其他工作 ...\n}\n```\n\n#### ProcessBatchWith\n\n零开销编译期分发。绕过回调表和 `shared_mutex`，使用 `std::visit` 直接分发。\n\n```cpp\ntemplate <typename Visitor>\nuint32_t ProcessBatchWith(Visitor&& vis) noexcept;\n```\n\n| 参数 | 类型 | 说明 |\n|------|------|------|\n| `vis` | `Visitor&&` | 可调用对象，必须处理 `PayloadVariant` 中所有类型 |\n\n**返回值**: 本次处理的消息数\n\n**与 ProcessBatch 对比**:\n\n| 操作 | ProcessBatch | ProcessBatchWith |\n|------|:---:|:---:|\n| `shared_mutex` 读锁 | 有 | **无** |\n| 回调表遍历 | 有 | **无** |\n| FixedFunction 间接调用 | 有 | **无** |\n| 可内联 | 否 | **是** |\n\n**使用方式**:\n\n```cpp\nauto visitor = mccc::make_overloaded(\n    [](const SensorData& d) { process(d); },\n    [](const MotorCmd& c) { execute(c); }\n);\nbus.ProcessBatchWith(visitor);\n```\n\n---\n\n### 队列状态 API\n\n#### QueueDepth\n\n当前队列中未处理的消息数。\n\n```cpp\nuint32_t QueueDepth() const noexcept;\n```\n\n#### QueueUtilizationPercent\n\n队列利用率百分比 (0-100)。\n\n```cpp\nuint32_t QueueUtilizationPercent() const noexcept;\n```\n\n#### GetBackpressureLevel\n\n获取当前背压级别。\n\n```cpp\nBackpressureLevel GetBackpressureLevel() const noexcept;\n```\n\n```cpp\nenum class BackpressureLevel : uint8_t {\n    NORMAL   = 0U,   // < 75% 满\n    WARNING  = 1U,   // 75-90% 满\n    CRITICAL = 2U,   // 90-100% 满\n    FULL     = 3U    // 100% 满\n};\n```\n\n---\n\n### 性能模式\n\n```cpp\nenum class PerformanceMode : uint8_t {\n    FULL_FEATURED = 0U,   // 完整功能：优先级准入 + 统计 + 错误回调\n    BARE_METAL    = 1U,   // 裸机模式：跳过优先级检查、统计、错误回调\n    NO_STATS      = 2U    // 无统计：保留优先级准入，跳过统计计数\n};\n```\n\n#### SetPerformanceMode\n\n```cpp\nvoid SetPerformanceMode(PerformanceMode mode) noexcept;\n```\n\n**性能对比**:\n\n| 模式 | 吞吐量 (MPSC) | 功能 |\n|------|--------|------|\n| BARE_METAL | ~33.65 M/s (30 ns) | 仅入队出队 |\n| NO_STATS | ~28 M/s | 优先级准入 |\n| FULL_FEATURED | ~26.27 M/s (38 ns) | 全部功能 |\n\n---\n\n### 统计信息\n\n#### GetStatistics\n\n获取统计快照（无锁读取）。\n\n```cpp\nBusStatisticsSnapshot GetStatistics() const noexcept;\n```\n\n```cpp\nstruct BusStatisticsSnapshot {\n    uint64_t messages_published;        // 成功发布的消息总数\n    uint64_t messages_dropped;          // 被拒绝的消息总数\n    uint64_t messages_processed;        // 已处理的消息总数\n    uint64_t processing_errors;         // 处理错误次数\n    uint64_t high_priority_published;   // HIGH 优先级发布数\n    uint64_t medium_priority_published; // MEDIUM 优先级发布数\n    uint64_t low_priority_published;    // LOW 优先级发布数\n    uint64_t high_priority_dropped;     // HIGH 优先级丢弃数\n    uint64_t medium_priority_dropped;   // MEDIUM 优先级丢弃数\n    uint64_t low_priority_dropped;      // LOW 优先级丢弃数\n};\n```\n\n#### ResetStatistics\n\n重置所有统计计数器。\n\n```cpp\nvoid ResetStatistics() noexcept;\n```\n\n---\n\n### 错误处理\n\n#### SetErrorCallback\n\n设置错误回调（函数指针，不是 `std::function`，零开销）。\n\n```cpp\nvoid SetErrorCallback(ErrorCallback callback) noexcept;\n\n// ErrorCallback 类型\nusing ErrorCallback = void (*)(BusError, uint64_t);\n```\n\n```cpp\nenum class BusError : uint8_t {\n    QUEUE_FULL        = 0U,   // 队列满，消息被丢弃\n    INVALID_MESSAGE   = 1U,   // 无效消息\n    PROCESSING_ERROR  = 2U,   // 处理回调异常\n    OVERFLOW_DETECTED = 3U    // 消息 ID 即将溢出\n};\n```\n\n**用法**:\n\n```cpp\nbus.SetErrorCallback([](mccc::BusError err, uint64_t msg_id) {\n    if (err == mccc::BusError::QUEUE_FULL) {\n        LOG_WARN(\"消息 %lu 被丢弃：队列满\", msg_id);\n    }\n});\n\n// 清除回调\nbus.SetErrorCallback(nullptr);\n```\n\n---\n\n## component.hpp — 组件基类\n\n### Component\\<PayloadVariant\\>\n\n可选的组件基类，提供安全的订阅生命周期管理。\n\n```cpp\ntemplate <typename PayloadVariant>\nclass Component : public std::enable_shared_from_this<Component<PayloadVariant>>;\n```\n\n**核心特性**:\n- 析构时自动取消所有订阅（RAII）\n- 使用 `weak_ptr` 防止回调中访问已销毁对象\n- 使用 `FixedVector` 管理订阅句柄，零堆分配\n\n#### SubscribeSafe\n\n安全订阅，回调接收 `shared_ptr<Component>` 作为 self 参数。\n\n```cpp\ntemplate <typename T, typename Func>\nvoid SubscribeSafe(Func&& callback) noexcept;\n```\n\n**回调签名**: `void(shared_ptr<Component>, const T&, const MessageHeader&)`\n\n```cpp\nclass MyComponent : public mccc::Component<MyPayload> {\npublic:\n    static std::shared_ptr<MyComponent> create() {\n        auto ptr = std::shared_ptr<MyComponent>(new MyComponent());\n        ptr->InitializeComponent();\n        ptr->SubscribeSafe<SensorData>(\n            [](std::shared_ptr<Component> self_base,\n               const SensorData& data,\n               const mccc::MessageHeader& hdr) {\n                auto self = std::static_pointer_cast<MyComponent>(self_base);\n                self->OnSensorData(data);\n            });\n        return ptr;\n    }\n\nprivate:\n    MyComponent() = default;\n    void OnSensorData(const SensorData& data) { /* ... */ }\n};\n```\n\n#### SubscribeSimple\n\n简单订阅，回调不接收 self 指针。\n\n```cpp\ntemplate <typename T, typename Func>\nvoid SubscribeSimple(Func&& callback) noexcept;\n```\n\n**回调签名**: `void(const T&, const MessageHeader&)`\n\n#### InitializeComponent\n\n组件初始化（当前为空操作，可扩展）。\n\n```cpp\nvoid InitializeComponent() noexcept;\n```\n\n**注意**: `Component` 必须通过 `std::shared_ptr` 持有（因为继承了 `enable_shared_from_this`），不能在栈上或裸 `new` 构造。\n\n---\n\n## static_component.hpp — CRTP 零开销组件\n\n### StaticComponent\\<Derived, PayloadVariant\\>\n\nCRTP 零开销组件基类，Handler 在编译期静态分发。\n\n```cpp\ntemplate <typename Derived, typename PayloadVariant>\nclass StaticComponent;\n```\n\n**与 Component 对比**:\n\n| 特性 | Component | StaticComponent |\n|------|:---:|:---:|\n| 虚析构函数 | 有 | **无** |\n| shared_ptr / weak_ptr | 有 | **无** |\n| 运行时订阅/退订 | 有 | 无 |\n| Handler 可内联 | 否 | **是** |\n| 适用场景 | 动态订阅 | 编译期确定的处理 |\n\n#### MakeVisitor\n\n创建可传给 `ProcessBatchWith` 的 visitor。\n\n```cpp\nauto MakeVisitor() noexcept;\n```\n\n#### HasHandler\\<Derived, T\\>\n\nSFINAE trait，编译期检测 Derived 是否有 `Handle(const T&)` 方法。\n\n```cpp\ntemplate <typename Derived, typename T>\nstruct HasHandler;  // ::value = true/false\n```\n\n**使用示例**:\n\n```cpp\nclass MySensor : public mccc::StaticComponent<MySensor, MyPayload> {\n public:\n  void Handle(const SensorData& d) noexcept { process(d); }\n  void Handle(const MotorCmd& c) noexcept { execute(c); }\n  // LogMsg 未处理 -> 编译期忽略\n};\n\nMySensor sensor;\nauto visitor = sensor.MakeVisitor();\nbus.ProcessBatchWith(visitor);\n```\n\n---\n\n## 编译期配置宏\n\n在 `#include <mccc/mccc.hpp>` **之前**定义这些宏来自定义配置：\n\n| 宏 | 默认值 | 说明 |\n|----|--------|------|\n| `MCCC_QUEUE_DEPTH` | 131072 (128K) | Ring Buffer 深度，**必须是 2 的幂** |\n| `MCCC_CACHELINE_SIZE` | 64 | 缓存行大小（字节） |\n| `MCCC_SINGLE_PRODUCER` | 0 | SPSC wait-free 快速路径 (1 = 跳过 CAS) |\n| `MCCC_SINGLE_CORE` | 0 | 单核模式 (1 = 关闭缓存行对齐 + relaxed + signal_fence) |\n| `MCCC_MAX_MESSAGE_TYPES` | 8 | variant 中最大消息类型数 |\n| `MCCC_MAX_CALLBACKS_PER_TYPE` | 16 | 每种消息类型的最大回调数 |\n| `MCCC_MAX_SUBSCRIPTIONS_PER_COMPONENT` | 16 | 每个组件的最大订阅数 |\n\n**示例**:\n\n```cpp\n#define MCCC_QUEUE_DEPTH 65536U           // 64K 队列\n#define MCCC_MAX_MESSAGE_TYPES 4U         // 仅 4 种消息类型\n#define MCCC_MAX_CALLBACKS_PER_TYPE 8U    // 每类最多 8 个回调\n#include <mccc/mccc.hpp>\n```\n\n---\n\n## 完整示例\n\n### 最小可运行示例\n\n```cpp\n#include <mccc/mccc.hpp>\n#include <cstdio>\n\nstruct Temperature { float celsius; };\nstruct Humidity    { float percent; };\n\nusing Payload = std::variant<Temperature, Humidity>;\nusing Bus = mccc::AsyncBus<Payload>;\n\nint main() {\n    auto& bus = Bus::Instance();\n\n    // 订阅\n    bus.Subscribe<Temperature>([](const auto& env) {\n        const auto* t = std::get_if<Temperature>(&env.payload);\n        if (t) printf(\"温度: %.1f°C\\n\", t->celsius);\n    });\n\n    bus.Subscribe<Humidity>([](const auto& env) {\n        const auto* h = std::get_if<Humidity>(&env.payload);\n        if (h) printf(\"湿度: %.1f%%\\n\", h->percent);\n    });\n\n    // 发布\n    bus.Publish(Temperature{25.5f}, /*sender_id=*/1);\n    bus.Publish(Humidity{60.0f}, /*sender_id=*/2);\n\n    // 消费\n    bus.ProcessBatch();\n\n    return 0;\n}\n```\n\n### 多线程生产者-消费者\n\n```cpp\n#include <mccc/mccc.hpp>\n#include <atomic>\n#include <thread>\n\nstruct SensorReading { uint32_t sensor_id; float value; };\nusing Payload = std::variant<SensorReading>;\nusing Bus = mccc::AsyncBus<Payload>;\n\nint main() {\n    auto& bus = Bus::Instance();\n    bus.SetPerformanceMode(Bus::PerformanceMode::FULL_FEATURED);\n\n    std::atomic<uint64_t> processed{0};\n\n    bus.Subscribe<SensorReading>([&processed](const auto& env) {\n        processed.fetch_add(1, std::memory_order_relaxed);\n    });\n\n    // 消费者线程\n    std::atomic<bool> running{true};\n    std::thread consumer([&]() {\n        while (running.load(std::memory_order_acquire)) {\n            bus.ProcessBatch();\n        }\n        while (bus.ProcessBatch() > 0) {}  // 排空\n    });\n\n    // 多个生产者\n    std::vector<std::thread> producers;\n    for (uint32_t id = 0; id < 4; ++id) {\n        producers.emplace_back([&bus, id]() {\n            for (int i = 0; i < 10000; ++i) {\n                bus.Publish(SensorReading{id, static_cast<float>(i)}, id);\n            }\n        });\n    }\n\n    for (auto& p : producers) p.join();\n\n    // 等待消费完成\n    std::this_thread::sleep_for(std::chrono::milliseconds(100));\n    running.store(false, std::memory_order_release);\n    consumer.join();\n\n    printf(\"处理了 %lu 条消息\\n\", processed.load());\n    return 0;\n}\n```\n\n### 背压监控\n\n```cpp\nauto bp = bus.GetBackpressureLevel();\nswitch (bp) {\n    case mccc::BackpressureLevel::NORMAL:\n        break;  // 正常\n    case mccc::BackpressureLevel::WARNING:\n        LOG_WARN(\"队列 75%%+ 满，考虑降低发布速率\");\n        break;\n    case mccc::BackpressureLevel::CRITICAL:\n        LOG_ERROR(\"队列 90%%+ 满，LOW 消息正在被丢弃\");\n        break;\n    case mccc::BackpressureLevel::FULL:\n        LOG_ERROR(\"队列已满，所有消息被丢弃\");\n        break;\n}\n```\n\n---\n\n## SubscriptionHandle\n\n```cpp\nstruct SubscriptionHandle {\n    size_t type_index;   // 消息类型索引\n    size_t callback_id;  // 回调 ID\n};\n```\n\n调用 `Subscribe` 返回，传给 `Unsubscribe` 取消订阅。无效 handle 的 `callback_id == static_cast<size_t>(-1)`。\n\n",
      "ctime": "1771552663",
      "mtime": "1771552663",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/mccc_bus_cpp17_practice.md": {
    "err_no": 0,
    "data": {
      "id": "7607636614357909530",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "从 C++14 到 C++17: mccc-bus 的四项零堆分配改造",
      "brief_content": "MCCC 系列第三篇。以 C++14 消息总线的四大堆分配瓶颈为出发点，逐项展示 C++17 的替代方案: std::function -> FixedFunction (SBO + static_a",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 源码仓库: [mccc-bus](https://gitee.com/liudegui/mccc-bus) | 本文代码引用基于 mccc-bus v2.0.0\n>\n> 前篇: [C++14 消息总线的工程优化与性能瓶颈分析](../cpp14_message_bus_optimized/)\n>\n> MCCC 的设计决策后来被 [newosp](https://github.com/DeguiLiu/newosp) 框架采纳并演化。\n\n## 背景: C++14 版本留下的四个堆分配瓶颈\n\n在 [前篇](../cpp14_message_bus_optimized/) 中，我们用 C++14 实现了一个正确的消息总线 (锁外回调、单 mutex、joinable 线程)，但性能测试暴露了根本性瓶颈:\n\n| 瓶颈 | C++14 实现 | 问题 |\n|------|-----------|------|\n| 回调存储 | `std::function` | SBO 仅 16B，超出则堆分配 |\n| 消息路由 | `std::map<int, vector>` | O(log N) 查找，节点分散堆上 |\n| 订阅管理 | `shared_ptr<SubscriptionItem>` | 原子引用计数，cache line bouncing |\n| 数据容器 | `std::string` / `std::vector` | 动态分配，长度运行时才知道 |\n\n多线程 (8 线程) 吞吐量仅 0.36 M/s，比单线程还低 36%。本文逐项展示 C++17 如何消除这些瓶颈，最终将吞吐量提升到 27-33 M/s。\n\n---\n\n## 一、std::function -> FixedFunction: 栈上类型擦除\n\n### 1.1 问题: std::function 的隐式堆分配\n\nC++14 版本的每次 `publishMessage` 都可能触发堆分配:\n\n```cpp\n// C++14 版本 -- 两处潜在堆分配\nstd::vector<MessageCallback> pendingCallbacks;          // vector 扩容\npendingCallbacks.push_back(item->messageCallback);      // function 拷贝\n```\n\n`std::function` 的 SBO (Small Buffer Optimization) 阈值在 libstdc++ 中仅 16 字节。一个捕获了 `this` 加两个成员变量的 lambda 就可能超出，静默触发 `malloc`。\n\n### 1.2 方案: FixedFunction 编译期容量保证\n\nmccc-bus 实现了 `FixedFunction<Sig, Capacity>`，将 SBO 容量提升到 64 字节，超容量在编译期直接拒绝:\n\n```cpp\n// mccc.hpp -- FixedFunction 核心结构\ntemplate <typename Sig, uint32_t Capacity = 64U>\nclass FixedFunction;\n\ntemplate <typename R, typename... Args, uint32_t Capacity>\nclass FixedFunction<R(Args...), Capacity> {\n    // 栈上存储，永不堆分配\n    alignas(std::max_align_t) uint8_t storage_[Capacity]{};\n\n    // 函数指针三元组替代虚函数表\n    using InvokeFn  = R (*)(void*, Args&&...);\n    using DestroyFn = void (*)(void*);\n    using MoveFn    = void (*)(void*, void*);\n    InvokeFn  invoke_fn_{nullptr};\n    DestroyFn destroy_fn_{nullptr};\n    MoveFn    move_fn_{nullptr};\n\npublic:\n    template <typename F>\n    FixedFunction(F&& f) noexcept {\n        using Decayed = std::decay_t<F>;\n        // 编译期拒绝超容量 callable\n        static_assert(sizeof(Decayed) <= Capacity,\n            \"Callable exceeds FixedFunction capacity\");\n        static_assert(alignof(Decayed) <= alignof(std::max_align_t),\n            \"Callable alignment exceeds max_align_t\");\n        new (storage_) Decayed(std::forward<F>(f));\n        // ... 设置函数指针三元组\n    }\n};\n```\n\n关键设计:\n\n- **编译期容量检查**: `static_assert(sizeof(Decayed) <= Capacity)` 确保永不堆分配\n- **函数指针 Ops 表**: `invoke/destroy/move` 三个函数指针替代虚基类，消除 vtable 间接寻址\n- **`-fno-exceptions` 兼容**: 不依赖 `std::bad_function_call`，空调用返回默认值\n\n### 1.3 对比\n\n| 特性 | `std::function` | `FixedFunction<Sig, 64>` |\n|------|:---:|:---:|\n| 堆分配 | 可能 (>16B) | **永不** |\n| 超容量行为 | 运行时 malloc | **编译期报错** |\n| 异常路径 | `bad_function_call` | **无** |\n| 间接调用 | vtable | **函数指针** |\n| `-fno-rtti` | 不兼容 | **兼容** |\n\n### 1.4 C++17 特性支撑\n\n- `std::decay_t<F>` (C++14 引入，C++17 广泛使用)\n- `if constexpr` 用于编译期分支选择不同的 invoke 路径\n- `std::invoke_result_t` 替代 C++14 的 `std::result_of`\n\n---\n\n## 二、unordered_map -> VariantIndex + 固定数组\n\n### 2.1 问题: 哈希表的不确定延迟\n\nC++14 版本用 `std::map` (红黑树) 做消息路由:\n\n```cpp\n// C++14 版本\nstd::map<int32_t, std::vector<SubscriptionItemPtr>> callbackMap_;\nauto it = callbackMap_.find(messageId);  // O(log N)，节点分散堆上\n```\n\n即使换成 `std::unordered_map`，哈希冲突时仍退化为链表遍历，延迟不可预测。两者都依赖堆分配。\n\n### 2.2 方案: 编译期类型索引 + std::array\n\nmccc-bus 利用 `std::variant` 在编译期将类型映射为固定索引:\n\n```cpp\n// 编译期递归: 将类型 T 映射为 variant 中的索引\ntemplate <typename T, size_t I, typename First, typename... Rest>\nstruct VariantIndexImpl<T, I, std::variant<First, Rest...>> {\n    static constexpr size_t value =\n        std::is_same_v<T, First>\n            ? I\n            : VariantIndexImpl<T, I + 1U, std::variant<Rest...>>::value;\n};\n\n// 类型不在 variant 中 -> 编译失败\ntemplate <typename T, typename... Types>\nstruct VariantIndex<T, std::variant<Types...>> {\n    static constexpr size_t value =\n        detail::VariantIndexImpl<T, 0U, std::variant<Types...>>::value;\n    static_assert(value != static_cast<size_t>(-1),\n        \"Type not found in PayloadVariant\");\n};\n```\n\n回调表从哈希表变为固定大小数组:\n\n```cpp\n// 运行时分发退化为数组下标访问 -- O(1) 且完全确定\nstd::array<CallbackSlot, MCCC_MAX_MESSAGE_TYPES> callback_table_;\n\ntemplate <typename T, typename Func>\nSubscriptionHandle Subscribe(Func&& func) {\n    constexpr size_t type_idx = VariantIndex<T, PayloadVariant>::value;\n    static_assert(type_idx < MCCC_MAX_MESSAGE_TYPES,\n        \"Type index exceeds MCCC_MAX_MESSAGE_TYPES\");\n    // callback_table_[type_idx] -- 一次数组下标访问\n}\n```\n\n### 2.3 overloaded + std::visit: 分支遗漏编译期报错\n\n`std::variant` 配合 `std::visit` 实现穷举检查:\n\n```cpp\ntemplate <class T, class... Ts>\nstruct overloaded<T, Ts...> : T, overloaded<Ts...> {\n    using T::operator();\n    using overloaded<Ts...>::operator();\n    explicit overloaded(T t, Ts... ts)\n        : T(std::move(t)), overloaded<Ts...>(std::move(ts)...) {}\n};\n```\n\n新增消息类型后，所有 `std::visit` 点如果未补全分支，编译器直接拒绝。C++14 的 `switch(messageId)` 缺少 `case` 只是 `-Wswitch` 警告，不是错误。\n\n### 2.4 对比\n\n| 特性 | `std::map` / `unordered_map` | VariantIndex + `std::array` |\n|------|:---:|:---:|\n| 查找复杂度 | O(log N) / O(1) 平均 | **O(1) 确定** |\n| 堆分配 | 节点/桶分配 | **零** (栈上固定数组) |\n| 类型安全 | 运行时 int key | **编译期类型索引** |\n| 新增类型 | 运行时发现遗漏 | **编译期报错** |\n\n---\n\n## 三、shared_ptr -> Envelope 内嵌 Ring Buffer\n\n### 3.1 问题: shared_ptr 的原子计数开销\n\nC++14 版本用 `shared_ptr` 管理订阅生命周期:\n\n```cpp\n// C++14 版本\nusing SubscriptionItemPtr = std::shared_ptr<SubscriptionItem>;\n// 每次拷贝/销毁: atomic fetch_add/fetch_sub -> cache line bouncing\n```\n\n在高频发布路径上，`shared_ptr` 的拷贝和销毁产生大量原子操作，多核间的缓存行乒乓严重影响吞吐量。\n\n### 3.2 方案: Envelope 直接内嵌到 Ring Buffer 槽位\n\nmccc-bus 将消息封装 (`MessageEnvelope`) 直接内嵌到 Ring Buffer 中:\n\n```cpp\n// 消息信封 -- 内嵌在 Ring Buffer 槽位中\ntemplate <typename PayloadVariant>\nstruct MessageEnvelope {\n    MessageHeader header;       // ID, 时间戳, 优先级\n    PayloadVariant payload;     // std::variant<SensorData, MotorCmd, ...>\n    // defaulted move，零拷贝发布\n};\n\n// Ring Buffer 槽位 -- envelope 直接内嵌，非指针\nstruct MCCC_ALIGN_CACHELINE RingBufferNode {\n    std::atomic<uint32_t> sequence{0U};\n    MessageEnvelope<PayloadVariant> envelope;  // 内嵌，非 shared_ptr\n};\n```\n\n发布路径零堆分配:\n\n```cpp\n// 生产者直接写入预分配槽位\nauto& node = ring_buffer_[prod_pos & (QueueDepth - 1U)];\nnode.envelope.payload = std::move(payload);  // move 到预分配内存\nnode.sequence.store(prod_pos + 1U, std::memory_order_release);\n```\n\n### 3.3 对比\n\n| 特性 | `shared_ptr` 管理 | Envelope 内嵌 |\n|------|:---:|:---:|\n| 每次发布的堆分配 | 1-2 次 (`make_shared` + vector 扩容) | **零** |\n| 引用计数开销 | atomic fetch_add/sub | **无** |\n| 数据局部性 | 指针追踪，缓存不友好 | **连续内存，Cache 友好** |\n| 生命周期 | 运行时引用计数 | **Ring Buffer 槽位复用** |\n\n---\n\n## 四、std::string/vector -> FixedString/FixedVector\n\n### 4.1 问题: 动态容器在热路径上的堆分配\n\nC++14 版本用标准容器存储消息数据:\n\n```cpp\n// C++14 版本\nstd::vector<uint8_t> messageContent;    // 堆分配\nstd::vector<int32_t> subscribedMessageIds;  // 堆分配\n```\n\n每次构造和销毁都可能触发 `malloc`/`free`，在高频路径上不可接受。\n\n### 4.2 方案: 编译期固定容量的栈上容器\n\nmccc-bus 实现了 `FixedString<N>` 和 `FixedVector<T, N>`:\n\n```cpp\n// FixedString -- 编译期字面量长度检查\ntemplate <uint32_t Capacity>\nclass FixedString {\n    char buf_[Capacity + 1U]{};\n    uint32_t size_{0U};\n\npublic:\n    // 模板参数 N 在编译期获取字符串字面量长度\n    template <uint32_t N,\n              typename = std::enable_if_t<(N <= Capacity + 1U)>>\n    FixedString(const char (&str)[N]) noexcept : size_(N - 1U) {\n        static_assert(N > 0U, \"String literal must include null terminator\");\n        static_assert(N - 1U <= Capacity, \"String literal exceeds capacity\");\n        std::memcpy(buf_, str, N);\n    }\n};\n\n// FixedVector -- 栈上固定容量\ntemplate <typename T, uint32_t Capacity>\nclass FixedVector {\n    alignas(T) uint8_t storage_[sizeof(T) * Capacity]{};\n    uint32_t size_{0U};\n\npublic:\n    bool push_back(const T& value) noexcept {\n        if (size_ >= Capacity) return false;  // 容量满返回 false，不抛异常\n        new (&data()[size_]) T(value);\n        ++size_;\n        return true;\n    }\n    // move 构造/赋值: defaulted\n};\n```\n\n### 4.3 编译期长度检查的价值\n\n`FixedString` 通过模板参数 `N` 在编译期获取字符串字面量的长度:\n\n```cpp\nFixedString<8> topic(\"sensor\");    // OK: 6 <= 8\nFixedString<4> topic(\"sensor\");    // 编译失败: \"String literal exceeds capacity\"\n```\n\nC 的 `strncpy(buf, \"sensor\", sizeof(buf))` 在超长时静默截断，不报任何错误。\n\n### 4.4 对比\n\n| 特性 | `std::string` / `std::vector` | `FixedString` / `FixedVector` |\n|------|:---:|:---:|\n| 内存分配 | 堆 (SSO 仅 15-22B) | **栈** (编译期固定) |\n| 超容量行为 | 运行时扩容或抛异常 | **编译期报错 / 返回 false** |\n| 类型安全 | `FixedString<32>` 和 `<64>` 是**不同类型** | 不同容量可混用 |\n| 拷贝优化 | 运行时 `memcpy` | 编译器已知长度，可替换为 `mov` 指令序列 |\n\n---\n\n## 五、C++17 特性在四项改造中的作用\n\n上述四项改造不是孤立的替换，它们依赖 C++17 的几个关键特性协同工作:\n\n### 5.1 std::variant -- 编译期类型路由的基础\n\n`std::variant` (C++17) 替代 C++14 的 `union` + 手动标签:\n\n```cpp\n// C++14: 手动标签 + union，运行时才发现类型错误\nstruct Message { int tag; union { SensorData s; MotorCmd m; }; };\n\n// C++17: variant，编译期类型安全\nusing Payload = std::variant<SensorData, MotorCmd>;\n// 访问错误类型 -> 编译期报错或运行时 bad_variant_access\n```\n\n### 5.2 if constexpr -- 编译期分支消除\n\nFixedFunction 内部使用 `if constexpr` 选择不同的调用路径:\n\n```cpp\ntemplate <typename F>\nvoid assign(F&& f) noexcept {\n    using Decayed = std::decay_t<F>;\n    if constexpr (std::is_trivially_copyable_v<Decayed>) {\n        std::memcpy(storage_, &f, sizeof(Decayed));\n        // trivially copyable: 不需要 destroy/move 函数\n    } else {\n        new (storage_) Decayed(std::forward<F>(f));\n        destroy_fn_ = &destroy_impl<Decayed>;\n        move_fn_ = &move_impl<Decayed>;\n    }\n}\n```\n\nC++14 需要 SFINAE + 两个重载函数实现同样的效果，代码量翻倍。\n\n### 5.3 std::is_same_v / std::enable_if_t -- 简化模板元编程\n\nC++17 的变量模板和别名模板减少了样板代码:\n\n```cpp\n// C++14\nstd::is_same<T, First>::value\ntypename std::enable_if<condition>::type\n\n// C++17\nstd::is_same_v<T, First>\nstd::enable_if_t<condition>\n```\n\n### 5.4 enum class + static_assert -- 编译期约束\n\n```cpp\nenum class MessagePriority : uint8_t { LOW, MEDIUM, HIGH };\nenum class BusError : uint8_t { QUEUE_FULL, INVALID_MESSAGE };\n// 禁止隐式转整型，禁止不同枚举混用\n```\n\n---\n\n## 六、RAII 与所有权管理\n\nC++17 的改造不仅是数据结构替换，还依赖 RAII 保证资源安全:\n\n### 6.1 Component 自动退订\n\n```cpp\n// component.hpp -- RAII 自动退订\nvirtual ~Component() {\n    for (const auto& handle : handles_) {\n        BusType::Instance().Unsubscribe(handle);\n    }\n}\n// 禁止拷贝\nComponent(const Component&) = delete;\nComponent& operator=(const Component&) = delete;\n```\n\n### 6.2 锁外析构防死锁\n\n```cpp\n// mccc.hpp -- 锁外析构保证顺序\nbool Unsubscribe(const SubscriptionHandle& handle) noexcept {\n    CallbackType old_callback;  // 在锁外析构\n    {\n        std::unique_lock<std::shared_mutex> lock(callback_mutex_);\n        old_callback = std::move(slot.entries[i].callback);\n    }\n    // old_callback 在锁释放后才析构，避免析构函数内获锁导致死锁\n    return static_cast<bool>(old_callback);\n}\n```\n\n---\n\n## 七、性能实测: 四项改造的综合效果\n\n> 测试环境: Ubuntu 24.04, Intel Xeon, GCC 13.3, `-O3 -march=native`\n\n| 指标 | C++14 mutex 版本 | MCCC (FULL) | MCCC (BARE) | 提升倍数 |\n|------|:---:|:---:|:---:|:---:|\n| 单线程吞吐量 | 0.56 M/s | 27.7 M/s | 33.0 M/s | 49-59x |\n| 多线程吞吐量 (8T) | 0.36 M/s | 20.6 M/s | 31.1 M/s | 57-86x |\n| 热路径堆分配 | 2-4 次/publish | **零** | **零** | -- |\n| P50 延迟 | 不可预测 | 585 ns | -- | -- |\n| P99 延迟 | 不可预测 | 933 ns | -- | -- |\n\n多线程场景下 MCCC 吞吐量是 C++14 版本的 57-86 倍。四项改造的各自贡献:\n\n| 改造 | 消除的瓶颈 | 估算收益 |\n|------|-----------|---------|\n| FixedFunction | std::function 堆分配 | 每次 publish 省 1-2 次 malloc |\n| VariantIndex + array | map 查找 + 堆节点 | O(log N) -> O(1)，消除堆分配 |\n| Envelope 内嵌 | shared_ptr 原子计数 | 消除 cache line bouncing |\n| FixedString/Vector | 动态容器堆分配 | 全部栈上，编译器可优化 memcpy |\n\n---\n\n## 总结: 从 C++14 到 C++17 的演进路径\n\n三篇文章构成了一条完整的演进路径:\n\n| 阶段 | 文章 | 核心方案 | 吞吐量 |\n|------|------|---------|:------:|\n| C++11 | [从零实现线程安全消息总线](../cpp11_message_bus/) | mutex + std::function + std::map | -- |\n| C++14 | [工程优化与性能瓶颈分析](../cpp14_message_bus_optimized/) | 锁外回调 + 单 mutex + joinable 线程 | 0.36 M/s (8T) |\n| C++17 | 本文 | FixedFunction + VariantIndex + Envelope 内嵌 | 31.1 M/s (8T) |\n\n每一步都有明确的问题驱动:\n\n1. **C++11 -> C++14**: 解决正确性问题 (重入死锁、锁序、资源泄漏)\n2. **C++14 -> C++17**: 解决性能问题 (堆分配、锁竞争、缓存不友好)\n\nC++17 提供的 `std::variant`、`if constexpr`、`std::is_same_v` 等特性，使得编译期类型路由、栈上类型擦除和固定容量容器成为可能。这些能力在 C++14 中要么无法实现 (`std::variant`)，要么需要大量样板代码 (SFINAE 替代 `if constexpr`)。\n\n### 延伸阅读\n\n| 主题 | 文章 |\n|------|------|\n| 设计决策与架构 | [Lock-free MPSC 消息总线的设计与实现](../MCCC_Design/) |\n| 性能对比评测 | [6 个开源方案的吞吐量、延迟与嵌入式适配性对比](../MCCC_Competitive_Analysis/) |\n| API 参考文档 | [MCCC 消息总线 API 全参考](../mccc_bus_api_reference/) |\n\n### 文件索引\n\n| 文件 | 行数 | 核心内容 |\n|------|------|---------|\n| `include/mccc/mccc.hpp` | 1097 | FixedString, FixedVector, FixedFunction, VariantIndex, AsyncBus |\n| `include/mccc/component.hpp` | 129 | Component RAII, SubscribeSafe/SubscribeSimple |\n| `CMakeLists.txt` | 40 | header-only INTERFACE library, C++17 |\n\n> 代码仓库: [mccc-bus](https://gitee.com/liudegui/mccc-bus) | 前身项目: [message_bus](https://gitee.com/liudegui/message_bus) | 后继项目: [newosp](https://github.com/DeguiLiu/newosp)\n",
      "ctime": "1771552666",
      "mtime": "1771552666",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/newosp_industrial_embedded_library.md": {
    "err_no": 0,
    "data": {
      "id": "7607781019853815818",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "newosp: 面向工业嵌入式的 C++17 Header-Only 基础设施库",
      "brief_content": "本文介绍的 newosp 库基于 MIT 协议开源，当前版本 v0.2.0。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/158073823)\n\n## 为什么写这个库\n\n做嵌入式 Linux 开发这些年，一直有个痛点：项目之间的基础设施代码反复造轮子。消息总线、状态机、串口协议、共享内存 IPC、线程池......每个项目都要重新搭一遍，质量参差不齐，测试覆盖更是随缘。\n\nROS2 太重，对资源受限的嵌入式 Linux 平台不友好；自研框架又容易陷入\"只有作者能维护\"的困境。于是我决定把这些年积累的基础设施抽象出来，做成一个轻量、可组合、经过充分测试的 C++17 库。\n\n这就是 [newosp](https://github.com/DeguiLiu/newosp) -- 一个面向工业嵌入式系统（激光雷达、机器人、边缘计算）的纯头文件基础设施库。\n\n项目地址: [https://github.com/DeguiLiu/newosp](https://github.com/DeguiLiu/newosp)\n\n## 核心设计原则\n\nnewosp 的设计围绕几个在嵌入式场景下至关重要的原则：\n\n**栈优先，热路径零堆分配。** 库内提供了 `FixedVector<T, N>`、`FixedString<N>`、`FixedFunction<Sig, Cap>` 等固定容量容器，所有数据都在栈上或静态分配。在实时性要求高的路径上，不会出现 `malloc` 导致的不确定延迟。整个库零 `std::function` 使用，回调统一通过 SBO（Small Buffer Optimization）的 `FixedFunction` 实现。\n\n**兼容 `-fno-exceptions -fno-rtti`。** 很多嵌入式项目为了减小二进制体积和避免异常处理的运行时开销，会关闭异常和 RTTI。newosp 用 `expected<V, E>` 和 `optional<T>` 做类型安全的错误处理，完全不依赖异常机制。\n\n**零全局状态。** 所有状态封装在对象中，通过 RAII 管理生命周期。Bus 通过依赖注入传入 Node，支持多实例并行，不会出现全局单例导致的测试困难和耦合问题。\n\n**编译期分发替代虚函数。** 标签分发、`if constexpr`、CRTP、变参模板......用现代 C++ 的编译期技术替代传统的虚函数 OOP，在保持灵活性的同时实现零开销抽象。`StaticNode` 通过模板参数化 Handler，编译器可生成直接跳转表并内联回调，消除间接调用开销。\n\n## 七层架构一览\n\nnewosp 按职责分为七层，共 43 个头文件：\n\n```\n应用层          app.hpp / post.hpp / qos.hpp / lifecycle_node.hpp\n服务与发现层    service.hpp / discovery.hpp / node_manager.hpp / *_hsm.hpp\n传输层          transport.hpp / shm_transport.hpp / serial_transport.hpp / transport_factory.hpp\n网络层          socket.hpp / connection.hpp / io_poller.hpp / net.hpp\n核心通信层      bus.hpp / node.hpp / static_node.hpp / worker_pool.hpp / spsc_ringbuffer.hpp / executor.hpp\n状态机与行为树  hsm.hpp / bt.hpp\n基础层          platform.hpp / vocabulary.hpp / config.hpp / log.hpp / async_log.hpp / timer.hpp\n                shell.hpp / mem_pool.hpp / shutdown.hpp / semaphore.hpp / watchdog.hpp\n                fault_collector.hpp / shell_commands.hpp / process.hpp / system_monitor.hpp\n```\n\n每一层只依赖下层，不存在循环依赖。上层模块统一复用基础层的 `FixedString`、`FixedVector`、`SteadyNowUs` 等组件，零重复实现。\n\n## 核心模块详解\n\n### 无锁消息总线 (bus.hpp + node.hpp)\n\n这是整个库的通信骨架。`AsyncBus<PayloadVariant>` 是一个基于 CAS 的无锁 MPSC 消息总线，支持优先级准入控制和 topic 路由。\n\n```cpp\n#include \"osp/node.hpp\"\n\n// 定义消息类型\nstruct SensorData { float temperature; float humidity; };\nstruct MotorCmd   { uint32_t mode; float target; };\nusing Payload = std::variant<SensorData, MotorCmd>;\n\n// 创建 Bus 和 Node (Bus 依赖注入)\nosp::AsyncBus<Payload> bus;\nosp::Node<Payload> sensor(\"sensor\", /*id=*/1, bus);\n\n// 订阅消息: void(const T&, const MessageHeader&)\nsensor.Subscribe<SensorData>([](const SensorData& d, const osp::MessageHeader& h) {\n    OSP_LOG_INFO(\"sensor\", \"temp=%.1f humidity=%.1f sender=%u\",\n                 d.temperature, d.humidity, h.sender_id);\n});\n\n// 发布并处理\nsensor.Publish(SensorData{25.0f, 60.0f});\nsensor.SpinOnce();  // 消费队列，分发到回调\n```\n\n几个关键设计点：\n- 基于 `std::variant` + `VariantIndex<T>` 的编译期类型路由，不需要字符串匹配\n- FNV-1a 32-bit hash 做 topic 路由，O(1) 查找\n- Bus 通过依赖注入传入 Node，而非全局单例（也支持 Meyer's singleton 模式 `AsyncBus::Instance()`）\n- 宏参数化 `OSP_BUS_QUEUE_DEPTH`（默认 4096）和 `OSP_BUS_BATCH_SIZE`（默认 256），编译期适配不同硬件\n- 三级优先级准入控制（LOW/MEDIUM/HIGH），队列 60%/80%/99% 满时分级丢弃\n- 回调使用 `FixedFunction<void(const Envelope&), 4*sizeof(void*)>` SBO 存储，零 `std::function`\n\n### 编译期绑定节点 (static_node.hpp)\n\n对于性能极敏感的场景，`StaticNode<Payload, Handler>` 将 Handler 作为模板参数，编译器可以生成直接跳转表并内联回调，消除 `FixedFunction` 的间接调用开销：\n\n```cpp\n#include \"osp/static_node.hpp\"\n\nstruct MyHandler {\n    void operator()(const SensorData& d, const osp::MessageHeader& h) {\n        // 编译器可内联此调用\n        OSP_LOG_INFO(\"handler\", \"temp=%.1f\", d.temperature);\n    }\n    void operator()(const MotorCmd& c, const osp::MessageHeader& h) {\n        OSP_LOG_INFO(\"handler\", \"motor mode=%u\", c.mode);\n    }\n};\n\n// 编译期绑定，零间接调用开销\nosp::StaticNode<Payload, MyHandler> node(\"sensor\", 1, MyHandler{}, bus);\n```\n\n### SPSC 环形缓冲 (spsc_ringbuffer.hpp)\n\n无锁 wait-free 的单生产者单消费者环形缓冲区，是共享内存传输和工作线程池的基础组件。支持 `trivially_copyable` 类型约束、批量读写操作，以及针对 ARM 弱内存序的 `FakeTSO` 模式（用显式 acquire/release fence 替代 x86 的隐式 TSO 保证）。\n\n### 层次状态机 (hsm.hpp)\n\n零堆分配的层次状态机实现，支持 LCA（Least Common Ancestor）转换算法和 guard 条件。在 newosp 中被广泛使用：串口 OTA 的帧解析、共享内存 IPC 的生产者/消费者状态管理、节点心跳监控（`node_manager_hsm.hpp`）、服务生命周期管理（`service_hsm.hpp`）、发现流程管理（`discovery_hsm.hpp`）......几乎所有需要状态管理的场景都用 HSM 来驱动。\n\n### 行为树 (bt.hpp)\n\n扁平数组存储、索引引用（非指针）的缓存友好行为树。支持 Sequence、Fallback、Parallel、Decorator 等标准节点类型。和 HSM 配合使用，HSM 管理底层状态转换，BT 编排高层任务流程。\n\n### 实时调度 (executor.hpp)\n\n提供 Single、Static、Pinned 三种通用调度器，以及一个 `RealtimeExecutor`，支持 `SCHED_FIFO` 实时调度策略、`mlockall` 内存锁定、CPU 亲和性绑定。适合对延迟敏感的工业控制场景。\n\n### 生命周期节点 (lifecycle_node.hpp)\n\nHSM 驱动的生命周期管理，提供丰富的状态层次：\n\n```\nAlive (root)\n+-- Unconfigured (Initializing / WaitingConfig)\n+-- Configured\n|   +-- Inactive (Standby / Paused)\n|   +-- Active (Starting / Running / Degraded)\n+-- Error (Recoverable / Fatal)\n+-- Finalized\n```\n\n向后兼容 4 状态公共 API（`Configure()` / `Activate()` / `Deactivate()` / `Shutdown()`），同时提供细粒度的 12 状态详细查询。回调使用函数指针，零堆分配。\n\n### 多传输后端 (transport_factory.hpp)\n\n`transport_factory` 根据通信双方的位置自动选择最优传输方式：\n- 同进程内: inproc（直接函数调用）\n- 同机器不同进程: 共享内存 IPC（`shm_transport.hpp`，无锁 SPSC，ARM 内存序加固）\n- 跨机器: TCP/UDP（`transport.hpp`，v0/v1 双版本帧协议，SequenceTracker 丢包检测）\n- 工业串口: `serial_transport.hpp`（CRC-CCITT 校验，符合 IEC 61508）\n\n### 异步日志 (async_log.hpp)\n\n每线程独立 SPSC 环形缓冲，单后台写线程 round-robin 轮询。DEBUG/INFO/WARN 走异步路径（wait-free push，零竞争），ERROR/FATAL 走同步 fprintf（crash-safe）。未启动异步后端时，所有宏透明回退到同步 `LogWrite()`。\n\n### 系统监控 (system_monitor.hpp)\n\n读取 `/proc/stat`、`/proc/meminfo`、`/sys/class/thermal` 等文件系统，监控 CPU 利用率、CPU 温度、内存使用、磁盘用量。POD 快照零拷贝，栈上解析，状态变化告警（仅阈值穿越时触发），可通过 `TimerScheduler` 周期采样。\n\n### 进程管理 (process.hpp)\n\n子进程 spawn/pipe/wait，进程查找（`FindPidByName`），Freeze/Resume/Kill 操作，`RunCommand` 命令执行。为多进程部署场景（如 `net_stress/` 示例中的 launcher 进程管理器）提供基础设施。\n\n### 可靠性基础设施\n\n- `watchdog.hpp`: 软件看门狗，截止时间监控 + 超时回调\n- `fault_collector.hpp`: 故障收集与上报，FaultReporter POD 注入，环形缓冲存储\n- `qos.hpp`: QoS 配置（Reliability、History、Deadline、Lifespan）\n- `shell_commands.hpp`: 内置诊断 Shell 命令，零侵入桥接，支持 TCP/stdin/UART 多后端\n\n## 四个工业级示例\n\n光看 API 文档容易觉得抽象，所以 newosp 提供了多个多文件示例，展示这些模块如何在真实场景中组合使用。这里重点介绍 4 个。\n\n### 1. 串口 OTA 固件升级 (serial_ota/)\n\n这是最复杂的一个示例，集成了 12 个 newosp 组件，模拟了一个完整的工业串口 OTA 固件升级流程。\n\n**场景**: 主机通过串口向设备推送固件，支持分块传输、CRC 校验、NAK 重传、超时恢复。\n\n**架构**:\n- `protocol.hpp`: 定义帧格式（0xAA 帧头 / 0x55 帧尾）、CRC-CCITT constexpr 查表、OTA 命令集\n- `parser.hpp`: HSM 驱动的 9 状态帧解析器（Idle -> LenLo -> LenHi -> CmdClass -> Cmd -> Data -> CrcLo -> CrcHi -> Tail），逐字节状态转移\n- `host.hpp`: 主机端升级流程，用行为树编排 4 个阶段（SendStart -> SendChunks -> SendEnd -> SendVerify）\n- `device.hpp`: 设备端 6 状态 OTA 状态机（Idle -> Erasing -> Receiving -> Verifying -> Complete/Error），内含 Flash 模拟器\n- `main.cpp`: 用 `SpscRingbuffer` 模拟双向 UART FIFO，注入约 5% 的信道噪声\n\n这个示例的亮点在于 HSM 和 BT 的配合：BT 负责编排\"发送启动 -> 分块传输 -> 发送结束 -> 校验\"的高层流程，HSM 负责底层的帧解析状态转换和设备端 OTA 状态管理。两者各司其职，代码结构清晰。\n\n同时集成了 `ThreadWatchdog`（5s 超时检测）、`FaultCollector`（故障上报）、`AsyncBus`（进度/状态变更/完成事件广播）、`DebugShell`（调试命令），展示了一个工业级应用该有的可观测性。\n\n### 2. 共享内存 IPC (shm_ipc/)\n\n三进程架构的共享内存通信示例，模拟视频帧的跨进程传输。\n\n**三个进程**:\n- `shm_producer`: HSM 驱动的帧生产者（8 状态），支持背压检测和自动降速\n- `shm_consumer`: HSM 驱动的帧消费者（8 状态），支持重连重试和帧完整性校验\n- `shm_monitor`: DebugShell 调试监控，提供 telnet 命令实时查看通道状态\n\n**设计要点**:\n- 生产者在 ring buffer 满时不是简单丢弃，而是进入 Paused 状态；连续 3 次满则进入 Throttled 降速状态\n- 消费者对每一帧做逐字节校验（`(seq_num + offset) & 0xFF`），确保数据完整性\n- 通过 `SpscRingbuffer` 在进程间传递统计快照（`ShmStats`，48 字节 trivially_copyable），监控进程可以实时获取生产者/消费者的运行状态\n- 集成 `ThreadWatchdog`（线程存活监控）和 `FaultCollector`（ring-full、thread-death、frame-invalid 等故障码）\n\n这个示例很好地展示了 newosp 在多进程场景下的能力：共享内存做数据面的零拷贝传输，`SpscRingbuffer` 做控制面的统计信息同步，`DebugShell` 提供运行时可观测性。\n\n### 3. 流式协议 (streaming_protocol/)\n\n模拟 GB28181/RTSP 风格的视频监控协议，展示 Bus + Node + Timer 的多节点协作。\n\n**4 个节点共享一条 AsyncBus**:\n- `Registrar`: 处理设备注册请求，分配 session_id\n- `HeartbeatMonitor`: 监控心跳延迟，>500ms 告警\n- `StreamController`: 处理流控命令（START/STOP）和流数据\n- `Client`: 发起注册、发送心跳、控制流\n\n**三阶段流程**:\n1. 设备注册（HIGH 优先级消息）\n2. 心跳保活（TimerScheduler 每 50ms 触发）\n3. 流控制（START -> 5 帧数据 -> STOP，数据用 LOW 优先级）\n\n这个示例的价值在于展示了 newosp 的消息优先级机制：注册请求用 HIGH 优先级确保及时处理，流数据用 LOW 优先级避免阻塞控制消息。所有消息类型都是 POD 结构，通过 `std::variant` 统一路由。\n\n### 4. 多节点客户端网关 (client_gateway/)\n\nIoT 网关场景，展示 WorkerPool + Node 的分工协作。\n\n**组件分工**:\n- `Node \"gateway\"`: 订阅连接/断连事件，管理客户端生命周期\n- `Node \"monitor\"`: 订阅心跳事件，监控客户端健康状态\n- `WorkerPool`（2 个 worker 线程）: 并行处理 `ClientData` 数据消息\n\n**5 阶段主流程**:\n1. 连接 4 个客户端\n2. 提交 32 条数据消息（4 clients x 8 msgs），WorkerPool 并行处理\n3. 发送心跳到监控节点\n4. `FlushAndPause` 排空在途工作，汇总处理结果\n5. 有序断连所有客户端\n\n这个示例展示了一个关键模式：用 Node 处理控制面（连接管理、心跳监控），用 WorkerPool 处理数据面（业务数据并行处理）。`FlushAndPause` 确保所有在途工作完成后再进入下一阶段，避免数据丢失。统计信息全部用 `std::atomic` 在栈上分配，零堆开销。\n\n## 测试与质量保证\n\nnewosp 目前有 1153 个测试用例，覆盖所有 43 个模块：\n\n- 正常模式: 1153 tests，100% 通过\n- `-fno-exceptions` 模式: 排除 sockpp 依赖的测试后单独验证\n- Sanitizer: AddressSanitizer + UBSanitizer + ThreadSanitizer 全部通过（零警告）\n- CI: GitHub Actions，Debug + Release 双配置，每次提交自动验证\n\n测试框架用的 Catch2 v3.5.2，每个模块对应独立的测试文件 `tests/test_<module>.cpp`，另有集成测试 `tests/test_integration.cpp`。\n\n## 快速上手\n\nnewosp 是纯头文件库，集成非常简单：\n\n```bash\ngit clone https://github.com/DeguiLiu/newosp.git\ncd newosp\ncmake -B build -DCMAKE_BUILD_TYPE=Release -DOSP_BUILD_EXAMPLES=ON\ncmake --build build -j$(nproc)\n```\n\n在你的项目中使用：\n\n```cmake\nadd_subdirectory(newosp)\ntarget_link_libraries(your_app PRIVATE osp)\n```\n\n然后就可以 `#include \"osp/bus.hpp\"` 开始用了。所有外部依赖（Catch2、sockpp、inicpp 等）通过 CMake FetchContent 自动获取，不需要手动安装。\n\n## 适用场景\n\nnewosp 适合这些场景：\n- 工业嵌入式 Linux 设备（激光雷达、机器人控制器、边缘网关）\n- 对实时性有要求，不能容忍 GC 或动态内存分配的不确定延迟\n- 需要多种通信方式（进程内消息、共享内存 IPC、TCP/UDP、串口）统一管理\n- 项目规模不大，不想引入 ROS2 这样的重量级框架\n- 需要在资源受限环境下运行（支持 `-fno-exceptions -fno-rtti`）\n\n如果你也在做类似的嵌入式 Linux 开发，欢迎试用和反馈。项目还在持续迭代中，Issue 和 PR 都欢迎。\n\n项目地址: [https://github.com/DeguiLiu/newosp](https://github.com/DeguiLiu/newosp)\n\n---\n\n> 本文介绍的 newosp 库基于 MIT 协议开源，当前版本 v0.2.0。\n",
      "ctime": "1771552670",
      "mtime": "1771552670",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/newosp_ospgen_codegen.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038552102",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "newosp ospgen: YAML 驱动的嵌入式 C++17 零堆分配消息代码生成",
      "brief_content": "newosp ospgen 是一个 200 行 Python 的 YAML->C++ 代码生成器，面向嵌入式 C++17 场景。生成 trivially_copyable POD 结构体、enum c",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 配套代码: [DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) -- header-only C++17 嵌入式基础设施库\n>\n> 设计文档: [design_codegen_zh.md](https://github.com/DeguiLiu/newosp/blob/main/docs/design_codegen_zh.md)\n>\n> 相关文章:\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- AsyncBus/Node 如何使用 ospgen 生成的消息类型\n> - [共享内存进程间通信](../shm_ipc_newosp/) -- ShmRingBuffer 为什么需要 trivially_copyable 保证\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- 消息队列对 trivially_copyable 的需求来源\n>\n> CSDN 原文: [newosp ospgen: YAML 驱动的嵌入式 C++17 零堆消息代码生成](https://blog.csdn.net/stallion5632)\n\n## 1. 问题: 嵌入式消息通信的两难困境\n\n嵌入式系统中的进程间/线程间消息通信有一个核心矛盾:\n\n**正确性要求极高**: struct 必须 `trivially_copyable` 才能安全 `memcpy` 进 SPSC 队列或共享内存; 字段对齐必须正确; `sizeof` 必须跨平台精确匹配; event ID 和 struct 必须严格同步。\n\n**手写维护成本也极高**: 20+ 个消息 struct，每个都要手写默认构造、确保字段对齐、添加 `static_assert`、维护 event enum、更新 `std::variant` 类型列表......一旦某处遗漏，可能是共享内存越界、ShmRingBuffer 崩溃、跨进程协议不兼容。\n\n| 手写的痛点 | 失败后果 |\n|---|---|\n| 忘记 `static_assert(trivially_copyable)` | ShmRingBuffer memcpy 传输时静默数据损坏 |\n| event enum ID 和 struct 散落不同文件 | 消息分发错乱，hard to debug |\n| 新增消息忘记更新 `std::variant<...>` | 编译错误还算好的，运行时类型不匹配更致命 |\n| 跨平台 sizeof 不一致 (ARM vs x86 padding) | 协议帧解析偏移，数据全乱 |\n| 多个开发者各自定义 struct 风格 | 有的零初始化，有的没有; 有的有注释，有的没有 |\n\n行业标准方案是使用 IDL (Interface Definition Language) 加代码生成器。但主流选项都有各自的问题:\n\n```\nProtobuf   → 堆分配 (std::string, RepeatedField)，嵌入式不可接受\nFlatBuffers → 零拷贝但 API 复杂，学习曲线陡峭\nROS2 IDL   → 绑定 ROS2 生态，不独立可用\nnanopb     → 纯 C，不支持 std::variant / enum class / 模板\n```\n\nnewosp 需要的是: **比 Protobuf 轻、比手写安全、比 nanopb 更 C++17**。\n\n## 2. 方案: ospgen -- 200 行 Python 的 YAML→C++ 生成器\n\nospgen 的设计哲学: **只做嵌入式 C++ 真正需要的事，一行多余代码都不写**。\n\n### 2.1 数据流\n\n```\ndefs/*.yaml          tools/templates/*.j2         build/generated/osp/*.hpp\n (消息定义)    +      (Jinja2 模板)        →      (C++ header-only)\n```\n\n整个生成器 `tools/ospgen.py` 约 200 行 Python，依赖 PyYAML + Jinja2，无需安装 protoc、flatc 等外部编译器。\n\n### 2.2 YAML 定义示例\n\n以 newosp 的视频流协议为例:\n\n```yaml\nnamespace: protocol\nversion: 1\nbyte_order: native\nincludes: [cstdint, cstring]\n\n# 类型安全的独立枚举\nenums:\n  - name: StreamAction\n    desc: \"Stream control action\"\n    type: uint8_t\n    entries:\n      - { name: STOP,  value: 0, desc: \"Stop streaming\" }\n      - { name: START, value: 1, desc: \"Start streaming\" }\n\n# 事件 ID (uint32_t enum)\nevents:\n  - { name: REGISTER,  id: 1, desc: \"Device registration request\" }\n  - { name: HEARTBEAT, id: 3, desc: \"Keepalive heartbeat\" }\n\n# 消息结构体\nmessages:\n  - name: RegisterRequest\n    desc: \"Device registration request sent by client\"\n    event: REGISTER                    # ← 编译期绑定到 event\n    expected_size: 50                  # ← sizeof 断言\n    fields:\n      - { name: device_id, type: \"char[32]\", desc: \"Unique device ID\" }\n      - { name: ip,        type: \"char[16]\", desc: \"Device IP address\" }\n      - { name: port,      type: uint16_t,   desc: \"Listening port\", range: [1, 65535] }\n```\n\n一份 YAML，定义了: 命名空间、版本号、枚举、事件、消息结构、字段描述、范围约束、event 绑定、sizeof 断言。**单一数据源，零歧义**。\n\n### 2.3 生成产物\n\n从上面的 YAML，ospgen 一次性生成:\n\n```cpp\nnamespace protocol {\n\n// ① 协议版本\nstatic constexpr uint32_t kVersion = 1;\n\n// ② 类型安全枚举 (enum class, MISRA C++ 合规)\nenum class StreamAction : uint8_t {\n  kStop = 0,   ///< Stop streaming\n  kStart = 1   ///< Start streaming\n};\n\n// ③ 事件枚举 (含 Doxygen 注释)\nenum ProtocolEvent : uint32_t {\n  kProtocolRegister = 1,   ///< Device registration request\n  kProtocolHeartbeat = 3,  ///< Keepalive heartbeat\n};\n\n// ④ POD 结构体 (Doxygen + 字段描述 + 零初始化构造)\n/// Device registration request sent by client\nstruct RegisterRequest {\n  char device_id[32];  ///< Unique device ID\n  char ip[16];         ///< Device IP address\n  uint16_t port;       ///< Listening port\n\n  RegisterRequest() noexcept : device_id{}, ip{}, port(0) {}\n\n  // ⑤ 字段范围校验\n  bool Validate() const noexcept {\n    if (port < 1 || port > 65535) return false;\n    return true;\n  }\n\n  // ⑥ 调试打印 (snprintf, 零堆分配)\n  uint32_t Dump(char* buf, uint32_t cap) const noexcept {\n    int n = std::snprintf(buf, cap,\n        \"RegisterRequest{device_id=%s, ip=%s, port=%u}\",\n        device_id, ip, static_cast<unsigned>(port));\n    return (n > 0) ? static_cast<uint32_t>(n) : 0;\n  }\n};\n\n// ⑦ 类型安全 Payload (std::variant)\nusing ProtocolPayload = std::variant<RegisterRequest, ...>;\n\n// ⑧ 编译期断言\nstatic_assert(std::is_trivially_copyable<RegisterRequest>::value, \"...\");\nstatic_assert(sizeof(RegisterRequest) == 50, \"size mismatch\");\n\n// ⑨ Event ↔ Message 编译期绑定\ntemplate <> struct EventMessage<kProtocolRegister> {\n  using type = RegisterRequest;\n};\ntemplate <> struct MessageEvent<RegisterRequest> {\n  static constexpr uint32_t value = kProtocolRegister;\n};\ntemplate <typename MsgT>\nconstexpr uint32_t EventIdOf() noexcept {\n  return MessageEvent<MsgT>::value;\n}\n\n}  // namespace protocol\n```\n\n**一份 YAML 输入，9 类 C++ 产物**。手写同等代码约 150-200 行，且无法保证一致性。\n\n## 3. 使用场景与必要性\n\n### 3.1 场景一: 无锁消息总线 (Bus/Node)\n\nnewosp 的 `AsyncBus<Payload>` 是无锁 MPSC 消息总线，`Node<Payload>` 是发布/订阅节点。它们的模板参数 `Payload` 就是生成的 `std::variant`:\n\n```cpp\nusing ProtoBus = osp::AsyncBus<protocol::ProtocolPayload>;\nosp::Node<protocol::ProtocolPayload> registrar(kNodeName_registrar, kNodeId_registrar);\n\nregistrar.Subscribe<protocol::RegisterRequest>(\n    [](const protocol::RegisterRequest& req, const osp::MessageHeader& hdr) {\n        if (!req.Validate()) { /* 字段越界 */ }\n        char buf[128];\n        req.Dump(buf, sizeof(buf));  // 调试输出\n    });\n```\n\n**为什么必须代码生成**: `std::variant` 的类型列表必须完整包含所有消息类型。手写时每新增一个消息，要同时修改 variant 定义、event enum、Subscribe 调用三处。ospgen 保证 YAML 增加一条 message 定义，variant 自动更新。\n\n### 3.2 场景二: 共享内存 IPC (ShmRingBuffer)\n\nnewosp 的 `ShmRingBuffer` 用 `memcpy` 在进程间传输消息。**只有 `trivially_copyable` 类型才能安全 `memcpy`**:\n\n```cpp\n// ShmRingBuffer<SlotSize, SlotCount>::TryPush 内部:\nstd::memcpy(slot_ptr, data, size);  // data 必须是 trivially_copyable\n```\n\n**为什么必须代码生成**: 如果某个 struct 含有 `std::string`、虚函数、或非平凡析构，`memcpy` 后行为未定义。ospgen 为每个消息自动生成 `static_assert(std::is_trivially_copyable<T>::value)`，编译期拦截。\n\n### 3.3 场景三: 跨进程协议 (Transport)\n\nnewosp 的 TCP/UDP Transport 将消息序列化为帧发送。接收端按 `sizeof` 解析:\n\n```cpp\n// 发送端\ntransport.Send(&msg, sizeof(msg));\n\n// 接收端\nRegisterRequest msg;\ntransport.Recv(&msg, sizeof(RegisterRequest));  // sizeof 必须两端一致\n```\n\n**为什么必须代码生成**: 编译器 padding 策略因平台而异。ARM 上 `uint8_t` 后跟 `uint32_t` 可能插入 3 字节 padding，x86 可能不同。`expected_size` + `static_assert` 确保跨平台 sizeof 一致，编译期发现不匹配:\n\n```cpp\n// 编译器 padding 导致 sizeof 变化时，立即报错\nstatic_assert(sizeof(RegisterResponse) == 40,\n              \"RegisterResponse size mismatch (check field alignment/packing)\");\n```\n\n### 3.4 场景四: OspPost 事件投递\n\nnewosp 的 `OspPost(iid, event, data, len)` 通过 event ID 路由消息到目标 Instance。手写时 event 和 message 的对应关系靠注释或约定，ospgen 生成编译期绑定:\n\n```cpp\n// 编译期验证: RegisterRequest 必须对应 REGISTER 事件\nstatic_assert(protocol::EventIdOf<protocol::RegisterRequest>() ==\n              protocol::kProtocolRegister, \"binding mismatch\");\n\n// 编译期类型获取: 知道 event ID，推导 message type\nusing MsgType = protocol::EventMessage<protocol::kProtocolRegister>::type;\n// MsgType == RegisterRequest，零运行时开销\n```\n\n**为什么必须代码生成**: event-message 绑定是模板特化，手写容易漏、容易错。YAML 中一行 `event: REGISTER` 自动生成正反两个映射 + constexpr 辅助函数。\n\n### 3.5 场景五: 协议演进与多人协作\n\n```yaml\nversion: 2                           # 协议版本升级\nmessages:\n  - name: RegisterRequestV1\n    deprecated: \"use RegisterRequestV2\"  # 标记废弃\n    expected_size: 50\n    # ...\n  - name: RegisterRequestV2\n    event: REGISTER\n    expected_size: 54                 # 新版本多了 4 字节\n    fields:\n      - { name: device_id, type: \"char[32]\" }\n      - { name: ip,        type: \"char[16]\" }\n      - { name: port,      type: uint16_t }\n      - { name: capabilities, type: uint32_t, desc: \"Feature flags\" }  # 新字段\n```\n\n生成:\n```cpp\n/// @deprecated use RegisterRequestV2\nstruct [[deprecated(\"use RegisterRequestV2\")]] RegisterRequestV1 { ... };\nstruct RegisterRequestV2 { ... };\n```\n\n手写协议升级时，旧版本 struct 容易被遗忘或误修改。YAML 的 `deprecated` + `version` 让协议演进有迹可循。\n\n## 4. 与业界方案的对比\n\n| 方案 | 定义语言 | 运行时依赖 | trivially_copyable | 生成器复杂度 |\n|---|---|---|---|---|\n| **ospgen** | YAML | 无 (header-only) | 强制 static_assert | ~200 行 Python |\n| Protobuf | .proto | libprotobuf (堆分配) | 不保证 | protoc 编译器 |\n| FlatBuffers | .fbs | flatbuffers 库 | 仅 struct 模式 | flatc 编译器 |\n| nanopb | .proto | nanopb 运行时 (C) | 是 (C struct) | Python 生成器 |\n| ROS2 IDL | .msg/.srv | rclcpp 生态 | 不保证 | rosidl 工具链 |\n\nospgen 的定位: **比 Protobuf 轻** (无运行时依赖)、**比手写安全** (编译期全覆盖断言)、**比 nanopb 更 C++17** (enum class + std::variant + 模板特化)。只需 `pip install pyyaml jinja2`，无需 protoc/flatc 等外部编译器。\n\nospgen v2 共生成 15 类 C++ 产物 (枚举、结构体、Validate、Dump、variant、static_assert、event-message 绑定等)，完整 YAML Schema 定义、生成内容详解和 CMake 集成方式见 [设计文档](https://github.com/DeguiLiu/newosp/blob/main/docs/design_codegen_zh.md)。\n\n## 5. 真实应用: streaming_protocol 示例\n\ncodegen_demo 是功能展示，逐项验证每个生成能力。但一个更有说服力的问题是: **ospgen 能不能直接用在真实的多文件应用中，替换掉手写的 struct？**\n\nnewosp 的 `examples/streaming_protocol/` 就是这个验证: 一个 GB28181/RTSP 风格的流媒体协议模拟，包含 Registrar、HeartbeatMonitor、StreamController 三个服务端 StaticNode 和一个 Client Node，通过 AsyncBus 进行发布/订阅通信。\n\n### 5.1 改造前: 手写 messages.hpp\n\n原始版本有一个独立的 `messages.hpp`，手写 5 个 struct + 1 个 variant:\n\n```cpp\n// messages.hpp (44 行手写代码)\nstruct RegisterRequest {\n  char device_id[32];\n  char ip[16];\n  uint16_t port;\n};\nstruct RegisterResponse { ... };\nstruct HeartbeatMsg { ... };\nstruct StreamCommand {\n  uint32_t session_id;\n  uint8_t action;       // 0 = stop, 1 = start   ← 魔数\n  uint8_t media_type;   // 0 = video, 1 = audio   ← 魔数\n};\nstruct StreamData { ... };\n\nusing Payload = std::variant<RegisterRequest, RegisterResponse,\n                             HeartbeatMsg, StreamCommand, StreamData>;\n```\n\nhandler 中也是硬编码节点 ID 和魔数比较:\n\n```cpp\nstatic constexpr uint32_t kRegistrarId = 1;     // 手动定义，与拓扑无关\nstatic constexpr uint32_t kHeartbeatId = 2;\n\nconst char* action = (cmd.action == 1) ? \"START\" : \"STOP\";  // 魔数\nconst char* media = (cmd.media_type == 0) ? \"video\"          // 魔数\n                  : (cmd.media_type == 1) ? \"audio\" : \"A/V\";\n```\n\n**问题清单**:\n\n| 缺陷 | 潜在后果 |\n|------|---------|\n| 无 `trivially_copyable` 断言 | ShmRingBuffer 传输时无编译期保护 |\n| 无 `sizeof` 断言 | 跨平台编译 padding 变化无法感知 |\n| 魔数枚举 (`action == 1`) | 可读性差，改错一个数字无编译期警告 |\n| 无 `Validate()` | 外部输入越界时静默传播 |\n| 无 `Dump()` | 调试时需手写 printf 格式串 |\n| 手动维护 node ID | 拓扑变更需同步修改多处 |\n| struct 定义与 event enum 分离 | 新增消息容易忘记同步 |\n\n### 5.2 改造后: 替换为 ospgen 生成代码\n\n改造只需三步:\n\n1. **删除** `messages.hpp` -- 5 个手写 struct 已在 `defs/protocol_messages.yaml` 中定义\n2. **替换引用** -- `#include \"messages.hpp\"` → `#include \"osp/protocol_messages.hpp\"` + `#include \"osp/topology.hpp\"`\n3. **使用生成能力** -- 在业务逻辑中调用 `Validate()`、`Dump()`、枚举类型、拓扑常量\n\n改造后的 handler:\n\n```cpp\n#include \"osp/protocol_messages.hpp\"   // ospgen 生成\n#include \"osp/topology.hpp\"            // ospgen 生成\n\nusing Payload = protocol::ProtocolPayload;  // 生成的 variant\n\nstruct RegistrarHandler {\n  void operator()(const protocol::RegisterRequest& req, ...) {\n    // ① Validate: 端口范围 [1, 65535] 自动检查\n    if (!req.Validate()) {\n      OSP_LOG_WARN(\"Registrar\", \"rejected: port out of range\");\n      return;\n    }\n    // ② Dump: 结构化调试输出，无需手写格式串\n    char dump[256];\n    req.Dump(dump, sizeof(dump));\n    OSP_LOG_INFO(\"Registrar\", \"recv: %s\", dump);\n    // ...\n    bus->Publish(Payload(resp), kNodeId_registrar);  // ③ 拓扑常量\n  }\n};\n\nstruct StreamHandler {\n  void operator()(const protocol::StreamCommand& cmd, ...) {\n    if (!cmd.Validate()) { ... }  // action 范围 [0, 1] 自动检查\n    // ④ 类型安全枚举替代魔数\n    const char* action =\n        (cmd.action == static_cast<uint8_t>(protocol::StreamAction::kStart))\n            ? \"START\" : \"STOP\";\n    const char* media =\n        (cmd.media_type == static_cast<uint8_t>(protocol::MediaType::kAv))\n            ? \"A/V\" : ...;\n  }\n};\n```\n\nmain.cpp 增加编译期验证:\n\n```cpp\n// 编译期: event-message 绑定正确性\nstatic_assert(protocol::EventIdOf<protocol::RegisterRequest>() ==\n                  protocol::kProtocolRegister, \"binding mismatch\");\n\n// 编译期: 跨平台 sizeof 一致性\nstatic_assert(sizeof(protocol::RegisterRequest) == 50, \"\");\nstatic_assert(sizeof(protocol::StreamCommand) == 8, \"\");\n\n// 运行时: 拓扑信息\nOSP_LOG_INFO(\"Proto\", \"protocol version=%u, node count=%u\",\n             protocol::kVersion, kNodeCount);\n\n// 节点创建: 使用拓扑常量\nRegistrarNode registrar(kNodeName_registrar, kNodeId_registrar, ...);\nosp::Node<Payload> client(kNodeName_client, kNodeId_client);\n```\n\n### 5.3 改造效果\n\n运行输出对比:\n\n```\n改造前:\n[INFO ] [Registrar] device CAM-310200001 from 192.168.1.100:5060\n[INFO ] [StreamCtrl] session 0x1001 START A/V\n\n改造后:\n[INFO ] [Proto] protocol version=1, node count=4\n[INFO ] [Registrar] recv: RegisterRequest{device_id=CAM-310200001, ip=192.168.1.100, port=5060}\n[INFO ] [StreamCtrl] session 0x1001 START A/V\n[DEBUG] [StreamCtrl] StreamData{session_id=4097, seq=0, payload_size=128}\n[INFO ] [Proto] topology: registrar(subs=2) heartbeat_monitor(subs=1) ...\n```\n\n**改造收益**:\n\n| 维度 | 改造前 | 改造后 |\n|------|--------|--------|\n| 消息定义 | 44 行手写 C++ | 0 行 (YAML 生成) |\n| 输入校验 | 无 | `Validate()` 自动检查 |\n| 调试输出 | 手写 printf | `Dump()` 一行调用 |\n| 枚举比较 | `cmd.action == 1` | `StreamAction::kStart` |\n| 节点 ID | 硬编码常量 | `kNodeId_registrar` (YAML 拓扑) |\n| sizeof 保护 | 无 | `static_assert` 编译期 |\n| trivially_copyable | 无保护 | `static_assert` 编译期 |\n| 新增消息同步 | 手动改 3+ 处 | 改 YAML 一处，自动生成 |\n\n核心价值: 手写 `messages.hpp` 只是 \"能用\"，ospgen 生成的代码是 \"安全地用\"。差别不在于功能，而在于**把嵌入式通信中容易犯的错误变成编译错误**。\n\n## 6. 设计决策与权衡\n\n### 6.1 为什么用 YAML 而不是 .proto 或自定义 DSL?\n\n| 选项 | 优点 | 缺点 |\n|------|------|------|\n| .proto | 生态成熟 | 绑定 Protobuf 语义，不支持 trivially_copyable |\n| 自定义 DSL | 完全可控 | 需要写 parser，维护成本 |\n| **YAML** | 现成 parser (PyYAML)，可读性好，嵌套结构自然 | 缩进敏感，无内置类型系统 |\n\nYAML 的\"缺点\"(无类型系统) 在这里反而是优点: 字段类型直接写 C++ 类型名 (`uint32_t`, `\"char[32]\"`)，无需 proto 到 C++ 的类型映射表。\n\n### 6.2 为什么用 Jinja2 而不是直接 string format?\n\n- Jinja2 的 `{% for %}` / `{% if %}` 让模板逻辑清晰，vs `\"\\n\".join([...])` 的可读性地狱\n- Jinja2 的 filter/global 机制让命名转换 (`snake_to_camel`) 可在模板中直接使用\n- 新增生成能力只需修改 `.j2` 模板，不改 Python 代码\n\n### 6.3 为什么不支持 nested messages 和 oneof?\n\n嵌入式消息的典型特征:\n\n- **扁平结构**: 字段是标量或固定数组，不需要嵌套\n- **固定大小**: `sizeof` 编译期确定，不存在变长字段\n- **memcpy 传输**: SPSC/ShmRingBuffer 直接 `memcpy` 整个 struct\n\nnested messages 和 oneof 会引入指针或变长字段，破坏 `trivially_copyable` 约束。这是有意为之的限制，不是遗漏。\n\n### 6.4 为什么 Dump() 用 snprintf 而不是 std::ostringstream?\n\n- `std::ostringstream` 需要堆分配，嵌入式热路径不可接受\n- `snprintf` 零堆分配，写入调用方提供的栈缓冲区\n- 生成器自动将 C++ 类型映射到 printf 格式符 (`uint32_t` → `%u` + `static_cast<unsigned>`)\n- `-fno-exceptions` 环境下 `ostringstream` 可能不可用\n\n### 6.5 为什么 Validate() 不抛异常?\n\nnewosp 编译选项包含 `-fno-exceptions`。`Validate()` 返回 `bool`，调用方决定如何处理。这比异常更适合嵌入式:\n\n```cpp\nif (!msg.Validate()) {\n    OSP_LOG_WARN(\"proto\", \"invalid message, dropping\");\n    return;  // 而不是 try-catch\n}\n```\n\n## 7. 总结\n\nospgen 的核心价值不在于 \"YAML + Jinja2 生成 C++\" 这个技术本身 -- 这在 Web/DevOps 领域早已普及。它的价值在于**将这个模式精确适配到嵌入式 C++17 的约束集**:\n\n| 嵌入式约束 | ospgen 的回答 |\n|-----------|-------------|\n| `trivially_copyable` | `static_assert` 强制保证 |\n| 零堆分配 | 固定数组 + snprintf Dump + noexcept 构造 |\n| `-fno-exceptions` | `Validate()` 返回 bool，不抛异常 |\n| 跨平台 sizeof | `expected_size` + `static_assert` |\n| `memcpy` 安全 | 仅生成 POD struct |\n| 编译期分发 | `EventMessage`/`MessageEvent` 模板特化 |\n| MISRA C++ | `enum class` 替代裸 enum |\n\n200 行 Python + 2 个 Jinja2 模板，解决了嵌入式消息通信中手写 struct 的一整类工程问题。如果你的项目也在用 C++17 + 消息总线/共享内存/自定义协议，ospgen 的思路值得参考。\n",
      "ctime": "1771552673",
      "mtime": "1771552673",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/newosp_shell_multibackend.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651718190",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "newosp 调试 Shell: 多后端架构与运行时控制命令设计",
      "brief_content": "工业嵌入式系统需要在 TCP telnet、串口、stdin 等不同环境下统一调试。newosp 的 Shell 模块通过函数指针 I/O 抽象实现多后端统一架构，通过 TCLAP 风格的子命令分发实",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> [newosp](https://github.com/DeguiLiu/newosp) 项目地址\n>\n> 相关文章:\n> - [嵌入式 Linux 调试 Shell 设计: 从 RT-Thread MSH 到自研 embsh](../embedded_cli_msh/) -- Shell 引擎选型与设计决策\n> - [telsh: 从 boost::asio 到纯 POSIX 的 Telnet Shell 重构](../telsh_refactoring/) -- Telnet 协议与会话管理实现\n\n---\n\n## 1. 结论前置\n\nnewosp 的调试 Shell 模块在一个 header-only 文件中提供完整的嵌入式调试能力:\n\n| 能力 | 实现 |\n|------|------|\n| 多后端统一 | TCP telnet / stdin / UART 三后端，函数指针 I/O 抽象，一套命令到处运行 |\n| 运行时控制 | 子命令分发 + 类型安全参数解析，支持动态改日志、改配置、重置统计、切换生命周期 |\n| 零侵入桥接 | 模块本身不依赖 shell.hpp，shell_commands.hpp 单向引用模块头文件 |\n| 资源开销 | ConsoleShell 300B 栈 + 0 堆 + 1 线程；GlobalCmdRegistry 64 槽 ~2KB |\n\n**18 个命令总览:**\n\n| 类型 | 命令 | 功能 |\n|------|------|------|\n| 控制 | `osp_log`, `osp_config`, `osp_bus`, `osp_lifecycle` | 运行时修改日志级别、配置参数、重置统计、状态机转换 |\n| 诊断 | `osp_watchdog`, `osp_faults`, `osp_sysmon` 等 14 个 | 只读查询系统各层状态 |\n\n**设计约束:**\n- C++17 header-only, `-fno-exceptions -fno-rtti`\n- 零堆分配 (函数指针 + 静态局部变量 + 栈缓冲)\n- 命令签名 `int (*)(int argc, char* argv[])` 与 POSIX main 一致\n\n---\n\n## 2. 架构总览\n\n```\n┌─────────────────────────────────────────────────────┐\n│                   应用层                             │\n│  shell_cmd::RegisterLog/Config/Bus/Lifecycle/...    │\n│  (zero-intrusion bridge: 模块不依赖 shell.hpp)      │\n├─────────────────────────────────────────────────────┤\n│                   命令系统                           │\n│  GlobalCmdRegistry (64 槽)                          │\n│  ShellDispatch (子命令分发)                          │\n│  ShellParseInt/Uint/Bool (类型安全参数解析)          │\n├─────────────────────────────────────────────────────┤\n│                   Shell 引擎                         │\n│  ShellRunSession (逐字符读取/分词/查表/执行)        │\n│  ShellPrintf (thread-local 会话路由)                │\n│  Tab 补全 / 历史 / ESC 序列 / IAC 协议             │\n├─────────────────────────────────────────────────────┤\n│                   I/O 抽象层                         │\n│  ShellWriteFn / ShellReadFn (函数指针)              │\n│  ┌──────────┐  ┌──────────┐  ┌──────────┐          │\n│  │ TCP send │  │ POSIX    │  │ POSIX    │          │\n│  │ /recv    │  │ write/   │  │ write/   │          │\n│  │ (telnet) │  │ read     │  │ read     │          │\n│  │          │  │ (stdin)  │  │ (UART)   │          │\n│  └──────────┘  └──────────┘  └──────────┘          │\n└─────────────────────────────────────────────────────┘\n```\n\n四层各司其职:\n- **I/O 抽象层**: 函数指针隔离底层差异, 后端可运行时切换\n- **Shell 引擎**: 行编辑、分词、Tab 补全、历史, 与后端无关\n- **命令系统**: 注册/查找/分发/参数解析, 与 Shell 引擎解耦\n- **应用层**: shell_commands.hpp 桥接模块状态, 零侵入\n\n---\n\n## 3. I/O 抽象: 函数指针方案\n\n### 3.1 方案选型\n\n| 方案 | 优点 | 缺点 | 判定 |\n|------|------|------|------|\n| 虚基类 `IShellBackend` | 语义清晰 | vtable 开销, 违反\"不优先 virtual\" | 否 |\n| 模板参数 `ShellT<Backend>` | 编译期绑定, 可内联 | Printf 类型不统一, 无法运行时选择后端 | 否 |\n| 函数指针 | 零 vtable, 运行时可选, POSIX 自然映射 | 无法内联 | **选用** |\n\nShell I/O 不是热路径 (人类打字速度 ~10 字符/秒), 无法内联的代价可忽略. 函数指针与 POSIX `read(2)/write(2)` 签名天然一致, 无需适配层.\n\n### 3.2 实现\n\n```cpp\n// 与 POSIX read/write 签名一致\nusing ShellWriteFn = ssize_t (*)(int fd, const void* buf, size_t len);\nusing ShellReadFn  = ssize_t (*)(int fd, void* buf, size_t len);\n\n// TCP 后端: send() with MSG_NOSIGNAL (避免 SIGPIPE)\ninline ssize_t ShellTcpWrite(int fd, const void* buf, size_t len) {\n  return ::send(fd, buf, len, MSG_NOSIGNAL);\n}\n\n// POSIX 后端: write()/read() 适用于 stdin、stdout、UART\ninline ssize_t ShellPosixWrite(int fd, const void* buf, size_t len) {\n  return ::write(fd, buf, len);\n}\n```\n\n不用 `std::function` 或 `FixedFunction` 的原因: Shell I/O 函数是无状态的 (不需要捕获), 原始函数指针最轻量.\n\n### 3.3 统一会话结构\n\n所有后端共享同一个 ShellSession:\n\n```cpp\nstruct ShellSession {\n  int read_fd = -1;               // 读端 fd (stdin/socket/uart)\n  int write_fd = -1;              // 写端 fd (stdout/socket/uart)\n  ShellWriteFn write_fn = nullptr;  // 后端特定写函数\n  ShellReadFn  read_fn  = nullptr;  // 后端特定读函数\n  bool telnet_mode = false;         // TCP 需要 \\r\\n, IAC 处理\n  char line_buf[256] = {};          // 命令行缓冲 (栈分配)\n  uint32_t line_pos = 0;\n  std::atomic<bool> active{false};\n};\n```\n\n关键点: `read_fd/write_fd` 分开 (stdin 和 stdout 是不同 fd); `telnet_mode` 区分 TCP 和 POSIX 行结束符; 256 字节 line_buf 栈分配, 零堆.\n\n### 3.4 ShellPrintf: thread-local 会话路由\n\n命令回调只调 `ShellPrintf(fmt, ...)`, 不关心底层后端:\n\n```cpp\ninline int ShellPrintf(const char* fmt, ...) {\n  ShellSession* sess = detail::CurrentSession();  // thread-local\n  if (sess == nullptr) return -1;\n  char buf[256];\n  va_list args;\n  va_start(args, fmt);\n  int n = std::vsnprintf(buf, sizeof(buf), fmt, args);\n  va_end(args);\n  if (n > 0) sess->write_fn(sess->write_fd, buf, n);\n  return n;\n}\n```\n\n每个会话运行在独立线程, `CurrentSession()` 返回 thread-local 指针, 天然隔离, 无需传参或全局锁. 命令执行前设置指针, 执行后清空:\n\n```\ncmd->func(argc, argv)\n  -> ShellPrintf(\"...\")\n    -> CurrentSession()->write_fn(write_fd, buf, len)\n       // TCP: send()  |  Console: write(1, ...)  |  UART: write(uart_fd, ...)\n```\n\n### 3.5 三个后端\n\n| 后端 | 场景 | 线程 | 堆 | 特性 |\n|------|------|------|-----|------|\n| `DebugShell` | 实验室 TCP telnet | 1 accept + N session | ~4KB | IAC 协议, 可选认证, 多连接 |\n| `ConsoleShell` | SSH 远程, 无 telnet | 1 | 0 | termios raw mode, 管道测试 |\n| `UartShell` | 早期硬件调试, 现场 | 1 | 0 | cfmakeraw, 支持 9600~921600 |\n\n```cpp\n// 实验室: telnet localhost 5090\nosp::DebugShell::Config tcp_cfg{.port = 5090, .max_connections = 2};\nosp::DebugShell tcp_shell(tcp_cfg);\ntcp_shell.Start();\n\n// SSH 远程: ./my_app --console\nosp::ConsoleShell console_shell;\nconsole_shell.Start();\n\n// 串口调试: minicom -D /dev/ttyUSB0\nosp::UartShell::Config uart_cfg{.device = \"/dev/ttyS0\", .baudrate = 115200};\nosp::UartShell uart_shell(uart_cfg);\nuart_shell.Start();\n```\n\n---\n\n## 4. 命令系统\n\n### 4.1 全局命令注册表\n\n```cpp\nstruct ShellCmd {\n  const char* name;    // 命令名 (字面量, 无拷贝)\n  ShellCmdFn func;     // int (*)(int argc, char* argv[])\n  const char* desc;    // 帮助文本\n};\n\nclass GlobalCmdRegistry {\n  ShellCmd cmds_[64];  // 固定 64 槽, 零堆分配\n  uint32_t count_ = 0;\n  // Meyer's 单例: 所有后端共享同一个注册表\n  static GlobalCmdRegistry& Instance();\n  bool Register(const char* name, ShellCmdFn func, const char* desc);\n  const ShellCmd* Find(const char* name) const;\n  uint32_t AutoComplete(const char* prefix, char* out, size_t out_size) const;\n};\n```\n\n注册方式:\n\n```cpp\n// 方式一: 宏 (全局函数, 静态注册)\nint my_cmd(int argc, char* argv[]) { ... }\nOSP_SHELL_CMD(my_cmd, \"My command\");\n\n// 方式二: 模板 Register 函数 (带上下文捕获)\ntemplate <typename T>\nvoid RegisterWatchdog(T& wd) {\n  static T* s_wd = &wd;  // 静态局部变量捕获, 零堆分配\n  static auto cmd = [](int, char*[]) -> int { ... };\n  GlobalCmdRegistry::Instance().Register(\"osp_watchdog\", +cmd, \"...\");\n}\n```\n\n`+cmd` 将无捕获 lambda 转为函数指针 (C++ 标准保证). `static` 确保对象指针在整个程序生命周期内有效, 且无堆分配.\n\n### 4.2 子命令分发: ShellDispatch\n\n当命令需要多个操作时 (如 `osp_bus status` 和 `osp_bus reset`), 手工解析 argv 容易出错且重复. ShellDispatch 参考 TCLAP 思想, 用声明式子命令表实现分发:\n\n```cpp\nstruct ShellSubCmd {\n  const char* name;       // 子命令名\n  const char* args_desc;  // 参数描述 (e.g. \"<level>\"), nullptr=无参数\n  const char* help;       // 帮助文本\n  ShellCmdFn handler;     // 处理函数\n};\n\nint ShellDispatch(int argc, char* argv[],\n                  const ShellSubCmd* table, uint32_t count,\n                  ShellCmdFn default_fn = nullptr) noexcept;\n```\n\n行为:\n- **无子命令** (`argc <= 1`): 调用 `default_fn` (保持向后兼容), 若为 nullptr 则打印帮助\n- **`help`**: 自动生成格式化帮助表\n- **匹配子命令**: 调用 `handler(argc-1, argv+1)` (argv 左移, 子命令名变 argv[0])\n- **未匹配**: 打印错误提示\n\n使用示例:\n\n```cpp\nstatic const ShellSubCmd kSubs[] = {\n    {\"status\", nullptr,    \"Show statistics\",  sub_status},\n    {\"reset\",  nullptr,    \"Reset counters\",   sub_reset},\n};\n\nstatic auto cmd = [](int argc, char* argv[]) -> int {\n    return ShellDispatch(argc, argv, kSubs, 2U, sub_status);\n    //                                          ^^^^^^^^^^\n    //                    default_fn: 无参数时执行 status (向后兼容)\n};\n```\n\n效果:\n\n```\nosp> osp_bus              # 调用 default_fn (show_status), 向后兼容\nosp> osp_bus status       # 显式调用 status\nosp> osp_bus reset        # 重置计数器\nosp> osp_bus help         # 自动生成帮助:\n  status       - Show statistics\n  reset        - Reset counters\nosp> osp_bus bogus        # Unknown subcommand: bogus (try 'osp_bus help')\n```\n\n### 4.3 类型安全参数解析\n\n命令参数作为 `char*` 传入, 直接 `atoi` 不安全 (undefined behavior on overflow). Shell 提供三个解析函数, 返回 `optional`:\n\n```cpp\n[[nodiscard]] optional<int32_t>  ShellParseInt(const char* str) noexcept;\n[[nodiscard]] optional<uint32_t> ShellParseUint(const char* str) noexcept;\n[[nodiscard]] optional<bool>     ShellParseBool(const char* str) noexcept;\n```\n\n- `ShellParseInt`: `strtol` base 10, 拒绝 null / 空串 / 尾部垃圾 / 溢出\n- `ShellParseUint`: `strtoul`, 额外拒绝前导 `-`\n- `ShellParseBool`: 大小写无关匹配 `true/1/yes/on` 和 `false/0/no/off`\n\n使用示例:\n\n```cpp\nauto num = ShellParseUint(argv[1]);\nif (!num.has_value() || num.value() > 5U) {\n    ShellPrintf(\"Invalid level: %s (expected 0-5)\\r\\n\", argv[1]);\n    return -1;\n}\n```\n\n辅助函数:\n\n```cpp\n[[nodiscard]] bool ShellArgCheck(int argc, int min_argc,\n                                 const char* usage) noexcept;\n// argc < min_argc 时自动打印 \"Usage: <usage>\" 并返回 false\n```\n\n---\n\n## 5. 运行时控制命令\n\n### 5.1 从只读到可控\n\n嵌入式系统调试的两类需求:\n\n| 需求 | 传统做法 | 问题 |\n|------|---------|------|\n| **查状态** (只读) | 诊断命令打印统计 | 已解决, 14 个诊断命令覆盖 |\n| **改行为** (可控) | 重新编译 + 烧录 + 重启 | 现场调试无法重编译, 修改一个日志级别要停机 |\n\nShell 的控制命令解决第二类需求: 在运行时动态调整系统行为, **仅修改内存, 重启恢复原值**, 适合现场调试和问题排查.\n\n### 5.2 osp_log: 日志级别控制\n\n```\nosp> osp_log\n[osp_log] level: INFO (1)\n\nosp> osp_log level debug\n[osp_log] level set to DEBUG\n\nosp> osp_log level 3\n[osp_log] level set to ERROR\n```\n\n实现要点:\n\n```cpp\ninline void RegisterLog() {\n  // ...\n  static auto sub_level = [](int argc, char* argv[]) -> int {\n    if (!ShellArgCheck(argc, 2, \"osp_log level <0-5|debug|...>\"))\n      return -1;\n\n    // 先尝试数字\n    auto num = ShellParseUint(argv[1]);\n    if (num.has_value()) {\n      if (num.value() > 5U) { /* 范围检查 */ return -1; }\n      log::SetLevel(static_cast<log::Level>(num.value()));\n      return 0;\n    }\n\n    // 再尝试名称 (大小写无关)\n    static const struct { const char* name; log::Level level; } kNames[] = {\n        {\"debug\", log::Level::kDebug}, {\"info\",  log::Level::kInfo},\n        {\"warn\",  log::Level::kWarn},  {\"error\", log::Level::kError},\n        {\"fatal\", log::Level::kFatal}, {\"off\",   log::Level::kOff},\n    };\n    for (const auto& n : kNames) {\n      if (detail::ShellStrCaseEq(argv[1], n.name)) {\n        log::SetLevel(n.level);\n        return 0;\n      }\n    }\n    return -1;\n  };\n  // ShellDispatch 子命令表: status, level\n}\n```\n\n### 5.3 osp_config: 配置查看与运行时修改\n\n```\nosp> osp_config\n[osp_config] all entries (3):\n  [net] port = 8080\n  [net] host = 192.168.1.100\n  [log] level = 3\n\nosp> osp_config set net port 9090\n[net] port = 9090 (set)\n\nosp> osp_config get net port\n[net] port = 9090\n```\n\nConfigStore 新增两个 public 方法支撑此命令:\n\n```cpp\nclass ConfigStore {\n public:\n  // 运行时设置 (upsert: 存在则更新, 不存在则新增)\n  bool SetString(const char* section, const char* key, const char* value) {\n    return AddEntry(section, key, value);  // protected AddEntry 已实现 upsert\n  }\n\n  // 遍历所有条目\n  template <typename Fn>\n  void ForEach(Fn&& visitor) const {\n    for (uint32_t i = 0; i < count_; ++i)\n      visitor(entries_[i].section, entries_[i].key, entries_[i].value);\n  }\n};\n```\n\n**仅修改内存**: `SetString` 不触发文件写入, 重启后丢失. 这是有意的设计 -- 现场调试改配置不应永久影响设备.\n\n### 5.4 osp_bus: 统计重置\n\n```\nosp> osp_bus\n[osp_bus] AsyncBus Statistics\n  published:     12450\n  dropped:       2\n  backpressure:  Normal\n\nosp> osp_bus reset\n[osp_bus] Statistics reset.\n```\n\n向后兼容: 无参数调用仍显示统计 (通过 `default_fn = show_status`).\n\n### 5.5 osp_lifecycle: 生命周期状态机转换\n\n```\nosp> osp_lifecycle\n[osp_lifecycle] LifecycleNode\n  state: Unconfigured (unconfigured)\n\nosp> osp_lifecycle configure\n[osp_lifecycle] Configure OK.\n\nosp> osp_lifecycle activate\n[osp_lifecycle] Activate OK.\n\nosp> osp_lifecycle cleanup\n[osp_lifecycle] Cleanup failed: InvalidTransition\n```\n\n6 个子命令对应状态机转换:\n\n```\nUnconfigured --configure--> Inactive --activate--> Active\n     ^                         |                     |\n     +------cleanup-----------+    <--deactivate---+\n     |                                              |\n     +--shutdown--> Finalized <------shutdown-------+\n```\n\n实现使用 `expected<void, LifecycleError>` 返回值, 转换失败打印错误类型 (`InvalidTransition` / `CallbackFailed` / `AlreadyFinalized`):\n\n```cpp\nstatic auto try_transition = [](const char* name,\n                                expected<void, LifecycleError> result) -> int {\n  if (result.has_value()) {\n    ShellPrintf(\"[osp_lifecycle] %s OK.\\r\\n\", name);\n    return 0;\n  }\n  ShellPrintf(\"[osp_lifecycle] %s failed: %s\\r\\n\",\n              name, lifecycle_error_name(result.get_error()));\n  return -1;\n};\n```\n\n---\n\n## 6. 诊断命令\n\n14 个只读命令按架构层分组, 通过模板 Register 函数零侵入注册:\n\n| 层 | 命令 | 输出内容 |\n|----|------|----------|\n| **可靠性** | `osp_watchdog` | 各线程名称、超时阈值、心跳间隔、是否超时 |\n| | `osp_faults` | 各优先级报告/丢弃数、队列使用率、最近 N 条故障 |\n| **通信** | `osp_pool` | 分发/处理消息数、队列满次数 |\n| **网络** | `osp_transport` | 收包/丢包/乱序/重复数、丢包率 |\n| | `osp_serial` | 帧/字节收发数、CRC/同步/超时错误、重传次数 |\n| **服务** | `osp_nodes` | HSM 节点 ID、状态、心跳间隔、丢失心跳数 |\n| | `osp_nodes_basic` | 基础节点连接状态 |\n| | `osp_service` | 服务 HSM 当前状态 |\n| | `osp_discovery` | 发现 HSM 状态、丢失节点数 |\n| **应用** | `osp_qos` | QoS 配置各字段 (可靠性/历史/时限/生存期) |\n| | `osp_app` | 应用名、实例数、待处理消息 |\n| **基础** | `osp_sysmon` | CPU 使用率/温度、内存使用、磁盘使用 |\n| | `osp_mempool` | 容量、已用、空闲 |\n| | `help` | 列出所有已注册命令 |\n\n示例输出:\n\n```\nosp> osp_watchdog\n[osp_watchdog] ThreadWatchdog (3/8 active, 0 timed out)\n  [0] main_loop            timeout=1000ms  last_beat=12ms_ago  OK\n  [1] sensor_thread        timeout=500ms   last_beat=45ms_ago  OK\n  [2] comm_thread          timeout=2000ms  last_beat=1501ms_ago  TIMEOUT\n\nosp> osp_sysmon\n[osp_sysmon] SystemMonitor\n  CPU:  total=15%  user=10%  sys=5%  iowait=0%\n  Temp: 42.3 C\n  Mem:  total=1048576kB  avail=524288kB  used=50%\n  Disk[0]: total=16106127360B  avail=8053063680B  used=50%\n```\n\n---\n\n## 7. 零侵入桥接模式\n\n`shell_commands.hpp` 的设计原则: 模块 (bus, watchdog, config...) 完全不知道 Shell 的存在. 桥接文件单向依赖:\n\n```\nshell_commands.hpp ──include──> shell.hpp\n                   ──include──> bus.hpp, watchdog.hpp, config.hpp, ...\n\nbus.hpp ──X──> shell.hpp  (bus 不依赖 shell)\n```\n\n不需要 Shell 的场景 (如 MCU 移植), 不 include shell_commands.hpp 即可, 零开销.\n\n注册实现模式:\n\n```cpp\ntemplate <typename WatchdogType>\ninline void RegisterWatchdog(WatchdogType& wd) {\n  // (1) 静态局部指针: 程序生命周期有效, 零堆分配\n  static WatchdogType* s_wd = &wd;\n\n  // (2) 无捕获 lambda: +cmd 转为函数指针\n  static auto cmd = [](int /*argc*/, char* /*argv*/[]) -> int {\n    ShellPrintf(\"[osp_watchdog] ...\\r\\n\");\n    s_wd->ForEachSlot([](const WatchdogSlotInfo& info) {\n      ShellPrintf(\"  [%u] %-20s ...\\r\\n\", info.slot_id, info.name);\n    });\n    return 0;\n  };\n\n  // (3) 注册到全局命令表\n  GlobalCmdRegistry::Instance().Register(\"osp_watchdog\", +cmd, \"...\");\n}\n```\n\n用户代码:\n\n```cpp\n#include \"osp/shell_commands.hpp\"\n\n// 按需注册, 不需要的命令不注册 = 零开销\nosp::shell_cmd::RegisterWatchdog(watchdog);\nosp::shell_cmd::RegisterFaults(collector);\nosp::shell_cmd::RegisterLog();\nosp::shell_cmd::RegisterConfig(config);\nosp::shell_cmd::RegisterBusStats(bus);\nosp::shell_cmd::RegisterLifecycle(lifecycle_node);\n```\n\n---\n\n## 8. 无硬件测试\n\nShell 的 I/O 抽象使得测试不依赖物理硬件:\n\n### 8.1 pipe(2) 模拟 ConsoleShell\n\n```cpp\nTEST_CASE(\"ConsoleShell executes help command\") {\n    int cmd_pipe[2], out_pipe[2];\n    ::pipe(cmd_pipe);   // Shell 从 cmd_pipe[0] 读命令\n    ::pipe(out_pipe);   // Shell 向 out_pipe[1] 写输出\n\n    osp::ConsoleShell::Config cfg;\n    cfg.read_fd = cmd_pipe[0];\n    cfg.write_fd = out_pipe[1];\n    cfg.raw_mode = false;  // pipe 不需要 termios\n\n    osp::ConsoleShell shell(cfg);\n    shell.Start();\n\n    ::write(cmd_pipe[1], \"help\\n\", 5);  // 注入命令\n    // 从 out_pipe[0] 读输出, 验证包含 \"help\"\n}\n```\n\n### 8.2 openpty() 模拟 UartShell\n\n```cpp\nTEST_CASE(\"UartShell executes via PTY\") {\n    int master_fd, slave_fd;\n    ::openpty(&master_fd, &slave_fd, nullptr, nullptr, nullptr);\n\n    osp::UartShell::Config cfg;\n    cfg.override_fd = slave_fd;  // Shell 使用 PTY slave 端\n    osp::UartShell shell(cfg);\n    shell.Start();\n\n    ::write(master_fd, \"osp_bus\\n\", 8);  // 通过 master 注入命令\n    // 从 master_fd 读输出\n}\n```\n\n### 8.3 命令回调: MockSession\n\n控制命令测试使用 pipe-backed MockSession 捕获 ShellPrintf 输出:\n\n```cpp\nstruct MockSession {\n  osp::detail::ShellSession session{};\n  int capture_read_fd, capture_write_fd;  // pipe pair\n\n  MockSession() {\n    int pipefd[2];\n    ::pipe(pipefd);\n    capture_read_fd = pipefd[0];\n    capture_write_fd = pipefd[1];\n    session.write_fd = capture_write_fd;\n    session.write_fn = osp::detail::ShellPosixWrite;\n    // ...\n  }\n\n  std::string DrainOutput() { /* read from capture_read_fd */ }\n};\n\n// RAII guard: 设置/清除 thread-local CurrentSession\nstruct SessionGuard {\n  explicit SessionGuard(MockSession& m) {\n    osp::detail::CurrentSession() = &m.session;\n  }\n  ~SessionGuard() { osp::detail::CurrentSession() = nullptr; }\n};\n```\n\n测试示例:\n\n```cpp\nTEST_CASE(\"osp_log level debug sets DEBUG\") {\n    osp::shell_cmd::RegisterLog();\n    MockSession mock;\n    SessionGuard guard(mock);\n\n    const auto* cmd = GlobalCmdRegistry::Instance().Find(\"osp_log\");\n    char arg0[] = \"osp_log\", arg1[] = \"level\", arg2[] = \"debug\";\n    char* argv[] = {arg0, arg1, arg2};\n    int rc = cmd->func(3, argv);\n    CHECK(rc == 0);\n    CHECK(osp::log::GetLevel() == osp::log::Level::kDebug);\n}\n```\n\n测试覆盖: 762 tests, ASan + UBSan clean.\n\n---\n\n## 9. 资源开销\n\n| 组件 | 栈 | 堆 | 线程 | 说明 |\n|------|-----|-----|------|------|\n| GlobalCmdRegistry (64 槽) | ~2 KB | 0 | 0 | Meyer's 单例 |\n| DebugShell (2 连接) | ~1 KB | ~4 KB | 3 | accept + 2 session |\n| ConsoleShell | ~300 B | 0 | 1 | 单会话 |\n| UartShell | ~300 B | 0 | 1 | 单会话 |\n| 18 个命令回调 | ~150 B | 0 | 0 | 静态局部变量 |\n| ShellDispatch 子命令表 | 静态 | 0 | 0 | const 数组 |\n\nConsoleShell/UartShell 比 DebugShell 少 ~4KB 堆和 2 个线程, 适合资源受限场景.\n\n---\n\n## 10. 经验总结\n\n1. **函数指针是嵌入式 I/O 抽象的最佳平衡点**. 比虚基类轻量, 比模板灵活, 对非热路径场景足够\n\n2. **thread-local 是 Shell 会话路由的自然选择**. 每个会话独立线程, 天然隔离, 无需传参\n\n3. **子命令分发要带 default_fn**. `osp_bus` 无参数时仍显示统计, 与升级前行为一致, 用户无感知升级\n\n4. **运行时修改仅限内存**. 现场调试改配置/日志级别不应永久影响设备, 重启恢复原值是刻意的安全边界\n\n5. **零侵入桥接优于修改模块接口**. 模块不知道 Shell 存在, 不需要 Shell 时零开销, 移植到无 Shell 平台零改动\n\n6. **pipe(2) 和 openpty() 是测试 I/O 的利器**. 不需要物理硬件也能测试完整的 Shell 交互流程\n\n---\n\n## 参考\n\n- newosp Shell 命令参考: [docs/shell_commands_zh.md](https://github.com/DeguiLiu/newosp/blob/main/docs/shell_commands_zh.md)\n- newosp 项目: https://github.com/DeguiLiu/newosp\n- RT-Thread FinSH/MSH: Shell 引擎灵感来源 (ShellSplit 分词器)\n",
      "ctime": "1771552676",
      "mtime": "1771552676",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/newosp_spmc_shm_data_distribution.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469718574",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "跨进程数据分发: newosp SPMC 共享内存实战",
      "brief_content": "从进程内 MPSC 总线到跨进程 SPMC 共享内存，newosp 同时支持 1:1 (SPSC) 和 1:N (SPMC) 两种共享内存数据分发模式。本文以 LiDAR 点云分发为例，展示 SPMC",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 在[上一篇文章](/posts/practice/cyberrt_datavisitor_mccc_rewrite/)中，我们用无锁 MPSC 消息总线实现了进程内的观察者模式数据分发。但工业嵌入式系统中，数据源和消费者往往运行在不同进程甚至不同容器中。本文介绍 newosp 的 SPMC 共享内存通道，将数据分发从进程内扩展到跨进程，支持一写多读的零拷贝传输。\n\n## 1. 问题: 进程内分发不够用\n\n[基于无锁消息总线的观察者模式](/posts/practice/cyberrt_datavisitor_mccc_rewrite/)解决了进程内的数据分发:\n\n```\n进程内 (MPSC Bus)\n┌─────────────────────────────────┐\n│  Receiver → AsyncBus → Visitor  │\n│                     → Visitor   │\n│                     → Visitor   │\n└─────────────────────────────────┘\n```\n\n这在单进程架构中工作良好。但当系统规模增长，出现以下需求时，进程内方案遇到瓶颈:\n\n- **故障隔离**: 感知算法崩溃不应影响数据采集进程\n- **独立升级**: 融合模块更新不需要重启整个系统\n- **资源隔离**: 不同消费者需要独立的 CPU/内存配额\n- **多语言**: 数据源是 C++ 驱动，消费者可能是 Python 算法\n\n这些场景需要跨进程的数据分发。\n\n## 2. newosp 的两层数据分发架构\n\nnewosp 提供完整的两层数据分发方案:\n\n```\n层级 1: 进程内 (AsyncBus, MPSC)\n  多个生产者 → 无锁 Ring Buffer → 单 Worker 线程 → 多个订阅者\n  适用: 同进程内的模块间通信\n\n层级 2: 跨进程 (ShmSpmcByteChannel, SPMC)\n  单个生产者 → POSIX 共享内存 → 多个消费者进程\n  适用: 跨进程/跨容器的数据分发\n```\n\n两层可以组合: 数据采集进程通过 SPMC 共享内存分发原始数据，每个消费者进程内部再用 AsyncBus 做二次路由。\n\n### 共享内存通道对比\n\n| 维度 | ShmByteChannel (SPSC) | ShmSpmcByteChannel (SPMC) |\n|------|----------------------|--------------------------|\n| 消费者数 | 1 | 1..N (编译期可配，默认 8) |\n| 写入检查 | `head - tail` | `head - slowest_tail` |\n| 通知机制 | `futex wake 1` | `futex wake ALL` |\n| 消费者注册 | 无 | CAS 原子注册 |\n| 适用场景 | 点对点传输 | 数据分发 (1:N) |\n| 内存开销 | header 64B + ring | header 64B + N×8B tails + ring |\n\nSPSC 通道 (`ShmByteChannel`) 适合确定性的点对点传输，如传感器驱动到预处理模块。SPMC 通道 (`ShmSpmcByteChannel`) 适合一对多分发，如 LiDAR 点云同时送给感知、融合、日志三个模块。\n\n## 3. SPMC 共享内存设计\n\n### 3.1 内存布局\n\n```\nPOSIX 共享内存 (/osp_lidar_spmc)\n┌──────────────────────────────────────────────┐\n│ ShmSpmcByteRingHeader (cache-line aligned)   │\n│   head          : atomic<uint32_t>           │\n│   capacity      : uint32_t                   │\n│   max_consumers : uint32_t                   │\n│   consumer_count: atomic<uint32_t>           │\n│   tails[N]      : atomic<uint32_t> × N       │  ← 每个消费者独立 tail\n│   active[N]     : atomic<uint8_t>  × N       │  ← 注册/注销标志\n│   futex_word    : atomic<uint32_t>           │  ← futex 通知\n│   writer_pid    : atomic<uint32_t>           │\n├──────────────────────────────────────────────┤\n│ Ring Buffer Data (capacity bytes)            │\n│   [4B len][payload][4B len][payload]...      │  ← 长度前缀消息\n└──────────────────────────────────────────────┘\n```\n\n关键设计:\n\n- **Per-consumer tail**: 每个消费者维护独立的读位置，互不干扰。写入时检查最慢消费者的 tail，防止覆盖未读数据。\n- **CAS 原子注册**: 消费者通过 `compare_exchange_strong` 原子操作注册到 `active[]` 数组，无锁、无竞态。\n- **futex 广播**: 写入后 `FUTEX_WAKE` 唤醒所有等待的消费者，而非逐个通知。\n- **长度前缀**: 每条消息前 4 字节 LE 编码长度，支持变长消息。\n\n### 3.2 写入流程\n\n```\nProducer::Write(data, len)\n  │\n  ├─ 计算 needed = 4 + len (长度前缀 + 数据)\n  │\n  ├─ 检查可写空间:\n  │    slowest_tail = min(tails[i] for active[i])\n  │    writeable = capacity - (head - slowest_tail)\n  │    if writeable < needed → 返回 kFull\n  │\n  ├─ 写入 ring buffer (可能跨尾部回绕)\n  │    store length (4B LE)\n  │    memcpy data\n  │\n  ├─ head.store(new_head, release)  ← 发布写入\n  │\n  └─ futex_wake(futex_word, INT_MAX)  ← 唤醒所有消费者\n```\n\n### 3.3 读取流程\n\n```\nConsumer[i]::Read(buf, max_len)\n  │\n  ├─ readable = head.load(acquire) - tails[i]\n  │    if readable == 0 → 返回 kEmpty\n  │\n  ├─ 读取长度前缀 (4B LE)\n  │    if msg_len > max_len → 返回 kTooLarge\n  │\n  ├─ memcpy data from ring buffer\n  │\n  └─ tails[i].store(new_tail, release)  ← 推进本消费者 tail\n```\n\n每个消费者独立推进自己的 tail，不影响其他消费者。这意味着:\n- 快消费者不会被慢消费者阻塞\n- 慢消费者会限制写入者的可用空间 (背压)\n- 消费者崩溃后注销，其 tail 不再参与 slowest_tail 计算\n\n### 3.4 消费者生命周期\n\n```\nOpenReader(channel_name)\n  │\n  ├─ shm_open + mmap (只读映射)\n  ├─ RegisterConsumer():\n  │    遍历 active[] 找空位\n  │    CAS: active[i] = 0 → 1\n  │    tails[i] = head (从当前位置开始读)\n  │    consumer_count.fetch_add(1)\n  └─ 返回 consumer_id = i\n\n~ShmSpmcByteChannel() (析构)\n  │\n  ├─ UnregisterConsumer():\n  │    active[consumer_id] = 0\n  │    consumer_count.fetch_sub(1)\n  └─ munmap + close\n```\n\nRAII 保证: reader 对象析构时自动注销消费者，即使进程异常退出 (通过 destructor)。\n\n## 4. API 使用\n\n### 4.1 生产者\n\n```cpp\n#include \"osp/shm_transport.hpp\"\n\n// 创建 SPMC 通道 (256KB ring, 最多 4 消费者)\nauto result = osp::ShmSpmcByteChannel::CreateOrReplaceWriter(\n    \"lidar_spmc\", 256 * 1024, 4);\nif (!result.has_value()) { /* 错误处理 */ }\nauto channel = std::move(result.value());\n\n// 写入数据\nuint8_t frame[16016];\nFillLidarFrame(frame, seq, timestamp);\nauto wr = channel.Write(frame, sizeof(frame));\nif (!wr.has_value()) {\n  // ring full, 背压处理\n}\n```\n\n### 4.2 消费者\n\n```cpp\n// 打开已有通道 (自动注册为消费者)\nauto result = osp::ShmSpmcByteChannel::OpenReader(\"lidar_spmc\");\nif (!result.has_value()) { /* 通道不存在或消费者已满 */ }\nauto reader = std::move(result.value());\n\n// 等待数据 (futex, 超时 100ms)\nreader.WaitReadable(100);\n\n// 读取\nuint8_t buf[16016];\nauto rd = reader.Read(buf, sizeof(buf));\nif (rd.has_value()) {\n  uint32_t len = rd.value();\n  ProcessFrame(buf, len);\n}\n```\n\n### 4.3 编译期配置\n\n```cpp\n// 在包含头文件前定义，覆盖默认值\n#define OSP_SHM_SPMC_MAX_CONSUMERS 16  // 默认 8\n#include \"osp/shm_transport.hpp\"\n```\n\n## 5. 完整示例: LiDAR 点云分发\n\n[data_visitor_dispatcher](https://github.com/DeguiLiu/newosp/tree/main/examples/data_visitor_dispatcher) 示例模拟工业场景中的 LiDAR 点云一对多分发:\n\n```\n                    POSIX 共享内存\n                 /osp_lidar_spmc (256KB)\n                 ShmSpmcByteRing (SPMC)\n                        │\n    ┌───────────────────┼───────────────────┐\n    │                   │                   │\nProducer           Visitor-Logging    Visitor-Fusion\n(10 Hz LiDAR)     (帧统计/日志)      (障碍物检测)\n    │\n    ├── Monitor (telnet Shell)\n    │\nLauncher (进程管理器)\n```\n\n### 5.1 数据格式\n\n```cpp\nstruct LidarPoint {\n  float x, y, z;\n  uint8_t intensity, ring, pad[2];\n};  // 16 bytes\n\nstruct LidarFrame {\n  uint32_t magic;        // 0x4C494441 ('LIDA')\n  uint32_t seq_num;\n  uint32_t point_count;  // 1000\n  uint32_t timestamp_ms;\n  LidarPoint points[1000];\n};  // 16016 bytes\n```\n\n每帧 16016 字节，10 Hz 产生，256KB ring buffer 可缓存约 16 帧。\n\n### 5.2 HSM 驱动的生产者\n\n生产者使用层次状态机管理生命周期:\n\n```\nOperational (root)\n├── Init       → 创建 ShmSpmcByteChannel\n├── Running    → 父状态 (处理 SHUTDOWN/LIMIT)\n│   ├── Streaming → 10 Hz 帧生产\n│   └── Paused    → 背压 (ring full)\n├── Error      → 可恢复错误, 1s 后重试\n└── Done       → 清理退出\n```\n\n```cpp\n// 状态转换由事件驱动\nauto wr = ctx.channel.Write(ctx.frame_buf, kFrameDataSize);\nif (wr.has_value()) {\n  ++ctx.frames_sent;\n  if (ctx.frames_sent >= ctx.max_frames)\n    sm.Dispatch({kEvtLimitReached});  // → Done\n} else {\n  sm.Dispatch({kEvtRingFull});        // → Paused\n}\n```\n\n当 ring buffer 满时，生产者从 Streaming 转入 Paused 状态，周期性检查可写空间，恢复后自动回到 Streaming。这比简单的 sleep-retry 更清晰，状态转换可追踪、可调试。\n\n### 5.3 消费者: 日志 vs 融合\n\n两个消费者读取相同的数据，做不同的处理:\n\n**Visitor-Logging**: 每 10 帧输出统计，检测序号间隙，3 秒无数据报 stall。\n\n**Visitor-Fusion**: 计算点云包围盒 (bounding box)，模拟 1-3ms 处理延迟，处理过慢时进入 Overloaded 状态跳帧。\n\n两者完全独立，互不影响。融合模块崩溃不会影响日志模块，反之亦然。\n\n### 5.4 Shell 调试\n\nMonitor 进程提供 telnet 调试接口:\n\n```bash\n$ telnet localhost 9600\nosp> dvd_status\nChannel: osp_lidar_spmc\n  Capacity: 262144 bytes\n  Consumers: 2\n  Readable: 48048 bytes\n\nosp> dvd_stats\n  Frames observed: 150\n  Avg FPS: 9.98\n  Avg frame size: 16016 bytes\n\nosp> dvd_peek\n  Frame #150: magic=LIDA seq=149 points=1000 ts=15000ms\n```\n\n### 5.5 运行\n\n```bash\n# 一键启动所有进程\n./build/examples/data_visitor_dispatcher/osp_dvd_launcher --frames 200\n\n# 或手动启动\n./osp_dvd_producer osp_lidar_spmc 500    # 终端 1\n./osp_dvd_visitor_logging osp_lidar_spmc  # 终端 2\n./osp_dvd_visitor_fusion osp_lidar_spmc   # 终端 3\n./osp_dvd_monitor osp_lidar_spmc 9600     # 终端 4\ntelnet localhost 9600                      # 终端 5\n```\n\n## 6. 工业应用场景\n\n### 6.1 激光雷达点云分发\n\n最典型的 SPMC 场景。一个 LiDAR 驱动进程采集点云，同时分发给:\n- 感知模块 (障碍物检测)\n- 定位模块 (SLAM)\n- 日志模块 (数据录制)\n- 可视化模块 (调试显示)\n\n使用 SPMC 共享内存，4 个消费者读取同一份数据，零拷贝，无序列化开销。\n\n### 6.2 视觉传感器多路消费\n\n工业相机采集图像 (640×480, 30 FPS, ~900KB/帧):\n- 质检算法 (缺陷检测)\n- 定位算法 (视觉里程计)\n- 录像模块 (存储回放)\n\nSPMC 通道容量设为 4MB，可缓存约 4 帧，足够应对消费者的短暂延迟。\n\n### 6.3 CAN 总线数据广播\n\n车载/工业控制场景，CAN 网关进程接收总线数据:\n- 仪表盘显示进程\n- 数据记录进程\n- 远程诊断进程\n- OTA 升级监控进程\n\nCAN 帧很小 (8-64 字节)，但频率高 (1000+ msg/s)。SPMC 的 futex 广播通知比逐个 pipe 通知更高效。\n\n### 6.4 边缘计算数据流\n\n边缘网关接收传感器数据流:\n- 本地推理模块 (TensorRT/ONNX)\n- 云端上传模块 (MQTT/gRPC)\n- 本地存储模块 (时序数据库)\n- 告警模块 (阈值检测)\n\n不同模块可能用不同语言实现 (C++ 推理、Python 上传)，POSIX 共享内存是天然的跨语言 IPC。\n\n### 6.5 SPSC vs SPMC 选型指南\n\n| 场景 | 推荐 | 原因 |\n|------|------|------|\n| 传感器 → 预处理 (1:1) | ShmByteChannel (SPSC) | 确定性延迟，无 slowest_tail 开销 |\n| 传感器 → 多算法 (1:N) | ShmSpmcByteChannel (SPMC) | 一份数据多路消费，零拷贝 |\n| 高频小消息 (>1000 msg/s) | SPMC + 批量读取 | futex 广播比多路 pipe 高效 |\n| 大帧低频 (<30 FPS) | SPMC | ring buffer 缓存足够 |\n| 消费者数动态变化 | SPMC | CAS 注册/注销，运行时增减 |\n| 消费者数固定为 1 | SPSC | 更简单，无注册开销 |\n\n## 7. 与进程内分发的对比\n\n回顾[基于无锁消息总线的观察者模式](/posts/practice/cyberrt_datavisitor_mccc_rewrite/)，两种方案的定位:\n\n| 维度 | AsyncBus (进程内) | ShmSpmcByteChannel (跨进程) |\n|------|-------------------|---------------------------|\n| 通信范围 | 同进程线程间 | 跨进程 (POSIX shm) |\n| 并发模型 | MPSC (多写单读) | SPMC (单写多读) |\n| 数据格式 | `std::variant` 类型安全 | 原始字节流 (应用层定义格式) |\n| 序列化 | 无 (内存直传) | 无 (共享内存零拷贝) |\n| 故障隔离 | 无 (同进程) | 有 (进程级隔离) |\n| 动态订阅 | `shared_ptr` + `weak_ptr` | CAS 原子注册 |\n| 通知机制 | Ring Buffer 轮询 | futex 唤醒 |\n| 延迟 | ~100ns (L1 cache) | ~1us (共享内存 + futex) |\n| 适用场景 | 模块间解耦 | 进程间数据分发 |\n\n两者可以组合使用: SPMC 负责跨进程传输，AsyncBus 负责进程内路由。\n\n```\n进程 A (数据采集)          进程 B (感知)           进程 C (融合)\n┌──────────────┐     ┌──────────────────┐   ┌──────────────────┐\n│ LiDAR Driver │     │ SPMC Reader      │   │ SPMC Reader      │\n│      │       │     │      │           │   │      │           │\n│      ▼       │     │      ▼           │   │      ▼           │\n│ SPMC Writer ─┼─shm─┤→ AsyncBus       │   │→ AsyncBus       │\n│              │     │   ├→ Detector    │   │   ├→ Fuser      │\n│              │     │   └→ Tracker     │   │   └→ Planner    │\n└──────────────┘     └──────────────────┘   └──────────────────┘\n```\n\n## 8. 资源预算\n\n以 LiDAR 点云分发场景为例 (16KB/帧, 10 Hz, 4 消费者):\n\n| 资源 | 用量 | 说明 |\n|------|------|------|\n| 共享内存 | 256KB + 128B header | ring buffer + SPMC header |\n| 每消费者开销 | 8B tail + 1B active | 原子变量 |\n| 写入带宽 | 160 KB/s | 16KB × 10 Hz |\n| futex 系统调用 | 10 次/s (wake) | 每帧一次广播 |\n| CPU (生产者) | <1% | memcpy + atomic store |\n| CPU (消费者) | <1% (读取) + 算法 | memcpy + atomic load |\n\n总内存开销约 256KB，对于嵌入式 ARM-Linux 平台 (通常 512MB+ RAM) 完全可接受。\n\n## 9. 进阶: JobPool 共享数据块流水线\n\nSPMC 通道解决了跨进程 1:N 数据分发，但工业场景中还有更复杂的需求:\n\n- 多个消费者共享同一份数据，最后一个完成后才释放内存\n- 数据需要经过多个处理阶段 (DAG 流水线)\n- 需要检测处理超时、上报故障\n\nnewosp 的 `JobPool` 模块 (`job_pool.hpp`) 提供了这些能力:\n\n```\nDataDispatcher<BlockSize, MaxBlocks>\n  +-- JobPool (固定大小内存池, lock-free CAS alloc/release)\n  +-- Pipeline (静态 DAG: fan-out + serial)\n  +-- FaultReporter (背压 + 超时上报)\n```\n\n### 9.1 核心机制: 引用计数\n\n```\nSubmit(block_id, refcount=1)\n  -> entry stage 执行\n  -> AddRef(2) for successors (logging + fusion)\n  -> Release() entry's ref\n  -> logging 执行 -> Release()\n  -> fusion 执行 -> Release() -> refcount=0 -> 回收到 free list\n```\n\n每个数据块有 `atomic<uint32_t> refcount`，消费者通过 `Release()` 递减。最后一个消费者使 refcount 降为 0 时，数据块自动回收。这比 SPMC 的 per-consumer tail 更灵活 -- 支持 DAG 拓扑而非仅 1:N 分发。\n\n### 9.2 与 SPMC 的关系\n\n两者定位不同，共存互补:\n\n| 维度 | ShmSpmcByteChannel | DataDispatcher (JobPool) |\n|------|--------------------|-----------------------|\n| 抽象层级 | 字节流传输 | 数据块生命周期管理 |\n| 数据共享 | 每消费者独立拷贝 | 引用计数零拷贝共享 |\n| 释放时机 | 消费者读完即推进 tail | 最后一个消费者 Release |\n| 流水线 | 无 | DAG (fan-out + pipeline) |\n| 超时检测 | 无 | 每块 deadline + 扫描 |\n| 适用场景 | 简单 1:N 分发 + 故障隔离 | 复杂流水线 + 生命周期管理 |\n\n简单场景 (纯分发，消费者独立处理) 用 SPMC。复杂场景 (多 stage 流水线，共享数据，超时检测) 用 JobPool。\n\n### 9.3 使用示例\n\n```cpp\n#include \"osp/job_pool.hpp\"\n\n// 创建 dispatcher: 16016B payload, 32 blocks\nosp::DataDispatcher<16016, 32> disp;\nosp::DataDispatcher<16016, 32>::Config cfg;\ncfg.name = \"lidar_pipeline\";\ncfg.default_timeout_ms = 500;\ncfg.backpressure_threshold = 4;\ndisp.Init(cfg);\n\n// 配置 DAG: entry -> logging + fusion (fan-out)\nauto s_entry = disp.AddStage({\"entry\", nullptr, nullptr, 0});\nauto s_log = disp.AddStage({\"logging\", LogHandler, &log_ctx, 0});\nauto s_fus = disp.AddStage({\"fusion\", FusionHandler, &fus_ctx, 0});\ndisp.AddEdge(s_entry, s_log);\ndisp.AddEdge(s_entry, s_fus);\ndisp.SetEntryStage(s_entry);\n\n// 生产: alloc -> fill -> submit (pipeline 自动执行)\nauto bid = disp.AllocBlock();\nFillLidarFrame(disp.GetBlockPayload(bid.value()), seq, ts);\ndisp.SubmitBlock(bid.value(), kFrameDataSize);\n// logging 和 fusion 都处理完后，数据块自动回收\n```\n\n完整示例见 `examples/data_visitor_dispatcher/pipeline_demo.cpp`。\n\n## 10. 相关资源\n\n- newosp 项目: [github.com/DeguiLiu/newosp](https://github.com/DeguiLiu/newosp) (Apache-2.0)\n- SPMC 示例: [data_visitor_dispatcher](https://github.com/DeguiLiu/newosp/tree/main/examples/data_visitor_dispatcher)\n- 进程内分发: [基于无锁消息总线的观察者模式](/posts/practice/cyberrt_datavisitor_mccc_rewrite/)\n- 参考项目: [data-visitor-dispatcher](https://gitee.com/liudegui/data-visitor-dispatcher) (mccc-bus 版)\n- 消息总线: [mccc-bus](https://gitee.com/liudegui/mccc-bus) -- C++17 header-only 无锁消息总线\n",
      "ctime": "1771552679",
      "mtime": "1771552679",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/qpc_active_object_hsm.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651734574",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640437528133645
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "QPC 框架深度解析: Active Object 与层次状态机的嵌入式实践",
      "brief_content": "QP/C (Quantum Platform in C) 是一个面向嵌入式实时系统的事件驱动框架，其核心是 Active Object (主动对象) 并发模型与层次状态机 (HSM)。本文从架构设计出",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 相关文章:\n> - [newosp 深度解析: C++17 事件驱动架构](../newosp_event_driven_architecture/) -- C++17 对 QPC Active Object 理念的重新实现\n> - [C 语言层次状态机框架: 从过程驱动到数据驱动](../c_hsm_data_driven_framework/) -- C 语言 HSM 的另一种设计方法\n> - [无锁编程核心原理](../lockfree_programming_fundamentals/) -- QActive 零拷贝队列的无锁理论基础\n> - [SPSC 无锁环形缓冲区设计剖析](../spsc_ringbuffer_design/) -- QActive 事件队列的 SPSC 设计详解\n>\n> 参考:\n> - [QPC 层次状态机（HSM）设计与优势分析](https://blog.csdn.net/stallion5632/article/details/149359525)\n> - [QPC 框架中状态机的设计优势和特殊之处](https://blog.csdn.net/stallion5632/article/details/149260812)\n> - [QPC QActive 零拷贝 & 无锁数据传输解析](https://blog.csdn.net/stallion5632/article/details/149374727)\n> - [QPC QActive 在 RT-Thread 上的实现原理详述](https://blog.csdn.net/stallion5632/article/details/149604623)\n>\n> QP/C 官方: [state-machine.com](https://www.state-machine.com/qpc/)\n\n## 1. QP/C 框架概述\n\n[QP/C](https://www.state-machine.com/qpc/) (Quantum Platform in C) 是由 Quantum Leaps 开发的轻量级实时嵌入式框架，其核心理念是将 **Active Object (主动对象/Actor)** 并发模型与 **层次状态机 (Hierarchical State Machine, HSM)** 融合，构建事件驱动的嵌入式系统。\n\nQP/C 的三大支柱:\n\n```mermaid\ngraph TB\n    subgraph AO[\"Active Object (QActive)\"]\n        A1[\"线程隔离\"]\n        A2[\"RTC 语义\"]\n    end\n    subgraph HSM[\"Hierarchical State Machine (QHsm/QMsm)\"]\n        H1[\"行为建模\"]\n        H2[\"层次复用\"]\n    end\n    subgraph EQ[\"Zero-Copy Event Queue (QEQueue)\"]\n        Q1[\"无锁通信\"]\n        Q2[\"指针传递\"]\n    end\n    OS[\"OS Abstraction: 裸机 / FreeRTOS / RT-Thread / QXK\"]\n    AO & HSM & EQ --> OS\n```\n\n### 1.1 Active Object 模型\n\nActive Object (AO) 是 QP/C 对 Actor 模式的具体实现。每个 AO 是一个自包含的并发构件，封装了:\n\n- **一个层次状态机 (QHsm)**: 作为行为引擎，处理事件并执行状态转换\n- **一个事件队列 (QEQueue)**: 作为\"信箱\"，接收所有发送给它的事件\n- **一个专属的执行上下文**: 映射为 RTOS 线程或裸机的前后台循环\n\nAO 的核心设计原则:\n\n| 原则 | 含义 | 工程价值 |\n|------|------|---------|\n| **线程隔离** | 每个 AO 独占私有数据，不与其他 AO 共享 | 从设计上消除数据竞争 |\n| **Run-to-Completion (RTC)** | 事件处理从开始到结束不被中断 | AO 内部无需锁保护 |\n| **异步通信** | AO 之间仅通过事件队列通信 | 生产者/消费者完全解耦 |\n| **Shared-Nothing** | 无共享状态，仅传递不可变事件 | 天然适合多核扩展 |\n\n### 1.2 与传统多线程编程的对比\n\n传统多线程模型的典型问题:\n\n```c\n// 传统方式: 多个线程共享数据，需要锁保护\nstatic SensorData g_sensorData;  // 全局共享\nstatic pthread_mutex_t g_mutex;\n\nvoid sensor_thread(void *arg) {\n    while (1) {\n        pthread_mutex_lock(&g_mutex);    // 获取锁\n        g_sensorData = read_sensor();     // 写共享数据\n        pthread_mutex_unlock(&g_mutex);   // 释放锁\n        usleep(1000);\n    }\n}\n\nvoid display_thread(void *arg) {\n    while (1) {\n        pthread_mutex_lock(&g_mutex);    // 获取锁\n        show(g_sensorData);               // 读共享数据\n        pthread_mutex_unlock(&g_mutex);   // 释放锁\n        usleep(100000);\n    }\n}\n```\n\nQP/C Active Object 方式:\n\n```c\n// AO 方式: 通过事件传递数据，无共享状态\ntypedef struct {\n    QEvt    super;\n    int32_t temperature;\n} SensorEvt;\n\n// 传感器 AO: 只负责采集，通过事件发布数据\nstatic QState Sensor_active(SensorAO *me, QEvt const *e) {\n    switch (e->sig) {\n    case SAMPLE_SIG: {\n        SensorEvt *evt = Q_NEW(SensorEvt, SENSOR_DATA_SIG);\n        evt->temperature = read_sensor();\n        QF_publish(&evt->super, me);  // 发布，不关心谁消费\n        return Q_HANDLED();\n    }\n    }\n    return Q_SUPER(&QHsm_top);\n}\n\n// 显示 AO: 只负责显示，订阅感兴趣的事件\nstatic QState Display_active(DisplayAO *me, QEvt const *e) {\n    switch (e->sig) {\n    case SENSOR_DATA_SIG: {\n        SensorEvt const *se = (SensorEvt const *)e;\n        show(se->temperature);  // 直接使用，无需加锁\n        return Q_HANDLED();\n    }\n    }\n    return Q_SUPER(&QHsm_top);\n}\n```\n\n两种方式的本质区别: 传统多线程是\"共享内存 + 锁保护\"，AO 是\"消息传递 + 线程隔离\"。后者从架构层面消除了数据竞争，代价是所有通信必须通过事件队列。\n\n## 2. 层次状态机 (HSM) 设计\n\n### 2.1 从平面 FSM 到层次 HSM\n\n传统平面状态机的核心问题是**状态爆炸**:\n\n```c\n// 平面 FSM: 状态组合呈指数增长\nenum {\n    STATE_IDLE_NORMAL,\n    STATE_IDLE_ERROR,\n    STATE_WORKING_NORMAL,\n    STATE_WORKING_ERROR,\n    STATE_SLEEP_NORMAL,\n    STATE_SLEEP_ERROR,\n    // ... 每增加一个维度，状态数翻倍\n};\n```\n\nHSM 通过**状态层次**解决此问题。子状态自动继承父状态的行为，只需处理差异化逻辑:\n\n```\nTop (根状态)\n├── Normal_mode (处理通用正常逻辑)\n│   ├── Idle\n│   ├── Working\n│   └── Sleep\n└── Error_mode (处理通用错误逻辑)\n    ├── Idle      ← 继承 Normal_mode::Idle 的大部分行为\n    ├── Working   ← 继承 Normal_mode::Working 的大部分行为\n    └── Sleep     ← 继承 Normal_mode::Sleep 的大部分行为\n```\n\n### 2.2 QMState: 编译期静态状态结构\n\nQP/C 的 HSM 实现基于 `QMState` 结构体，所有状态关系在编译期确定:\n\n```c\ntypedef struct QMState {\n    struct QMState const *superstate;    // 父状态指针 (编译期绑定)\n    QStateHandler const   stateHandler;  // 状态处理函数\n    QActionHandler const  entryAction;   // ENTRY 动作\n    QActionHandler const  exitAction;    // EXIT  动作\n    QActionHandler const  initAction;    // INIT  动作 (初始转移)\n} QMState;\n```\n\n设计要点:\n\n- **所有指针在编译期生成**: `superstate` 链、处理函数、Entry/Exit/Init 动作全部是静态绑定，零运行时开销\n- **superstate 链深度远小于平面状态数**: 典型嵌入式应用的状态树深度为 3-5 层，而平面状态可能有数十甚至上百个\n- **内存布局紧凑**: `QMState` 数组在链接时连续排列，对 I-Cache 友好\n\n### 2.3 事件派发: 冒泡-继承-覆盖\n\nHSM 的事件派发核心是**冒泡 (Bubble)** 机制:\n\n```c\nvoid QMsm_dispatch_(QHsm * const me, QEvt const * const e) {\n    QMState const *t = me->state.obj;  // 当前状态\n    QState r;\n\n    // 从当前状态开始，沿 superstate 链向上冒泡\n    do {\n        r = (*t->stateHandler)(me, e);   // 调用状态处理函数\n        if (r == Q_RET_UNHANDLED) {\n            t = t->superstate;           // 未处理 → 委托给父状态\n        }\n    } while (r == Q_RET_UNHANDLED && t != NULL);\n\n    // 如果需要状态转换，执行预生成的 Entry/Exit/Init 序列\n    if (r >= Q_RET_TRAN) {\n        QMsm_execTatbl_(me, me->temp.tatbl);\n    }\n}\n```\n\n这一机制实现了面向对象中的**继承与覆盖**:\n\n```c\n// 父状态: 处理通用事件\nstatic QState Parent_state(MyAO *me, QEvt const *e) {\n    switch (e->sig) {\n    case COMMON_SIG:\n        handle_common();     // 所有子状态共享的默认行为\n        return Q_HANDLED();\n    }\n    return Q_SUPER(&QHsm_top);\n}\n\n// 子状态: 覆盖特定事件，其余自动委托给父状态\nstatic QState Child_state(MyAO *me, QEvt const *e) {\n    switch (e->sig) {\n    case SPECIFIC_SIG:\n        handle_specific();   // 子状态专属处理\n        return Q_HANDLED();\n    case COMMON_SIG:\n        handle_override();   // 覆盖父状态的默认行为\n        return Q_HANDLED();\n    }\n    return Q_SUPER(&Parent_state);  // 其余事件冒泡到父状态\n}\n```\n\n### 2.4 自动化 Entry/Exit/Init\n\n状态转换时，HSM 自动计算 **LCA (Lowest Common Ancestor, 最低公共祖先)**，按正确顺序执行 Exit 和 Entry 动作:\n\n```\n转换: S1.1 → S2.1\n\n自动执行序列:\n  S1.1-EXIT → S1-EXIT → S2-ENTRY → S2.1-ENTRY → S2.1-INIT\n              ↑ LCA ↑\n```\n\n这种自动化保证了:\n\n- 资源的正确获取和释放 (Entry 获取，Exit 释放)\n- 不会遗漏中间层的清理逻辑\n- 整个转换过程满足 Run-to-Completion 语义\n\n### 2.5 QHsm vs QMsm: 两种实现策略\n\nQP/C 提供两种 HSM 实现，适用于不同开发模式:\n\n| 维度 | QHsm (手工编码) | QMsm (QM 工具生成) |\n|------|:---------------:|:------------------:|\n| 编码方式 | 手写状态函数 + `Q_SUPER()` | QM 图形化工具自动生成 |\n| 派发性能 | 运行时沿 superstate 链查找 | 编译期已确定路径，直接表驱动 |\n| 栈使用 | 中等 (递归查找深度) | **70% 更少** (预计算路径) |\n| 转换开销 | 运行时计算 LCA | **编译期预计算 LCA** |\n| 维护性 | 高 (代码可读性好) | 中 (依赖 QM 工具) |\n| 适用场景 | 原型开发、小型项目 | 生产系统、性能敏感场景 |\n\n**QMsm 的编译期优化原理:**\n\n```c\n// QMsm 的转换动作表在编译期由 QM 工具生成\n// 不需要运行时查找 LCA，直接执行预定义的 Exit/Entry 序列\nstatic QMTranActTable const tatbl_s11_to_s21 = {\n    &QMsm_s2_s21,  // 目标状态\n    {\n        Q_ACTION_CAST(&s11_exit),   // Exit S1.1\n        Q_ACTION_CAST(&s1_exit),    // Exit S1\n        Q_ACTION_CAST(&s2_entry),   // Entry S2\n        Q_ACTION_CAST(&s21_entry),  // Entry S2.1\n        Q_ACTION_NULL               // 终止标记\n    }\n};\n```\n\n### 2.6 HSM 的关键优势总结\n\n| 特性 | 说明 |\n|------|------|\n| **冒泡-继承-覆盖** | 未处理事件自动冒泡；子状态覆盖、父状态提供默认；符合开闭原则 |\n| **编译期静态绑定** | 状态关系、转移表、Entry/Exit 序列在编译期生成，无动态查找 |\n| **零动态分配** | 状态派发与转移不使用堆内存，只读访问静态表 |\n| **缓存友好** | 状态表及处理函数连续排列，减少 I-Cache 失效 |\n| **插拔式拦截** | 在状态树任意层插入横切逻辑 (日志、度量、限流)，不修改子状态 |\n| **与 RTOS 调度解耦** | HSM 派发独立于线程上下文，可在 PendSV 或轻量任务中完成 |\n\n## 3. 零拷贝事件队列 (QEQueue)\n\n### 3.1 事件传递: 只传指针，不拷贝数据\n\nQP/C 在 AO 之间传递事件时，遵循**零拷贝**原则:\n\n| 操作 | 成本 | 机制 |\n|------|------|------|\n| 事件创建 | 对完整事件对象一次 `memset` | 对象通常几十字节 |\n| 队列入/出队 | **O(1)** 指针写读，无 memcpy | `frontEvt` + `ring[]` |\n| 大数据载荷 | 只传指针和长度，不移动数据 | 外部缓冲区 |\n| 唤醒开销 | 一次 RTOS 调度 | 队列空→非空触发 |\n\n### 3.2 SPSC 环形缓冲: frontEvt 优化\n\nQEQueue 的设计精妙之处在于 `frontEvt` 快速路径:\n\n```c\n// QEQueue 内部结构 (简化)\ntypedef struct {\n    QEvt const * volatile frontEvt;  // 最新事件的快速缓存\n    QEvt const **ring;               // 环形缓冲数组\n    QEQueueCtr   end;                // 数组长度\n    QEQueueCtr   head;               // 写入位置\n    QEQueueCtr   tail;               // 读取位置\n    QEQueueCtr   nFree;              // 空闲槽数\n} QEQueue;\n```\n\n入队操作:\n\n```c\n// 事件投递 (简化)\nbool QActive_post_(QActive *me, QEvt const *e, uint_fast16_t margin) {\n    QF_CRIT_ENTRY();  // 进入临界区 (关中断)\n\n    if (me->eQueue.frontEvt == NULL) {\n        // 快速路径: 队列为空，直接放入 frontEvt\n        me->eQueue.frontEvt = e;\n        // 唤醒 AO 线程\n        rt_thread_resume(me->thread);\n    } else {\n        // 普通路径: 放入环形缓冲\n        me->eQueue.ring[me->eQueue.head] = e;\n        if (me->eQueue.head == 0U) {\n            me->eQueue.head = me->eQueue.end;\n        }\n        --me->eQueue.head;\n        --me->eQueue.nFree;\n    }\n\n    QF_CRIT_EXIT();   // 退出临界区\n    return true;\n}\n```\n\n出队操作:\n\n```c\nQEvt const *QActive_get_(QActive *me) {\n    QF_CRIT_ENTRY();\n\n    if (me->eQueue.frontEvt == NULL) {\n        // 队列为空，挂起线程等待事件\n        rt_thread_suspend(rt_thread_self());\n        QF_CRIT_EXIT();\n        rt_schedule();        // 让出 CPU\n        QF_CRIT_ENTRY();     // 被唤醒后重新进入临界区\n    }\n\n    QEvt const *e = me->eQueue.frontEvt;\n\n    if (me->eQueue.nFree < me->eQueue.end) {\n        // 环形缓冲中还有事件，提升到 frontEvt\n        me->eQueue.frontEvt = me->eQueue.ring[me->eQueue.tail];\n        if (me->eQueue.tail == 0U) {\n            me->eQueue.tail = me->eQueue.end;\n        }\n        --me->eQueue.tail;\n        ++me->eQueue.nFree;\n    } else {\n        me->eQueue.frontEvt = NULL;  // 队列已空\n    }\n\n    QF_CRIT_EXIT();\n    return e;\n}\n```\n\n`frontEvt` 优化的意义: 在低负载场景 (大多数嵌入式系统的常态)，事件到达时队列通常为空。此时事件直接存入 `frontEvt`，出队时直接读取 `frontEvt`，完全避免了环形缓冲的头尾指针操作。\n\n### 3.3 携带数据的事件模式\n\n**小数据: 内嵌在事件结构体中**\n\n```c\ntypedef struct {\n    QEvt    super;     // 基类\n    int32_t value;     // 直接内嵌 payload\n} DataEvt;\n\n// 生产者\nDataEvt *e = Q_NEW(DataEvt, DATA_SIG);\ne->value = 42;\nQACTIVE_POST(&receiver->super, &e->super, 0);\n\n// 消费者\nDataEvt const *de = (DataEvt const *)e;\nprocess(de->value);  // 直接使用，零拷贝\n```\n\n**大数据: 外部缓冲 + 指针**\n\n当 payload 较大 (几 KB 以上) 时，避免在事件对象内部持有大数组:\n\n```c\nstatic uint8_t bigBuf[10240];  // 外部大缓冲\n\ntypedef struct {\n    QEvt     super;\n    uint8_t *dataPtr;     // 指向外部缓冲\n    uint32_t length;\n} BigEvt;\n\nBigEvt *e = Q_NEW(BigEvt, BIG_SIG);\ne->dataPtr = bigBuf;\ne->length  = sizeof(bigBuf);\n// 入队仅写入 BigEvt 指针 (几字节)，不拷贝 10KB 数据\nQACTIVE_POST(&consumer->super, &e->super, 0);\n```\n\n### 3.4 动态事件池\n\nQP/C 通过**固定大小事件池**替代 `malloc/free`，实现 O(1) 分配和回收:\n\n```c\n// 初始化: 预分配事件池\nstatic uint8_t poolSto[20 * sizeof(DataEvt)];\nQF_poolInit(poolSto, sizeof(poolSto), sizeof(DataEvt));\n\n// 分配: O(1) 从池中弹出\nDataEvt *e = Q_NEW(DataEvt, SENSOR_SIG);\n\n// 回收: O(1) 归还到池中\n// QF_gc(e) 在事件循环中自动调用\n```\n\n事件池的引用计数机制:\n\n- `Q_NEW()` 分配时引用计数为 1\n- `QF_publish()` 广播时，每个订阅者增加引用计数\n- 每个 AO 处理完后 `QF_gc()` 减少引用计数\n- 引用计数归零时自动回收到池中\n\n## 4. QActive 在 RT-Thread 上的实现\n\n### 4.1 架构映射\n\n`qpc-rtthread` 将 QP/C 的抽象模型与 RT-Thread 的内核原语精确对接:\n\n| QP/C 层 | RT-Thread 层 | 说明 |\n|---------|-------------|------|\n| QActive 对象 | `rt_thread_t` 线程 | 一一对应，每个 AO 创建一个专属线程 |\n| QEQueue 事件队列 | 普通 C 数组 + 指针 | 纯 C 实现，不依赖 `rt_mailbox` |\n| `QActive_ctor()` | -- | 纯 C 构造函数，绑定初始状态处理函数 |\n| `QACTIVE_START()` | `rt_thread_create()` + `rt_thread_startup()` | 创建并启动 AO 线程 |\n| `QActive_get_()` | `rt_thread_suspend()` | 队列空时挂起线程，让出 CPU |\n| `QHSM_DISPATCH()` | 同一线程内函数调用 | 纯函数调用，不涉及 RTOS API |\n| `QACTIVE_POST_FROM_ISR()` | `rt_thread_resume()` | ISR 中仅恢复线程，调度延迟到中断退出 |\n\n### 4.2 QActive 生命周期\n\n```\nQActive_ctor()          QACTIVE_START()           qf_thread_function()\n   │                        │                          │\n   ▼                        ▼                          ▼\n绑定初始状态  ──→  QEQueue_init()           ┌──→ QActive_get_() ─── 阻塞等待\n                   QActive_register_()      │       │\n                   QHSM_INIT()             │       ▼ 有事件\n                   rt_thread_create()       │   QHSM_DISPATCH()\n                   rt_thread_startup()      │       │\n                          │                 │       ▼\n                          └──────────────→  │   QF_gc() 回收事件\n                                            │       │\n                                            └───────┘ 永不退出\n```\n\n完整的启动代码:\n\n```c\n// 1. AO 实例和资源 (全部静态分配)\nstatic BlinkyAO  l_blinky;\nstatic QEvt const *blinkyQSto[8];     // 事件队列缓冲\nstatic uint8_t    blinkyStk[256];      // 线程栈\n\n// 2. 构造\nvoid BlinkyAO_ctor(void) {\n    QActive_ctor(&l_blinky.super, Q_STATE_CAST(&Blinky_initial));\n}\n\n// 3. 启动\nvoid BlinkyAO_start(void) {\n    BlinkyAO_ctor();\n    QACTIVE_START(&l_blinky.super,\n                  BLINKY_PRIO,                     // 优先级\n                  blinkyQSto, Q_DIM(blinkyQSto),   // 事件队列\n                  blinkyStk, sizeof(blinkyStk),     // 线程栈\n                  (void *)0);                       // 初始事件参数\n}\n```\n\n### 4.3 事件循环: 一次性事件驱动\n\n所有 AO 线程运行同一个事件循环:\n\n```c\nstatic void qf_thread_function(void *arg) {\n    QActive *me = (QActive *)arg;\n    for (;;) {\n        QEvt const *e = QActive_get_(me);     // 阻塞等待事件\n        QHSM_DISPATCH(&me->super, e);         // 派发给状态机\n        QF_gc(e);                              // 回收动态事件\n    }\n}\n```\n\n与传统\"多线程 + 多次唤醒\"的对比:\n\n| 场景 | 传统多线程/回调 | QActive + HSM |\n|------|:-------------:|:------------:|\n| 同一事件引发多级状态转换 | 多次唤醒/阻塞，多次上下文切换 | 单次唤醒 → `QHSM_DISPATCH` 连续执行 → 单次阻塞 |\n| 调度抖动 | 数十至数百微秒 | < 20 us (单次唤醒 + 函数调用) |\n| 逻辑耦合 | 硬编码函数跳转，难以插桩 | 全事件驱动，自动委托，易加横切日志 |\n\n关键优势在于: `QHSM_DISPATCH()` 在同一线程上下文中一口气完成所有冒泡、Exit/Entry/Init 动作，不触发额外调度。整个过程是纯粹的函数调用链，开销等同于几次函数指针跳转。\n\n### 4.4 线程与中断的投递路径\n\n`qpc-rtthread` 为线程和中断提供两条优化的投递路径:\n\n| 上下文 | 投递宏 | 唤醒与调度 |\n|-------|-------|-----------|\n| **线程** | `QACTIVE_POST()` | 队列从空变非空时，`rt_thread_resume()` + **立即** `rt_schedule()` |\n| **中断** | `QACTIVE_POST_FROM_ISR()` | 队列从空变非空时，仅 `rt_thread_resume()`，调度**延迟**到 `rt_interrupt_leave()` |\n\nISR 投递的实现:\n\n```c\n// 在 ISR 中发布事件\nstatic QEvt const sigX_evt = { SIG_X, 0U };\n\n// ISR 版本: 最短路径，几十条指令\nQACTIVE_POST_FROM_ISR(&myAO->super, &sigX_evt);\n// 内部: 写队列指针 + rt_thread_resume()\n// 调度器在 rt_interrupt_leave() 中统一触发\n```\n\n这种设计保证了 ISR 的简短和确定性: ISR 只做入队和恢复线程，不在中断上下文中调用调度器。\n\n### 4.5 时间事件 (QTimeEvt)\n\nQTimeEvt 是 QP/C 内置的高效定时器，完全避免了 `rt_thread_mdelay()` 或创建大量 `rt_timer`:\n\n```c\n// 在 AO 构造函数中创建周期性定时事件\nQTimeEvt_ctorX(&me->sampleEvt, &me->super, SAMPLE_SIG, 0U);\n\n// 在状态机初始化时启动: 首次 1 tick 延迟，周期 1 tick\nQTimeEvt_armX(&me->sampleEvt, 1U, 1U);\n\n// 停止定时器\nQTimeEvt_disarm(&me->sampleEvt);\n```\n\n与 RT-Thread SysTick 的集成:\n\n```c\nvoid SysTick_Handler(void) {\n    rt_interrupt_enter();\n    rt_tick_increase();       // RT-Thread 系统节拍\n    QF_TICK_X(0U, (void *)0); // QP/C 时间事件驱动\n    rt_interrupt_leave();\n}\n```\n\n每次 SysTick 中断，`QF_TICK_X()` 遍历定时器链表，将到期的定时事件通过 `QACTIVE_POST_FROM_ISR()` 发送给对应的 AO。\n\n## 5. 方案对比: QActive on RT-Thread vs. QXK\n\nQP/C 自带一个名为 QXK 的小型抢占式内核。在已有 RT-Thread 的项目中，推荐使用 QActive on RT-Thread 模式:\n\n| 特性 | QXK (QP/C 自带内核) | QActive on RT-Thread |\n|------|:------------------:|:-------------------:|\n| **阻塞调用** | 严格禁止 | 完全允许 (在普通线程中) |\n| **栈模型** | 主栈 + 私有栈，动态切换 | 标准线程栈，简单明了 |\n| **调度器** | QXK + RT-Thread 双调度器 | **仅 RT-Thread 调度器** |\n| **生态集成** | 难以使用 RT-Thread 驱动和组件 | **无缝集成** |\n| **学习成本** | 高 (需理解 QXK 限制) | 低 (标准 RT-Thread API) |\n\nQActive on RT-Thread 的已知权衡:\n\n| 权衡 | 风险 | 缓解措施 |\n|------|------|---------|\n| RTC 被同级抢占 | 同优先级 AO 可能互相抢占 | 为关键 AO 分配独一无二的优先级 |\n| 无抢占阈值 | 低优先级 AO 唤醒也触发调度 | 合理规划优先级，批量处理事件 |\n| RAM 占用 | 每个 AO 对应一个线程栈 | 控制 AO 粒度，简单工作用普通函数 |\n\n## 6. 实战: 1kHz 高频采样\n\n### 6.1 传统实现的问题\n\n```c\nvoid sensor_thread_entry(void *p) {\n    while (1) {\n        rt_thread_mdelay(1);   // 每次循环: 阻塞→调度→唤醒→调度\n        data = read_sensor();\n        process_data(data);\n    }\n}\n```\n\n每次循环都经历\"阻塞 → 上下文切换 → 唤醒 → 上下文切换\"，调度开销大且 `rt_thread_mdelay()` 精度受限于软定时器。\n\n### 6.2 QActive + QTimeEvt 实现\n\n```c\ntypedef struct {\n    QActive   super;\n    QTimeEvt  sampleEvt;     // 内置定时器\n} SensorAO;\n\nstatic SensorAO   l_sensor;\nstatic QEvt const *sensorQSto[8];\nstatic uint8_t     sensorStk[256];\n\nenum { SAMPLE_SIG = Q_USER_SIG };\n\n// 构造\nvoid SensorAO_ctor(void) {\n    QActive_ctor(&l_sensor.super, Q_STATE_CAST(&Sensor_initial));\n    QTimeEvt_ctorX(&l_sensor.sampleEvt, &l_sensor.super, SAMPLE_SIG, 0U);\n}\n\n// 状态机\nstatic QState Sensor_initial(SensorAO *me, QEvt const *e) {\n    (void)e;\n    QTimeEvt_armX(&me->sampleEvt, 1U, 1U);  // 周期 1ms (假设 1kHz tick)\n    return Q_TRAN(&Sensor_active);\n}\n\nstatic QState Sensor_active(SensorAO *me, QEvt const *e) {\n    switch (e->sig) {\n    case SAMPLE_SIG: {\n        uint16_t data = BSP_readADC();\n        BSP_processData(data);\n        return Q_HANDLED();\n    }\n    }\n    return Q_SUPER(&QHsm_top);\n}\n```\n\n### 6.3 调度序列\n\n```\nSysTick → QF_TICK_X() → sampleEvt.ctr-- → ctr==0\n  → QACTIVE_POST_FROM_ISR(SAMPLE_SIG) → rt_thread_resume()\n    → rt_interrupt_leave() → 调度 → SensorAO 运行\n      → QActive_get_() 取到 SAMPLE_SIG\n        → QHSM_DISPATCH → Sensor_active 执行采样\n          → 处理完毕 → QActive_get_() → 队列空 → 挂起\n```\n\n### 6.4 性能对比\n\n| 优化点 | QActive + QTimeEvt | 传统软定时器 + 线程 |\n|-------|:------------------:|:------------------:|\n| ISR 工作量 | 极小: 更新计数器、写指针、恢复线程 | 较大: 遍历链表、调用回调、发送 IPC |\n| 切换次数 | 最少: 每周期 1 次中断 + 1 次调度 | 多次: 中断 → 软定时器线程 → 业务线程 |\n| 数据拷贝 | **零拷贝**: 仅传递事件指针 | 有拷贝: MailBox 通常复制消息内容 |\n| 定时精度 | 直接由 SysTick 驱动，无中间层 | 受限于软定时器实现 |\n\n## 7. 最佳实践\n\n### 7.1 AO 设计原则\n\n- **单一职责**: 每个 AO 只负责一类紧密相关的业务 (传感器、网络、UI)\n- **粒度适中**: AO 数量建议几十个以内，平衡架构清晰度与资源开销\n- **AO 与普通线程配合**: AO 处理非阻塞事件驱动逻辑；普通线程处理阻塞操作 (文件 I/O、Shell)\n\n### 7.2 API 使用要点\n\n| 规则 | 说明 |\n|------|------|\n| 禁止在状态机内阻塞 | 不调用 `rt_thread_mdelay()`、`rt_sem_take()` 等阻塞 API |\n| 使用 QTimeEvt | 所有定时需求通过 `QTimeEvt` 实现，不用 `rt_timer` |\n| ISR 用专用宏 | ISR 中必须使用 `QACTIVE_POST_FROM_ISR()` |\n| 监控资源水位 | 调试期用 `QF_getPoolMin()` 和 `QActive_getQueueMin()` 监控 |\n\n### 7.3 性能优化\n\n- **批量处理**: 高频事件在 AO 事件循环中一次性处理多个，减少循环开销\n- **长逻辑拆分**: 耗时操作拆分为多步，通过向自身投递后续事件分步完成\n- **队列深度规划**: 根据峰值事件突发预估，`QACTIVE_POST()` 返回 `false` 时需有降级策略\n\n## 8. 总结\n\n| 维度 | 传统多线程 | QP/C Active Object |\n|------|:--------:|:------------------:|\n| 并发模型 | 共享内存 + 锁 | 消息传递 + 线程隔离 |\n| 状态管理 | if-else / switch-case | 层次状态机 (HSM) |\n| 数据传递 | memcpy / IPC | **零拷贝指针传递** |\n| 同步机制 | mutex / semaphore | **SPSC 队列 + 关中断临界区** |\n| 动态分配 | malloc / free | **固定事件池 O(1) 分配** |\n| 定时器 | 软定时器 → IPC → 线程 | **QTimeEvt 直接投递** |\n| 调度开销 | 多次上下文切换 | 单次唤醒 + RTC 连续执行 |\n| 扩展性 | 锁竞争随核心数增长 | AO 天然适合多核分布 |\n\nQP/C 的 Active Object 模型通过**线程隔离 + 零拷贝事件队列 + 层次状态机**三位一体的设计，从架构层面消除了传统多线程编程中的数据竞争、锁死锁、优先级反转等问题。HSM 的冒泡-继承-覆盖机制提供了比平面 FSM 更强的行为复用能力，QMsm 的编译期优化使其在资源受限的嵌入式平台上保持极高的运行效率。\n\n对于 RT-Thread 用户，QActive on RT-Thread 方案在保持 QP/C 全部架构优势的同时，无缝集成 RT-Thread 的驱动和生态，是构建事件驱动嵌入式系统的推荐选择。\n\n## 参考资料\n\n1. [QP/C 官方文档](https://www.state-machine.com/qpc/) -- Quantum Leaps\n2. [QPC 层次状态机（HSM）设计与优势分析](https://blog.csdn.net/stallion5632/article/details/149359525)\n3. [QPC 框架中状态机的设计优势和特殊之处](https://blog.csdn.net/stallion5632/article/details/149260812)\n4. [QPC QActive 零拷贝 & 无锁数据传输解析](https://blog.csdn.net/stallion5632/article/details/149374727)\n5. [QPC QActive 在 RT-Thread 上的实现原理详述](https://blog.csdn.net/stallion5632/article/details/149604623)\n6. Miro Samek, *Practical UML Statecharts in C/C++*, 2nd Edition -- QP/C 作者的经典著作\n7. [RT-Thread 官方文档](https://www.rt-thread.org/document/site/)\n\n",
      "ctime": "1771552683",
      "mtime": "1771552683",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/rtthread_msh_linux_multibackend.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469734958",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "将 RT-Thread MSH 移植到 Linux: 嵌入式调试 Shell 的多后端设计",
      "brief_content": "RT-Thread 的 MSH (Micro Shell) 是嵌入式领域最成功的命令行交互组件之一。本文剖析 MSH 的核心设计理念，讨论在嵌入式 Linux 上实现同等功能的三种方案 (Embedd",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> RT-Thread 的 MSH (Micro Shell) 是嵌入式领域最成功的命令行交互组件之一。本文剖析 MSH 的核心设计理念，讨论在嵌入式 Linux 上实现同等功能的三种方案 (Embedded CLI 移植、newosp shell、自研 embsh)，并重点介绍 embsh 如何在一个纯头文件库中融合多后端 I/O、telnet 协议、认证、历史导航和 Tab 补全。\n\n## 1. RT-Thread MSH 的设计精髓\n\nRT-Thread MSH 具备以下核心设计:\n\n- **MSH_CMD_EXPORT 宏注册**: 一行宏将函数注册为 Shell 命令，零侵入\n- **argc/argv 标准签名**: `int cmd(int argc, char** argv)`，与 POSIX 一致\n- **多传输后端**: 串口、Telnet、USB CDC 等多种输入源\n- **自动 help**: 内置命令列表，开发者无需手动维护\n- **Tab 补全 + 历史记录**: 交互体验接近 Linux bash\n\n这些设计使得 MSH 成为嵌入式 shell 的标杆。在嵌入式 Linux 平台上，我们需要同等的调试能力。\n\n## 2. 方案对比: 三种实现路径\n\n### 2.1 方案 A: Embedded CLI 移植\n\n[Embedded CLI](https://github.com/funbiscuit/embedded-cli) 是一个纯 C 实现的轻量级命令行框架:\n\n- 零 RTOS 依赖，适合裸机和 Linux\n- 支持命令注册、参数解析、历史记录、Tab 补全\n- 输入源无关: 任意字节流 (UART、TCP、USB CDC)\n\n**局限性**:\n\n| 维度 | Embedded CLI | RT-Thread MSH |\n|------|-------------|---------------|\n| 语言 | 纯 C | 纯 C |\n| 认证 | 不支持 | 不支持 |\n| Telnet IAC | 不支持 | 内置 |\n| 命令 context | 有 (void*) | 无 |\n| 多 session | 需自行实现 | 需自行实现 |\n\nEmbedded CLI 适合单后端场景，但缺少 telnet 协议支持和认证机制，在需要远程调试的嵌入式 Linux 场景下不够完整。\n\n### 2.2 方案 B: newosp 内置 shell\n\n[newosp](https://github.com/DeguiLiu/newosp) 框架的 `shell.hpp` 提供了三后端 Shell:\n\n```cpp\n// TCP telnet (最多 N 并发 session)\nosp::DebugShell shell(cfg);\nshell.Start();\n\n// stdin/stdout 控制台\nosp::ConsoleShell console(cfg);\nconsole.Start();\n\n// UART 串口\nosp::UartShell uart(cfg);\nuart.Start();\n```\n\n优点: 多后端、Tab 补全、线程安全注册。\n局限: 与 newosp 耦合 (依赖 platform.hpp + vocabulary.hpp)，无认证，无方向键历史，命令签名无 context 指针。\n\n### 2.3 方案 C: embsh -- 独立的嵌入式 Shell 库 (推荐)\n\n[embsh](https://github.com/DeguiLiu/embsh) 融合了 newosp shell (多后端) 和 telsh (IAC + 认证 + 历史) 的优点:\n\n| 特性 | Embedded CLI | newosp shell | **embsh** |\n|------|-------------|-------------|-----------|\n| 多后端 I/O | 需自行实现 | TCP + Console + UART | **TCP + Console + UART** |\n| Telnet IAC | 不支持 | 部分 | **完整 FSM** |\n| 认证 | 不支持 | 不支持 | **用户名/密码** |\n| 方向键历史 | 有 | 无 | **16 条环形缓冲** |\n| Tab 补全 | 有 | 有 | **有 (最长公共前缀)** |\n| Context 指针 | 有 | 无 | **有** |\n| MSH 兼容宏 | 需适配 | 不兼容 | **MSH_CMD_EXPORT** |\n| 外部依赖 | 无 | osp 框架 | **无 (自包含)** |\n\n## 3. embsh 核心架构\n\n### 3.1 命令签名: 带 context 的函数指针\n\n```cpp\n// embsh 命令签名 (兼容 RT-Thread MSH + 扩展 context)\nusing CmdFn = int (*)(int argc, char* argv[], void* ctx);\n```\n\ncontext 指针的价值: 无状态函数指针可以绑定有状态对象，而不需要闭包或全局变量。\n\n```cpp\n// 无状态命令 (等价于 MSH 签名)\nstatic int cmd_help(int argc, char* argv[], void* /*ctx*/) {\n    // ...\n    return 0;\n}\n\n// 有状态命令 (通过 context 绑定对象)\nstruct LedController {\n    int pin;\n    void toggle() { /* ... */ }\n};\n\nstatic int cmd_led(int argc, char* argv[], void* ctx) {\n    auto* led = static_cast<LedController*>(ctx);\n    led->toggle();\n    return 0;\n}\n\n// 注册时绑定 context\nLedController led{13};\nembsh::CommandRegistry::Instance().Register(\"led\", cmd_led, &led, \"Toggle LED\");\n```\n\n### 3.2 MSH_CMD_EXPORT 兼容宏\n\nembsh 提供与 RT-Thread MSH 源码级兼容的注册宏:\n\n```cpp\n// embsh 上使用\n#include \"embsh/command_registry.hpp\"\n\nstatic int reboot(int argc, char* argv[], void* ctx) {\n    // ...\n    return 0;\n}\nMSH_CMD_EXPORT(reboot, \"Reboot the system\");\n```\n\n未来迁移到 RT-Thread 时，只需替换头文件:\n\n```cpp\n#ifdef __LINUX__\n  #include \"embsh/command_registry.hpp\"\n#else\n  #include <finsh.h>   // RT-Thread 原生 MSH\n#endif\n```\n\n### 3.3 多后端 I/O 抽象\n\nembsh 通过函数指针抽象 I/O，三个后端共享同一命令注册表:\n\n```\n                    +--> TelnetServer (TCP, 8 sessions, IAC + auth)\nCommandRegistry <---+--> ConsoleShell (stdin/stdout, termios raw)\n                    +--> UartShell    (serial, configurable baud)\n```\n\n函数指针 (非虚函数) 实现零开销后端切换:\n\n```cpp\nusing WriteFn = ssize_t (*)(int fd, const void* buf, size_t len);\nusing ReadFn  = ssize_t (*)(int fd, void* buf, size_t len);\n\n// TCP: send/recv with MSG_NOSIGNAL\n// POSIX: write/read for console/UART\n```\n\n### 3.4 行编辑与历史导航\n\nembsh 的 line_editor 模块提供:\n\n- **256B 行缓冲区**: 固定大小，零堆分配\n- **方向键导航**: ESC 序列 FSM 解析 `\\x1b[A/B/C/D`\n- **16 条历史记录**: 环形缓冲，跳过重复\n- **Tab 补全**: 单匹配自动填充 + 空格，多匹配显示列表 + 最长公共前缀\n- **IAC 过滤**: telnet 协议字节透明处理\n\n输入处理流程:\n\n```\n字节输入 -> IAC 过滤 (telnet) -> ESC FSM -> 字符分类\n  |\n  +-- 普通字符: line_buf[pos++] + 回显\n  +-- Tab: AutoComplete\n  +-- Up/Down: 历史导航\n  +-- Enter: ShellSplit + 命令执行\n  +-- Backspace: 删除 + 回退\n  +-- Ctrl+C: 取消当前行\n  +-- Ctrl+D: EOF / 退出\n```\n\n## 4. 串口集成: 嵌入式 Linux 上的 UART Shell\n\n### 4.1 串口初始化\n\nembsh 的 UartShell 封装了完整的 termios 配置:\n\n```cpp\nembsh::UartShell::Config cfg;\ncfg.device = \"/dev/ttyPS0\";    // Zynq PS UART\ncfg.baudrate = 115200;\ncfg.prompt = \"sensor> \";\n\nembsh::UartShell uart(cfg);\nuart.Start();\n```\n\n内部实现: 打开设备 -> cfmakeraw -> 设置波特率/8N1/无流控 -> VMIN=1 阻塞读取。\n\n### 4.2 在 RT-Thread 上的等价用法\n\n```c\n// RT-Thread: MSH 自动绑定到 console 设备\nMSH_CMD_EXPORT(sensor_read, \"Read sensor data\");\n\n// 嵌入式 Linux (embsh): 手动指定串口设备\nMSH_CMD_EXPORT(sensor_read, \"Read sensor data\");\n// + UartShell 配置\n```\n\n业务命令代码完全一致，仅 Shell 后端配置不同。\n\n## 5. TCP Telnet 远程调试\n\n### 5.1 认证与安全\n\nembsh 的 TelnetServer 支持可选的用户名/密码认证:\n\n```cpp\nembsh::ServerConfig cfg;\ncfg.port = 2323;\ncfg.username = \"admin\";\ncfg.password = \"secret\";\ncfg.banner = \"\\r\\n=== Sensor Debug Shell ===\\r\\n\";\n\nembsh::TelnetServer server(cfg);\nserver.Start();\n```\n\n认证流程:\n1. 连接后发送 banner + \"Username:\" 提示\n2. 密码输入星号掩码显示\n3. 最多 3 次尝试，失败断开连接\n4. 认证通过后进入正常命令模式\n\n### 5.2 IAC 协议处理\n\ntelnet 客户端会发送 IAC (Interpret As Command) 协议字节。embsh 内置 IAC FSM:\n\n```\nNormal -> 收到 0xFF -> IAC 状态\n  -> WILL/WONT/DO/DONT (0xFB-0xFE) -> Negotiate 状态 -> 消费 option 字节 -> Normal\n  -> SB (0xFA) -> Sub 状态 -> 消费直到 IAC SE -> Normal\n  -> 0xFF (IAC IAC) -> 传递 literal 0xFF -> Normal\n```\n\n## 6. 多后端同时运行\n\nembsh 支持 TCP 和 Console 同时运行，共享同一命令注册表:\n\n```cpp\n#include \"embsh/console_shell.hpp\"\n#include \"embsh/telnet_server.hpp\"\n\n// TCP 远程调试\nembsh::TelnetServer tcp_server(tcp_cfg);\ntcp_server.Start();\n\n// 本地控制台 (main 线程阻塞)\nembsh::ConsoleShell console(con_cfg);\nconsole.Run();\n```\n\n运维人员可通过 telnet 远程登录，开发人员同时在本地控制台调试。\n\n## 7. 编译期配置\n\n| 宏 | 默认值 | 说明 |\n|----|--------|------|\n| `EMBSH_MAX_COMMANDS` | 64 | 最大命令数 |\n| `EMBSH_MAX_SESSIONS` | 8 | TCP 最大并发 session |\n| `EMBSH_LINE_BUF_SIZE` | 256 | 行缓冲区大小 |\n| `EMBSH_HISTORY_SIZE` | 16 | 历史记录条数 |\n| `EMBSH_MAX_ARGS` | 32 | 单条命令最大参数数 |\n| `EMBSH_DEFAULT_PORT` | 2323 | TCP 默认端口 |\n\n## 8. 资源预算\n\n| 资源 | 数值 | 说明 |\n|------|------|------|\n| Session 内存 | ~4.5KB | 256B line_buf + 16x256B history + 控制字段 |\n| 8 Session 总计 | ~36KB | TCP 最大并发 |\n| 命令表 | ~2KB | 64 x 32B (name+desc+fn+ctx) |\n| 编译期可控 | 全部 | 通过宏调整，适配不同资源约束 |\n\n## 9. 总结\n\n| 维度 | Embedded CLI | RT-Thread MSH | embsh |\n|------|-------------|---------------|-------|\n| 平台 | 裸机 + Linux | RT-Thread | **嵌入式 Linux** |\n| 语言 | C | C | **C++17 (header-only)** |\n| 后端 | 单后端 | 多后端 | **TCP + Console + UART** |\n| 认证 | 无 | 无 | **用户名/密码** |\n| 历史 | 有 | 有 | **16 条 + 方向键** |\n| Tab 补全 | 有 | 有 | **有** |\n| Context 指针 | 有 | 无 | **有** |\n| MSH 兼容 | 需适配 | 原生 | **MSH_CMD_EXPORT 宏** |\n| 外部依赖 | 无 | RT-Thread | **无** |\n\nembsh 已开源: [https://github.com/DeguiLiu/embsh](https://github.com/DeguiLiu/embsh)，52 个 Catch2 单元测试全部通过，适用于工业传感器、机器人、边缘计算等嵌入式 Linux 调试场景。\n\n---\n",
      "ctime": "1771552686",
      "mtime": "1771552686",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/telnet_debug_shell_posix_refactoring.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651750958",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式 Telnet 调试 Shell 重构: 纯 POSIX 轻量化实现",
      "brief_content": "在嵌入式 Linux 产品开发中，telnet 调试 shell 是一个常见需求：通过网络连接到设备，执行诊断命令、查看运行状态、修改配置参数。本文为 C++17 header-only 纯 POSI",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "## 背景\n\n在嵌入式 Linux 产品开发中，telnet 调试 shell 是一个常见需求：通过网络连接到设备，执行诊断命令、查看运行状态、修改配置参数。本文为 C++17 header-only 纯 POSIX 实现的过程，最终产物是 [telsh](https://gitee.com/liudegui/telsh) 项目。\n\n\n## 方案\n\n### 设计原则\n\n- C++17，零 boost 依赖，纯 POSIX socket\n- Header-only，方便嵌入式项目集成\n- 零堆分配（固定容量数组），适合资源受限环境\n- 每个 session 独立状态，无全局变量\n\n### 架构\n\n```\ntelsh/\n  include/\n    osp/                        -- 复用自 newosp 项目\n      platform.hpp              -- 平台检测、断言\n      vocabulary.hpp            -- FixedFunction、FixedString\n      log.hpp                   -- 日志宏\n    telsh/\n      command_registry.hpp      -- 命令注册 (64 条, 零堆分配)\n      telnet_session.hpp        -- 会话管理 (IAC/认证/历史)\n      telnet_server.hpp         -- 服务器 (固定 session 池)\n  tests/                        -- Catch2 测试 (28 cases)\n  examples/                     -- 示例\n```\n\n### 关键设计决策\n\n#### 1. 统一命令签名\n\n```cpp\n//统一函数指针签名\nusing CmdFn = int (*)(int argc, char* argv[], void* ctx);\n```\n\n所有命令参数都是字符串 (argv)，由命令自行解析类型。`void* ctx` 传递用户上下文，替代成员函数绑定。编译期类型安全，零堆分配。\n\n注册接口：\n\n```cpp\n// 自由函数\nregistry.Register(\"reboot\", \"Reboot device\", my_reboot_fn);\n\n// 带上下文的回调 (替代成员函数绑定)\nCounter counter;\nregistry.Register(\"count\", \"Show counter\", count_fn, &counter);\n\n// 宏自动注册\nTELSH_CMD(hello, \"Print greeting\") {\n    (void)ctx;\n    telsh::TelnetServer::Printf(\"Hello, %s!\\r\\n\", argv[1]);\n    return 0;\n}\n```\n\n#### 2. Per-session IAC 状态机\n\n```cpp\nclass TelnetSession {\n  // IAC 状态是成员变量，不是全局 static\n  enum class IacPhase : uint8_t { kNormal, kIac, kNego, kSub };\n  struct IacState {\n    IacPhase phase = IacPhase::kNormal;\n    uint8_t prev_byte = 0;\n  };\n  IacState iac_;  // 每个 session 独立\n};\n```\n\n#### 3. 固定 session 池替代裸 new\n\n```cpp\nclass TelnetServer {\n  static constexpr uint32_t kMaxSessions = 8;\n  struct SessionSlot {\n    TelnetSession session;\n    std::thread thread;\n    std::atomic<bool> active{false};\n  };\n  SessionSlot slots_[kMaxSessions];  // 栈上固定数组\n};\n```\n\n- 不动态分配，session 数量编译期确定\n- `std::thread` joinable（不 detach），生命周期可控\n- `Stop()` 时关闭 socket 解除 `recv()` 阻塞，然后 join 所有线程\n\n#### 4. 命令行原地解析\n\n```cpp\n// ShellSplit: 原地修改 cmdline，返回 argc/argv\n// 支持单引号、双引号\ninline int ShellSplit(char* cmdline, char* argv[], int max_args);\n```\n\n不分配内存，不依赖 `boost::split`，直接在输入缓冲区上操作。\n\n\n## 从 newosp 复用的组件\n\ntelsh 从 [newosp](https://github.com/DeguiLiu/newosp) 项目拷贝了 3 个 header-only 文件作为基础设施：\n\n- `platform.hpp` (169 行) -- 平台检测、`OSP_ASSERT` 宏、编译器提示\n- `vocabulary.hpp` (858 行) -- `FixedFunction`、`FixedString`、`ScopeGuard`\n- `log.hpp` (391 行) -- `OSP_LOG_INFO/WARN/ERROR` 日志宏\n\n这些文件无外部依赖，可以独立使用。这也是 newosp header-only 设计的优势：任何模块都可以单独拷贝到其他项目中使用。\n\n## 使用示例\n\n```cpp\n#include \"telsh/telnet_server.hpp\"\n\n// 用宏注册命令\nTELSH_CMD(hello, \"Print greeting\") {\n    telsh::TelnetServer::Printf(\"Hello!\\r\\n\");\n    return 0;\n}\n\nint main() {\n    telsh::ServerConfig config;\n    config.port = 2500;\n    config.username = \"admin\";\n    config.password = \"1234\";\n\n    telsh::TelnetServer server(\n        telsh::CommandRegistry::Instance(), config);\n    server.Start();\n\n    // ... 主循环 ...\n    server.Stop();\n}\n```\n\n```bash\n$ telnet 127.0.0.1 2500\nusername: admin\npassword: ****\nLogin OK.\ntelsh> help\nAvailable commands:\n  hello            - Print greeting\ntelsh> hello\nHello!\ntelsh> exit\nBye.\n```\n\n\n项目地址：\n- Gitee: https://gitee.com/liudegui/telsh\n- GitHub: https://github.com/DeguiLiu/telsh\n",
      "ctime": "1771552689",
      "mtime": "1771552689",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/uart_protocol_parsing.md": {
    "err_no": 0,
    "data": {
      "id": "7608006131038568486",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        7026219092189118477
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "嵌入式串口协议栈设计: 粘包、缓冲区滑窗与层次状态机",
      "brief_content": "串口协议解析是嵌入式系统中最基础也最容易被忽视的工程问题。本文基于一个完整的 Linux 模拟工程，深入对比缓冲区滑窗扫描与层次状态机（HSM）两种解析架构，覆盖粘包处理、ISR 设计、环形缓冲区、无",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 原文链接:\n> - [嵌入式串口数据流处理中的粘包解决方案](https://blog.csdn.net/stallion5632/article/details/139940595)\n> - [串口协议解析方案对比：缓冲区滑窗与分层状态机](https://blog.csdn.net/stallion5632/article/details/148597654)\n> - [基于 RT-Thread 的 Bootloader 串口通信协议栈优化方案](https://blog.csdn.net/stallion5632/article/details/149034862)\n>\n> 配套代码: [uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) -- C99 实现，POSIX 线程模拟 MCU 中断\n\n## 1. 问题域：为什么串口协议解析值得认真设计\n\n串口（UART）是嵌入式系统中最普遍的通信接口。从 Bootloader 固件升级、传感器数据采集到工业总线协议，几乎所有嵌入式项目都需要处理串口数据的接收与解析。\n\n然而，串口协议解析在工程中经常被轻视：一个 `while` 循环加几个 `if` 判断就能\"跑起来\"。这种做法在低波特率、简单协议场景下或许够用，但当面对以下真实工程约束时，问题会迅速暴露：\n\n| 工程约束 | 具体挑战 |\n|----------|----------|\n| 高波特率 (921600+) | ISR 执行时间成为瓶颈，处理不及时导致 FIFO 溢出 |\n| 多路串口并行 | 每路需要独立上下文，状态隔离不彻底导致数据串扰 |\n| 噪声与粘包 | 字节丢失、帧头误同步、多帧粘连的错误恢复 |\n| OTA 升级 | 大数据量传输中任何帧丢失都需要重传机制 |\n| 多协议扩展 | 同一串口承载 OTA、诊断、配置等不同帧类型 |\n| 资源受限 | Cortex-M0/M3 级别 MCU，RAM 仅数十 KB |\n\n本文围绕一个完整的工程实现（[uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux)），深入对比两种主流解析架构，并讨论在 RT-Thread 等 RTOS 上的集成策略。\n\n## 2. 粘包问题：串口协议解析的第一道坎\n\n串口通信中最常见也最基础的问题是**粘包**：多个独立的数据包被接收端视为一个连续的字节流，边界不可区分。\n\n### 2.1 粘包的成因\n\n- **发送端频率高于接收端处理速度**：接收端来不及逐帧处理，多帧数据堆积在缓冲区\n- **变长数据包**：包长度不固定，接收端无法预知下一帧的边界在哪里\n- **UART 硬件无帧边界概念**：UART 只传输字节流，不像 CAN 或以太网有天然的帧分隔\n\n### 2.2 三种基本解决思路\n\n| 方法 | 原理 | 优点 | 缺点 |\n|------|------|------|------|\n| 特殊分隔符 | 用特殊字节标记帧的开始/结束 | 实现简单 | 数据中出现分隔符需要转义处理 |\n| 固定长度 | 每帧长度一致，按固定偏移切分 | 解析最快 | 不适用变长数据，浪费带宽 |\n| 协议设计 | 帧头 + 长度字段 + 校验 | 灵活通用 | 实现复杂度高于前两者 |\n\n实际工业协议几乎都采用第三种方案，或者第一种和第三种的组合（帧头标记 + 长度字段 + CRC）。\n\n### 2.3 一个朴素实现的问题\n\n最直觉的做法是在主循环中阻塞式地按字段顺序读取：\n\n```c\n/* 朴素实现 -- 阻塞式逐字段读取 */\nint recv_frame(int fd, uart_frame_t *frame, int timeout_us)\n{\n    /* 1. 等待帧头 */\n    while (1) {\n        uart_read(fd, &frame->header, 1, timeout_us);\n        if (frame->header == 0xAA) break;  /* 找到帧头 */\n    }\n\n    /* 2. 读取长度 */\n    if (uart_read(fd, &frame->len, 1, timeout_us) != 1)\n        return -1;\n\n    /* 3. 读取命令类型 */\n    if (uart_read(fd, &frame->type, 1, timeout_us) != 1)\n        return -1;\n\n    /* 4. 读取数据 */\n    if (frame->len > 1) {\n        if (uart_read(fd, frame->data, frame->len - 1, timeout_us)\n            != frame->len - 1)\n            return -1;\n    }\n\n    /* 5. 读取校验 */\n    if (uart_read(fd, &frame->crc, 1, timeout_us) != 1)\n        return -1;\n\n    /* 6. 校验 */\n    if (frame->crc != calculate_crc((uint8_t *)frame, ...))\n        return -1;\n\n    return 0;\n}\n```\n\n这个实现能在理想条件下工作，但存在严重的工程缺陷：\n\n1. **阻塞式读取**：`uart_read()` 使用 `select()` 超时等待，主线程被完全阻塞，无法处理其他任务\n2. **无错误恢复**：如果中间字节丢失，整个解析流程卡死在某个 `uart_read()` 上等超时\n3. **无粘包处理**：如果一次 `read()` 返回了跨帧的数据，多余字节直接丢失\n4. **单实例限制**：状态完全依赖函数调用栈，无法同时解析多路串口\n\n这正是为什么需要更系统化的解析架构。后续章节介绍的**缓冲区滑窗**和**层次状态机**方案，都是为了解决这些工程问题而设计的。\n\n## 3. 架构分层：ISR 极简原则\n\n无论采用哪种解析方案，一个核心设计原则贯穿始终：**ISR 只做数据搬运，协议处理全部在线程态完成**。\n\n```\n+-----------------------------------+\n|  业务层     OTA / 诊断 / 配置     |\n+-----------------------------------+\n|  协议层     帧解析 / CRC / FSM    |  <-- 线程态\n+-----------------------------------+\n|  驱动层     ISR + Ring Buffer     |  <-- 中断态\n+-----------------------------------+\n|  硬件       UART FIFO             |\n+-----------------------------------+\n```\n\nISR 的职责边界非常清晰：\n\n1. 从硬件 FIFO 读取字节\n2. 写入环形缓冲区（或 SPSC 队列）\n3. 通知线程（信号量 / 事件标志）\n4. **不做**任何协议解析、CRC 计算、状态转换\n\n这个原则的核心原因是中断延迟的确定性。ISR 执行时间越长，其他中断被阻塞的时间越长，系统的实时性越不可控。在 921600 bps 下，每个字节的传输时间约 10.9 us，ISR 必须在这个时间窗口内完成处理。\n\n### 3.1 UART HAL 层设计\n\n配套工程使用 POSIX 线程模拟 MCU 中断机制，但接口设计完全贴合真实 MCU HAL：\n\n```c\n/* 串口设备上下文 -- 每路独立 */\ntypedef struct {\n    bool_t initialized;\n    uart_config_t config;\n    uart_state_e state;\n    uart_fifo_t rx_fifo;           /* 硬件 FIFO 模拟 (64 字节) */\n    volatile uint32_t int_status;  /* 中断状态标志 */\n    uart_stats_t stats;\n    pthread_t rx_thread;           /* ISR 模拟线程 */\n    sem_t rx_sem;                  /* 接收通知信号量 */\n    struct timespec last_rx_time;  /* 超时检测时间戳 */\n} uart_port_ctx_t;\n```\n\n关键设计点：\n\n- **每路串口独立上下文**：3 路串口各自维护 `uart_port_ctx_t`，彻底隔离状态\n- **硬件 FIFO 模拟**：64 字节循环缓冲，支持水位线触发\n- **中断类型区分**：`RECV_DATA_AVAILABLE`（FIFO 水位）、`CHARACTER_TIMEOUT`（空闲超时）、`LINE_ERROR`（帧/奇偶校验错误）\n\nISR 回调的典型实现：\n\n```c\nstatic void uart_isr_callback(uint8_t port, uint32_t int_status)\n{\n    uint8_t byte;\n\n    /* 仅做数据搬运：FIFO -> 解析器缓冲 */\n    while (uart_hal_rx_available(port)) {\n        uart_hal_try_get_byte(port, &byte);\n\n        if (current_mode == MODE_RINGBUFFER) {\n            rb_parser_put_byte(&rb_parser, byte);\n        } else {\n            /* HSM 模式：先攒批，再通过 SPSC 队列传递 */\n            batch_buf[batch_len++] = byte;\n            if (batch_len >= BATCH_SIZE) {\n                spsc_queue_push(&hsm_rx_queue, batch_buf, batch_len);\n                batch_len = 0;\n            }\n        }\n    }\n}\n```\n\n## 4. 协议帧格式\n\n工程中定义了两级帧格式，这里重点讨论实际使用的简单帧：\n\n```\n+------+--------+----------+-----+------+----------+------+\n| 0xAA | LEN(2B)| CMD_CLASS| CMD | DATA | CRC16(2B)| 0x55 |\n| 帧头 | 小端序 |   1 B    | 1 B | N B  |  小端序  | 帧尾 |\n+------+--------+----------+-----+------+----------+------+\n\nLEN = sizeof(CMD_CLASS) + sizeof(CMD) + sizeof(DATA)\nCRC = CRC16-CCITT(CMD_CLASS + CMD + DATA), poly=0x1021, init=0x0000\n```\n\n```c\n#pragma pack(push, 1)\ntypedef struct {\n    uint8_t header;         /* 0xAA */\n    uint16_t length;        /* payload 长度 (小端序) */\n    uint8_t cmd_class;      /* 命令类: SYS=0x01, SPI=0x02, OTA=0x04 */\n    uint8_t cmd;            /* 具体命令 */\n    uint8_t data[256];      /* 变长数据 */\n    uint16_t crc16;         /* CRC16-CCITT */\n    uint8_t tail;           /* 0x55 */\n} uart_frame_t;\n#pragma pack(pop)\n```\n\nCRC16-CCITT 使用查表法实现，256 项查找表在编译期确定：\n\n```c\nstatic inline uint16_t uart_calc_crc16(const uint8_t *data, uint16_t len)\n{\n    uint16_t crc = 0x0000;\n    while (len--) {\n        crc = (crc << 8) ^ crc16_table[((crc >> 8) ^ *data++) & 0xFF];\n    }\n    return crc;\n}\n```\n\n## 5. 方案一：环形缓冲区滑窗扫描\n\n### 5.1 核心思路\n\n滑窗法的逻辑直白：ISR 把字节追加到环形缓冲区，主循环反复扫描缓冲区，通过游标滑动来定位帧头、验证帧长、校验 CRC 和帧尾，最后提取完整帧。\n\n```\nISR 写入                 主循环读取\n   |                        |\n   v                        v\n+--+--+--+--+--+--+--+--+--+--+--+--+\n|  |AA|03|01|81|xx|CR|CL|55|  |  |  |\n+--+--+--+--+--+--+--+--+--+--+--+--+\n      ^                       ^\n      head (消费者)            tail (生产者)\n      |<-- 滑动窗口扫描 -->|\n```\n\n### 5.2 数据结构\n\n```c\ntypedef struct {\n    uint32_t size;              /* 必须为 2 的幂 */\n    uint32_t mask;              /* size - 1, 用位与替代取模 */\n    volatile uint32_t head;     /* 读索引 (消费者) */\n    volatile uint32_t tail;     /* 写索引 (生产者) */\n    uint8_t *buffer;\n} rb_queue_t;\n\ntypedef struct {\n    rb_queue_t rb;\n    uint8_t rb_buffer[1024];            /* 静态分配 */\n    uart_frame_t frame;\n    rb_parser_stats_t stats;\n    rb_frame_callback_t callback;\n    void *user_data;\n} rb_parser_t;\n```\n\n环形缓冲区的大小强制为 2 的幂，这使得取模运算退化为位与操作：`index & mask`，在没有硬件除法器的 Cortex-M0 上尤为重要。\n\n### 5.3 帧提取算法\n\n`rb_parser_try_extract()` 的核心流程：\n\n```\n1. 从 head 开始扫描，跳过非 0xAA 字节（同步丢弃）\n2. peek 第 2~3 字节，组装 16 位长度值（小端序）\n3. 计算完整帧大小 = 1(头) + 2(长度) + LEN + 2(CRC) + 1(尾)\n4. 若缓冲区内数据不足完整帧，返回等待\n5. peek payload 区域，计算 CRC16\n6. 比较计算 CRC 与帧内 CRC\n7. 验证尾字节 == 0x55\n8. 全部通过：回调上层，head 前进一帧\n9. 任一步骤失败：head 前进 1 字节，重新扫描\n```\n\n这个算法的关键操作是 `peek`：在不移动 head 的情况下读取缓冲区中任意偏移位置的字节。只有当整帧验证通过后，才一次性推进 head：\n\n```c\nstatic inline uint8_t rb_peek(const rb_queue_t *rb, uint32_t offset)\n{\n    return rb->buffer[(rb->head + offset) & rb->mask];\n}\n```\n\n### 5.4 统计与错误跟踪\n\n```c\ntypedef struct {\n    uint32_t frames_received;   /* 成功帧数 */\n    uint32_t bytes_received;    /* 总字节数 */\n    uint32_t sync_errors;       /* 同步丢弃的非帧头字节 */\n    uint32_t crc_errors;        /* CRC 不匹配 */\n    uint32_t tail_errors;       /* 帧尾不是 0x55 */\n    uint32_t length_errors;     /* 长度字段越界 */\n    uint32_t overflow_errors;   /* 缓冲区溢出丢弃 */\n} rb_parser_stats_t;\n```\n\n每种错误类型独立计数，这对于现场调试至关重要。`sync_errors` 反映信道噪声水平，`overflow_errors` 反映处理速度是否跟得上接收速度。\n\n### 5.5 优缺点分析\n\n**适用场景**：协议结构固定、帧长度短、波特率中低、对实时性要求不苛刻的简单应用。\n\n| 优势 | 劣势 |\n|------|------|\n| 实现直白，代码量小（约 300 行） | 状态隐含在代码流中，调试时无法直接观察\"当前解析到哪一步\" |\n| 不依赖外部框架 | 粘包/噪声场景下需要多次全局扫描，最坏 O(N^2) |\n| 批量处理效率高（一次可剥离多帧） | 协议变更需修改核心扫描逻辑，维护成本高 |\n| 内存布局紧凑 | 多实例需要手动管理多套缓冲区和游标 |\n\n## 6. 方案二：层次状态机（HSM）事件驱动\n\n### 6.1 核心思路\n\n状态机方案将协议解析的每个阶段映射为一个显式状态，每个接收字节作为事件分发到当前状态的处理函数。状态转换由转换表驱动，而非代码分支。\n\n```mermaid\nstateDiagram-v2\n    [*] --> Idle\n    Idle --> Length1 : 0xAA\n    Length1 --> Length2 : byte\n    Length2 --> CmdClass : byte (validate length)\n    CmdClass --> Cmd : byte\n    Cmd --> Data : has_data (len > 2)\n    Cmd --> CRC1 : no_data (len == 2)\n    Data --> Data : data_incomplete\n    Data --> CRC1 : data_complete\n    CRC1 --> CRC2 : byte\n    CRC2 --> Tail : byte\n    Tail --> Idle : 0x55 (frame complete)\n    Tail --> Idle : error (tail mismatch)\n\n    Length2 --> Idle : length_invalid\n    Data --> Idle : timeout\n    CRC1 --> Idle : timeout\n```\n\n### 6.2 HSM 框架设计\n\n工程中实现了一个轻量级的层次状态机框架（移植自 Andreas Misje 的开源实现），核心数据结构如下：\n\n```c\n/* 状态定义 */\nstruct hsm_state {\n    const hsm_state_t *parent;           /* 父状态（层次结构） */\n    hsm_action_fn entry_action;          /* 进入动作 */\n    hsm_action_fn exit_action;           /* 退出动作 */\n    const hsm_transition_t *transitions; /* 转换表 */\n    size_t num_transitions;\n    const char *name;                    /* 调试名称 */\n};\n\n/* 转换规则 */\nstruct hsm_transition {\n    uint32_t event_id;                   /* 触发事件 */\n    const hsm_state_t *target;           /* 目标状态 */\n    hsm_guard_fn guard;                  /* 守卫条件（可选） */\n    hsm_action_fn action;                /* 转换动作（可选） */\n    hsm_transition_type_t type;          /* 外部/内部转换 */\n};\n\n/* 状态机实例 */\nstruct hsm {\n    const hsm_state_t *current_state;\n    const hsm_state_t *initial_state;\n    void *user_data;\n    hsm_action_fn unhandled_event_hook;\n    const hsm_state_t **entry_path_buffer; /* LCA 路径计算缓冲 */\n    uint8_t buffer_size;\n};\n```\n\n这个框架的几个关键设计决策：\n\n**层次继承**：每个状态有 `parent` 指针。当子状态无法处理某个事件时，事件自动上抛给父状态。这使得公共行为（如超时重置）只需在父状态定义一次。\n\n**Guard 条件**：转换规则支持 `guard` 函数，只有守卫条件返回 `TRUE` 时转换才会发生。这比在 action 中做条件判断更清晰。\n\n**LCA（最低公共祖先）计算**：层次转换时，框架自动计算源状态和目标状态的最低公共祖先，只执行必要的 exit/entry 动作序列。\n\n**零动态内存**：`entry_path_buffer` 由调用者提供（栈分配），框架本身不做任何 `malloc`。\n\n### 6.3 协议解析器的状态定义\n\n```c\n/* 事件定义 */\ntypedef enum {\n    HSM_EVENT_BYTE = 1,     /* 字节接收 */\n    HSM_EVENT_RESET,        /* 复位 */\n    HSM_EVENT_TIMEOUT       /* 超时 */\n} hsm_parser_event_e;\n\n/* 解析器上下文 */\ntypedef struct {\n    hsm_t sm;\n    const hsm_state_t *entry_path[8];   /* 层次深度上限 */\n\n    uart_frame_t frame;\n    uint8_t current_byte;\n    uint16_t expected_len;\n    uint16_t data_index;\n    uint8_t crc_buf[2];\n    uint8_t payload_buf[260];           /* CRC 计算缓冲 */\n    uint16_t payload_index;\n\n    hsm_parser_stats_t stats;\n    hsm_frame_callback_t callback;\n    void *user_data;\n} hsm_parser_t;\n```\n\n每个状态对应协议帧的一个字段，转换表以声明式的方式描述了完整的解析流程。以 `state_cmd` 为例：\n\n```c\n/* Cmd 状态的转换表 -- 根据是否有数据分支 */\nstatic const hsm_transition_t cmd_transitions[] = {\n    /* 有数据 (len > 2): 进入 Data 状态 */\n    { HSM_EVENT_BYTE, &state_data, guard_has_data, action_store_cmd,\n      SM_TRANSITION_EXTERNAL },\n    /* 无数据 (len == 2): 直接进入 CRC1 状态 */\n    { HSM_EVENT_BYTE, &state_crc1, guard_no_data, action_store_cmd,\n      SM_TRANSITION_EXTERNAL },\n    /* 超时: 回到 Idle */\n    { HSM_EVENT_TIMEOUT, &state_idle, NULL, action_timeout_error,\n      SM_TRANSITION_EXTERNAL },\n};\n```\n\nGuard 函数的实现简洁明了：\n\n```c\nstatic bool_t guard_has_data(hsm_t *sm, const hsm_event_t *event)\n{\n    hsm_parser_t *parser = (hsm_parser_t *)sm->user_data;\n    return (parser->expected_len > 2) ? TRUE : FALSE;\n}\n\nstatic bool_t guard_is_tail(hsm_t *sm, const hsm_event_t *event)\n{\n    hsm_parser_t *parser = (hsm_parser_t *)sm->user_data;\n    return (parser->current_byte == SIMPLE_FRAME_TAIL) ? TRUE : FALSE;\n}\n```\n\n### 6.4 事件分发流程\n\n每个字节到达时的处理流程：\n\n```c\nbool_t hsm_parser_put_byte(hsm_parser_t *parser, uint8_t byte)\n{\n    parser->current_byte = byte;\n    parser->stats.bytes_received++;\n\n    hsm_event_t event = { .id = HSM_EVENT_BYTE, .context = &byte };\n    return hsm_dispatch(&parser->sm, &event);\n}\n```\n\n`hsm_dispatch()` 内部的算法：\n\n1. 在当前状态的转换表中查找匹配 `event_id` 的转换\n2. 若找到且有 guard，执行 guard 检查\n3. Guard 通过（或无 guard）：执行 exit/action/entry 序列\n4. 若当前状态无匹配，向上委托给 `parent` 状态\n5. 所有层级都未处理，调用 `unhandled_event_hook`\n\n### 6.5 优缺点分析\n\n**适用场景**：复杂/可扩展协议、多路并行解析、需要高可靠性和可维护性的工业系统。\n\n| 优势 | 劣势 |\n|------|------|\n| 状态显式可见，调试时可直接查询 `hsm_get_current_state_name()` | 转换表定义的代码量较大 |\n| 每字节 O(1) 处理，无全局扫描 | 比滑窗法多一层间接调用开销 |\n| 错误恢复局部化：任意状态可直接转回 Idle | 框架本身需要约 200 行实现 |\n| 协议扩展只需增删状态，不改核心框架 | 初学者需要理解层次状态机的概念模型 |\n| 多实例天然支持：每个 `hsm_parser_t` 独立 | |\n\n## 7. 关键优化：SPSC 无锁队列\n\n在 HSM 方案中，如果每个字节都在 ISR 内直接调用 `hsm_dispatch()`，ISR 的执行时间会显著增加。工程中采用了一个重要的优化：**SPSC 无锁队列作为 ISR 与协议线程之间的缓冲层**。\n\n```\nISR (生产者)                     协议线程 (消费者)\n    |                                |\n    | spsc_queue_push(batch)         | spsc_queue_pop(batch)\n    |                                |\n    v                                v\n+---+---+---+---+---+---+---+---+---+\n|   |   |   |   |   |   |   |   |   |\n+---+---+---+---+---+---+---+---+---+\n    ^                           ^\n    write_idx                   read_idx\n```\n\n```c\ntypedef struct {\n    uint32_t size;           /* 2 的幂 */\n    uint32_t mask;\n    volatile uint32_t head;  /* 消费者索引 */\n    volatile uint32_t tail;  /* 生产者索引 */\n    uint8_t *buffer;\n} spsc_queue_t;\n```\n\nSPSC 队列的无锁特性来自生产者和消费者分别只写自己的索引：\n\n- ISR 只写 `tail`，只读 `head`\n- 协议线程只写 `head`，只读 `tail`\n- 不需要互斥锁，只需要内存屏障保证可见性\n\n在 ARM Cortex-M 上，内存屏障通过 `__DMB()` 指令实现：\n\n```c\n#if defined(__ARM_ARCH)\n    #define SPSC_QUEUE_DMB()  __asm volatile(\"dmb\" ::: \"memory\")\n#else\n    #define SPSC_QUEUE_DMB()  __sync_synchronize()\n#endif\n```\n\nISR 内的批量写入：\n\n```c\n/* ISR: 攒批写入，减少队列操作次数 */\nstatic uint8_t batch_buf[256];\nstatic uint32_t batch_len = 0;\n\nvoid isr_handler(uint8_t byte)\n{\n    batch_buf[batch_len++] = byte;\n    if (batch_len >= 256) {\n        spsc_queue_push(&hsm_rx_queue, batch_buf, batch_len);\n        batch_len = 0;\n    }\n}\n```\n\n协议线程的批量消费：\n\n```c\n/* 协议线程: 批量取出，逐字节喂给 HSM */\nuint8_t pop_buf[256];\nint32_t budget = 1024;\n\nwhile (budget > 0) {\n    int32_t got = spsc_queue_pop(&hsm_rx_queue, pop_buf,\n                                 (budget < 256) ? budget : 256);\n    if (got <= 0) break;\n\n    hsm_parser_put_data(&parser, pop_buf, (uint32_t)got);\n    budget -= got;\n}\n```\n\n这个设计将 ISR 的执行时间压缩到\"攒字节 + 偶尔一次 memcpy\"的水平，状态机的全部计算开销转移到协议线程。\n\n## 8. RT-Thread RTOS 集成\n\n上述 Linux 模拟工程的架构可以直接移植到 RT-Thread 平台。RT-Thread 提供了完整的基础设施来替代 POSIX 接口：\n\n| Linux 模拟 | RT-Thread 替代 | 说明 |\n|------------|---------------|------|\n| `pthread_t` + ISR 模拟 | 硬件 UART ISR | 真实中断，无需模拟 |\n| `sem_t` | `rt_sem_t` | 二值信号量通知线程 |\n| SPSC 队列 | `rt_ringbuffer` | RT-Thread 内置环形缓冲组件 |\n| `pthread_create()` | `rt_thread_create()` | 协议处理线程 |\n| `usleep()` | `rt_sem_take(RT_WAITING_FOREVER)` | 阻塞等待接收事件 |\n\n### 8.1 RT-Thread 上的 ISR 实现\n\n```c\n/* RT-Thread 串口 ISR -- 仅数据搬运 */\nstatic rt_err_t uart_rx_indicate(rt_device_t dev, rt_size_t size)\n{\n    uart_dev_t *udev = (uart_dev_t *)dev->user_data;\n    uint8_t ch;\n\n    while (rt_device_read(dev, -1, &ch, 1) == 1) {\n        rt_ringbuffer_putchar(&udev->rx_rb, ch);\n        udev->stats.rx_bytes++;\n    }\n\n    rt_sem_release(udev->rx_sem);\n    return RT_EOK;\n}\n```\n\n### 8.2 协议处理线程\n\n```c\nstatic void protocol_thread_entry(void *parameter)\n{\n    protocol_context_t *ctx = (protocol_context_t *)parameter;\n    uart_dev_t *dev = &uart_dev[ctx->uart_id];\n\n    while (1) {\n        /* 阻塞等待 ISR 通知 */\n        if (rt_sem_take(dev->rx_sem, RT_WAITING_FOREVER) != RT_EOK)\n            continue;\n\n        /* 从环形缓冲区逐字节取出，喂给状态机 */\n        uint8_t ch;\n        while (rt_ringbuffer_getchar(&dev->rx_rb, &ch) == 1) {\n            hsm_parser_put_byte(&ctx->parser, ch);\n            ctx->last_rx_tick = rt_tick_get();\n        }\n\n        /* 超时检测 */\n        if ((rt_tick_get() - ctx->last_rx_tick) >\n            RT_TICK_PER_SECOND * PROTOCOL_RX_TIMEOUT / 1000) {\n            hsm_event_t evt = { .id = HSM_EVENT_TIMEOUT, .context = NULL };\n            hsm_dispatch(&ctx->parser.sm, &evt);\n            ctx->stats.rx_timeouts++;\n        }\n    }\n}\n```\n\n### 8.3 静态上下文管理\n\n在 RTOS 环境中，每路串口需要完全独立的上下文：\n\n```c\n#define UART_MAX_NUM         3\n#define STATIC_BUFFER_SIZE   2048\n\ntypedef struct {\n    struct rt_ringbuffer rx_rb;\n    uint8_t rb_mem[STATIC_BUFFER_SIZE]; /* 静态分配，无 malloc */\n    rt_sem_t rx_sem;\n    uint32_t overrun_count;\n} uart_dev_t;\n\ntypedef struct protocol_context {\n    hsm_parser_t parser;\n    uint8_t uart_id;\n    rt_tick_t last_rx_tick;\n    uart_stats_t stats;\n} protocol_context_t;\n\nstatic uart_dev_t uart_dev[UART_MAX_NUM];\nstatic protocol_context_t proto_ctx[UART_MAX_NUM];\n```\n\n所有内存静态分配，零 `malloc`。这是嵌入式系统的标准做法：动态内存分配在长期运行的系统中会导致碎片化，且分配延迟不可预测。\n\n## 9. 裸机（Super-Loop）环境适配\n\n并非所有嵌入式系统都有 RTOS。在裸机环境下，没有线程、没有信号量，只有中断和主循环。两种解析方案在裸机下的适配如下。\n\n### 9.1 裸机架构\n\n```\nISR (硬件中断)\n    |\n    | 写入 ring buffer / SPSC\n    | 设置标志位\n    |\n    v\nmain() {\n    system_init();\n    while (1) {                    /* super-loop */\n        if (rx_flag) {\n            rx_flag = 0;\n            protocol_process();    /* 协议解析 */\n        }\n        other_tasks();             /* LED、ADC、看门狗... */\n    }\n}\n```\n\n核心区别：没有信号量阻塞等待，改用 `volatile` 标志位轮询。\n\n### 9.2 裸机 ISR 实现\n\n```c\n/* 裸机 ISR -- 以 STM32 HAL 为例 */\nstatic volatile uint8_t rx_flag = 0;\n\nvoid USART1_IRQHandler(void)\n{\n    if (__HAL_UART_GET_FLAG(&huart1, UART_FLAG_RXNE)) {\n        uint8_t byte = (uint8_t)(huart1.Instance->DR & 0xFF);\n\n        /* 直接写入解析器的 ring buffer */\n        rb_parser_put_byte(&parser, byte);\n\n        rx_flag = 1;\n    }\n}\n```\n\nISR 的职责与 RTOS 环境完全一致：只做数据搬运。区别仅在于通知方式从信号量变为标志位。\n\n### 9.3 主循环处理\n\n**滑窗方案 -- 裸机**：\n\n```c\nint main(void)\n{\n    system_init();\n    uart_init();\n    rb_parser_init(&parser, on_frame_received, NULL);\n\n    while (1) {\n        /* 轮询处理：有数据就解析 */\n        if (rx_flag) {\n            rx_flag = 0;\n            rb_parser_process(&parser);  /* 扫描并提取所有完整帧 */\n        }\n\n        /* 超时检测（裸机无 OS tick，用硬件定时器） */\n        if (systick_elapsed_ms(last_rx_time) > PROTOCOL_TIMEOUT_MS) {\n            rb_parser_reset(&parser);\n        }\n\n        wdog_feed();\n        other_periodic_tasks();\n    }\n}\n```\n\n**HSM 方案 -- 裸机**：\n\n```c\nint main(void)\n{\n    system_init();\n    uart_init();\n    hsm_parser_init(&parser, on_frame_received, NULL);\n\n    while (1) {\n        /* 从 SPSC 队列批量取出，喂给 HSM */\n        uint8_t buf[64];\n        int32_t got = spsc_queue_pop(&rx_queue, buf, sizeof(buf));\n        if (got > 0) {\n            hsm_parser_put_data(&parser, buf, (uint32_t)got);\n            last_rx_tick = systick_get();\n        }\n\n        /* 超时事件注入 */\n        if (systick_elapsed_ms(last_rx_tick) > PROTOCOL_TIMEOUT_MS) {\n            hsm_event_t evt = { .id = HSM_EVENT_TIMEOUT, .context = NULL };\n            hsm_dispatch(&parser.sm, &evt);\n        }\n\n        wdog_feed();\n    }\n}\n```\n\n### 9.4 裸机环境的注意事项\n\n| 问题 | 解决方案 |\n|------|----------|\n| 无 OS tick | 使用 SysTick 或硬件定时器提供毫秒级时间基准 |\n| 无信号量 | `volatile uint8_t` 标志位 + 主循环轮询 |\n| 主循环延迟不确定 | 控制 `other_tasks()` 的最大执行时间，避免饿死协议处理 |\n| 中断嵌套 | 确保 ring buffer / SPSC 的写入是原子的（单字节写入天然原子） |\n| 内存屏障 | 单核 MCU 用 `atomic_signal_fence(memory_order_seq_cst)` 或 `__DMB()` |\n\n在单核 MCU 上，ISR 与主循环之间不存在真正的并发（ISR 抢占主循环，但不会同时执行），因此 SPSC 队列的内存序要求可以放松为 `relaxed` + `signal_fence`，避免不必要的硬件屏障开销。\n\n## 10. 业务层：命令分发架构\n\n帧解析完成后，业务层根据 `cmd_class` 字段分发到具体的命令处理器：\n\n```c\nvoid handle_packet(const uart_frame_t *frame, void *user_data)\n{\n    switch (frame->cmd_class) {\n        case VDCMD_CLASS_SYS:\n            handle_sys_cmd(frame);\n            break;\n        case VDCMD_CLASS_SPI:\n            handle_spi_cmd(frame);\n            break;\n        case VDCMD_CLASS_OTA:\n            handle_ota_cmd(frame);\n            break;\n        case VDCMD_CLASS_CONFIG:\n            handle_config_cmd(frame);\n            break;\n        default:\n            stats.unknown_class++;\n            break;\n    }\n}\n```\n\n这种设计使得协议层和业务层完全解耦。协议层只关心帧的完整性和正确性（CRC、帧头帧尾），业务层只关心命令语义。新增命令类只需添加一个 `case` 分支和对应的处理函数。\n\n### 10.1 OTA 升级的会话管理\n\nOTA 是最典型的需要会话状态的业务。配套工程中的 OTA 上下文：\n\n```c\ntypedef struct {\n    ota_state_e state;        /* IDLE / RECEIVING / VERIFYING / COMPLETE */\n    uint32_t total_size;\n    uint32_t received_size;\n    uint32_t start_addr;\n    uint32_t crc_expected;\n    uint32_t crc_calculated;  /* 增量计算，非最终一次性校验 */\n    uint32_t error_count;\n} ota_context_t;\n```\n\nOTA 命令序列：`START`（擦除 Flash、初始化上下文） -> `DATA`（写入数据块、增量 CRC） -> `END`（标记传输完成） -> `VERIFY`（比对 CRC、确认升级）。\n\n## 11. 性能与资源对比\n\n### 11.1 算法复杂度\n\n| 维度 | 缓冲区滑窗 | HSM 事件驱动 |\n|------|-----------|-------------|\n| 每字节处理 | O(1) 平均，O(N) 最坏（扫描丢弃） | O(1) 确定性（转换表查找） |\n| 帧提取 | O(帧长) 的 peek + CRC | O(帧长) 的逐字节分发 |\n| 错误恢复 | O(N) 滑窗重扫描 | O(1) 直接转回 Idle |\n| 多帧粘包 | 需要循环调用 `try_extract()` | 自然处理，无需额外逻辑 |\n\n### 11.2 内存占用\n\n| 资源 | 缓冲区滑窗 | HSM 事件驱动 |\n|------|-----------|-------------|\n| 环形缓冲区 | 1024 B（必须容纳多帧） | 不需要（或 SPSC 队列 4096 B） |\n| 帧缓冲 | 256 B | 260 B |\n| 状态结构 | 无 | ~200 B（状态/转换表为 const） |\n| 统计计数器 | 28 B | 28 B |\n| **每实例总计** | ~1320 B | ~500 B (不含 SPSC) / ~4560 B (含 SPSC) |\n\n### 11.3 代码体积\n\n| 模块 | 缓冲区滑窗 | HSM 事件驱动 |\n|------|-----------|-------------|\n| 解析器 | ~300 行 | ~400 行 |\n| 框架 | 0（无框架） | ~200 行（HSM 核心） |\n| **总计** | ~300 行 | ~600 行 |\n\n### 11.4 ISR 延迟\n\n| 方案 | ISR 内操作 | 估算延迟 (Cortex-M4 @ 168 MHz) |\n|------|-----------|------|\n| 滑窗 | 写入 ring buffer（1 次内存写 + 索引更新） | < 100 ns |\n| HSM (无 SPSC) | 每字节 `hsm_dispatch()` | ~500 ns - 1 us |\n| HSM (有 SPSC) | 写入批量缓冲 + 偶尔 push | < 200 ns (均摊) |\n\n## 12. 选择决策矩阵\n\n| 项目特征 | 推荐方案 |\n|----------|----------|\n| 协议格式固定，短期不会变 | 滑窗 |\n| 可能扩展新命令类/新帧格式 | HSM |\n| 单路串口、低波特率 | 滑窗 |\n| 多路串口并行 | HSM |\n| Bootloader（代码体积敏感） | 滑窗 |\n| 长期维护的产品固件 | HSM |\n| 团队多人协作 | HSM（状态图即文档） |\n| 需要高可靠性错误恢复 | HSM |\n| 原型快速验证 | 滑窗 |\n\n实际工程中，两种方案并非互斥。一个常见的组合是：**Bootloader 阶段使用滑窗法**（代码体积最小化），**应用固件使用 HSM**（可维护性和扩展性优先）。\n\n## 13. 调试与诊断\n\n两种方案都内置了统计计数器，可通过 RT-Thread 的 MSH 命令行或自定义 Shell 查询：\n\n```\nUART0 Statistics:\n  RX Bytes:   24680\n  Frames OK:  1024\n  Sync Err:   3        <-- 信道噪声指标\n  CRC Err:    0        <-- 数据完整性\n  Tail Err:   0        <-- 帧结构完整性\n  Length Err:  0        <-- 协议合规性\n  Overflow:   0        <-- 处理速度 vs 接收速度\n  Timeouts:   1        <-- 传输中断\n```\n\nHSM 方案额外提供了实时状态查询能力：\n\n```c\nprintf(\"Current state: %s\\n\", hsm_parser_get_state(&parser));\n/* 输出: Current state: Data */\n```\n\n这在调试\"卡在某个状态不动\"的问题时非常有价值。\n\n## 14. 总结\n\n串口协议解析看似简单，但在工业嵌入式系统中，它需要应对高波特率、噪声干扰、多路并行、长期运行稳定性等一系列工程挑战。\n\n**缓冲区滑窗**是一个实用的基线方案，适合简单协议和资源极度受限的场景。它的核心优势是实现直白、代码量少、不依赖外部框架。\n\n**层次状态机**是面向复杂协议的工程化方案。它的核心优势是状态显式可见、错误恢复局部化、协议扩展无需修改框架、多实例天然支持。配合 SPSC 无锁队列，可以在不增加 ISR 延迟的前提下获得 HSM 的全部优势。\n\n无论选择哪种方案，以下设计原则是通用的：\n\n1. **ISR 极简**：只做数据搬运，不做协议处理\n2. **静态分配**：所有缓冲区预分配，热路径零 malloc\n3. **独立上下文**：每路串口完全隔离，无共享状态\n4. **统计计数**：每种错误类型独立计数，支撑现场诊断\n5. **CRC 校验**：查表法 CRC16-CCITT，平衡速度与代码体积\n\n配套代码 [uart_statemachine_ringbuffer_linux](https://gitee.com/liudegui/uart_statemachine_ringbuffer_linux) 提供了完整的双方案实现，可在 Linux 环境下直接编译运行验证，也可作为移植到 MCU/RTOS 平台的参考起点。\n",
      "ctime": "1771552693",
      "mtime": "1771552693",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/ztask_cpp_modernization.md": {
    "err_no": 0,
    "data": {
      "id": "7608007253651767342",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640447497994253
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "ztask 调度器的 C++14 重写: 类型安全、RAII 与模板化改造",
      "brief_content": "在轻量 RTOS 项目和嵌入式Linux中，合作式任务调度器是比操作系统线程更轻量的执行抽象。",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 源码仓库: [gitee.com/liudegui/ztask-cpp](https://gitee.com/liudegui/ztask-cpp)\n> 设计文档: [docs/design.md](https://gitee.com/liudegui/ztask-cpp/blob/main/docs/design.md)\n\n> 在轻量 RTOS 项目和嵌入式Linux中，合作式任务调度器是比操作系统线程更轻量的执行抽象。\n\n\n## 1. 设计决策\n本文的设计是参考与对比[tomzbj/ztask](https://github.com/tomzbj/ztask)\n\n| 决策 | 理由 |\n|------|------|\n| Header-only | 零链接开销，模板按容量实例化 |\n| 排序侵入式链表 | O(1) poll vs 数组扫描 O(n) vs 堆 O(log n) |\n| 定长数组存储 | 栈分配，cache-friendly，确定性内存 |\n| Generation 计数器 | 2B TaskId 内嵌 ABA 防护 |\n| Tick 驱动时基 | 硬件无关，裸机/RTOS/Linux 通用 |\n| 不内建线程安全 | 目标平台单线程为主，用户按需添加同步 |\n| TicksToNextTask() | MCU idle/sleep/stop 模式的低功耗优化路径 |\n\n## 2. 架构设计\n\nztask-cpp 保留了ztask原始算法的核心 -- 排序侵入式链表，但将运行时约束提升为编译期保证:\n\n```\n                    C 版 ztask                          ztask-cpp\n              ┌─────────────────────┐           ┌─────────────────────────────┐\n  容量管理    │ malloc / 静态池      │    →      │ template<MaxTasks>           │\n              │ zt_init(mem, size)  │           │ 编译期固定，零初始化代码       │\n              ├─────────────────────┤           ├─────────────────────────────┤\n  类型安全    │ void(*)(void)       │    →      │ void(*)(void* ctx)          │\n              │ 全局变量传 context   │           │ ctx 参数直接传递             │\n              ├─────────────────────┤           ├─────────────────────────────┤\n  ABA 防护    │ 裸指针 handle       │    →      │ (generation<<8|index) 编码   │\n              │ 无过期检测          │           │ 256 代 ABA 防护              │\n              ├─────────────────────┤           ├─────────────────────────────┤\n  Tick 类型   │ 固定 uint32_t      │    →      │ TickType 模板参数            │\n              │ 49 天溢出           │           │ uint64_t 可选 (585 年)       │\n              └─────────────────────┘           └─────────────────────────────┘\n```\n\n### 2.1 核心类模板\n\n```cpp\ntemplate <uint32_t MaxTasks, typename TickType = uint32_t>\nclass TaskScheduler {\n public:\n  using TaskFn = void (*)(void* ctx);\n  using TaskId = uint16_t;\n  static constexpr TaskId kInvalidId = 0xFFFF;\n\n  TaskScheduler() noexcept;\n  void Tick() noexcept;\n  TaskId Bind(TaskFn fn, TickType repeat_ticks, TickType delay_ticks,\n              void* ctx = nullptr) noexcept;\n  TaskId BindOneShot(TaskFn fn, TickType delay_ticks,\n                     void* ctx = nullptr) noexcept;\n  void Unbind(TaskId id) noexcept;\n  uint32_t Poll() noexcept;\n  TickType TicksToNextTask() const noexcept;\n  // ...\n};\n```\n\n所有方法标记 `noexcept`，兼容 `-fno-exceptions -fno-rtti` 编译。Header-only，无链接依赖。\n\n### 2.2 数据结构: 定长数组上的侵入式排序链表\n\n```\nTaskSlot 内存布局 (32 字节 / 32-bit 平台):\n┌──────────────────────────────────────────────────────┐\n│ fn: TaskFn            (4/8 B)                        │\n│ ctx: void*            (4/8 B)                        │\n│ repeat_ticks: TickType (4/8 B)                       │\n│ next_schedule: TickType (4/8 B)                      │\n│ next_index: uint32_t  (4 B)   -- 侵入式链表指针       │\n│ generation: uint8_t   (1 B)   -- ABA 代计数器         │\n│ active: bool          (1 B)                          │\n│ [padding]             (2 B)                          │\n└──────────────────────────────────────────────────────┘\n```\n\n设计选择的理由:\n\n**为什么不用堆 (priority_queue)?**\n- `std::priority_queue` 底层是 `std::vector`，insert/extract 均 O(log n)\n- 隐含堆分配 -- 嵌入式环境不可接受\n- 指针追踪导致 cache-unfriendly\n\n**为什么不用简单数组扫描?**\n- O(n) poll 在实时系统中不可接受\n- 每次 poll 浪费 CPU 周期检查未就绪任务\n\n**排序侵入式链表的优势:**\n- 任务存储在定长数组中 -- cache-friendly，零分配\n- 侵入式 `next_index` 按 `next_schedule` 升序链接\n- head 始终指向最早到期任务 -- poll 仅检查 head，O(1)\n- insert O(n) 最坏情况，但任务绑定是低频操作\n\n总内存占用:\n\n| 容量 | 总大小 |\n|------|--------|\n| `TaskScheduler<8>` | 268 B |\n| `TaskScheduler<16>` | 524 B |\n| `TaskScheduler<32>` | 1036 B |\n\n## 3. 关键设计细节\n\n### 3.1 TaskId 编码与 ABA 防护\n\nTaskId 是一个 16-bit 值，高 8 位为 generation 计数器，低 8 位为 slot index:\n\n```\nTaskId (16-bit):\n┌────────────────┬────────────────┐\n│ generation (8) │ slot_index (8) │\n└────────────────┴────────────────┘\n```\n\n每次 slot 被释放时 generation 自增。Unbind 时同时校验 index 和 generation:\n\n```cpp\nvoid Unbind(TaskId id) noexcept {\n  uint32_t slot_idx = id & 0xFF;\n  uint8_t generation = static_cast<uint8_t>(id >> 8);\n\n  if (slot_idx >= MaxTasks) return;\n\n  TaskSlot& slot = slots_[slot_idx];\n  // generation 不匹配 -> 过期 ID，静默忽略\n  if (!slot.active || slot.generation != generation) return;\n\n  RemoveFromList(slot_idx);\n  slot.active = false;\n  slot.generation = static_cast<uint8_t>((slot.generation + 1) & 0xFF);\n  --active_count_;\n}\n```\n\n256 代循环提供充足的 ABA 窗口。对于典型嵌入式场景 (任务绑定/解绑频率远低于 256 次/slot 生命周期)，碰撞概率可忽略。\n\n### 3.2 Poll 算法: 执行前摘链\n\nPoll 的关键安全设计是执行前先将任务从链表摘除:\n\n```cpp\nuint32_t Poll() noexcept {\n  uint32_t executed = 0;\n\n  while (head_index_ != kNoTask) {\n    TaskSlot& head = slots_[head_index_];\n\n    // 排序链表: head 不就绪则无任务就绪\n    if (head.next_schedule > current_ticks_) break;\n\n    // 关键: 执行前摘链 (允许回调内调用 Unbind)\n    uint32_t exec_idx = head_index_;\n    head_index_ = head.next_index;\n\n    // 执行回调\n    slots_[exec_idx].fn(slots_[exec_idx].ctx);\n    ++executed;\n\n    // 执行后检查 active (回调可能已 Unbind 自身)\n    if (slots_[exec_idx].active) {\n      if (slots_[exec_idx].repeat_ticks > 0) {\n        // 周期任务: 重新调度\n        slots_[exec_idx].next_schedule =\n            current_ticks_ + slots_[exec_idx].repeat_ticks;\n        InsertSorted(exec_idx);\n      } else {\n        // 一次性任务: 自动释放\n        slots_[exec_idx].active = false;\n        slots_[exec_idx].generation++;\n        --active_count_;\n      }\n    }\n  }\n  return executed;\n}\n```\n\n这个设计确保了两个安全属性:\n1. **任务自解绑安全**: 回调函数可以调用 `Unbind(self_id)`，因为执行时任务已不在链表中\n2. **重入绑定安全**: 回调函数可以调用 `Bind()` 注册新任务，InsertSorted 操作不会影响当前执行流\n\n### 3.3 TicksToNextTask: 低功耗精确休眠\n\n```cpp\nTickType TicksToNextTask() const noexcept {\n  if (head_index_ == kNoTask)\n    return static_cast<TickType>(-1);  // 无任务\n\n  if (slots_[head_index_].next_schedule <= current_ticks_)\n    return 0;  // 任务已就绪\n\n  return slots_[head_index_].next_schedule - current_ticks_;\n}\n```\n\nO(1) 复杂度。典型的低功耗主循环:\n\n```cpp\nztask::TaskScheduler<16> sched;\n\nwhile (true) {\n  sched.Tick();\n  sched.Poll();\n\n  auto remaining = sched.TicksToNextTask();\n  if (remaining == 0) continue;  // 仍有就绪任务\n\n  if (remaining <= 5)\n    __WFI();                    // 短休眠: idle\n  else if (remaining <= 50)\n    HAL_PWR_EnterSLEEPMode();   // 中休眠: sleep (~20% 功耗)\n  else\n    HAL_PWR_EnterSTOPMode();    // 深休眠: stop (~5% 功耗)\n}\n```\n\n## 4. C vs C++14: 逐项对比\n\n### 4.1 编译期容量 vs 运行时内存池\n\n```c\n// C 版: 运行时初始化，容量错误延迟到运行期\nstatic uint8_t mem[10 * sizeof(zt_task_t)] __attribute__((aligned(4)));\nint32_t num = zt_init(mem, sizeof(mem));\nif (num < 0) { /* 处理错误 */ }\n```\n\n```cpp\n// C++ 版: 编译期固定，无初始化代码\nztask::TaskScheduler<10> sched;  // 栈分配，大小编译期确定\n// 容量为 0 时可通过 static_assert 在编译期捕获\n```\n\nC++ 版的优势不仅仅是语法简洁 -- 编译器可以:\n- 在编译期计算总内存大小，无运行时 `sizeof` 计算\n- 模板实例化时展开循环，对小 MaxTasks 值可完全展开\n- 构造函数中的初始化循环在 `-O2` 下被优化为 `memset`\n\n### 4.2 Context 传递: void* 参数 vs 全局变量\n\n```c\n// C 版: 无 context 参数，只能用全局变量\nstatic uint32_t g_led_count = 0;\nstatic void led_task(void) {\n  g_led_count++;\n  toggle_led();\n}\n```\n\n```cpp\n// C++ 版: context 指针直接传递\nstruct LedContext {\n  uint32_t count;\n  uint8_t pin;\n};\n\nstatic void led_task(void* ctx) {\n  auto* led = static_cast<LedContext*>(ctx);\n  led->count++;\n  toggle_pin(led->pin);\n}\n\nLedContext led1{0, GPIO_PIN_5};\nLedContext led2{0, GPIO_PIN_6};\nsched.Bind(led_task, 100, 0, &led1);  // 同一回调，不同实例\nsched.Bind(led_task, 100, 0, &led2);\n```\n\n### 4.3 TaskId 编码 vs 裸指针\n\n| 属性 | C 版 (裸指针) | C++ 版 (编码 ID) |\n|------|:---:|:---:|\n| ABA 防护 | 无 | 256 代循环 |\n| 过期 ID 检测 | 不可能 | generation 校验 |\n| ID 大小 | 4/8 B (指针) | 2 B (uint16_t) |\n| 传递开销 | 指针宽度 | 寄存器友好 |\n\n### 4.4 TickType 可配置\n\nC 版固定使用 `uint32_t`，在 1ms tick 下约 49 天溢出。C++ 版通过模板参数支持不同精度:\n\n```cpp\n// 默认: 32-bit, 49 天 @ 1ms\nTaskScheduler<16, uint32_t> sched32;\n\n// 长周期: 64-bit, 5.85 亿年 @ 1ms\nTaskScheduler<16, uint64_t> sched64;\n\n// 资源极度受限: 16-bit, 65 秒 @ 1ms\nTaskScheduler<8, uint16_t> sched16;\n```\n\n## 5. 性能基准\n\n基准测试环境: GCC 11.4, `-O3`, x86_64 Linux, 1M iterations/operation。\n\n| 操作 | C 版 (ns/op) | C++ 版 (ns/op) | 差异 |\n|------|---:|---:|---:|\n| Bind | 45 | 42 | -6.7% |\n| Poll (hit) | 40 | 38 | -5.0% |\n| Poll (idle) | 2 | 2 | 0% |\n| TicksToNextTask | 2 | 2 | 0% |\n| Bind+Unbind | 82 | 77 | -6.1% |\n\nC++ 版在热路径 (Bind/Poll) 上稳定快 5-7%，原因是模板实例化使编译器能对 `MaxTasks` 相关的循环和分支进行更激进的内联和展开。idle poll 和 TicksToNextTask 均为 2ns，体现了 O(1) 头部检查的极低开销。\n\n内存占用完全一致:\n\n| 指标 | C 版 | C++ 版 |\n|------|---:|---:|\n| 单任务 slot | 32 B | 32 B |\n| 调度器 (16 tasks) | 524 B | 524 B |\n\n## 6. 时间复杂度\n\n| 操作 | 最好 | 平均 | 最坏 |\n|------|:---:|:---:|:---:|\n| Tick() | O(1) | O(1) | O(1) |\n| Poll() | O(1) | O(k) | O(n) |\n| Bind() | O(1) | O(n/2) | O(n) |\n| Unbind() | O(1) | O(n/2) | O(n) |\n| TicksToNextTask() | O(1) | O(1) | O(1) |\n\n*k = 就绪任务数, n = 活跃任务总数*\n\n关键路径是 Poll -- 在无任务就绪时仅需一次比较即退出，这是低功耗系统最频繁的状态。\n\n## 7. 线程安全\n\nztask-cpp **设计上不是线程安全的**。这是刻意的选择:\n\n- 目标平台通常是单线程裸机 MCU\n- 锁同步开销对实时系统不可接受\n- 用户在需要时可自行添加外部同步\n\n安全使用模式:\n\n| 场景 | 说明 |\n|------|------|\n| 单线程主循环 | 所有调用在 main loop (最常见) |\n| ISR + 主循环 | `Tick()` 在 ISR，`Poll()` 在主循环 (ISR 不调用其他方法即安全) |\n| RTOS 多任务 | 用 mutex 包装调度器 |\n\n## 8. 边界情况处理\n\n### 8.1 Tick 溢出\n\n`uint32_t` 在 1ms tick 下约 49 天溢出。unsigned 算术天然处理回绕:\n\n```cpp\n// 无符号减法在回绕时仍正确\nif (head.next_schedule <= current_ticks_) { ... }\n```\n\n限制: 调度超过 `2^31` ticks 的未来任务可能行为异常。\n\n### 8.2 Slot 耗尽\n\n`Bind()` 在无可用 slot 时返回 `kInvalidId`。调用者应检查返回值:\n\n```cpp\nauto id = sched.Bind(my_task, 100, 0);\nif (id == ztask::TaskScheduler<16>::kInvalidId) {\n  // 处理容量不足\n}\n```\n\n建议: `MaxTasks` 取预期峰值的 2x 余量。\n\n### 8.3 Generation 回绕\n\ngeneration 为 8-bit (0-255)，256 次复用后回绕。若同一 slot 在 256 代内未被误引用，则安全。对典型嵌入式场景 (任务绑定频率远低于 256 次/slot) 完全足够。\n\n## 9. 典型集成示例\n\n### 9.1 主循环\n\n```cpp\n#include <ztask/ztask.hpp>\n\nstatic ztask::TaskScheduler<16> sched;\n\n// 硬件定时器 ISR (1ms)\nextern \"C\" void TIM2_IRQHandler(void) {\n  sched.Tick();\n  TIM2->SR &= ~TIM_SR_UIF;\n}\n\nstruct SensorCtx {\n  uint32_t readings;\n  uint8_t  adc_channel;\n};\n\nstatic void read_sensor(void* ctx) {\n  auto* s = static_cast<SensorCtx*>(ctx);\n  s->readings++;\n  uint16_t val = HAL_ADC_Read(s->adc_channel);\n  process_reading(val);\n}\n\nstatic void heartbeat_led(void* /*ctx*/) {\n  HAL_GPIO_TogglePin(GPIOA, GPIO_PIN_5);\n}\n\nint main(void) {\n  HAL_Init();\n  SystemClock_Config();\n  setup_timer_1ms();\n\n  SensorCtx sensor{0, ADC_CHANNEL_0};\n\n  sched.Bind(read_sensor, 50, 10, &sensor);   // 50ms 周期, 10ms 延迟\n  sched.Bind(heartbeat_led, 500, 0);           // 500ms 心跳\n\n  while (true) {\n    sched.Poll();\n\n    auto remaining = sched.TicksToNextTask();\n    if (remaining > 0 && remaining != UINT32_MAX) {\n      __WFI();  // 等待中断唤醒\n    }\n  }\n}\n```\n\n\n---\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/xxxxxxxx)\n",
      "ctime": "1771552696",
      "mtime": "1771552696",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  },
  "practice/ztask_scheduler.md": {
    "err_no": 0,
    "data": {
      "id": "7607598321469751342",
      "article_id": "0",
      "user_id": "3087084382599640",
      "category_id": "6809637769959178254",
      "tag_ids": [
        6809640560995860488
      ],
      "link_url": "",
      "cover_image": "",
      "is_gfw": 0,
      "title": "ztask: 零动态分配的裸机合作式任务调度器设计分析",
      "brief_content": "分析 ztask 裸机合作式调度器的设计: 静态内存池管理、基于 Tick 的排序链表调度（O(1) poll）、低功耗休眠计算。附完整 C 源码（~200 行）和典型应用示例。适用于无 RTOS 的",
      "is_english": 0,
      "is_original": 1,
      "edit_type": 10,
      "html_content": "deprecated",
      "mark_content": "> 参考: [tomzbj/ztask](https://github.com/tomzbj/ztask)\n\n## 1. 简介\n\n`ztask` 是一个为资源受限的嵌入式系统设计的、轻量级的合作式任务调度器。它的核心设计理念是简洁、高效、确定性和低功耗。它不依赖于任何操作系统，也不使用动态内存分配（如`malloc`），使其非常适合用于裸机应用中。\n\n## 2. 核心设计理念\n\n### 2.1 合作式调度 (Cooperative Scheduling)\n\n调度器本身不会强制中断正在执行的任务。每个任务函数一旦开始执行，就会一直运行直到它自己返回。这种非抢占式的模型避免了多线程应用中常见的复杂性，如竞态条件、死锁和资源同步问题。\n\n### 2.2 基于Tick的时基 (Tick-based Timing)\n\n系统的所有时间度量都基于一个单调递增的\"Tick\"计数器。这个计数器通常由一个硬件定时器以固定的时间间隔（如1毫秒）来驱动。\n\n### 2.3 静态内存管理 (Static Memory Management)\n\n调度器所需的所有内存都从一个在初始化时由用户提供的静态内存池中分配。杜绝了因内存碎片或分配失败而导致系统崩溃的风险。\n\n## 3. 架构与实现方案\n\n### 3.1 核心数据结构\n\n- 任务控制块 (`zt_task_t`): `func` 任务函数指针, `repeat_ticks` 重复周期, `next_schedule` 下次执行时间戳, `next` 链表指针\n- 活动任务链表 (`active_tasks`): 按 `next_schedule` 升序排列的单向链表\n- 空闲任务链表 (`free_tasks`): 管理所有当前未被使用的任务块\n\n### 3.2 内存管理机制\n\n`zt_init` 将用户传入的静态内存分割成多个 `zt_task_t` 单元，串联成 `free_tasks` 链表。`zt_bind` 从空闲链表头部取节点，任务完成或 `zt_unbind` 时归还。\n\n### 3.3 核心调度算法\n\n1. `zt_bind`: 从空闲链表获取节点，计算 `next_schedule`，插入活动链表正确位置\n2. `zt_poll`: 仅检查活动链表头部任务。时间到则取出执行，周期性任务重新插入，一次性任务归还空闲链表。时间复杂度 O(1)\n\n## 4. 关键API函数\n\n- `zt_init()`: 初始化调度器，构建内存池\n- `zt_tick()`: 由硬件定时器中断调用，驱动内部时钟\n- `zt_bind()`: 注册并调度一个新任务\n- `zt_unbind()`: 从调度器中移除一个已注册的任务\n- `zt_poll()`: 在主循环中调用，检查并执行到期的任务\n- `zt_ticks_to_next_task()`: 低功耗核心API，返回距离下一个任务执行还需等待的tick数\n\n## 5. 完整代码\n\n### ztask.h\n\n```c\n#ifndef ZTASK_H\n#define ZTASK_H\n\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n\n#include <stdint.h>\n#include <stdbool.h>\n#include <stddef.h>\n\nstruct zt_task_s;\ntypedef struct zt_task_s* zt_task_handle_t;\ntypedef void (*zt_func_t)(void);\n\nint32_t zt_init(void *zt_mem, uint32_t size);\nzt_task_handle_t zt_bind(zt_func_t func, uint32_t repeat_ticks, uint32_t delay_ticks);\nvoid zt_unbind(zt_task_handle_t task);\nvoid zt_poll(void);\nvoid zt_tick(void);\nuint32_t zt_ticks_to_next_task(void);\nuint32_t zt_get_ticks(void);\n\n#ifdef __cplusplus\n}\n#endif\n\n#endif /* ZTASK_H */\n```\n\n### ztask.c\n\n```c\n#include \"ztask.h\"\n\ntypedef struct zt_task_s {\n    zt_func_t func;\n    uint32_t repeat_ticks;\n    uint32_t next_schedule;\n    struct zt_task_s *next;\n} zt_task_t;\n\nstatic struct {\n    volatile uint32_t ticks;\n    zt_task_t *active_tasks;\n    zt_task_t *free_tasks;\n} g_ztask_ctx;\n\nstatic void zt_insert_task(zt_task_t * const task)\n{\n    if ((g_ztask_ctx.active_tasks == NULL) ||\n        (task->next_schedule < g_ztask_ctx.active_tasks->next_schedule)) {\n        task->next = g_ztask_ctx.active_tasks;\n        g_ztask_ctx.active_tasks = task;\n    } else {\n        zt_task_t *current = g_ztask_ctx.active_tasks;\n        while ((current->next != NULL) &&\n               (current->next->next_schedule < task->next_schedule)) {\n            current = current->next;\n        }\n        task->next = current->next;\n        current->next = task;\n    }\n}\n\nint32_t zt_init(void * const zt_mem, const uint32_t size)\n{\n    if ((zt_mem == NULL) || (size < sizeof(zt_task_t))) { return -1; }\n\n    uint8_t* mem_ptr = (uint8_t*)zt_mem;\n    const uint32_t num_tasks = size / sizeof(zt_task_t);\n\n    g_ztask_ctx.ticks = 0U;\n    g_ztask_ctx.active_tasks = NULL;\n    g_ztask_ctx.free_tasks = (zt_task_t*)mem_ptr;\n\n    zt_task_t *current = g_ztask_ctx.free_tasks;\n    for (uint32_t i = 0U; i < (num_tasks - 1U); ++i) {\n        mem_ptr += sizeof(zt_task_t);\n        current->next = (zt_task_t*)mem_ptr;\n        current = current->next;\n    }\n    current->next = NULL;\n    return (int32_t)num_tasks;\n}\n\n// 注意: volatile 仅防止编译器优化，ticks++ 在多数 ARM 单核 MCU 上是安全的\n// （单条 STR 指令），但在多核平台上应使用 atomic_uint32_t。\nvoid zt_tick(void) { g_ztask_ctx.ticks++; }\nuint32_t zt_get_ticks(void) { return g_ztask_ctx.ticks; }\n\nzt_task_handle_t zt_bind(zt_func_t const func, const uint32_t repeat_ticks,\n                         const uint32_t delay_ticks)\n{\n    if (func == NULL) { return NULL; }\n    zt_task_t *new_task = g_ztask_ctx.free_tasks;\n    if (new_task != NULL) {\n        g_ztask_ctx.free_tasks = new_task->next;\n        new_task->func = func;\n        new_task->repeat_ticks = repeat_ticks;\n        new_task->next_schedule = g_ztask_ctx.ticks + delay_ticks;\n        zt_insert_task(new_task);\n    }\n    return new_task;\n}\n\nvoid zt_unbind(zt_task_handle_t const task)\n{\n    if (task == NULL) { return; }\n    zt_task_t* const to_remove = (zt_task_t*)task;\n\n    if (g_ztask_ctx.active_tasks == to_remove) {\n        g_ztask_ctx.active_tasks = to_remove->next;\n    } else {\n        zt_task_t *current = g_ztask_ctx.active_tasks;\n        while ((current != NULL) && (current->next != to_remove)) {\n            current = current->next;\n        }\n        if (current != NULL) { current->next = to_remove->next; }\n    }\n    to_remove->next = g_ztask_ctx.free_tasks;\n    g_ztask_ctx.free_tasks = to_remove;\n}\n\nvoid zt_poll(void)\n{\n    for (;;) {\n        zt_task_t *task_to_run = NULL;\n        if (g_ztask_ctx.active_tasks != NULL) {\n            if ((g_ztask_ctx.ticks - g_ztask_ctx.active_tasks->next_schedule)\n                < (UINT32_MAX / 2U)) {\n                task_to_run = g_ztask_ctx.active_tasks;\n                g_ztask_ctx.active_tasks = task_to_run->next;\n            }\n        }\n        if (task_to_run != NULL) {\n            task_to_run->func();\n            if (task_to_run->repeat_ticks > 0U) {\n                task_to_run->next_schedule += task_to_run->repeat_ticks;\n                zt_insert_task(task_to_run);\n            } else {\n                task_to_run->next = g_ztask_ctx.free_tasks;\n                g_ztask_ctx.free_tasks = task_to_run;\n            }\n        } else {\n            break;\n        }\n    }\n}\n\nuint32_t zt_ticks_to_next_task(void)\n{\n    if (g_ztask_ctx.active_tasks != NULL) {\n        const uint32_t now = g_ztask_ctx.ticks;\n        const uint32_t diff = g_ztask_ctx.active_tasks->next_schedule - now;\n        if (diff < (UINT32_MAX / 2U)) {\n            return diff;  // task is in the future\n        }\n        return 0U;  // task is overdue\n    }\n    return UINT32_MAX;\n}\n```\n\n## 6. 典型应用\n\n```c\n#define MAX_TASKS 10\nstatic uint8_t zt_mem[MAX_TASKS * sizeof(struct zt_task_s)] __attribute__((aligned(4)));\n\nint main(void) {\n    zt_init(zt_mem, sizeof(zt_mem));\n    setup_timer_for_ztick(); // 配置1ms定时器中断调用 zt_tick()\n\n    zt_bind(task_a, 100, 50);\n    zt_bind(task_b, 1000, 1000);\n\n    while(1) {\n        zt_poll();\n        uint32_t sleep_ticks = zt_ticks_to_next_task();\n        if (sleep_ticks > 0) {\n            enter_sleep_mode(sleep_ticks);\n        }\n    }\n}\n```\n\n核心优势: O(1) 任务检查、精确休眠计算、无动态内存分配、代码简洁易移植。\n\n> 原文链接: [CSDN](https://blog.csdn.net/stallion5632/article/details/153326149)\n\n---\n",
      "ctime": "1771552699",
      "mtime": "1771552699",
      "status": 0,
      "original_type": 0,
      "theme_ids": []
    },
    "err_msg": "success"
  }
}